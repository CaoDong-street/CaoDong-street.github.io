<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PS control 论文（1）</title>
      <link href="/2022/01/06/ps-control-lun-wen-1/"/>
      <url>/2022/01/06/ps-control-lun-wen-1/</url>
      
        <content type="html"><![CDATA[<p>对应文章地址：<a href="https://www.sciencedirect.com/science/article/pii/S0967066120302914">MUDE-based control of quadrotor for accurate attitude tracking - ScienceDirect</a></p><p>这篇文章是阿木实验室创始人<strong>戚煜华</strong>的最新文章，文章的实验非常充分，具有可重复性。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>针对一种基于高精度执行器动力学模型的四旋翼无人机，本文提出了一种基于改进的不确定性和干扰估计器(modified uncertainty and disturbance estimator, MUDE)的姿态控制器，。执行器动力学近似于一阶加时滞动态模型，而执行器的静态和动态模型都是使用电机测试平台建立出来的。执行器模型被进一步用作虚拟传感器，以提供执行器为控制器生成的扭矩估算值。通过这些估算，可以构建出一个MUDE，其不仅可以补偿姿态动力学中的不确定性和干扰，还可以补偿时间延迟和执行器动力学中的干扰。对执行器扰动抑制的系统性考虑明显改善了机动过程中的整体姿态跟踪性能，这种方法明显优于其他假设在执行器理想状态下的现有解决方案。此外，基于本文所提出的闭环系统的稳定性和性能分析表明可以通过调整单个参数来减少估计误差和闭环跟踪误差。最后，通过对比本文提出的控制方法、经典不确定和干扰估计器以及串级PID控制器应用于实际四旋翼无人机平台后的效果，表明了本文提出的控制方法在信号追踪以及干扰抑制的有效性和优势。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>据我们所知，本文首次提出了在控制设计中利用高精度执行器动态模型来同时提高姿态跟踪和抗干扰性能的思想。本工作的主要目的是开发一种简单有效的四旋翼姿态控制控制解决方案，它不仅能够在快速的机动过程中提供高精度的跟踪性能，而且能够补偿姿态运动和执行器动力学方面的模型的严重的不确定性和外部扰动。为此，首先建立了四旋翼姿态和执行器动力学模型，并利用电机测试平台对执行器静态和动态模型的参数进行了识别。实验证明了执行器的时延是不可忽略的，因此这是一个一阶加时滞模型，而不是一个简单的一阶模型，采用了执行器动力学描述，并进一步用于控制设计和扰动估计。同时，静态模型作为推力和油门信号之间的数学映射，构成了四旋翼飞行控制器的推力混合模块。提出了一种改进的不确定性和扰动估计器(MUDE)，用于估计和补偿姿态和执行器动力学上的集总扰动，以及执行器的时滞。在一个真实的四旋翼平台上实现了本文控制方法的验证。实验结果表明，与大多数商用无人机中使用的级联PID控制器以及传统基于UDE的控制器相比，本文中的控制方法为步长输入提供了更小的超冲量，为时变输入提供了更好的跟踪精度，以及在干扰下更快的性能恢复能力。本文的主要贡献总结如下：</p><p>（1）  利用高精度执行器动力学模型提高反馈控制性能，且明显优于现有的假设理想的执行器或者使用简化的或静态的执行器模型的大部分控制方式。进一步将执行器模型作为虚拟传感器，为反馈控制器提供执行器产生的扭矩估计，有助于扩大系统稳定裕度，提高姿态跟踪的收敛速度，从而提高机动过程中的姿态跟踪精度。</p><p>（2）  在设计MUDE中系统考虑扰动执行器动力学，以提高整体扰动抑制能力，具体地说，虚拟传感器还使用在MUDE来获得更好的干扰估计，而现有的方法避免在抗干扰机制中使用不可估量的执行器状态。</p><p>（3）  提出了一种在两个不同坐标下分别设计状态反馈控制器和MUDE的新思想，以解决由于考虑执行器动力学而引起的不匹配扰动问题。引入了一种非奇异坐标变换，建立了一个具有等效匹配干扰的辅助系统，并在新的坐标下设计了反馈控制器。</p><h2 id="2-四旋翼系统建模"><a href="#2-四旋翼系统建模" class="headerlink" title="2 四旋翼系统建模"></a>2 四旋翼系统建模</h2><p>在本节中，首先，利用反馈线性化技术建立了姿态动态模型，并利用反馈线性化技术建模进行了线性化。其次，介绍了执行器模型，并给出了辨识建模结果。</p><h3 id="2-1-姿态动力模型"><a href="#2-1-姿态动力模型" class="headerlink" title="2.1 姿态动力模型"></a>2.1 姿态动力模型</h3><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gy3zfx6gsjj30mb0h549z.jpg" alt="图1在坐标系中的四旋翼系统"></p><p>如图1所示，本工作采用X机身结构的四旋翼平台，它由安装在机臂末端的四个电机控制。欧拉角Θ=[𝜙，𝜃，𝜓]用来表示四旋翼的方向，其中𝜙是滚转角，𝜃是俯仰角，𝜓分别是偏航角。通过应用所谓的小角近似，惯性系中四旋翼的姿态动力学可描述为</p>$$\begin{aligned}\dot{\phi} &amp;=\frac{1}{J_{x x}}\left[\left(J_{y y}-J_{z z}\right) \dot{\theta}_{\bar{\psi}}+J_{r} \bar{\Omega} \dot{\theta}+d_{\mathrm{rx}}+\tau_{x}\right] \\\theta &amp;=\frac{1}{J_{y y}}\left[\left(J_{z z}-J_{x x}\right) \phi \dot{\psi}-J_{r} \bar{\Omega} \phi+d_{r y}+\tau_{y}\right] \\\ddot{\varphi} &amp;=\frac{1}{J_{z z}}\left[\left(J_{x x}-J_{y y}\right) \phi \dot{\theta}+d_{r z}+\tau_{z}\right]\end{aligned} \tag{1}$$<p>其中𝑱=diag（[𝐽𝑥𝑥，𝐽𝑦𝑦，𝐽𝑧𝑧]）是四旋翼的转动惯量，𝐽𝑟表示螺旋桨和转子在𝑧轴中的惯性。 定义𝛺=𝜛1+ 𝜛2− 𝜛3− 𝜛4，其中𝜛𝑖是电机的转速。 𝒅𝜏=[𝑑𝜏𝑥 𝑑𝜏𝑦 𝑑𝜏𝑧]𝑇是扰动转矩，如果四旋翼在实践中不是严格对称的，即惯性积𝐽𝑥𝑦、𝐽𝑦𝑧和𝐽𝑧𝑥不是零，耦合动力学也被集中在这个术语中。 𝝉=[𝜏𝑥 𝜏𝑦 𝜏𝑧]𝑇是四个电机产生的转矩，可以计算为</p><p>其中 $J=\operatorname{diag}\left(\left[J_{x x}, J_{y y}, J_{z z}\right]\right)$是四旋翼的转动惯量， $J_{r}$ 表示螺旋桨和转子在𝑧轴中的惯性。定义𝛺=𝜛1+ 𝜛2− 𝜛3− 𝜛4，其中𝜛𝑖是电机的转速。$d_{t}=\left[\begin{array}{lll}d_{z x} &amp; d_{x y} &amp; d_{z z}\end{array}\right]^{T}$ 是扰动转矩， 如果四旋翼在实践中不是严格对称的，即惯性积 $J_{x y}, J_{y z}$ 和 $J_{z x}$ 不为零， 耦合动力学也集中在这一项中。 $\tau=\left[\begin{array}{lll}\tau_{x} &amp; \tau_{y} &amp; \tau_{z}\end{array}\right]^{T}$ 是四个电机产生的转矩，可以计算为</p>$$\begin{aligned}&amp;\tau_{x}=\frac{\sqrt{2}}{2} l\left(-T_{1}+T_{2}+T_{3}-T_{4}\right), \\&amp;\tau_{y}=\frac{\sqrt{2}}{2} l\left(T_{1}-T_{2}+T_{3}-T_{4}\right), \\&amp;\tau_{z}=\frac{c_{\mathscr{M}}}{c_{T}}\left(T_{1}+T_{2}-T_{3}-T_{4}\right) .\end{aligned} \tag{2}$$<p>其中𝑙是四旋翼的臂长度，𝑐𝑀和𝑐𝑇是下一节将确定的执行器子参数，而𝑇𝑖是来自第<em>i</em>个执行器的执行器产生的推力。</p><p>为了解耦和简化动力学（1），采用反馈线性化技术。 将虚拟输入定义为</p>$$u_{x}=\frac{\tau_{x}}{J_{x x}}, \quad u_{y}=\frac{\tau_{y}}{J_{y y}}, \quad u_{z}=\frac{\tau_{z}}{J_{z z}}, \tag{3}$$<p>并将集总干扰定义为</p>$$\begin{aligned}&amp;f_{\phi}=\frac{1}{J_{x x}}\left[\left(J_{y y}-J_{z z}\right) \dot{\theta} \dot{\psi}+d_{e x}+J_{y} \bar{\Omega} \dot{\theta}\right] \\&amp;f_{\theta}=\frac{1}{J_{y y}}\left[\left(J_{z z}-J_{x x}\right) \phi \dot{\psi} \dot{\psi}+d_{x y}-J_{y} \bar{\Omega} \phi\right] \\&amp;f_{\psi}=\frac{1}{J_{z z}}\left[\left(J_{x x}-J_{y y}\right) \dot{\phi} \dot{\phi}+d_{z z}\right] .\end{aligned}\tag{4}$$<p>则动力学（1）可以改写成如下简化的形式</p>$$\dot{\theta}=u+f \text {. } \tag{5}$$<p>其中$u=\left[\begin{array}{lll}u_{x} &amp; u_{y} &amp; u_{z}\end{array}\right]^{T}, f=\left[\begin{array}{lll}f_{\phi} &amp; f_{\theta} &amp; f_{\psi}\end{array}\right]^{T} .$</p><p>备注1. 为了减少模型不确定性对控制性能的影响，在四旋翼动力学中耦合项$\left(J_{y y}-J_{z z}\right) \dot{\theta} \psi,\left(J_{z z}-J_{x x}\right) \phi \dot{\psi}$, 和$\left(J_{x x}-J_{y y}\right) \dot{\theta} \dot{\phi}$ 被包含在（4）中的集总干扰项中，并将通过所提出的基于MUDE的控制对它们进行动态估计和补偿。如果这些耦合项可以精确已知或近似在合理的范围内，他们可以合并入虚拟输入（3)并被基于反馈线性化技术产生的相应的补偿项所抵消，而剩余建模误差将包含在集总干扰(4)中。</p><p>如图2所示，一个四旋翼的每个执行器由一个ESC、一个电机以及一个螺旋桨组成。电机由基于每个电机的输入油门$𝜎_𝑖$和电池电压$𝑈_𝑏$ 输入的ESC所驱动，而ESC将油门信号转换为多个失相电压输出。使用以下方程式描述的旋转电机驱动螺旋桨产生的力$𝑇_𝑖$和无功力矩$𝜏_𝑖$：</p>$$𝑇_𝑖=c_T𝜛^2_i，𝜏_𝑖=c_M𝜛^2_i \tag{6}$$<p>其中$𝑐_𝑇$和$𝑐_M$分别是推力常数和转矩常数。</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy3zpukcouj30y809bacc.jpg" alt="图2执行器模型"></p><p>为了确定执行器模型的内部参数，采用来自RCbenchmark的第1580系列推力支架，其应用方式如图3所示。可以同时测量和记录油门指令、推力、扭矩、电压以及电机转速。</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy3zqxc3rtj30x70oxk9a.jpg" alt="图3 1580系列推力架"></p><h4 id="2-2-1-静态模型辨识"><a href="#2-2-1-静态模型辨识" class="headerlink" title="2.2.1 静态模型辨识"></a>2.2.1 静态模型辨识</h4><p>在相同的实验条件下（正常的大气温度和工作范围内的电池电压），给出了[0,1]范围内的不同油门指令，并记录了电机达到稳态时的结果。将实验数据导入矩阵曲线拟合工具箱，得到静态模型识别结果，如图4所示。</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy40bd43ryj30m90eg0wb.jpg" alt="执行器静态模型的识别结果"></p><p>观察到推力/扭矩与转速之间的关系满足二次方程（6）。 然后从拟合曲线可以得到电机参数：$𝑐_𝑇=8.308×10^{−8}N∕RPM^2，𝑐_𝑀=1.456×10^{−9}N m/RPM^2$。</p><p>要将推力指令$𝑇_𝑖$（从控制器获得的控制输入）映射到油门信号$𝜎_𝑖$（自动驾驶仪中的低级别信号），应采用以下四阶多项式近似：</p>$$𝜎_𝑖=p_1T_i^4+p_2T_i^3+p_3T_i^2+p_4T_i+p_5 \tag{7}$$<p>其中$p_1 = −0.00069, p_2 = 0<em>.</em>01271, p_3 = −0<em>.</em>07948, p_4 = 0.30521, p_5 = 0.00878$。</p><h4 id="2-2-2-动态模型辨识"><a href="#2-2-2-动态模型辨识" class="headerlink" title="2.2.2 动态模型辨识"></a>2.2.2 动态模型辨识</h4><p>静态模型只给出了一个基于静态信号的电机动力学的一个简单的近似值。然而，在电机的动态响应中，需要系统地考虑时间延迟和响应时间。本文将该模型简化为以下一阶加时延形式，而不是为各个执行机构建立一个全面的模型（考虑电气，机械和空气性能）。</p>$$T=\frac{e^{-\tau_{0} s}}{\alpha s+1} T_{s s} \tag{8}$$<p>其中， $\tau_{0}$是时间延迟， $\alpha$ 是时间常数， $T_{s s}$是力的稳态。</p><p>在相同的实验条件下，向系统输入阶跃信号，记录每次试验的实验数据。从5图中所示的曲线拟合结果表明，执行器响应的时滞是显著的，响应过程接近FOPDT模型。</p><p>为了提高识别结果的准确性，本实验在不同的初始以及最终输入油门信号的环境下重复了8次，覆盖了电机的大部分工作范围。</p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1gy41ns1rahj30zu075tb6.jpg" alt="表1 辨识结果"></p><p>从表一中实验结果可以看出，执行器的时滞总是存在的。由于在大多数无人机中，姿态控制的控制频率只有250Hz（每个控制周期0.004s），因此在实际操作中不能忽视执行器的时间延迟。平均实验的测试结果得到：</p> $$\alpha=0.035, \quad \tau_{0}=0.04 \mathrm{~s} .\tag{9}$$<p>将（8)代入(2），给出执行器在时域上的动态模型为</p>$$\dot{\boldsymbol{\tau}}(t)=-\frac{1}{\alpha} \boldsymbol{\tau}(t)+\frac{1}{\alpha} \boldsymbol{u}_{\tau}\left(t-\tau_{0}\right)+\boldsymbol{d}_{\tau},\tag{10}$$<p>其中 $u_{\tau}=\left[\begin{array}{lll}u_{\phi} &amp; u_{\theta} &amp; u_{\psi}\end{array}\right]^{T}$ 是扭矩命令， 而 $d_{\tau}$表示在执行器上的集中干扰，如电池电压降和接地效应。</p><p>在实际应用中，公式化执行器模型，即公式（10），令 $d_{\tau}=0$，则将其作为虚拟传感器来估计电机产生的转矩。在转矩估计良好的情况下，可以通过系统地考虑非理想执行器来设计内环控制器，以实现姿态的高精度控制。</p><p>备注2.建模结果见表1和公式（9），且只适用于第5节中所述特定执行机构系统(包括电机、ESC和电池)。如果执行器的任何部件被更改，则需要重新进行模型建立。建模实验在相同的实验条件下进行：常温（25.0◦C）和工作范围蓄电池电压（11.1∼12.6V）。在实验条件合理的变化范围内，鉴定结果是有意义的。为了验证建模结果，将从实际飞行中记录的相同扭矩命令 $u_{\tau}$ 应用于推力支架和建立的标准执行器模型，然后比较了该模型对试验台的推力测量结果和推力估计结果。请注意，推力估计是由𝑇=𝜏/𝐿计算的，其中𝜏是估计的扭矩，而𝐿=0.165m是四旋翼的臂长。比较结果如图6所示，基于此可以看出估计误差约为±0.1N。本文的执行器模型具有较高的精度，即验证结果只表现出估计误差，其幅度为实际执行器产生的推力的4%。</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gy41s59f6kj30hx0e4n14.jpg" alt="图6 对所识别的执行器模型进行了验证"></p><h2 id="3-MUDE控制器设计"><a href="#3-MUDE控制器设计" class="headerlink" title="3 MUDE控制器设计"></a>3 MUDE控制器设计</h2><p>结合(1)和(10)公式，可以得到全内环动力学(包括姿态和执行器动力学）的线性时变(LTI)模型如下式所示.</p>$$\left[\begin{array}{c}\dot{\Theta} \\\ddot{\Theta} \\\dot{\tau}\end{array}\right]=\left[\begin{array}{ccc}0 &amp; \boldsymbol{I}_{3} &amp; 0 \\0 &amp; 0 &amp; \boldsymbol{J}^{-1} \\\mathbf{0} &amp; 0 &amp; -\frac{1}{\alpha} \boldsymbol{I}_{3}\end{array}\right]\left[\begin{array}{c}\Theta \\\dot{\Theta} \\\tau\end{array}\right]+\left[\begin{array}{c}0 \\0 \\\frac{1}{\alpha} \boldsymbol{I}_{3}\end{array}\right] u_{\tau}+\left[\begin{array}{c}0 \\\boldsymbol{J}^{-1} \boldsymbol{f}_{1} \\\boldsymbol{f}_{2}\end{array}\right] \tag{11}$$<p>其中 $\boldsymbol{I}_{3}$ 为 $3 \times 3$ 单位矩阵, $\boldsymbol{f}_{1}=\boldsymbol{f}$是总扰动扭矩,而 $f_{2}=\frac{1}{\alpha}\left[u_{\tau}\left(t-\tau_{0}\right)-u_{\tau}(t)\right]+d_{\tau}$ 是执行器上的集中扰动。对集中扰动采用以下假设。</p><p><strong>假设1</strong>. 扰动$f_{1}, f_{2}$和导数$\dot{f}_{1}$对于所有$t \geq 0$的情况都是有界的。</p><p>下面，将分别设计每个通道的控制器。请注意，这三个通道的动力学形式与（11）给出的形式相同。因此，在不丧失通用性的情况下，设计了俯仰角通道的控制器，然后可以应用具有不同控制增益（根据模型参数𝑱）的相同控制器结构。得到俯仰角运动的动力学模型如下：</p>$$\left[\begin{array}{c}\dot{\theta} \\\ddot{\theta} \\\dot{\tau}_{y}\end{array}\right]=\left[\begin{array}{ccc}0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; \frac{1}{J_{y y}} \\0 &amp; 0 &amp; -\frac{1}{\alpha}\end{array}\right]\left[\begin{array}{c}\theta \\\dot{\theta} \\\tau_{y}\end{array}\right]+\left[\begin{array}{c}0 \\0 \\\frac{1}{\alpha}\end{array}\right] u_{\theta}+\left[\begin{array}{c}0 \\\frac{f_{1}}{J_{y y}} \\f_{2}\end{array}\right] \tag{12}$$<p>其中，$f_{1}$和$f_{2}$分别表示俯仰执行器中的集中扰动转矩和执行器上的集中扰动。请注意，扰动转矩$f_{1}$与转矩命令$𝑢_𝜃$不出现在同一通道中，这被称为不匹配扰动。抑制不匹配扰动的关键难点不在于扰动估计，而在于难以针对$𝑢_𝜃$设计适当的补偿信号来抵消不同通道的影响。为了解决这个问题，引入了一个坐标变换来开发一个具有匹配干扰并等价于（12）的辅助系统。定义一个辅助变量</p>$$\eta=\tau_{y}+f_{1},\tag{13}$$<p>它表示四旋翼上的总扭矩，然后求导得到</p>$$\begin{aligned}\dot{\eta} &amp;=-\frac{1}{\alpha} \tau_{y}+\frac{1}{\alpha} u_{\theta}+f_{2}+\dot{f}_{1} \\&amp;=-\frac{1}{\alpha} \eta+\frac{1}{\alpha} u_{\theta}+f_{2}+\frac{1}{\alpha} f_{1}+\dot{f}_{1} .\end{aligned} \tag{14}$$<p>动力学公式（12）可以转化为<br>$$\left[\begin{array}{c}\dot{\theta} \\ \ddot{\theta} \\ \dot{\eta}\end{array}\right]=\left[\begin{array}{ccc}0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; \frac{1}{J_{y y}} \\ 0 &amp; 0 &amp; -\frac{1}{\alpha}\end{array}\right]\left[\begin{array}{c}\theta \\ \dot{\theta} \\ \eta\end{array}\right]+\left[\begin{array}{l}0 \\ 0 \\ \frac1{\alpha}\end{array}\right]\left(u_{\theta}+\bar{f}\right) \tag{15}$$,<br>其中$\bar{f}=\alpha f_{2}+f_{1}+\alpha \dot{f_{1}}$ 是等效匹配扰动，该辅助系统称为变换姿态控制模型，可以更直观地设计了抗干扰机制。</p><p>为了以（15）的形式控制一类扰动二阶系统，可以在经典PD控制器中引入UDE来动态补偿集中扰动的影响。最初在中UDE的基本思想是，在频域中，集中的扰动通过具有适当带宽的滤波器来近似。使用相同的想法，当给出所需的状态 $\ddot{\theta}_{d}, \dot{\theta}_{d}$和$\theta_{d}$时，设计了以下形式的基于MUDE的控制器</p>$$u_{\theta}=\ddot{\theta}_{d}+k_{p} \tilde{\theta}+k_{d} \tilde{\dot\theta}+k_{\eta} \tilde{\eta}-\hat{f},\tag{16}$$<p>其中</p>$$\tilde{\theta}=\theta_{d}-\theta, \quad \tilde{\dot\theta}=\dot{\theta}_{d}-\dot{\theta} \quad \tilde{\eta}=\eta_{d}-\eta \text {, }\tag{17}$$<p>而 $\hat{\bar{f}}$ 是估计总扰动 $\bar{f}$的MUDE。 但是由于以下两个事实，控制器（16）不能直接使用。首先，状态反馈 $\eta$ 是不可用的，因为 $\eta$ 包含一个未知的干扰 $f_{1}$ 而且因此 $\eta$ 是不可测的。其次，由于$\eta$是不可用的，所以 $\hat{f}$不能从变换的姿态控制模型（15）中导出。 $\eta$.</p><p>为了解决这些问题，下面使用了姿态控制模型(12)。虽然 $\bar{f}$ 不能直接估计，但它的估计仍然可以通过分别通过估计三个独立的对象来组成。这些估计数分别用 $\hat{f}_{1}, \hat{\dot{f}}_{1}$ 以及 $\hat{f}<em>{2}$表示，并将在之后进行设计。对于 $\hat{f}</em>{1}$ ，</p>$$\tilde{\eta}=\tau_{d}-\eta=\tilde{\tau}-\hat{f}_{1},\tag{18}$$<p>然后将控制器(16)修改为</p>$$u_{\theta}=\underbrace{\ddot{\theta}_{d}+k_{p} \tilde{\theta}+k_{d} \tilde{\dot\theta}+k_{\eta} \tilde{\tau}}_{\text {nominal control }}-\underbrace{\left[\left(k_{\eta}+1\right) \hat{f}_{1}+\alpha \hat{f}_{1}+\alpha \hat{f}_{2}\right]}_{\text {MUDE }}], \tag{19}$$<p>其中 $\tilde{\tau}=\tau_{d}-\tau_{y}$ 可以通过使用不受干扰的模型（10）作为具有输入$u_{\theta}$的虚拟传感器来获得, 而 $\tau_{d}$ 是期望的扭矩 ，计算公式为</p>$$\tau_{d}=J_{y y} \ddot{\theta}_{d} \text {. }\tag{20}$$<p>下一步是通过分别为 $f_{1}, \dot{f}_{1}$ 和 $f_{2}$设计估计器在(19)中构造MUDE。 首先，类似于经典的UDE， $f_{1}$可以设计为</p>$$\hat{F}_{1}(s)=G_{f 1}(s) F_{1}(s)=G_{f 1}(s)\left[J_{y y} \ddot{\theta}(s)-\tau_{y}(s)\right], \tag{21}$$<p>而且选择</p>$$G_{f_{1}}(s)=\frac{1}{T^{f_{1} }s+1}, T^{f_{1}}&gt;0, \tag{22}$$<p>生成</p>$$\hat{F}_{1}(s)=\frac{s}{T^{f_{1} }s+1} \dot{\theta}(s)-\frac{1}{T^{f_{1} }s+1} \tau_{y}(s) .\tag{23}$$<p>其次，  $\dot{f}_{1}$的估计器被设计来满足</p>$$\hat{\dot{F}}_{1}(s)=G_{\dot{f}_{1}}(s)\left[\ddot{\theta}(s)-\dot{\tau}_{y}(s)\right] .\tag{24}$$<p>其中 $\ddot{\theta}(s), \ddot{\theta}(s)$ 和 $\dot{\tau}_{y}(s)$, 表示角加速度、角加加速度和扭矩的导数，不能从机载传感器测量，因此滤波器$$G_{f_{1}}(s)$$的相对阶数必须不能低于2以确保（24）的物理可实现性。因此，应考虑以下二阶滤波器</p>$$G_{\dot{f}_{1}}(s)=\frac{1}{T_{1}^{\dot{f}_{1}} s^{2}+T_{2}^{\dot{f}_{1}} s+1}, T_{1}^{f_{1}}&gt;0, T_{2}^{f_{1}}&gt;0,\tag{25}$$<p>可以推出：</p>$$\hat{F}_{1}(s)=\frac{s^{2}}{T_{1}^{\dot{f}_{1}} s^{2}+T_{2}^{\dot{f}_{1}} s+1} \dot{\theta}(s)-\frac{s}{T_{1}^{\dot{f}_{1} }s^{2}+T_{2}^{\dot{f}_{1}} s+1}{\tau_{y}}(s) \text {. } \tag{26}$$<p>第三， $f_{2}$可以由下式被估计</p>$$\hat{F}_{2}(s)=G_{f_{2}}(s)\left[\dot{\tau}_{y}(s)+\frac{\tau_{y}(s)}{\alpha}-\frac{u_{\theta}(s)}{\alpha}\right] . \tag{27}$$<p>其中</p>$$G_{f_{2}}(s)=\frac{1}{T^{f_{2}}s+1}, T^{f_{2}}&gt;0,\tag{28}$$<p>被选择以避免使用不可用的信号 $\tau_{y}(s)$。结合公式（16），（27）以及（28）可以生成</p>$$\begin{aligned}\hat{F}_{2}(s)=&amp; \frac{1}{\alpha T^{f_{2}} s}\left[(\alpha s+1) \tau_{y}(s)-\ddot{\theta}_{d}(s)-k_{p} \tilde{\dot\theta}(s)-k_{d} \bar{\theta}(s)\right.\\&amp;\left.-k_{\eta} \tilde{\tau}_{y}(s)+\left(k_{\eta}+1\right) \hat{F}_{1}(s)+\alpha \hat{\dot{F}}_{1}(s)\right] .\end{aligned} \tag{29}$$<p>然后，从以设计公式（23），（26）以及（19）构造了MUDE。</p><p>备注3 针对所考虑的问题，经典的基于UDE的控制器满足</p>$$u_{\theta}^{\mathrm{UDE}}=\underbrace{\ddot{\theta}_{d}+k_{p} \tilde{\theta}+k_{d} \tilde{\dot\theta}}_{\text {nominal control }}-\underbrace{\left[-\frac{1}{T_{f}}\left(k_{d} \tilde{\theta}+k_{p} \int_{0}^{t} \tilde{\theta} d t+\tilde{\theta}\right)\right]}_{\mathrm{UDE} \hat{f}_{1}} .\tag{30}$$<p>MUDE是经典UDE的一个变体，因为它们具有相同的设计理念：基于频域的设计和使用适当的滤波器以避免使用状态导数测量。然而，基于MUDE的控制在几个方面都区别于经典的基于UDE的控制。首先，基于MUDE的控制器（19）还包含了一个转矩反馈项$k_{\eta} \tilde{\tau}$ 扩大系统的稳定裕度，提高系统的暂态性能。T。这一修改对于在四旋翼积极机动时实现高精度的姿态跟踪至关重要。其次，基于MUDE的控制是在两种不同坐标（12)和(15）的基础上来设计的，以解决考虑现实执行器带来的不匹配扰动问题，而经典的基于UDE的控制是基于简单的扰动双积分器模型（5）设计的。MUDE对扰动𝑓1的估计精度高于经典的UDE，因为经典的基于UDE的控制假设理想的执行器，基于$u_{\theta}=\tau_{y}$ 而进行$\hat{f}_{1}$的推导，这导致因实际上$𝑢_𝜃$和$𝜏_𝑦$之间的存在差别而产生的估计误差。最后，MUDE不仅能够估计对姿态运动的集中扰动$𝑓_{%raw%}${%endraw%}，而且还能够估计时间延迟和扰动（由$𝑓_2$表示）对执行器的影响。 </p><h2 id="4-稳定性和性能分析"><a href="#4-稳定性和性能分析" class="headerlink" title="4.稳定性和性能分析"></a>4.稳定性和性能分析</h2><p>跟踪误差的动力学模型为</p>{%raw%}$$\left[\begin{array}{c}\tilde{\dot\theta} \\\tilde{\ddot{\theta}} \\\tilde{\dot\eta}\end{array}\right]=A \underbrace{\left[\begin{array}{c}\tilde{\theta} \\\tilde{\dot\theta} \\\bar{\eta}\end{array}\right]}_{\tilde{x}}-B\left[\left(k_{\eta}+1\right) \bar{f}_{1}+\alpha\left(\bar{\dot{f}}_{1}+\bar{f}_{2}\right)\right] .\tag{31}$${%endraw%}<p>其中</p>{%raw%}$$\begin{aligned}&amp;\boldsymbol{A}=\left[\begin{array}{ccc}0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; \frac{1}{J_{y y}} \\-\frac{k_{p}}{\alpha} &amp; -\frac{k_{d}}{\alpha} &amp; -\frac{\left(k_{\eta}+1\right)}{\alpha}\end{array}\right], \quad \boldsymbol{B}=\left[\begin{array}{c}0 \\0 \\\frac{1}{\alpha}\end{array}\right], \\&amp;\tilde{f}_{1}=f_{1}-\hat{f}_{1}, \quad \tilde{f}_{1}=f_{1}-\hat{f}_{1}, \quad \tilde{f}_{2}=f_{2}-\hat{f}_{2} .\end{aligned}$${%endraw%} {%raw%}$\boldsymbol{A}${%endraw%} 的特征多项式{%raw%}$$\left|s \boldsymbol{I}_{3}-\boldsymbol{A}\right|=s^{3}+\frac{k_{\eta}+1}{\alpha} s^{2}+\frac{k_{d}}{J_{y y} \alpha} s+\frac{k_{p}}{J_{y y} \alpha} .\tag{34}$${%endraw%}<p>利用Routh判据，给出了稳定性条件</p>{%raw%}$$k_{p}&gt;0, k_{d}&gt;0, k_{\eta}&gt;-1,\left(k_{\eta}+1\right) k_{d}-\alpha k_{p}&gt;0 .\tag{35}$${%endraw%}<p>在稳定性条件下，跟踪精度依赖于估计残差</p>{%raw%}$$\tilde{f}_{\text {res }}=\left(k_{\eta}+1\right) \tilde{f}_{1}+\alpha\left(\tilde{f}_{1}+\tilde{f}_{2}\right) .\tag{36}$${%endraw%}<p>可以看出 {%raw%}$\alpha\left(\tilde{f}_{1}+\tilde{f}_{2}\right)${%endraw%} 对跟踪精度影响不大，由于电机的时间常数{%raw%}$\alpha \approx 0.04${%endraw%} 很小. 因此估计器的带宽{%raw%}$\dot{f}_{1}${%endraw%} 和 {%raw%}$f_{2}${%endraw%}(这也决定了噪声灵敏度) 不一定要太大。估计误差满足</p>{%raw%}$$\begin{aligned}&amp;\tilde{F}_{1}(s)=\left[1-G_{f_{1}}(s)\right] F_{1}(s)=\frac{T^{f_{1}} s}{T^{f_{1} s+1}} F_{1}(s), \\&amp;\tilde{F}_{1}(s)=\left[1-G_{f_{1}}(s)\right] \dot{F}_{1}(s)=\frac{T_{1}^{f_{1}} s^{2}+T_{2}^{\dot{f}_{1}} s}{T_{1}^{f_{1}} s^{2}+T_{2}^{f_{1}} s+1} \dot{F}_{1}(s), \\&amp;\tilde{F}_{2}(s)=\left[1-G_{f_{2}}(s)\right] F_{2}(s)=\frac{T^{f_{2}} s}{T^{f_{2} s+1}} F_{2}(s) .\end{aligned}\tag{37-39}$${%endraw%}<p>为了说明估计误差是如何与滤波器参数相关的，应用了以下参数映射</p>{%raw%}$$c_{0}=\varepsilon \alpha_{1}, c_{1}=\varepsilon \alpha_{2}, \ldots, c_{k}=\varepsilon \alpha_{k},\tag{40}$${%endraw%}<p>稳定低通滤波器的一般形式为：</p>{%raw%}$$G(s)=\frac{1}{c_{0} s^{k+1}+\cdots+c_{k} s+1},\tag{41}$${%endraw%}<p>其中 {%raw%}$\alpha_{1}, \ldots \alpha_{k+2}${%endraw%} 和 {%raw%}$\varepsilon${%endraw%}是正参数值。 然后可以得到以下结果。</p><p>引理1. 对于所有式(41)中参数为(40)的稳定滤波器，使{%raw%}$\varepsilon \rightarrow 0${%endraw%} 导致 {%raw%}$\bar{F}(s)=[1-G(s)] F(s)${%endraw%}足够小 以保证 {%raw%}$F(s)${%endraw%} 是有界的。<br>证明： 由 (40) 和 (41)，容易得到</p>{%raw%}$$\tilde{F}(s)=\varepsilon \cdot \frac{\alpha_{1} s^{k+1}+\cdots+\alpha_{k+1} s}{\varepsilon \alpha_{1} s^{k+1}+\cdots+\varepsilon \alpha_{k+1} s+1} F(s) .\tag{42}$${%endraw%}<p>注意映射(40)不会改变滤波器{%raw%}$G(s)${%endraw%}的极点 。因为它的分母与与{%raw%}$G(s)${%endraw%}相同， {%raw%}$$ \frac{\alpha_{1} s^{k+1}+\cdots+\alpha_{k+1} s}{\varepsilon \alpha_{1} s^{k+1}+\cdots+\varepsilon \alpha_{k+1} s+1}$${%endraw%}有界输入-有界输出稳定的。然后由于𝐹(𝑠)的有界性，很明显，𝜀→0使𝐹(𝑠)任意小，即完成证明。</p><p>引理1得出了可以通过调整滤波器参数来减少所提出的UDEs的估计误差 {%raw%}$\hat{F}_{1}, \hat{\dot{F}}_{1}${%endraw%} 和 {%raw%}$\hat{F}_{2}${%endraw%}， 该结论将用于得到估计残余误差（36）和跟踪误差的最终边界。</p><p>定理 1. 在假设1和稳定性条件(35)下，当下列参数映射<br>{%raw%}$$T^{f_{1}}=\varepsilon \alpha_{1}, T_{1}^{\dot{f}_{1}}=\varepsilon \alpha_{2}, T_{2}^{\dot{f}_{1}}=\varepsilon \alpha_{3}, T^{f_{2}}=\varepsilon \alpha_{4}, \quad \alpha_{1}, \alpha_{2}, \alpha_{3}, \alpha_{4}, \varepsilon&gt;0 \tag{43}$${%endraw%},<br>应用于滤波器 {%raw%}$G_{f_{1}}(s), G_{\dot{f}_{1}}(s)${%endraw%} 和{%raw%}$G_{f_{2}}(s)${%endraw%}，估计残差(36) 被{%raw%}$f_{b}(\varepsilon)${%endraw%}限制， 而当<em>t</em>趋于∞时，跟踪误差 {%raw%}$\|\tilde{x}(t)\|_{2}${%endraw%} 最终被 {%raw%}$\bar{f}_{b}(\varepsilon)${%endraw%} 所约束为有界。 其中满足当{%raw%}$\varepsilon \rightarrow 0${%endraw%}时，该边界满足{%raw%}$f_{b}(\varepsilon) \rightarrow 0${%endraw%} 和 {%raw%}$\bar{f}_{b}(\varepsilon) \rightarrow 0${%endraw%}。</p><p>证明： 假设1保证了 $F<em>{1}(s), \dot{F}</em>{1}(s),F_{2}(s)$的有界性。将引理1的结果直接应用于估计误差动力学(37)- (39) 直接产生了 {%raw%}$\tilde{F}_{r e s}(s)=\varepsilon H(s)${%endraw%}，其中</p>{%raw%}$$H(s)=\frac{\alpha_{1} s}{\varepsilon \alpha_{1} s+1} F_{1}(s)+\frac{\alpha_{2} s^{2}+\alpha_{3} s}{\varepsilon \alpha_{2} s^{2}+\varepsilon \alpha_{3} s+1} \dot{F}_{1}(s)+\frac{\alpha_{4} s}{\varepsilon \alpha_{4} s+1} F_{2}(s) \tag{44}$${%endraw%}<p>是有界信号。因此在时域中可以得出</p>{%raw%}$$\tilde{f}_{\text {res }}(t) \leq \varepsilon\|h(t)\|_{\infty} \stackrel{\Delta}{=} f_{b}(\varepsilon),\tag{45}$${%endraw%}<p>其中 当 {%raw%}$\varepsilon \rightarrow 0${%endraw%}时，{%raw%}$f_{b}(\varepsilon) \rightarrow 0${%endraw%} 。在稳定条件(35)下，很明显(31)的零输入响应收敛于原点，例如  当{%raw%}$t \rightarrow \infty${%endraw%}，{%raw%}$\left\|\tilde{x}_{z i r}(t)\right\|_{2}=\left\|e^{A t} \tilde{x}(0)\right\|_{2} \rightarrow 0${%endraw%}  。零状态响应的2-范数满足</p>{%raw%}$$\begin{aligned}\left\|\tilde{x}_{z s r}(t)\right\|_{2} &amp;=\left\|\int_{0}^{t} e^{A\left(t-t_{s}\right)} \boldsymbol{B} \tilde{f}_{r e s}\left(t_{s}\right) d t_{s}\right\|_{2} \\&amp; \leq\left\|\int_{0}^{t} e^{A\left(t-t_{s}\right)} d t_{s}\right\|_{2}\|\boldsymbol{B}\|_{2}\left\|\tilde{f}_{r e s}(t)\right\|_{\infty} \\&amp; \leq\left\|\left(e^{A t}-\boldsymbol{I}_{3}\right)\right\|_{2}\left\|\boldsymbol{A}^{-1}\right\|_{2}\|\boldsymbol{B}\|_{2}\left\|\tilde{f}_{r e s}(t)\right\|_{\infty}\end{aligned} \tag{46}$${%endraw%}<p>由公式(45)和(46)， 当 {%raw%}$t \rightarrow \infty${%endraw%}导致</p>{%raw%}$$\|\tilde{x}(t)\|_{2} \leq\left\|\tilde{x}_{z i r}(t)\right\|_{2}+\left\|\tilde{x}_{z s r}(t)\right\|_{2} \leq\left\|A^{-1}\right\|_{2}\|B\|_{2} f_{b}(\varepsilon) \stackrel{\Delta}{=} \bar{f}_{b}(\varepsilon) \tag{47}$${%endraw%}<p>证毕。</p><p>定理1 证明了减少 {%raw%}$\varepsilon${%endraw%} (相应地减少了滤波器参数 {%raw%}$T^{f_{1}}, T_{1}^{\dot{f}_{1}}, T_{2}^{f_{1}},T^{f_{2}}${%endraw%} ) 减小稳态估计误差和闭环跟踪误差。这一结果提供了滤波器参数与跟踪精度之间的明确关系，使参数调优更容易。这个结果提供了一个清晰的滤波器参数和跟踪精度之间的关系，使参数调整更容易。</p><p>备注4 但在实际应用中，抑制干扰与降低mudde对测量噪声的灵敏度之间存在矛盾.  {%raw%}$\theta${%endraw%} 和 {%raw%}$\dot{\theta}${%endraw%}中测量噪声是由于低成本的板载传感器，而{%raw%}$\tau_{y}${%endraw%}由执行器建模所引起的估计误差和辨识误差，可能一起限制最小可行的{%raw%}$\varepsilon${%endraw%}。因此，需要在提高跟踪性能和降低测量噪声和执行器模型不确定性的敏感性之间进行权衡。</p><h2 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5.实验结果"></a>5.实验结果</h2><h3 id="5-1-实验装置"><a href="#5-1-实验装置" class="headerlink" title="5.1 实验装置"></a>5.1 实验装置</h3><p>实验采用了一个由F330D JI框架、PropDrive28261200Kv电机、LitteBee20AESCS、8045螺旋桨和3S2200米Ah25C LIPO电池组成的四旋翼原型。</p><p>如图7所示，实验在旋转试验平台上进行。平台的底座安装在桌子上，四旋翼安装在平台的可旋转端。四旋翼车身框架的𝑦轴与平台的旋转轴对齐，从而只能激活四旋翼的俯仰运动。在实验中，带有有效载荷罩的竹棒连接在四旋翼上，有效载荷可以挂在钩上，以模拟俯仰运动上可能时变的外部扰动转矩。</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy4y8jt3mqj30gl0abwkl.jpg" alt="图7 旋转测试平台进行四旋翼姿态控制"></p><h3 id="5-2-控制器测试"><a href="#5-2-控制器测试" class="headerlink" title="5.2 控制器测试"></a>5.2 控制器测试</h3><p>在实验中，测试了三个控制器，包括级联PID控制器（CPID），由（30）给出的经典的基于UDE的控制器和基于MUDE的控制器（19）。串级PID控制器嵌入在PX4固件中，广泛应用于大多数商用无人机中。它的设计形式如下：</p>{%raw%}$$u_{\theta}^{\mathrm{CPID}}=k_{p} \tilde{\dot{\theta}}+k_{i} \int_{0}^{t} \tilde{\dot{\theta}} d t+k_{d} \tilde{\ddot{\theta}} \tag{48}$${%endraw%}<p>其中姿态角速率{%raw%}${\dot{\theta}_d}${%endraw%}的数值由比例控制器{%raw%}${\dot{\theta}_d}=𝑘\tilde{𝜃}${%endraw%}生成。</p><p>备注5 在基于MUDE的控制器中，在频域上设计了不确定性和扰动估计器（23)(26)(29）。同时为了实现C语言编程，并在运行PX4固件1.8.2版本的皮克鹰飞行控制器上实现整个解决方案，需要将它们转换为离散时间形式。所提出的解决方案的计算复杂度被认为很低，因为皮克斯鹰只配备了一个运行在168兆赫的STM32F427处理器。这些代码发表在Github网站上，可以在网站<a href="https://github.com/potato77/Firmware_MUDE上找到。">https://github.com/potato77/Firmware_MUDE上找到。</a></p><p>前述实验中所研究的反馈控制器，俯仰角由PX4固件中嵌入的EKF模块(扩展卡尔曼滤波)获得，俯仰角速率由陀螺仪测量并通过低通滤波器处理。默认控制器反馈增益如表2所示。需要注意的是，经典UDE和MUDE使用相同的控制反馈增益{%raw%}$𝑘_𝑝${%endraw%}和{%raw%}$𝑘_𝑑${%endraw%}，以保证比较结果的公平性。CPID中选择了经过飞行验证的反馈增益。</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy4yrjwv0cj30zc07kq42.jpg" alt="表2 控制器反馈增益"></p><h3 id="5-3-实验结果"><a href="#5-3-实验结果" class="headerlink" title="5.3 实验结果"></a>5.3 实验结果</h3><p>实验中考虑的案例研究总结见表3。考虑了三个典型的期望，其中正弦期望满足</p>{%raw%}$$\theta_{d}=0.5236 \cdot \sin (4 t) \mathrm{rad} \tag{49}$${%endraw%}<p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gy4ys4oeczj30z70gudkn.jpg" alt="表3 在实验中的案例研究"></p><p>其中，0.5236rad=30度几乎是真实飞行期间四旋翼的最大倾斜角度。通过在钩子上悬挂有效载荷(150g)，将扰动添加到四转子俯仰运动中，在稳态时，当𝜃=0时，等效扰动转矩约为0.6N m。当俯仰角度变化时，负载充当对系统的时变扰动（当忽略有效载荷的摆动时，误差为0.6cos𝜃 N m）。在案例1-4中，对CPID控制器（48）、基于UDE的控制（30）和所提出的基于MUDE的控制（19）进行了测试和比较。在案例5-6中，{%raw%}$T^{𝑓_{1}}${%endraw%}和{%raw%}$T^{𝑓_{2}}${%endraw%}的参数分别被应用于MUDE，证明了所提出的调参准则的有效性。在案例7中，手动控制四旋翼在室内环境中飞行，并给出了真实的飞行测试结果。</p><p>本文实验视频可以在<a href="https://www.bilibili.com/av60962814/（适用于案例1-6）和https://www.bilibili.com/BV1v54y1q7X7（针对案例7）找到。">https://www.bilibili.com/av60962814/（适用于案例1-6）和https://www.bilibili.com/BV1v54y1q7X7（针对案例7）找到。</a></p><h4 id="5-3-1-案例1"><a href="#5-3-1-案例1" class="headerlink" title="5.3.1 案例1"></a>5.3.1 案例1</h4><p>试验结果如图8所示，可以看出三个控制器的跟踪误差很接近，但当四旋翼跟踪一个恒定的参考信号时，基于MUDE的控制产生的跟踪误差最小，如图8(a)所示。由于四旋翼处于稳态状态，转矩命令{%raw%}$𝑢_𝜃${%endraw%}收敛到零的一个小邻域，因此电机以几乎恒定的速度旋转，如图8(b)所示。 在这种特殊情况下，执行器的动力学可以被忽略。</p><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gy4zq408khj30td0twwsi.jpg" alt="图8 案例1的实验结果"></p><p>如图8（c）-（e）所示的正弦轨迹跟踪结果。 然而，基于MUDE的控制器在跟踪精度上有了显著的提高，而其竞争控制器的结果显示出一些幅值约为0.05∼0.08rad的残差。这是因为当四旋翼进行运动时，由于执行器的动力学和时间延迟，执行器产生的扭矩与扭矩信号不一致。 与CPID和经典的基于UDE的控制相比，MUDE中{%raw%}$\hat{f}_2${%endraw%}项有效地补偿了这种转矩差，所提出的控制器（19）中的附加转矩误差反馈项{%raw%}$k_{\eta} \tilde{\tau}${%endraw%} 有助于扩大系统稳定裕度，提高姿态跟踪的收敛速度，从而同时提高了整体稳态和瞬态跟踪性能。这一点由这些控制器生成的转矩命令进行验证，如图8(e)所示。CPID缺乏前馈控制，因此转矩命令具有明显的相位延迟，而经典UDE控制中的前馈项在一定程度上有助于纠正这种相位延迟。该MUDE还补偿了执行器的动态延迟和时间延迟，从而进一步纠正了转矩命令中的相位延迟。在以上分析的基础上，对于准确的姿态跟踪问题，特别是当四旋翼快速运动时，考虑执行器动力学的控制设计具有现实意义，其中所考虑的执行器模型是一阶系统。将在案例6中显示，本文考虑的执行器的时间延迟对跟踪性能有显著影响，因此在解决执行器延迟问题上，所提出基于MUDE的控制方法是一个不错的解决方案。</p><h4 id="5-3-2-案例2"><a href="#5-3-2-案例2" class="headerlink" title="5.3.2 案例2"></a>5.3.2 案例2</h4><p>本文研究了在实际飞行任务中极其常见的阶跃轨迹跟踪。试验结果如图9所示。需要注意的是，由于阶跃型期望相对于时间是不可微的，因此所提出的控制器和经典的基于UDE的控制器的角速率参数由与CPID的相同的比例控制器{%raw%}${\dot{\theta}_d}=𝑘\tilde{𝜃}${%endraw%}计算，而基于MUDE的控制的前馈控制和转矩期望设置为零。结果表明，基于MUDE的控制跟踪误差无超调，收敛速度快，振荡小，稳态误差很小。相比之下，基于CPID和基于UDE的控制会导致不同级别的超调和恢复速度比基于MUDE的控制要慢。在振荡方面，CPID在所有被测试的控制器中是最好的，而经典的UDE在过渡过程中存在明显的振荡。</p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1gy543539xlj30wu0mkwk5.jpg" alt="图9 案例2的实验结果"></p><h4 id="5-3-3-案例3"><a href="#5-3-3-案例3" class="headerlink" title="5.3.3 案例3"></a>5.3.3 案例3</h4><p>在此情况下，考虑了不同控制器的恒定抗干扰抑制性能。四旋翼在𝑡=0∼3s而有效载荷被挂在𝑡的=3s的钩子上。试验结果如图10所示，可以从图中的屏幕截图中看,从图10(a)和图10(b)可以看出基于MUDE的控制受干扰影响最小，并且恢复跟踪性能比其他两个控制器更快。此外，图10(c)显示了由MUDE生成的三个估计项。当四转子受几乎恒定的外部扭矩0.6N m时，$\hat{𝑓}_{%raw%}$迅速收敛到0.6。而{%raw%}$\hat{\dot{𝑓}}_{%raw%}${%endraw%}和{%raw%}$\hat{𝑓}_2${%endraw%}则收敛到0。这些结果是合理的，因为 {%raw%}$\hat{\dot{𝑓}}_{%raw%}${%endraw%}和{%raw%}$\hat{𝑓}_2${%endraw%}在稳态条件下接近零。</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gy54qlk7cwj30rk0suds4.jpg" alt="图10 案例3的实验结果"></p><h4 id="5-3-4-案例4"><a href="#5-3-4-案例4" class="headerlink" title="5.3.4 案例4"></a>5.3.4 案例4</h4><p>在案例4中，研究了三个控制器在时变干扰下的跟踪性能。实验以四旋翼跟踪正弦轨迹开始，然后在𝑡=10s左右将有效载荷悬挂到钩子上。如图11(a)-(b)所示，在稳态(𝑡=0∼10s)中，提出的基于MUDE的控制提供了对正弦参考的几乎完美的跟踪。在抗干扰方面，基于MUDE的控制器能够提供快速的跟踪性能恢复，并在稳态跟踪精度方面在三个控制器中表现最好。</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gy557jgv3oj30z60ncwra.jpg" alt="图11 案例4的实验结果"></p><p>从案例1-4的实验结果可以看出，基于MUDE的控制不仅可以抵抗系统上的各种干扰，而且在运动过程中还能提供较高的跟踪精度。</p><h4 id="5-3-5-案例5"><a href="#5-3-5-案例5" class="headerlink" title="5.3.5 案例5"></a>5.3.5 案例5</h4><p>本案例研究说明了调整MUDE的𝑇𝑓1以提供更好的外部干扰转矩抑制性能的有效性。实验设置与案例3相同。分别选择四个不同的参数输入{%raw%}$𝑇^{𝑓_1}=\left\{ {1,0.4,0.1,0.05} \right\}${%endraw%}，相应的结果如图12(a)所示。可分析得到，通过减少{%raw%}$𝑇^{𝑓_1}${%endraw%}以提高了抗干扰性能。更具体地说，当添加扰动时，一个较小的{%raw%}$𝑇^{𝑓_1}${%endraw%}提供了一个较小的偏离稳定状态，并且可以在较短的时间内估计和补偿扰动。然而，由于测量噪声{%raw%}$𝑇^{𝑓_1}${%endraw%}在实践中不能任意小。从（23）中，一个小的{%raw%}$𝑇^{𝑓_1}${%endraw%}可以显著放大角速率测量结果 中的高频噪声，这正好解释了图12(b)中当选择{%raw%}$𝑇^{𝑓_1}${%endraw%}小于0.1时所示  中的震荡。虽然震荡可以被四旋翼的阻尼和执行器的动力学大大过滤掉，但它仍然可能导致执行器器的磨损，甚至是系统的不稳定。因此，在软件程序中应该小心确定{%raw%}$𝑇^{𝑓_1}${%endraw%}的大小。</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy55b66rn1j30xm0o8n50.jpg" alt="图12 案例5的实验结果"></p><h4 id="5-3-6-案例6"><a href="#5-3-6-案例6" class="headerlink" title="5.3.6 案例6"></a>5.3.6 案例6</h4><p>调整参数{%raw%}$𝑇^{𝑓_2}${%endraw%}的结果如图13(a)-(c)所示。四旋翼在𝑡=0∼10s徘徊，并𝑡=10s后跟踪正弦轨迹。{%raw%}$𝑇^{𝑓_2}${%endraw%}是为估计执行器的时间延迟和扰动项 {%raw%}$f_{2}=\frac{1}{\alpha}\left[u_{\tau}\left(t-\tau_{0}\right)-u_{\tau}(t)\right]+d_{\tau}${%endraw%}而设计的估计器（29）的参数。可以观察到，在悬停过程中，调整{%raw%}$𝑇^{𝑓_2}${%endraw%}对跟踪精度的影响不大。这是合理的，因为在稳态条件下，电机几乎以一个恒定的速度旋转（这是稳定转矩指令的直接结果）。因此，集中扰动{%raw%}$𝑓_2${%endraw%}很大程度上是由执行器上的输入扰动$1𝒅_𝜏${%endraw%}决定的，在大多数情况下，这是可以忽略不计的。然而，当跟踪时变参考(𝑡=10∼20s)时，由于转矩命令{%raw%}$𝒖_𝜏${%endraw%}不再恒定，由于模型不确定项  ，{%raw%}$𝒇_2${%endraw%}的影响变得显著。因此，当{%raw%}$𝑇^{𝑓_2}${%endraw%}从2减少到0.2时，跟踪性能得到了显著的改善。 这一结果表明，执行器的时间延迟是不能忽略的，调整{%raw%}$𝑇^{𝑓_2}${%endraw%}参数是非常重要的，特别是对于快速运动。</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gy55g7n3x7j30xu0n5dps.jpg" alt="图13 案例6的实验结果"></p><h4 id="5-3-7-案例7"><a href="#5-3-7-案例7" class="headerlink" title="5.3.7 案例7"></a>5.3.7 案例7</h4><p>在此情况下，评估了所提出的基于MUDE的控制在实际飞行中的抗干扰和跟踪性能。四旋翼设置为手动飞行模式，随机和快速的滚动/俯仰命令（即期望欧拉角）是通过遥控器由飞行员给出的。一个150克的悬浮有效载荷附着在一个起落架上(见图14(f))，结合四旋翼的耦合动力学，可视为添加到四旋翼中的时变外部扰动转矩。飞行测试结果如图14(a)-(e)所示。一般来说，基于MUDE的控制能够抑制干扰，并提供良好的姿态跟踪性能。具体地说，由于参考值是随机的，在这种情况下可能会突然变化，因此跟踪误差表现出与案例2相似的峰值，如图14(b)所示。尽管有这些峰值，基于MUDE的控制还是可以快速消除跟踪错误。如附图14(c)-(d)所示，演示了pitch角和roll角的扰动估计结果，从中可以看出，由悬挂的有效载荷产生的外部扰动力矩由MUDE动态估计。利用这些估计信号，控制器可以主动补偿干扰，不仅保证了巨大干扰下的飞行安全，而且实现了对参考进行快速、准确的跟踪。</p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1gy55scsujij30nn0u0gyi.jpg" alt="图14 案例7的实验结果"></p><h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h2><p>提出了一种基于MUDE的鲁棒控制器，用于四旋翼精确的姿态跟踪和外部干扰抑制。结果表明，在标准控制器和UDE设计中系统考虑执行器动力学，可以提高经典基于UDE算法的方案的跟踪性能，特别是在快速运动时的跟踪性能。执行器的不可估量的状态，即执行器产生的扭矩，是用识别的FOPTD模型估计的。通过调整MUDE的单个参数，可以显著降低姿态跟踪和扰动估计误差，并在实际的四旋翼平台上进行了实验验证。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
            <tag> 控制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS state论文(2)</title>
      <link href="/2022/01/05/ps-state-lun-wen-2/"/>
      <url>/2022/01/05/ps-state-lun-wen-2/</url>
      
        <content type="html"><![CDATA[<p>文章地址：<a href="https://ieeexplore.ieee.org/document/7989532">Autonomous swing-angle estimation for stable slung-load flight of multi-rotor UAVs | IEEE Conference Publication | IEEE Xplore</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>提出了一种实用的多旋翼无人机绳载负载摆角估计方法，该方法对保证多旋翼无人机安全工作至关重要。为了不依赖于额外的(不在系统上的，例如动作捕捉)传感器来监测摆角，本文提出的方法提供了一个自主的（在无人机-负载系统上的）摆角估计，只使用一个惯性测量单元(IMU)和一个附加在负载上的测压单元。利用扰动观测器(disturbance observer。DOB)导出的外力估计来估计摆角。所提出的基于DOB的扰动估计技术的独特结构只利用了IMU数据。</p><h2 id="系统动力学"><a href="#系统动力学" class="headerlink" title="系统动力学"></a>系统动力学</h2><h3 id="A-带负载和不带负载的无人机动力学"><a href="#A-带负载和不带负载的无人机动力学" class="headerlink" title="A 带负载和不带负载的无人机动力学"></a>A 带负载和不带负载的无人机动力学</h3><p>多旋翼无人机动力学模型如下：</p>$$\left\{\begin{array}{c}m \ddot{\mathbf{x}}=R(\mathbf{q}) T_{f}+m g \mathbf{z}_{\mathbf{e}} \\J \dot{\mathbf{\Omega}}=T_{m}-\boldsymbol{\Omega} \times J \boldsymbol{\Omega}\end{array}\right.\tag{1}$$<p>其中 $m$ 为无人机质量， $\mathbf{x}=\left[\begin{array}{lll}x &amp; y&amp; z\end{array}\right]^{T}$ 为其在地球坐标系中的位置。</p> $R(\mathbf{q})$ 是机体坐标系到地球坐标系的旋转矩阵，其中 $\mathrm{q}=\left[\begin{array}{lll}\phi &amp; \theta &amp; \psi\end{array}\right]^{T}$为地球坐标系中的滚转角、俯仰角、偏航角。$T_{f}$为推力扭矩矢量，在机体坐标系内的 $T_{f}=$ $\left[0-0-\Sigma F_{i}\right]^{T}$， $g$ 为重力加速度，$J$为转动惯量, $\boldsymbol{\Omega}=\left[\begin{array}{llr}p &amp; q &amp; r\end{array}\right]^{T}$为在机体坐标系中角速度，而 $T_{m}=\left[\tau_{r} \tau_{p} \tau_{y}\right]^{T}$为在机体坐标系中的推力扭矩矢量。为了稳定，无人机的姿态运动在滚转和俯仰角度都被限制在±0.3弧度。这使得机体的陀螺效应很小，可以忽略(1)式中的 $\Omega \times J \Omega$。也使得下式角速度坐标变换方程中的变换矩阵 $W(\mathbf{q}) \approx I_{3 \times 3}$。$\dot{\mathbf{q}}=W(\mathbf{q}) \Omega \approx \Omega \tag{2}$<p>最后，±0.3弧度约束使得小角度假设是有效的，可以令$\sin (*) \approx *$ and $\cos (*) \approx 1$ 。公式(1)可以改写为：平动动力学：</p>$$\left[\begin{array}{c}\ddot{x} \\\ddot{y} \\\ddot{z}\end{array}\right]=\frac{1}{m}\left[\begin{array}{ccc}\Sigma F_{i} s \psi &amp; \Sigma F_{i} c \psi &amp; 0 \\-\Sigma F_{i} c \psi &amp; \Sigma F_{i} s \psi &amp; 0 \\0 &amp; 0 &amp; \frac{-1}{m} c \phi c \theta\end{array}\right]\left[\begin{array}{c}\phi \\\theta \\\Sigma F_{i}\end{array}\right]+\left[\begin{array}{c}0 \\0 \\g\end{array}\right]_{(3)}  \tag{3}$$<p>与转动动力学</p>$$\left[\begin{array}{c}\ddot{\phi} \\\ddot{\theta} \\\ddot{\psi}\end{array}\right]=\left[\begin{array}{ccc}\frac{1}{J_{x x}} &amp; 0 &amp; 0 \\0 &amp; \frac{1}{J_{y y}} &amp; 0 \\0 &amp; 0 &amp; \frac{1}{J_{z z}}\end{array}\right]\left[\begin{array}{c}\tau_{r} \\\tau_{p} \\\tau_{r}\end{array}\right]  \tag{4}$$<p>为简洁起见，将式(3)(4)表示为</p>$$\left\{\begin{array}{l}\ddot{\mathbf{x}}=G\left(\mathbf{q}, \Sigma F_{i}\right) \mathbf{\Gamma}+g \mathbf{z}_{e} \\\ddot{\mathbf{q}}=J^{-1} T_{m}\end{array}\right. \tag{5}$$<p>在进一步的描述中， 其中 $\boldsymbol{\Gamma}=\left[\phi \theta \Sigma F_{i}\right]^{T}$ 为无人机控制的状态集 $G\left(\mathbf{q}, \Sigma F_{i}\right)$  是$\ddot{\mathbf{X}}$ 与 $\boldsymbol{\Gamma}$之间的关系矩阵。</p><p>同时，当负载附加时，系绳张力起扰力作用。在这一方面，在方程(5)中增加一个额外的力和一个力矩项，就完成了负载附加后的方程。将式(5)改写后，无人机的动力学方程为</p>$$\left\{\begin{array}{l}\ddot{\mathbf{x}}=G\left(\mathbf{q}, \Sigma F_{i}\right) \boldsymbol{\Gamma}+g \mathbf{z}_{e}+\frac{1}{m} F_{s} \\\ddot{\mathbf{q}}=J^{-1}\left(T_{m}+T_{s}\right)\end{array}\right. \tag{6}$$<p>其中$F_{s}=\left[\begin{array}{lll}F_{s, x} &amp; F_{s, y} &amp; F_{s, z}\end{array}\right]^{T}$和$T_{s}=\left[T_{s, x} T_{s, y} T_{s, z}\right]^{T}$分别是由复杂期产生的扰动力和力矩。方程(6)的概念通过推导扰动力与摆角的关系给出了摆角估计的关键思想。</p><p>同时，用于仿真的无人机动力学既要考虑全动力学，又要考虑吊挂载荷动力学。因此，我们应该将仿真的动力学写为</p><script type="math/tex; mode=display">\left\{\begin{array}{c}m \ddot{\mathbf{x}}=R(\mathbf{q}) T_{f}+F_{s}+m g \mathbf{z}_{c} \\J \dot{\Omega}=T_{m}+T_{s}-\Omega \times J \Omega\end{array}\right.\tag{7}</script><p>但(7)式不能直接用于仿真，因为计算$F_{s}$和$T_{s}$随时间变化的解还未知。$F_{s}$和$T_{s}$是由系统的机械约束产生的力和力矩。在我们的案例中，机械约束是无人机和负载之间的恒定长度。因此，对于无人机和负载的仿真，我们需要在长度约束的基础上，计算出每个时间步长中的$F_{s}$值。</p><h3 id="B-负载-无人机动力学仿真"><a href="#B-负载-无人机动力学仿真" class="headerlink" title="B 负载-无人机动力学仿真"></a>B 负载-无人机动力学仿真</h3><p>多年来，对悬载直升机的约束动力学系统建模进行了研究。最有前途的方法之一是Udwadia-Kalaba  (UK)方程。U-K方程是基于高斯最小约束原理的动力学方程，其中系统运动由满足约束条件下最接近无约束加速度的系统的加速度矢量控制。在方程中，可以写成</p>$$\ddot{\zeta}=\arg \min \Delta\left(\ddot{\zeta}_{\delta}\right) \tag{8}$$<p>其中 $\Delta\left(\ddot{\zeta}_{\delta}\right)=\left(\ddot{\zeta}_{\delta}-\ddot{\zeta}_{u}\right)^{T} M\left(\ddot{\zeta}_{\delta}-\ddot{\zeta}_{u}\right)=\Upsilon^{T} \Upsilon$ 需要最小化的成本函数， $\zeta_{\delta}$ 表示所有可能的加速度矢量, $\ddot{\zeta}_{u}$自由状态下不受任何物理约束的加速度而 $M$为质量矩阵。$\Upsilon$ 满足式(8)和约束方程 $A \ddot{\zeta}_{\delta}=b$，则有 </p>$$\Upsilon=\left(A M^{-\frac{1}{2}}\right)^{+}\left(b-A \ddot{\zeta}_{u}\right)=M^{\frac{1}{2}}\left(\ddot{\zeta}_{\delta}-\ddot{\zeta}_{u}\right) \tag{9}$$<p>因此，作用在物体上的总力为</p>$$F_{\text {total }}=M \ddot{\zeta}=F_{u}+F_{c}=M\left(\ddot{\zeta}_{u}+M^{-\frac{1}{2}}\left(A M^{\frac{-1}{2}}\right)+\left(b-A \ddot{\zeta}_{u}\right)\right) \tag{10}$$<p>其中 $F_{u}=M \zeta_{u}$ 是无约束力 而 $F_{c}=$ $M^{\frac{1}{2}}\left(A M^{\frac{-1}{2}}\right)^{+}\left(b-A \ddot{\zeta}_{u}\right)$是约束力。</p><p>对于绳载负载无人机的仿真，设置位置矢量为 $\zeta=\left[\begin{array}{llll}\mathbf{x}_{h} &amp; \mathbf{q}_{h} &amp; \mathbf{x}_{l} &amp; \mathbf{q}_{l}\end{array}\right]^{T}$，其中$\mathbf{x}_{h}$ 和 $\mathbf{q}_{h}, \mathbf{x}_{l}$和$\mathbf{q}_{l}$ 分别给出了无人机和吊挂物的位置和姿态。 质量矩阵 $M=\operatorname{diag}\left(m_{u} I_{3 \times 3}, J_{u}, m_{l} I_{3 \times 3}, J_{l}\right)$ 由 $m_{u}$ 及 $J_{u}, m_{l}$ 及 $J_{l}$组成，分别为无人机和负载的质量和力矩. 将无约束力设为$F_{u}=\left[\begin{array}{ll}{\left[T_{f}+m_{u} g \mathbf{z}_{e}\right]^{T}} &amp; T_{m}^{T} m_{l} g \mathbf{z}_{e}^{T} &amp; 0_{1 \times 3}\end{array}\right]^{T} .$。</p><h2 id="摆动角估计与轴向力估计"><a href="#摆动角估计与轴向力估计" class="headerlink" title="摆动角估计与轴向力估计"></a>摆动角估计与轴向力估计</h2><p>我们基于负载产生轴向扰动力提出一种摆动角估计技术。因此，我们需要分别估计$x_e、y_e$和$z_e$轴上的扰动力。</p><p>首先，我们将定义负载的摆动角度。然后，我们将提出一种利用加速度- DOB[10]估计扰动力的方法。最后，我们将介绍利用估计的干扰力估计摆角的方法。</p><h3 id="A-摆动角度的定义"><a href="#A-摆动角度的定义" class="headerlink" title="A 摆动角度的定义"></a>A 摆动角度的定义</h3><p>如下图所示。α是$z_e$轴与缆绳在$y_e-z_e$平面上的夹角。β是轴$z^\prime_e$和缆绳之间在$x^\prime_e - z^\prime_e$平面上的夹角，其中$x^\prime_ey^\prime_ez^\prime_e$坐标系为$x_ey_ez_e$绕$x_e$轴旋转得到的，旋转后的轴$z^\prime_e$方向与$y_e-z_e$平面上中缆绳的方向相同。</p><p><img src="https://tva3.sinaimg.cn/large/007mx13gly1gy2owexwe1j30lt0ihwkn.jpg" alt="摆动角的定义"></p><h3 id="B-DOB导出的扰动力估计"><a href="#B-DOB导出的扰动力估计" class="headerlink" title="B DOB导出的扰动力估计"></a>B DOB导出的扰动力估计</h3><p>DOB算法最初是为受干扰系统的鲁棒控制而开发的。DOB的主要思想是在下一步的控制中估计干扰量并对其进行补偿。但我们不是用估计的扰动来补偿，而是用它来监测由吊挂载荷产生的扰动力。在<a href="https://ieeexplore.ieee.org/document/7798901">Robust acceleration control of a hexarotor UAV with a disturbance observer | IEEE Conference Publication | IEEE Xplore</a>中，引入了一种旨在补偿横向力扰动的DOB算法，与传统的DOB应用于无人机相比，这是一种独特的方法，目标实现姿态控制的鲁棒性。</p><p>在此基础上，提出了一种横向力控制方法，实现了无人机各轴的横向加速度控制。由于DOB算法需要输入具有相同物理意义的命令来补偿扰动，因此获得无人机的加速度控制对DOB算法的实现至关重要。</p><p>下图为<a href="https://ieeexplore.ieee.org/document/7798901">Robust acceleration control of a hexarotor UAV with a disturbance observer | IEEE Conference Publication | IEEE Xplore</a>中引入的DOB作用力控制算法的结构。$\ddot{x}_d$是在原加速度命令的基础上添加扰动补偿信号而生成的每个轴上的整体加速度命令。$\ddot{x}_d$随后如下式被转化为$\Gamma_d$：</p><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gy2owaucm5j30lj09v780.jpg" alt="基于加速度-DOB算法的无人机整体控制方案，包括位置和姿态控制器"></p>$$\boldsymbol{\Gamma}_{\mathrm{d}}=G^{-1}\left(\mathbf{q}, \Sigma F_{i}\right)\left(\ddot{\mathbf{x}}_{\mathbf{d}}-g \mathbf{z}_{e}\right) .\tag{11}$$<p>为了计算出 公式(11)中的$\Gamma_{\mathrm{d}}$， 需要其总拉力 $\Sigma F_{i}$计算出 $G^{-1}$。虽然许多研究将推力值作为一种可测量的输出状态，但获取精确的推力值非常困难。这种在$\Sigma F_{i}$中的不确定性是由于转子动力学的不完善和电池电压的持续下降，使得电子速度控制器(ESC)难以保持输入指令和输出电压/电流之间的恒定关系。因此，需要引入了一种利用式(1)代替输入输出推力指令关系的数学模型估计$\Sigma F_{i}$的替代方法。得到的$T_f$估计为</p>$$T_{f}=m R^{-1}(\mathbf{q})\left(\ddot{\mathbf{x}}-g \mathbf{z}_{c}\right) . \tag{12}$$<p>上式中的变量都是已知的，通过估计总推力，我们现在可以在式(11)中计算$Γ_d$，这是一个$Λ_p$的输入命令，$Λ_p$图2为中的灰框，它由带有姿态和推力控制器的六旋翼装置组成($y =Λ_pΓ_d$)。</p><p>为了估计干扰力，$\hat{\bar{x}}_{d}$的估计量 $\tilde{\tilde{x}}_{\mathrm{d}}+d$ 应该被计算。符号 $\hat{*}$ 代表全文中的估计量. 首先, $\hat{\Gamma}$是 $\Gamma$在 $\ddot{\mathbf{x}}$的基础上计算最近的加速度。 在这个时候，由于轴向力的干扰会影响无人机的正常性能，$\hat{\boldsymbol{\Gamma}}$ 会不同于 $\Gamma$ 。 随后通过使用正常传递函数的倒数$\Lambda_{n}^{-1}$计算出期望姿态指令$\hat{\boldsymbol{\Gamma}}_{\mathrm{d}}$。   $\Lambda_{n}$ 代表 $\Lambda_{p}$ 处于正常状态。然后通过,  信号通过$G$ 模块将 $\hat{\Gamma}_{d}$ 转化为了 $\tilde{\tilde{x}}_{d}$ （期望的轴向加速度指令），这也可能与实际轴向加速度指令有很大的不同，因为它是基于$\hat{\boldsymbol{\Gamma}}_{\mathrm{d}}$计算出来的，最后，估计的扰动加速度$\hat{d}$由下式计算出。</p>$$\hat{d}=\hat{\tilde{\mathbf{x}}}_{d}-\tilde{\tilde{\mathbf{x}}}_{d}=G\left(\mathbf{q}, \Sigma F_{i}\right) \Lambda_{n}{ }^{-1} G^{-1}\left(\mathbf{q}, \Sigma F_{i}\right) \ddot{\mathbf{x}}-\tilde{\tilde{\mathbf{x}}}_{d} \tag{13}$$$\hat{d}$受到外界影响的扰动加速度指令估计值，因此可以通过将质量乘以各轴上估计的扰动来估计各轴上的扰动力，即$$\hat{F}_{s}=m \hat{d} \tag{14}$$<p>干扰力的估计是本文实现摆动角估计的一个关键概念。该方法的特殊意义在于，$\hat{d}$不仅是一个用于增强系统稳定性的集中值，而且是一个具有物理意义的值，特别是一个通过简单修改作用于系统的外力。此外，它是非常实用的，因为没有其他传感器，但只需要IMU的工作。</p><p>我们认为，这种方法是本文中介绍的一个独特的概念。但由于现代无人机硬件的不完善，这种方法在实现上存在一定的局限性。在下一小节中，我们将讨论局限性，并找出解决问题的方法。</p><h3 id="C-克服物理极限"><a href="#C-克服物理极限" class="headerlink" title="C 克服物理极限"></a>C 克服物理极限</h3><p>所提出的扰动估计的一个问题是几乎不可能精确的$z_e$方向扰动估计。这是因为与$x_e$和$y_e$方向模型相比，推进器的传递函数不断变化，这与上一小节引入的$T_f$估计不准确的原因是一样的。因此，需要另一种方法来补充这种不准确性。</p><p>本文提出的实用解决方案是使用一个测绳拉力的测力元件，它给出了悬索产生的整体扰动力的范数$|| F_s||$。根据摆角的定义，地球坐标系中中的轴向扰动力为</p>$$\left\{\begin{array}{l}F_{s, x}=\left\|F_{s}\right\| \sin \beta \\F_{s, y}=\left\|F_{s}\right\| \cos \beta \sin \alpha \\F_{s, z}=\left\|F_{s}\right\| \cos \beta \cos \alpha\end{array}\right. \tag{15}$$<p>其中 $F_{s, x}, F_{s, y}$ 和 $\left\|F_{s}\right\|$ 为已知量，然而 $F_{s, z}$为未知量。然而，尽管有$F_{s, z}$的不确定性，我们现在能够计算摆动角度，因为我们可以改变方程(15)中的前两个方程为</p>$$\left\{\begin{array}{l}\frac{F_{s, x}}{\left\|F_{s}\right\|}=\sin \beta \\\frac{F_{s, y}}{\left\|F_{s}\right\|}=\cos \beta \sin \alpha\end{array}\right.\tag{16}$$<p>方程左边的所有变量已知，即可以得到两个变量 ( $\alpha$ 和 $\beta$ )。</p><h3 id="D-摆角估计"><a href="#D-摆角估计" class="headerlink" title="D 摆角估计"></a>D 摆角估计</h3><p>在我们进行摆动角估计之前，需要对引入的基于DOB的$F_{s,x}, F_{s,y}$估计方法进行修改，以考虑负载。由于动力学由式(5)改变为式(6)，因此式(12)中引入的总体推力估计方法也需要改变。基于式(7)的修正推力估计方程为</p>$$T_{f}=m R^{-1}(\mathbf{q})\left(\ddot{\mathbf{x}}-g \mathbf{z}_{e}-\frac{1}{m} F_{s}\right) \tag{17}$$<p>其中将$F_s$加到原方程中。因此，我们需要一个精确的$F_s$估计来得到好的$T_f$估计结构.</p><p>然而，$F_{s}$ 中的$F_{s, x}$和$F_{s, y}$ 需要精确的估计量 $T_{f}$ 总推力因为公式(13)中的 $G\left(\mathbf{q}, \Sigma F_{i}\right)$ 使用 $\Sigma F_{i}$ 进行计算。同时，总推力估算还需要 $\hat{F}_{s, z}$ (由结合$\hat{\alpha}$与$\hat{\beta}$计算得到)。下图是显示估计值之间关系的图表。这四个估计量都相互依赖。但式(17)的推力估计误差是有限的，因为飞行过程中$F_s$不会超过某一水平。因此，其余的估计量也有一个有限的输出误差。</p><p>在此基础上，摆角估计如下:</p>$$\left\{\begin{aligned}\hat{\beta} &amp;=\arcsin \left(\frac{\hat{F}_{s, x}}{\left\|F_{s}\right\|}\right) \\\hat{\alpha} &amp;=\arcsin \left(\frac{\hat{F}_{s, y}}{\left\|F_{s}\right\| \cos \hat{\beta}}\right)\end{aligned}\right.$$<p>然后用更新后的估计摆动角度计算更好的$F_{s, z}=\left\|F_{s}\right\| \cos \beta \cos \alpha\\$在方程(15)。.从而补充了 $\hat{F}_{s}$的所有分量而实现了更精确的 $T_{f}$ 估计。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
            <tag> 负载状态 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS state论文(3)</title>
      <link href="/2022/01/04/ps-state-lun-wen-3/"/>
      <url>/2022/01/04/ps-state-lun-wen-3/</url>
      
        <content type="html"><![CDATA[<p>对应文章地址：<a href="https://github.com/RENyunfan/visual_encoder_estimator">Vision-encoder-based Payload State Estimation for Autonomous MAV<br>With a Suspended Payload</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>负载状态估计的鲁棒性和在线性很重要，但具有挑战性，特别是在户外环境中。本文开发了一种新型的实时有效载荷位置估计系统;该系统由单目鱼眼摄像机和一种基于编码器的新型装置组成。提出了一种基于高斯融合的负载状态估计算法。在负载位置估计鲁棒的基础上，提出了一种有效负载控制器，以保证可靠的快速轨迹跟踪性能。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>实现负载状态估计的方法有很多。</p><p>例如，<a href="https://ieeexplore.ieee.org/document/8258883">Aggressive Flight With Suspended Payloads Using Vision-Based Control | IEEE Journals &amp; Magazine | IEEE Xplore</a>使用视觉方法来估计载荷的位置。该方法要求负载上有特定的人工标记(如白色圆形标签)，而视频流的低频和高延迟使其难以准确估计负载的状态。</p><p><a href="https://83cc9dc9-26fc-4d30-af80-fb51f5335552.filesusr.com/ugd/5878bd_9240d7f63adb4034aa2ee56c0291b309.pdf">Autonomous Swing-Angle Estimation for Stable Slung-Load Flight of Multi-Rotor UAVs </a>使用惯性测量单元(IMU)来估计负载的位置;但IMU作为积分型传感器，在长时间工作后可能会产生累积误差。</p><p>本文贡献分为三部分：</p><p>首先，针对无外界观测的实际场景（无法使用动作捕捉），设计了一种结合编码器和鱼眼摄像机的负载估计系统。通过对编码器和视觉信息的融合，进一步提出了一种基于高斯融合的估计算法，以获得精确和鲁棒的性能。</p><p>其次，提出了一种负载控制器，该控制器能够保证可靠的快速轨迹的跟踪性能。提高视觉-编码器估计系统检测缆绳是否绷紧，并自动切换控制策略。</p><p>最后，通过实验验证了整个估计系统对复杂飞行环境和极端负载变化的鲁棒性。</p><h2 id="估计器设计和建模"><a href="#估计器设计和建模" class="headerlink" title="估计器设计和建模"></a>估计器设计和建模</h2><h3 id="A-系统中的坐标系定义以及变量定义"><a href="#A-系统中的坐标系定义以及变量定义" class="headerlink" title="A 系统中的坐标系定义以及变量定义"></a>A 系统中的坐标系定义以及变量定义</h3><p><img src="https://tva3.sinaimg.cn/large/007mx13gly1gy1q179luvj30m30b6ada.jpg" alt="系统中定义的参数与变量"></p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1gy1q517w34j30yo0sfth9.jpg" alt="图1 坐标系定义"></p><h3 id="B-编码器设计和角度定义"><a href="#B-编码器设计和角度定义" class="headerlink" title="B 编码器设计和角度定义"></a>B 编码器设计和角度定义</h3><p>为了使载荷可控，载荷与微型飞行器之间的缆绳应保持拉紧。如果缆绳没有拉紧，MAV-载荷系统退化为普通MAV系统。因此，负载的工作空间一般为两个自由度可控的球壳。</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gy1qdmx9ooj30p00irjue.jpg" alt="图2 估计器坐标系的极坐标定义"></p><p>通过考虑估计器坐标系中的笛卡尔坐标，将负载向量投影到xOz, yOz平面上。分别定义角$θ_1$和$θ_2$，如上图所示。负载在估计器笛卡尔坐标系中的位置为</p>$$\left\{\begin{array}{l}x^{2}+y^{2}+z^{2}=l^{2} \\ \frac{x}{z}=\tan \theta_{1} \\ \frac{y}{z}=\tan \theta_{2}\end{array}\right. \tag{1}$$<p>其中当绳子拉紧时，<em>l</em>为常量。</p><p>为了测量$θ_1$和$θ_2$以上值，设计了一种新型的测量系统。设计的系统机构如图1所示。选用AS5047P磁旋转位置传感器作为角度传感器。AS5047P是一种高分辨率旋转位置传感器，可在360度范围内进行高速(高达28krpm)角度测量，几乎没有延迟。AS5047P具有强大的设计，可以抑制任何均匀外部杂散磁场的影响。标准的4线SPI串行接口允许主机微控制器从AS5047P读取14位绝对角度位置数据，无需专用编程器即可进行非易失性设置。如图2所示，设计了一种两轴平移机构来测量图3中提到的两个角度。为了减少轴之间的摩擦，高速轴承被采用并嵌入3d打印的支持。支架可进一步采用金属材料替代，可在承载要求较高的现场使用。传感器模型的详细介绍如下:</p><h3 id="C-相机模型"><a href="#C-相机模型" class="headerlink" title="C 相机模型"></a>C 相机模型</h3><p>装备一个向下的鱼眼摄像机来估计负载的状态，如图1所示。我们假定缆绳的末端与基于编码器的估计器的原点重合。编码器坐标系的原点距离摄像机光学中心的距离定义为$p^C_\mathcal{E}$。根据针孔相机模型，将相机到负载的单位矢量定义为</p>$$\mathbf{q}^{\mathcal{C}}=\frac{\left(\frac{\Delta u}{f_{x}}, \frac{\Delta v}{f_{y}}, 1\right)^{T}}{\left\|\left(\frac{\Delta u}{f_{x}}, \frac{\Delta v}{f_{y}}, 1\right)\right\|},$$<p>其中 $\Delta u$ 和 $\Delta v$ 有效载荷到图像中心的像素坐标; $f_{x}$ 和$f_{y}$ 通过相机标定获得相机模型的内在参数<a href="https://www.researchgate.net/publication/6899685_A_Generic_Camera_Model_and_Calibration_Method_for_Conventional_Wide-Angle_and_Fish-Eye_Lenses">A Generic Camera Model and Calibration Method for Conventional, Wide-Angle, and Fish-Eye Lenses (researchgate.net)</a>。 在世界坐标系下的负载位置由如下公式得到</p>$$\begin{gathered}\theta=\arccos \left(\mathbf{q}^{\mathcal{C}} \cdot \mathbf{p}_{\mathcal{E}}^{\mathcal{C}}\right), \\\bar{l}=\left\|\mathbf{p}_{\mathcal{E}}^{\mathcal{C}}\right\| \cos \theta+\sqrt{\left\|\mathbf{p}_{\mathcal{E}}^{\mathcal{c}}\right\|^{2} \cos ^{2} \theta-\left\|\mathbf{p}_{\mathcal{E}}^{\mathcal{C}}\right\|^{2}+l^{2},} \\\mathbf{x}_{L}^{\mathcal{E}}=\mathbf{R}_{\mathcal{C}}^{\mathcal{E}} \overline{l}{\mathbf{q}}^{\mathcal{C}}+\mathbf{p}_{\mathcal{C}}^{\mathcal{E}}, \\\mathbf{x}_{L}^{\mathcal{W}}=\mathbf{x}_{Q}^{\mathcal{W}}+\mathbf{R}_{\mathcal{B}}^{\mathcal{W}} \mathbf{R}_{\mathcal{E}}^{\mathcal{B}} \mathbf{x}_{L}^{\mathcal{E}}, \mathbf{q}^{\mathcal{W}}=\mathbf{x}_{L}^{\mathcal{W}} /\left\|\mathbf{x}_{L}^{\mathcal{W}}\right\|,\end{gathered}$$<p>其中$\theta$为 $\mathbf{q}^{\mathcal{C}}$与 $\mathbf{p}_{\mathcal{E}}^{\mathcal{C}} $之间的夹角， $ \bar{l}$ 是相机到有效载荷的估计距离。</p><p>在下面几节中我们省略了世界坐标系$\mathcal{W}$的上标，即q表示$q^\mathcal{W}$, x表示$x^\mathcal{W}$ ,R表示$R^\mathcal{W}_B$，从而简化表示。</p><h3 id="D-无人机-负载系统动力学"><a href="#D-无人机-负载系统动力学" class="headerlink" title="D 无人机-负载系统动力学"></a>D 无人机-负载系统动力学</h3><p>这部分内容与<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load | IEEE Conference Publication | IEEE Xplore</a>一样。</p><h2 id="负载位置和拉紧状态估计"><a href="#负载位置和拉紧状态估计" class="headerlink" title="负载位置和拉紧状态估计"></a>负载位置和拉紧状态估计</h2><p>本节介绍了基于视觉编码器的载荷估计器的算法框架，如下图所示。编码器和鱼眼摄像机的估计结果与高斯滤波器相融合，产生高频、实时且鲁棒的估计负载的位置以及缆绳的拉紧状态。</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gy1sb2p1qvj31780gh7cb.jpg" alt="估计器系统的框架"></p><h3 id="A-基于编码器的估计器"><a href="#A-基于编码器的估计器" class="headerlink" title="A 基于编码器的估计器"></a>A 基于编码器的估计器</h3><p>对于每个磁力编码器，角度数据通过模数转换获得，总量程$n_{total} = 2^{14}$。假设整个编码器系统的测量受到白噪声的干扰，则测量角度可以表示为</p>$\hat{\theta}=2 \pi \frac{n_{a d c}}{n_{\text {total }}}+w_{n},$<p>其中$n_{\text {adc }} \in\left[0, n_{\text {total }}\right]$为测量的原始角度, 而 $w_{n} \sim \mathcal{N}\left(0, \sigma_{e}^{2}\right)$。</p><p>根据编码器估计器系统的机械设计，测量值可以表示为</p>$$\begin{aligned}\mathbf{x}_{L}^{\mathcal{E}} &amp;=h(\hat{\theta}) \\&amp;=h(\theta)+\eta,\end{aligned}$$<p>其中函数 $h(\cdot)$ 是公式(1)所示测量函数，$\eta \in \mathbb{R}^{3}$ 是变换后的噪声方差。噪声由零均值高斯噪声描述，其协方差矩阵为 $R$。对于测量值 $\theta$， 条件概率密度为:</p>$$\begin{aligned}p\left(\mathbf{x}_{L}^{\mathcal{E}} \mid \theta\right) &amp;=\mathcal{N}\left(\mathbf{x}_{L}^{\mathcal{\varepsilon}} ; h(\theta), R\right) \\&amp;=\frac{1}{\sqrt{|2 \pi R|}} \exp \left(-\frac{1}{2}\left\|h(\theta)-\mathbf{x}_{L}^{\mathcal{\varepsilon}}\right\|_{R}^{2}\right) .\end{aligned}$$<h3 id="B-基于视觉的估计器"><a href="#B-基于视觉的估计器" class="headerlink" title="B 基于视觉的估计器"></a>B 基于视觉的估计器</h3><p>值得注意的是，如果缆绳处于松弛状态，基于编码器的估计器不能提供有效载荷位置的鲁棒估计;这将导致MAV飞行控制失败。为了解决这个问题，我们进一步利用了单目鱼眼相机;摄像机不仅用于检测缆绳的绷紧状态，还提供负载的位置信息。</p><p>为了实现鲁棒检测，采用STAPLE（<a href="https://ieeexplore.ieee.org/document/7780525">Staple: Complementary Learners for Real-Time Tracking | IEEE Conference Publication | IEEE Xplore</a>）跟踪负载，利用相关性过滤器(使用HOG特征)和全局颜色直方图的线性组合，构造如下的评分函数：</p>$$f(u, v)=\gamma_{t p} f_{t p}(u, v)+\gamma_{h t} f_{h t}(u, v),$$<p>其中 $f_{t p}(u, v)$ 为由相关过滤器计算的模板分数; $f_{h t}(u, v)$ 是直方图分数; $\gamma_{t p}$ 和 $\gamma_{h t}$  为评分函数中的权重。 STAPLE对运动模糊、光照变化、物体变形和复杂背景等具有挑战性的情况具有很强的鲁棒性。有了这些特征，我们的视觉系统在室内和室外实验中显示出了很强的鲁棒性。<br>此外，得益于基于编码器的估计器，我们赋予STAPLE检索丢失的跟踪对象的能力。在原始STAPLE中存有一个低概率事件，在重新跟踪对象时，对象是在视野之外。在我们的系统中，如果目标跟踪在基于视觉的估计器中失败，它将由基于编码器的估计器估计的位置重新初始化。</p><p>为了判断电缆的绷紧状态，计算基于编码器的估计器和基于视觉的估计器之间的估计位置差 $\Delta \mathbf{x}_{L}=\left\|\mathbf{x}_{L_{\text {vision }}}-\mathbf{x}_{L_{\text {encoder }}}\right\|_{2}$ 。</p><p>定义负载外接圆半径为<em>r</em>，当上述估计位置差小于<em>r</em>时，缆绳为拉紧，反之为松弛。</p><h3 id="C-基于视觉和编码器的传感器融合"><a href="#C-基于视觉和编码器的传感器融合" class="headerlink" title="C 基于视觉和编码器的传感器融合"></a>C 基于视觉和编码器的传感器融合</h3><p>如A、B节所述，编码器和基于视觉的估计器都提供了负载的位置估计。由于这两种估计都受到噪声干扰，因此有必要将两种传感器的测量结果进行融合以提供精确的结果。不失一般性，假设整个视觉-编码器系统得到的位置估计量$\mathbf{x}_{L_{e s t}}^{B}$服从高斯分布：</p>$$P\left(\mathbf{x}_{L_{e s t}}^{B}\right)=\mathcal{N}\left(\mu, \sigma^{2}\right) .\tag{2}$$<p>视觉和编码器的观测结果也服从高斯分布</p>$$P\left(\mathbf{x}_{L_{o b x}}^{\mathcal{B}}\right)=\mathcal{N}\left(\mu_{o b s}, \sigma_{o b s}^{2}\right) .$$<p>根据高斯分布的乘积，(2)中的参数计算为</p>$$\begin{gathered}\mu_{\text {est }}=\frac{\sigma_{\text {vision }}^{2} \mu_{\text {encoder }}+\sigma_{\text {vision }}^{2} \mu_{\text {encoder }}}{\sigma_{\text {vision }}^{2}+\sigma_{\text {encoder }}^{2}}, \\\sigma_{\text {est }}^{2}=\frac{\sigma_{\text {encoder }}^{2} \sigma_{\text {vision }}^{2}}{\sigma_{\text {vision }}^{2}+\sigma_{\text {encoder }}^{2}} .\end{gathered}$$<p>利用公式(1)，实时计算得到融合的负载位置估计。</p><blockquote><p>传感器融合实际上就是直接对两个传感器测得的同一个对象的测量值取平均数，从而降低测量值中的噪声，提高精确度。<a href="https://www.bilibili.com/video/BV1qV411e78g?from=search&amp;seid=17646318753860577233&amp;spm_id_from=333.337.0.0">了解传感器融合和跟踪 （全6P）MATLAB&amp;Simulink</a></p><p>对于上标B表示机体坐标系，但前文编码器中的负载位置在估计器坐标系中表示，不对应有问题。</p></blockquote><h2 id="轨迹生成与控制"><a href="#轨迹生成与控制" class="headerlink" title="轨迹生成与控制"></a>轨迹生成与控制</h2><h3 id="A-轨迹生成"><a href="#A-轨迹生成" class="headerlink" title="A 轨迹生成"></a>A 轨迹生成</h3><p>这部分内容与<a href="https://ieeexplore.ieee.org/document/8258883">Aggressive Flight With Suspended Payloads Using Vision-Based Control | IEEE Journals &amp; Magazine | IEEE Xplore</a>类似，本文负载位置最高阶导数为4阶，而<a href="https://ieeexplore.ieee.org/document/8258883">Aggressive Flight With Suspended Payloads Using Vision-Based Control | IEEE Journals &amp; Magazine | IEEE Xplore</a>中变量对应的负载位置最高阶导数为6阶。</p><h3 id="B-控制设计和控制器切换策略"><a href="#B-控制设计和控制器切换策略" class="headerlink" title="B 控制设计和控制器切换策略"></a>B 控制设计和控制器切换策略</h3><p>与<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load | IEEE Conference Publication | IEEE Xplore</a>的控制器一样，分为绳子有张力和无张力处理。有张力时为一个负载-无人机系统。无张力时，系统退化为无人机和负载两个系统。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>无人机重量为1.96kg，负载重量为0.168kg。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
            <tag> 负载状态 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICRA2019文章目录</title>
      <link href="/2022/01/03/icra2019-paper-list/"/>
      <url>/2022/01/03/icra2019-paper-list/</url>
      
        <content type="html"><![CDATA[<h1 id="ICRA2019-paper-list"><a href="#ICRA2019-paper-list" class="headerlink" title="ICRA2019-paper-list"></a>ICRA2019-paper-list</h1><p>The 2019 International Conference on Robotics and Automation (ICRA) has been held on 20-24 May 2019 in Montreal, Canada. The ICRA 2019 is a flagship IEEE Robotics &amp; Automation Society conference and will feature a premiere international venue for international robotics researchers.</p><p>This list is edited by <a href="https://github.com/PaoPaoRobot">PaopaoRobot, 泡泡机器人</a> , the Chinese academic nonprofit organization. Recently we will classify these papers by topics. Welcome to follow our github and our WeChat Public Platform Account ( <a href="https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&amp;mid=100000102&amp;idx=1&amp;sn=0a8a831a4f2c18443dbf436ef5d5ff8c&amp;chksm=6c10bf625b6736748c9612879e166e510f1fe301b72ed5c5d7ecdd0f40726c5d757e975f37af&amp;mpshare=1&amp;scene=1&amp;srcid=0530KxSLjUE9I38yLgfO2nVm&amp;pass_ticket=0aB5tcjeTfmcl9u0eSVzN4Ag4tkpM2RjRFH8DG9vylE%3D#rd">paopaorobot_slam</a> ). Of course, you could contact with <a href="https://github.com/yvonshong">Yvon Shong</a>.</p><div class="table-container"><table><thead><tr><th style="text-align:center">index</th><th style="text-align:left">paper title</th></tr></thead><tbody><tr><td style="text-align:center">0007</td><td style="text-align:left">High-Fidelity Grasping in Virtual Reality Using Glove-Based System</td></tr><tr><td style="text-align:center">0008</td><td style="text-align:left">Self-Supervised Incremental Learning for Sound Source Localization in Complex Indoor Environment</td></tr><tr><td style="text-align:center">0016</td><td style="text-align:left">Unsupervised Out-Of-Context Action Understanding</td></tr><tr><td style="text-align:center">0031</td><td style="text-align:left">Aided Inertial Navigation - Unified Feature Representations and Observability Analysis</td></tr><tr><td style="text-align:center">0036</td><td style="text-align:left">Learning Wheel Odometry and IMU Errors for Localization</td></tr><tr><td style="text-align:center">0038</td><td style="text-align:left">Balance Map Analysis As a Measure of Walking Balance Based on Pendulum-Like Leg Movements</td></tr><tr><td style="text-align:center">0039</td><td style="text-align:left">A New Approach for an Adaptive Linear Quadratic Regulated Motion Cueing Algorithm for an 8 DoF Full Motion Driving Simulator</td></tr><tr><td style="text-align:center">0041</td><td style="text-align:left">MH-iSAM2 - Multi-Hypothesis iSAM Using Bayes Tree and Hypo-Tree</td></tr><tr><td style="text-align:center">0047</td><td style="text-align:left">Singularity of Cable-Driven Parallel Robot with Sagging Cables - Preliminary Investigation</td></tr><tr><td style="text-align:center">0049</td><td style="text-align:left">On the Combination of Gamification and Crowd Computation in Industrial Automation and Robotics Applications</td></tr><tr><td style="text-align:center">0055</td><td style="text-align:left">Locomotion Dynamics of a Miniature Wave-Like Robot Modeling and Experiments</td></tr><tr><td style="text-align:center">0060</td><td style="text-align:left">Deep Reinforcement Learning of Navigation in a Complex and Crowded Environment with a Limited Field of View</td></tr><tr><td style="text-align:center">0070</td><td style="text-align:left">Lifelong Learning for Heterogeneous Multi-Modal Tasks</td></tr><tr><td style="text-align:center">0073</td><td style="text-align:left">Trajectory Planning for a Tractor with Multiple Trailers in Extremely Narrow Environments - A Unified Approach</td></tr><tr><td style="text-align:center">0075</td><td style="text-align:left">Detection-By-Localization - Maintenance-Free Change Object Detector</td></tr><tr><td style="text-align:center">0078</td><td style="text-align:left">Living with a Mobile Companion Robot in Your Own Apartment - Final Implementation and Results of a 20-Weeks Field Study</td></tr><tr><td style="text-align:center">0082</td><td style="text-align:left">Improving Data Efficiency of Self-Supervised Learning for Robotic Grasping</td></tr><tr><td style="text-align:center">0085</td><td style="text-align:left">Design of a Modular Continuum Robot Segment for Use in a General Purpose Manipulator</td></tr><tr><td style="text-align:center">0090</td><td style="text-align:left">Linear Heterogeneous Reconfiguration of Cubic Modular Robots Via Simultaneous Tunneling and Permutation</td></tr><tr><td style="text-align:center">0095</td><td style="text-align:left">Visual SLAM - Why Bundle Adjust</td></tr><tr><td style="text-align:center">0109</td><td style="text-align:left">Analytic Collision Risk Calculation for Autonomos Vehicle Navigation</td></tr><tr><td style="text-align:center">0111</td><td style="text-align:left">Oriented Point Sampling for Plane Detection in Unorganized Point Clouds</td></tr><tr><td style="text-align:center">0114</td><td style="text-align:left">1-Actuator 3-DoF Manipulation Using an Underactuated Mechanism with Multiple Nonparallel and Viscoelastic Passive Joints</td></tr><tr><td style="text-align:center">0116</td><td style="text-align:left">Critically Fast Pick-And-Place with Suction Cups</td></tr><tr><td style="text-align:center">0118</td><td style="text-align:left">Project AutoVision - Localization and 3D Scene Perception for an Autonomous Vehicle with a Multi-Camera System</td></tr><tr><td style="text-align:center">0120</td><td style="text-align:left">A Kalman Filter-Based Algorithm for Simultaneous Time Synchronization and Localization in UWB Networks</td></tr><tr><td style="text-align:center">0122</td><td style="text-align:left">Pose Graph Optimization for Unsupervised Monocular Visual Odometry</td></tr><tr><td style="text-align:center">0123</td><td style="text-align:left">3D Printed Soft Pneumatic Actuators with Intent Sensing for Hand Rehabilitative Exoskeletons</td></tr><tr><td style="text-align:center">0124</td><td style="text-align:left">Dual Refinement Network for Single-Shot Object Detection</td></tr><tr><td style="text-align:center">0126</td><td style="text-align:left">DeltaMag - An Electromagnetic Manipulation System with Parallel Mobile Coils</td></tr><tr><td style="text-align:center">0128</td><td style="text-align:left">Interactive Open-Ended Object Affordance and Grasp Learning for Robotic Manipulation</td></tr><tr><td style="text-align:center">0129</td><td style="text-align:left">Eagle Shoal - A New Designed Modular Tactile Sensing Dexterous Hand for Domestic Service Robots</td></tr><tr><td style="text-align:center">0131</td><td style="text-align:left">Uncertainty-Aware Path Planning for Navigation on Road Networks Using Augmented MDPs</td></tr><tr><td style="text-align:center">0143</td><td style="text-align:left">Dynamically-consistent Generalized Hierarchical Control</td></tr><tr><td style="text-align:center">0144</td><td style="text-align:left">Multi-Modal Geometric Learning for Grasping and Manipulation</td></tr><tr><td style="text-align:center">0148</td><td style="text-align:left">Online Continuous Mapping Using Gaussian Process Implicit Surfaces</td></tr><tr><td style="text-align:center">0150</td><td style="text-align:left">A Compliant and Precise Pneumatic Rotary Drive Using Pneumatic Artificial Muscles in a Swash Plate Design</td></tr><tr><td style="text-align:center">0151</td><td style="text-align:left">Team-Based Robot Righting via Pushing and Shell Design</td></tr><tr><td style="text-align:center">0152</td><td style="text-align:left">Autonomous Latching System for Self-driving Robotic Boats</td></tr><tr><td style="text-align:center">0153</td><td style="text-align:left">Reshaping Particle Configurations by Collisions with Rigid Objects</td></tr><tr><td style="text-align:center">0155</td><td style="text-align:left">Learning to Capture a Film-Look Video with a Camera Drone</td></tr><tr><td style="text-align:center">0156</td><td style="text-align:left">Chance Constrained Motion Planning for High-Dimensional Robots</td></tr><tr><td style="text-align:center">0163</td><td style="text-align:left">Design and Experimental Validation of a 2DOF Sidestick Powered by Hyper-Redundant Magnetorheological Actuators Providing Active Feedback</td></tr><tr><td style="text-align:center">0165</td><td style="text-align:left">Robotic Endoscopy System (easyEndo) with a Robotic Arm Mountable on a Conventional Endoscope</td></tr><tr><td style="text-align:center">0170</td><td style="text-align:left">RoPose-Real - Real World Dataset Acquisition for Data-Driven Industrial Robot Arm Pose Estimation</td></tr><tr><td style="text-align:center">0174</td><td style="text-align:left">Analyzing Electromagnetic Actuator Based on Force Analysis</td></tr><tr><td style="text-align:center">0175</td><td style="text-align:left">Stiffness-Tuneable Limb Segment with Flexible Spine for Malleable Robots</td></tr><tr><td style="text-align:center">0179</td><td style="text-align:left">Door Opening and Traversal with an Industrial Cartesian Impedance Controlled Mobile Robot</td></tr><tr><td style="text-align:center">0180</td><td style="text-align:left">Improving Dual-Arm Assembly by Master-Slave Compliance</td></tr><tr><td style="text-align:center">0181</td><td style="text-align:left">Design and Testing of a New Cell Microinjector with Embedded Soft Force Sensor</td></tr><tr><td style="text-align:center">0185</td><td style="text-align:left">Design and Control of a Passively Morphing Quadcopter</td></tr><tr><td style="text-align:center">0190</td><td style="text-align:left">Closing the Sim-To-Real Loop - Adapting Simulation Randomization with Real World Experience</td></tr><tr><td style="text-align:center">0193</td><td style="text-align:left">Learning Ad-Hoc Compact Representations from Salient Landmarks for Visual Place Recognition in Underwater Environments</td></tr><tr><td style="text-align:center">0196</td><td style="text-align:left">An Actively Controlled Variable Stiffness Structure Via Layer Jamming and Pneumatic Actuation</td></tr><tr><td style="text-align:center">0204</td><td style="text-align:left">High-Speed Ring Insertion by Dynamic Observable Contact Hand</td></tr><tr><td style="text-align:center">0206</td><td style="text-align:left">Sensorless Force Control of Automated GrindingDeburring Using an Adjustable Force Regulation Mechanism</td></tr><tr><td style="text-align:center">0212</td><td style="text-align:left">A Variational Observation Model of 3D Object for Probabilistic Semantic SLAM</td></tr><tr><td style="text-align:center">0214</td><td style="text-align:left">Trust Regions for Safe Sampling-Based Model Predictive Control</td></tr><tr><td style="text-align:center">0215</td><td style="text-align:left">Velocity Constrained Trajectory Generation for a Collinear Mecanum Wheeled Robot</td></tr><tr><td style="text-align:center">0216</td><td style="text-align:left">Exploiting a Human-Aware World Model for Dynamic Task Allocation in Flexible Human-Robot Teams</td></tr><tr><td style="text-align:center">0222</td><td style="text-align:left">Automatic Labeled LiDAR Data Generation Based on Precise Human Model</td></tr><tr><td style="text-align:center">0226</td><td style="text-align:left">eRTIS - A Fully Embedded Real Time 3D Imaging Sonar Sensor for Robotic Applications</td></tr><tr><td style="text-align:center">0233</td><td style="text-align:left">Personalized Online Learning and Classification of Whole-Body Motions Using Multiple Inertial Measurement Units</td></tr><tr><td style="text-align:center">0235</td><td style="text-align:left">Improving Incremental Planning Performance through Overlapping Replanning and Execution</td></tr><tr><td style="text-align:center">0239</td><td style="text-align:left">Tightly Coupled 3D Lidar Inertial Odometry and Mapping</td></tr><tr><td style="text-align:center">0243</td><td style="text-align:left">Vibration Control for Manipulators on a Translationally Flexible Base</td></tr><tr><td style="text-align:center">0245</td><td style="text-align:left">Towards Learning Abstract Representations for Locomotion Planning in High-Dimensional State Spaces</td></tr><tr><td style="text-align:center">0246</td><td style="text-align:left">Online Object and Task Learning Via Human Robot Interaction</td></tr><tr><td style="text-align:center">0248</td><td style="text-align:left">I Can See Clearly Now - Image Restoration Via De-Raining</td></tr><tr><td style="text-align:center">0250</td><td style="text-align:left">Robots Learn Social Skills - End-To-End Learning of Co-Speech Gesture Generation for Humanoid Robots</td></tr><tr><td style="text-align:center">0251</td><td style="text-align:left">Fast Stochastic Functional Path Planning in Occupancy Maps</td></tr><tr><td style="text-align:center">0253</td><td style="text-align:left">Active Constraints for Tool-Shaft Collision Avoidance in Minimally Invasive Surgery</td></tr><tr><td style="text-align:center">0254</td><td style="text-align:left">A Defect Identification Approach of Operations for the Driving Element of Multi-Duty Parallel Manipulators</td></tr><tr><td style="text-align:center">0255</td><td style="text-align:left">Reconfigurable Network for Efficient Inferencing in Autonomous Vehicles</td></tr><tr><td style="text-align:center">0257</td><td style="text-align:left">A Linear-Complexity EKF for Visual-Inertial Navigation with Loop Closures</td></tr><tr><td style="text-align:center">0264</td><td style="text-align:left">Cannot Avoid Penalty Lets Minimize</td></tr><tr><td style="text-align:center">0268</td><td style="text-align:left">Streamlines for Motion Planning in Underwater Currents</td></tr><tr><td style="text-align:center">0274</td><td style="text-align:left">A Novel Reconfigurable Revolute Joint with Adjustable Stiffness</td></tr><tr><td style="text-align:center">0276</td><td style="text-align:left">Multi-Modal Generative Models for Learning Epistemic Active Sensing</td></tr><tr><td style="text-align:center">0280</td><td style="text-align:left">Generation of Stealth Walking Gait on Low-Friction Road Surface</td></tr><tr><td style="text-align:center">0284</td><td style="text-align:left">Improving Drone Localisation Around Wind Turbines Using Monocular Model-Based Tracking</td></tr><tr><td style="text-align:center">0286</td><td style="text-align:left">Hierarchical Depthwise Graph Convolutional Neural Network for 3D Semantic Segmentation of Point Clouds</td></tr><tr><td style="text-align:center">0288</td><td style="text-align:left">Methodology of Designing Multi-Agent Robot Control Systems Utilising Hierarchical Petri Nets</td></tr><tr><td style="text-align:center">0291</td><td style="text-align:left">Scanning the Internet for ROS - A View of Security in Robotics Research</td></tr><tr><td style="text-align:center">0297</td><td style="text-align:left">Robotic Orientation Control of Deformable Cells</td></tr><tr><td style="text-align:center">0299</td><td style="text-align:left">Expectation-Maximization for Adaptive Mixture Models in Graph Optimization</td></tr><tr><td style="text-align:center">0306</td><td style="text-align:left">FMD Stereo SLAM - Fusing MVG and Direct Formulation towards Accurate and Fast Stereo SLAM</td></tr><tr><td style="text-align:center">0307</td><td style="text-align:left">Self-Supervised Surgical Tool Segmentation Using Kinematic Information</td></tr><tr><td style="text-align:center">0310</td><td style="text-align:left">Design and Formal Verification of a Safe Stop Supervisor for an Automated Vehicle</td></tr><tr><td style="text-align:center">0314</td><td style="text-align:left">Modeling and Planning Manipulation in Dynamic Environments</td></tr><tr><td style="text-align:center">0317</td><td style="text-align:left">Lidar Measurement Bias Estimation Via Return Waveform Modelling in a Context of 3D Mapping</td></tr><tr><td style="text-align:center">0320</td><td style="text-align:left">Fast Radar Motion Estimation with a Learnt Focus of Attention Using Weak Supervision</td></tr><tr><td style="text-align:center">0322</td><td style="text-align:left">Probably Unknown - Deep Inverse Sensor Modelling in Radar</td></tr><tr><td style="text-align:center">0326</td><td style="text-align:left">Rorg - Service Robot Software Management with Linux Containers</td></tr><tr><td style="text-align:center">0327</td><td style="text-align:left">Augmented Reality Assisted Instrument Insertion and Tool Manipulation for the First Assistant in Robotic Surgery</td></tr><tr><td style="text-align:center">0329</td><td style="text-align:left">Sim-To-Real Transfer Learning Using Robustified Controllers in Robotic Tasks Involving Complex Dynamics</td></tr><tr><td style="text-align:center">0331</td><td style="text-align:left">Kinematically Redundant (63)-Dof Hybrid Parallel Robot with Large Orientational Workspace and Remotely Operated Gripper</td></tr><tr><td style="text-align:center">0334</td><td style="text-align:left">The Robust Canadian Traveler Problem Applied to Robot Routing</td></tr><tr><td style="text-align:center">0335</td><td style="text-align:left">Trajectory-Based Probabilistic Policy Gradient for Learning Locomotion Behaviors</td></tr><tr><td style="text-align:center">0336</td><td style="text-align:left">Localization with Sliding Window Factor Graphs on Third-Party Maps for Automated Driving</td></tr><tr><td style="text-align:center">0337</td><td style="text-align:left">LineRanger Analysis and Field Testing of an Innovative Robot for Efficient Assessment of Bundled High-Voltage Powerlines</td></tr><tr><td style="text-align:center">0340</td><td style="text-align:left">DeepSignals - Predicting Intent of Drivers through Visual Attributes</td></tr><tr><td style="text-align:center">0341</td><td style="text-align:left">Structured Domain Randomization - Bridging the Reality Gap by Context-Aware Synthetic Data</td></tr><tr><td style="text-align:center">0343</td><td style="text-align:left">Nonlinear System Identification of Soft Robot Dynamics Using Koopman Operator Theory</td></tr><tr><td style="text-align:center">0345</td><td style="text-align:left">Visual Diver Recognition for Underwater Human-Robot Collaboration</td></tr><tr><td style="text-align:center">0352</td><td style="text-align:left">Dynamic Period-Two Gait Generation in a Hexapod Robot Based on the Fixed-Point Motion of a Reduced-Order Model</td></tr><tr><td style="text-align:center">0353</td><td style="text-align:left">Sensor-Failure-Resilient Multi-IMU Visual-Inertial Navigation</td></tr><tr><td style="text-align:center">0354</td><td style="text-align:left">Learning To Grasp Under Uncertainty Using POMDPs</td></tr><tr><td style="text-align:center">0355</td><td style="text-align:left">Enabling Identity-Aware Tracking Via Fusion of Visual and Inertial Features</td></tr><tr><td style="text-align:center">0357</td><td style="text-align:left">Autonomous Tissue Manipulation via Surgical Robot Using Learning Based Model Predictive Control</td></tr><tr><td style="text-align:center">0359</td><td style="text-align:left">Flying STAR a Hybrid Crawling and Flying Sprawl Tuned Robot</td></tr><tr><td style="text-align:center">0362</td><td style="text-align:left">A New Approach to Local Navigation for Autonomous Driving Vehicles Based on the Curvature Velocity Method</td></tr><tr><td style="text-align:center">0364</td><td style="text-align:left">Risk Averse Robust Adversarial Reinforcement Learning</td></tr><tr><td style="text-align:center">0366</td><td style="text-align:left">Predicting Vehicle Behaviors Over an Extended Horizon Using Behavior Interaction Network</td></tr><tr><td style="text-align:center">0367</td><td style="text-align:left">Who Takes What - Using RGB-D Camera and Inertial Sensor for Unmanned Monitor</td></tr><tr><td style="text-align:center">0368</td><td style="text-align:left">Radar-only ego-motion estimation in difficult settings via graph matching</td></tr><tr><td style="text-align:center">0371</td><td style="text-align:left">LookUP - Vision-Only Real-Time Precise Underground Localisation for Autonomous Mining Vehicles</td></tr><tr><td style="text-align:center">0373</td><td style="text-align:left">Efficient Obstacle Rearrangement for Object Manipulation Tasks in Cluttered Environments</td></tr><tr><td style="text-align:center">0374</td><td style="text-align:left">Bounded Collision Force by the Sobolev Norm</td></tr><tr><td style="text-align:center">0376</td><td style="text-align:left">Distortion-free Robotic Surface-drawing using Conformal Mapping</td></tr><tr><td style="text-align:center">0378</td><td style="text-align:left">Uncertainty Estimation for Projecting Lidar Points Onto Camera Images for Moving Platforms</td></tr><tr><td style="text-align:center">0380</td><td style="text-align:left">Surgical Instrument Segmentation for Endoscopic Vision with Data Fusion of CNN Prediction and Kinematic Pose</td></tr><tr><td style="text-align:center">0383</td><td style="text-align:left">Pneumatically Actuated Deployable Tissue Distension Device for NOTES for Colon</td></tr><tr><td style="text-align:center">0389</td><td style="text-align:left">Efficient Integrity Monitoring for KF-Based Localization</td></tr><tr><td style="text-align:center">0390</td><td style="text-align:left">SweepNet - Wide-Baseline Omnidirectional Depth Estimation</td></tr><tr><td style="text-align:center">0393</td><td style="text-align:left">Inkjet Printable Actuators and Sensors for Soft-bodied Crawling Robots</td></tr><tr><td style="text-align:center">0394</td><td style="text-align:left">Guaranteed Active Constraints Enforcement on Point Cloud-Approximated Regions for Surgical Applications</td></tr><tr><td style="text-align:center">0395</td><td style="text-align:left">3D Surface Reconstruction Using a Two-Step Stereo Matching Method Assisted with Five Projected Patterns</td></tr><tr><td style="text-align:center">0397</td><td style="text-align:left">Learning from Extrapolated Corrections</td></tr><tr><td style="text-align:center">0399</td><td style="text-align:left">A New Robot Skating on Water Surface Intimating Water Striders Based on Flexible Driving Mechanism</td></tr><tr><td style="text-align:center">0405</td><td style="text-align:left">Assembly of Multilayered Hepatic Lobule-Like Vascular Network by Using Heptapole Magnetic Tweezer</td></tr><tr><td style="text-align:center">0408</td><td style="text-align:left">Dynamic Manipulation of Flexible Objects with Torque Sequence Using a Deep Neural Network</td></tr><tr><td style="text-align:center">0409</td><td style="text-align:left">Distant Vehicle Detection Using Radar and Vision</td></tr><tr><td style="text-align:center">0412</td><td style="text-align:left">Point Cloud Compression for 3D LiDAR Sensor Using Recurrent Neural Network with Residual Blocks</td></tr><tr><td style="text-align:center">0413</td><td style="text-align:left">Graduated Fidelity Lattices for Motion Planning under Uncertainty</td></tr><tr><td style="text-align:center">0417</td><td style="text-align:left">Multimodal Policy Search Using Overlapping Mixtures of Sparse Gaussian Process Prior</td></tr><tr><td style="text-align:center">0420</td><td style="text-align:left">Goal-Driven Navigation for Non-Holonomic Multi-Robot System by Learning Collision</td></tr><tr><td style="text-align:center">0421</td><td style="text-align:left">Designing an Accurate and Customizable Epidural Anaesthesia Haptic Simulator</td></tr><tr><td style="text-align:center">0423</td><td style="text-align:left">Asymmetric Local Metric Learning with PSD Constraint for Person Re-Identification</td></tr><tr><td style="text-align:center">0424</td><td style="text-align:left">Active Multi-Contact Continuous Tactile Exploration with Gaussian Process Differential Entropy</td></tr><tr><td style="text-align:center">0427</td><td style="text-align:left">Multi-View Picking - Next-Best-View Reaching for Improved Grasping in Clutter</td></tr><tr><td style="text-align:center">0428</td><td style="text-align:left">Exploiting Human and Robot Muscle Synergies for Human-In-The-Loop Optimization of EMG-Based Assistive Strategies</td></tr><tr><td style="text-align:center">0431</td><td style="text-align:left">Road Detection through CRF based LiDAR-Camera Fusion</td></tr><tr><td style="text-align:center">0434</td><td style="text-align:left">Real-Time Model Based Path Planning for Wheeled Vehicles</td></tr><tr><td style="text-align:center">0435</td><td style="text-align:left">Leveraging Temporal Reasoning for Policy Selection in Learning from Demonstration</td></tr><tr><td style="text-align:center">0442</td><td style="text-align:left">CartesIO - A ROS Based Real-Time Capable Cartesian Control Framework</td></tr><tr><td style="text-align:center">0445</td><td style="text-align:left">Incorporating End-To-End Speech Recognition Models for Sentiment Analysis</td></tr><tr><td style="text-align:center">0446</td><td style="text-align:left">Self-Modifying Morphology Experiments with DyRET - Dynamic Robot for Embodied Testing</td></tr><tr><td style="text-align:center">0447</td><td style="text-align:left">Probabilistic Active Filtering for Object Search in Clutter</td></tr><tr><td style="text-align:center">0448</td><td style="text-align:left">Improving Keypoint Matching Using a Landmark-Based Image Representation</td></tr><tr><td style="text-align:center">0450</td><td style="text-align:left">Resolved Viscoelasticity Control Considering Singularity for Knee-Stretched Walking of a Humanoid</td></tr><tr><td style="text-align:center">0451</td><td style="text-align:left">Multimodal Spatio-Temporal Information in End-To-End Networks for Automotive Steering Prediction</td></tr><tr><td style="text-align:center">0452</td><td style="text-align:left">Online Multilayered Motion Planning with Dynamic Constraints for Autonomous Underwater Vehicles</td></tr><tr><td style="text-align:center">0456</td><td style="text-align:left">Robust 3D Object Classification by Combining Point Pair Features and Graph Convolution</td></tr><tr><td style="text-align:center">0465</td><td style="text-align:left">Visual Repetition Sampling for Robot Manipulation Planning</td></tr><tr><td style="text-align:center">0467</td><td style="text-align:left">Adding Cues to Binary Feature Descriptors for Visual Place Recognition</td></tr><tr><td style="text-align:center">0468</td><td style="text-align:left">Autonomous Cooperative Flight of Rigidly Attached Quadcopters</td></tr><tr><td style="text-align:center">0469</td><td style="text-align:left">A Novel Force Sensor with Zero Stiffness at Contact Transition Based on Optical Line Generation</td></tr><tr><td style="text-align:center">0475</td><td style="text-align:left">Performance Metrics for a Robotic Actuation System Using Static and Mobile Electromagnets</td></tr><tr><td style="text-align:center">0476</td><td style="text-align:left">Merging Position and Orientation Motion Primitives</td></tr><tr><td style="text-align:center">0477</td><td style="text-align:left">A Fast and Robust 3D Person Detector and Posture Estimator for Mobile Robotic Applications</td></tr><tr><td style="text-align:center">0481</td><td style="text-align:left">Energy Budget Transaction Protocol for Distributed Robotic Systems</td></tr><tr><td style="text-align:center">0485</td><td style="text-align:left">Position Control of Medical Cable-Driven Flexible Instruments by Combining Machine Learning and Kinematic Analysis</td></tr><tr><td style="text-align:center">0486</td><td style="text-align:left">Robot Localization Based on Aerial Images for Precision Agriculture Tasks in Crop Fields</td></tr><tr><td style="text-align:center">0487</td><td style="text-align:left">A Bio-Robotic Remora Disc with Attachment and Detachment Capabilities for Reversible Underwater Hitchhiking</td></tr><tr><td style="text-align:center">0494</td><td style="text-align:left">Disturbance Compensation Based Control for an Indoor Blimp Robot</td></tr><tr><td style="text-align:center">0499</td><td style="text-align:left">Automated Models of Human Everyday Activity Based on Game and Virtual Reality Technology</td></tr><tr><td style="text-align:center">0501</td><td style="text-align:left">Factored Contextual Policy Search with Bayesian Optimization</td></tr><tr><td style="text-align:center">0502</td><td style="text-align:left">Fabrication and Characterization of Muscle Rings Using Circular Mould and Rotary Electrical Stimulation for Bio-Syncretic Robots</td></tr><tr><td style="text-align:center">0504</td><td style="text-align:left">Learning Haptic Exploration Schemes for Adaptive Task Execution</td></tr><tr><td style="text-align:center">0506</td><td style="text-align:left">Every Hop Is an Opportunity - Quickly Classifying and Adapting to Terrain During Targeted Hopping</td></tr><tr><td style="text-align:center">0508</td><td style="text-align:left">Fast and Robust Initialization for Visual-Inertial SLAM</td></tr><tr><td style="text-align:center">0510</td><td style="text-align:left">Hydraulically-Actuated Compliant Revolute Joint for Medical Robotic Systems Based on Multimaterial Additive Manufacturing</td></tr><tr><td style="text-align:center">0520</td><td style="text-align:left">Bonnet - An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs</td></tr><tr><td style="text-align:center">0521</td><td style="text-align:left">Robotic Control of a Multi-Modal Rigid Endoscope Combining Optical Imaging with All-Optical Ultrasound</td></tr><tr><td style="text-align:center">0522</td><td style="text-align:left">ScalableFusion - High-Resolution Mesh-Based Real-Time 3D Reconstruction</td></tr><tr><td style="text-align:center">0523</td><td style="text-align:left">EasyLabel - A Semi-Automatic Pixel-Wise Object Annotation Tool for Creating Robotic RGB-D Datasets</td></tr><tr><td style="text-align:center">0525</td><td style="text-align:left">Cell Injection Microrobot Development and Evaluation in Microfluidic Chip</td></tr><tr><td style="text-align:center">0527</td><td style="text-align:left">One-Shot Learning of Multi-Step Tasks from Observation Via Activity Localization in Auxiliary Video</td></tr><tr><td style="text-align:center">0531</td><td style="text-align:left">A Flexible Low-Cost Biologically Inspired Sonar Sensor Platform for Robotic Applications</td></tr><tr><td style="text-align:center">0532</td><td style="text-align:left">Tele-Echography Using a Two-Layer Teleoperation Algorithm with Energy Scaling</td></tr><tr><td style="text-align:center">0535</td><td style="text-align:left">Discontinuity-Sensitive Optimal Control Learning by Mixture of Experts</td></tr><tr><td style="text-align:center">0538</td><td style="text-align:left">Sliding Mode Momentum Observers for Estimation of External Torques and Joint Acceleration</td></tr><tr><td style="text-align:center">0540</td><td style="text-align:left">Enabling Technology for Safe Robot-Assisted Retinal Surgery - Early Warning for Unsafe Scleral Force</td></tr><tr><td style="text-align:center">0547</td><td style="text-align:left">Real-Time Intent Prediction of Pedestrians for Autonomous Ground Vehicles Via Spatio-Temporal DenseNet</td></tr><tr><td style="text-align:center">0549</td><td style="text-align:left">High-Precision Localization Using Ground Texture</td></tr><tr><td style="text-align:center">0551</td><td style="text-align:left">Approximate Probabilistic Security for Networked Multi-Robot Systems</td></tr><tr><td style="text-align:center">0552</td><td style="text-align:left">Actively Improving Robot Navigation on Different Terrains Using Gaussian Process Mixture Models</td></tr><tr><td style="text-align:center">0554</td><td style="text-align:left">State Estimation in Contact-Rich Manipulation</td></tr><tr><td style="text-align:center">0555</td><td style="text-align:left">On Parameter Estimation of Space Manipulator Systems with Flexible Joints Using the Energy Balance</td></tr><tr><td style="text-align:center">0556</td><td style="text-align:left">Needle Localization for Robot-Assisted Subretinal Injection Based on Deep Learning</td></tr><tr><td style="text-align:center">0561</td><td style="text-align:left">KO-Fusion - Dense Visual SLAM with Tightly-Coupled Kinematic and Odometric Tracking</td></tr><tr><td style="text-align:center">0563</td><td style="text-align:left">Deep Multi-Sensory Object Category Recognition Using Interactive Behavioral Exploration</td></tr><tr><td style="text-align:center">0564</td><td style="text-align:left">Online Adaptation of Uncertain Models Using Neural Network Priors and Partially Observable Planning</td></tr><tr><td style="text-align:center">0570</td><td style="text-align:left">A Parallel Low-Impedance Sensing Approach for Highly Responsive Physical Human-Robot Interaction</td></tr><tr><td style="text-align:center">0575</td><td style="text-align:left">Feasible Coordination of Multiple Homogeneous or Heterogeneous Mobile Vehicles with Various Constraints</td></tr><tr><td style="text-align:center">0576</td><td style="text-align:left">Deformation-based shape control with a multirobot system</td></tr><tr><td style="text-align:center">0579</td><td style="text-align:left">Kinematic Analysis of a 4-DOF Parallel Mechanism with Large Translational and Orientational Workspace</td></tr><tr><td style="text-align:center">0580</td><td style="text-align:left">ClusterNav - Learning-Based Robust Navigation Operating in Cluttered Environments</td></tr><tr><td style="text-align:center">0582</td><td style="text-align:left">Experimental Assessment of Plume Mapping Using Point Measurements from Unmanned Vehicles</td></tr><tr><td style="text-align:center">0584</td><td style="text-align:left">A New Overloading Fatigue Model for Ergonomic Risk Assessment with Application to Human-Robot Collaboration</td></tr><tr><td style="text-align:center">0587</td><td style="text-align:left">Safe Human Robot Cooperation in Task Performed on the Shared Load</td></tr><tr><td style="text-align:center">0588</td><td style="text-align:left">Studies on Positioning Manipulators Actuated by Solid Media Transmissions</td></tr><tr><td style="text-align:center">0589</td><td style="text-align:left">Learning Scene Geometry for Visual Localization in Challenging Conditions</td></tr><tr><td style="text-align:center">0591</td><td style="text-align:left">Robotic Joint Control System based on Analogue Spiking Neural Networks and SMA Actuators</td></tr><tr><td style="text-align:center">0593</td><td style="text-align:left">Robust Generalized Point Set Registration Using Inhomogeneous Hybrid Mixture Models Via Expectation Maximization</td></tr><tr><td style="text-align:center">0595</td><td style="text-align:left">CNN-SVO - Improving the Mapping in Semi-Direct Visual Odometry Using Single-Image Depth Prediction</td></tr><tr><td style="text-align:center">0598</td><td style="text-align:left">Model Based in Situ Calibration with Temperature Compensation of 6 Axis Force Torque Sensors</td></tr><tr><td style="text-align:center">0600</td><td style="text-align:left">Learning Robust Manipulation Skills with Guided Policy Search Via Generative Motor Reflexes</td></tr><tr><td style="text-align:center">0601</td><td style="text-align:left">Development of a Strain Gauge Based Disturbance Estimation and Compensation Technique for a Wheeled Inverted Pendulum Robot</td></tr><tr><td style="text-align:center">0602</td><td style="text-align:left">Group Surfing - A Pedestrian-Based Approach to Sidewalk Robot Navigation</td></tr><tr><td style="text-align:center">0604</td><td style="text-align:left">Semiparametrical Gaussian Processes Learning of Forward Dynamical Models for Navigating in a Circular Maze</td></tr><tr><td style="text-align:center">0605</td><td style="text-align:left">A Lightweight Force-Controllable Wearable Arm Based on Magnetorheological-Hydrostatic Actuators</td></tr><tr><td style="text-align:center">0606</td><td style="text-align:left">Robotic Bronchoscopy Drive Mode of the Auris Monarch Platform</td></tr><tr><td style="text-align:center">0609</td><td style="text-align:left">Multi-Task Template Matching for Object Detection Segmentation and Pose Estimation Using Depth Images</td></tr><tr><td style="text-align:center">0611</td><td style="text-align:left">Synthesis of Real-Time Observers from Past-Time Linear Temporal Logic and Timed Specification</td></tr><tr><td style="text-align:center">0612</td><td style="text-align:left">Laparoscopy Instrument Tracking for Single View Camera and Skill Assessment</td></tr><tr><td style="text-align:center">0613</td><td style="text-align:left">Learning Action Representations for Self-supervised Visual Exploration</td></tr><tr><td style="text-align:center">0614</td><td style="text-align:left">Human-Inspired Balance Model to Account for Foot-Beam Interaction Mechanics</td></tr><tr><td style="text-align:center">0617</td><td style="text-align:left">A Practical Approach to Insertion with Variable Socket Position Using Deep Reinforcement Learning</td></tr><tr><td style="text-align:center">0619</td><td style="text-align:left">A Simple Adaptive Tracker with Reminiscences</td></tr><tr><td style="text-align:center">0620</td><td style="text-align:left">Ascento - A Two-Wheeled Jumping Robot</td></tr><tr><td style="text-align:center">0621</td><td style="text-align:left">EMG-Controlled Non-Anthropomorphic Hand Teleoperation Using a Continuous Teleoperation Subspace</td></tr><tr><td style="text-align:center">0622</td><td style="text-align:left">Non-Parametric Imitation Learning of Robot Motor Skills</td></tr><tr><td style="text-align:center">0623</td><td style="text-align:left">Data-Driven Gait Segmentation for Walking Assistance in a Lower-Limb Assistive Device</td></tr><tr><td style="text-align:center">0634</td><td style="text-align:left">Robustness to Out-Of-Distribution Inputs Via Task-Aware Generative Uncertainty</td></tr><tr><td style="text-align:center">0636</td><td style="text-align:left">Robust Object-Based SLAM for High-Speed Autonomous Navigation</td></tr><tr><td style="text-align:center">0637</td><td style="text-align:left">Intent-Uncertainty-Aware Grasp Planning for Robust Robot Assistance in Telemanipulation</td></tr><tr><td style="text-align:center">0638</td><td style="text-align:left">Design and Evaluation of an Energy-Saving Drive for a Versatile Robotic Gripper</td></tr><tr><td style="text-align:center">0641</td><td style="text-align:left">Controller Synthesis for Discrete-Time Hybrid Polynomial Systems Via Occupation Measures</td></tr><tr><td style="text-align:center">0644</td><td style="text-align:left">Recursive Bayesian Classi64257cation for Perception of Evolving Targets Using a Gaussian Toroid Prediction Model</td></tr><tr><td style="text-align:center">0646</td><td style="text-align:left">Support Surface Estimation for Legged Robots</td></tr><tr><td style="text-align:center">0647</td><td style="text-align:left">Fault-tolerant Flight Control of a VTOL Tailsitter UAV</td></tr><tr><td style="text-align:center">0648</td><td style="text-align:left">Recursive Integrity Monitoring for Mobile Robot Localization Safety</td></tr><tr><td style="text-align:center">0649</td><td style="text-align:left">A Four-Magnet System for 2D Wireless Open-Loop Control of Microrobots</td></tr><tr><td style="text-align:center">0651</td><td style="text-align:left">SpaceBok - A Dynamic Legged Robot for Space Exploration</td></tr><tr><td style="text-align:center">0652</td><td style="text-align:left">Characterizing the Effects of Reduced Gravity on Rover Wheel-Soil Interactions Using Computer Vision Techniques</td></tr><tr><td style="text-align:center">0654</td><td style="text-align:left">Learning-driven Coarse-to-Fine Articulated Robot Tracking</td></tr><tr><td style="text-align:center">0658</td><td style="text-align:left">A Scalable Framework For Real-Time Multi-Robot Multi-Human Collision Avoidance</td></tr><tr><td style="text-align:center">0660</td><td style="text-align:left">SuperDepth - Self-Supervised Super-Resolved Monocular Depth Estimation</td></tr><tr><td style="text-align:center">0661</td><td style="text-align:left">Dynamic Stepping on Unknown Obstacles with Upper-Body Compliance and Angular Momentum Damping from the Reaction Null-Space</td></tr><tr><td style="text-align:center">0663</td><td style="text-align:left">Generalized Controllers in POMDP Decision-Making</td></tr><tr><td style="text-align:center">0665</td><td style="text-align:left">A Heuristic for Task Allocation and Routing of Heterogeneous Robots while Minimizing Maximum Travel Cost</td></tr><tr><td style="text-align:center">0666</td><td style="text-align:left">Safe and Complete Real-Time Planning and Exploration in Unknown Environments</td></tr><tr><td style="text-align:center">0667</td><td style="text-align:left">Learning Primitive Skills for Mobile Robots</td></tr><tr><td style="text-align:center">0668</td><td style="text-align:left">Sound-Indicated Visual Object Detection for Robotic Exploration</td></tr><tr><td style="text-align:center">0669</td><td style="text-align:left">Visual Representations for Semantic Target Driven Navigation</td></tr><tr><td style="text-align:center">0670</td><td style="text-align:left">Online Learning for Proactive Obstacle Avoidance with Powered Transfemoral Prostheses</td></tr><tr><td style="text-align:center">0674</td><td style="text-align:left">Visual-Inertial Navigation - A Concise Review</td></tr><tr><td style="text-align:center">0677</td><td style="text-align:left">Improved A-Search Guided Tree Construction for Kinodynamic Planning</td></tr><tr><td style="text-align:center">0678</td><td style="text-align:left">Constrained Feedback Control by Prioritized Multi-Objective Optimization</td></tr><tr><td style="text-align:center">0679</td><td style="text-align:left">Uncertainty-Aware Data Aggregation for Deep Imitation Learning</td></tr><tr><td style="text-align:center">0681</td><td style="text-align:left">A GPU Based Parallel Genetic Algorithm for the Orientation Optimization Problem in 3D Printing</td></tr><tr><td style="text-align:center">0682</td><td style="text-align:left">Customizing Object Detectors for Indoor Robots</td></tr><tr><td style="text-align:center">0684</td><td style="text-align:left">Visual Guidance and Automatic Control for Robotic Personalized Stent Graft Manufacturing</td></tr><tr><td style="text-align:center">0685</td><td style="text-align:left">Deep Learning Based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation</td></tr><tr><td style="text-align:center">0689</td><td style="text-align:left">Algorithmic Resolution of Multiple Impacts in Nonsmooth Mechanical Systems with Switching Constraints</td></tr><tr><td style="text-align:center">0691</td><td style="text-align:left">Finding Divers with SCUBANet</td></tr><tr><td style="text-align:center">0693</td><td style="text-align:left">Non-Parametric Informed Exploration for Sampling-Based Motion Planning</td></tr><tr><td style="text-align:center">0694</td><td style="text-align:left">Coordinating Multi-Robot Systems through Environment Partitioning for Adaptive Informative Sampling</td></tr><tr><td style="text-align:center">0695</td><td style="text-align:left">Interaction-Aware Multi-Agent Reinforcement Learning for Mobile Agents with Individual Goals</td></tr><tr><td style="text-align:center">0697</td><td style="text-align:left">Uncertainty-Aware Occupancy Map Prediction Using Generative Networks for Robot Navigation</td></tr><tr><td style="text-align:center">0699</td><td style="text-align:left">Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations</td></tr><tr><td style="text-align:center">0700</td><td style="text-align:left">Illumination Robust Monocular Direct Visual Odometry for Outdoor Environment Mapping</td></tr><tr><td style="text-align:center">0702</td><td style="text-align:left">Experimental Validation of High-Efficiency Hydraulic Direct-Drive System for a Biped Humanoid Roboti 12 Comparison with Valve-Based Control System</td></tr><tr><td style="text-align:center">0703</td><td style="text-align:left">OffsetNet - Deep Learning for Localization in the Lung Using Rendered Images</td></tr><tr><td style="text-align:center">0704</td><td style="text-align:left">Optimal Path Planning for W-Regular Objectives with Abstraction-Refinement</td></tr><tr><td style="text-align:center">0705</td><td style="text-align:left">Semantic Predictive Control for Interpretable and Efficient Policy Learning</td></tr><tr><td style="text-align:center">0708</td><td style="text-align:left">Mini Cheetah - A Platform for Pushing the Limits of Dynamic Quadruped Control</td></tr><tr><td style="text-align:center">0716</td><td style="text-align:left">Orienting Oocytes Using Vibrations for In-Vitro Fertilization Procedures</td></tr><tr><td style="text-align:center">0717</td><td style="text-align:left">GEN-SLAM - Generative Modeling for Monocular Simultaneous Localization and Mapping</td></tr><tr><td style="text-align:center">0720</td><td style="text-align:left">Adaptive Variance for Changing Sparse-Reward Environments</td></tr><tr><td style="text-align:center">0722</td><td style="text-align:left">Uncertainty Aware Learning from Demonstrations in Multiple Contexts using Bayesian Neural Networks</td></tr><tr><td style="text-align:center">0728</td><td style="text-align:left">Model Reference Adaptive Control of a Two-Wheeled Mobile Robot</td></tr><tr><td style="text-align:center">0730</td><td style="text-align:left">Learning Robust Manipulation Strategies with Multimodal State Transition Models and Recovery Heuristics</td></tr><tr><td style="text-align:center">0739</td><td style="text-align:left">Passive Dynamic Object Locomotion by Rocking and Walking Manipulation</td></tr><tr><td style="text-align:center">0742</td><td style="text-align:left">Informed Information Theoretic Model Predictive Control</td></tr><tr><td style="text-align:center">0743</td><td style="text-align:left">Exploiting Trademark Databases for Robotic Object Fetching</td></tr><tr><td style="text-align:center">0745</td><td style="text-align:left">Data Driven Inverse Kinematics of Soft Robots Using Local Models</td></tr><tr><td style="text-align:center">0746</td><td style="text-align:left">Integrity Risk-Based Model Predictive Control for Mobile Robots</td></tr><tr><td style="text-align:center">0747</td><td style="text-align:left">Online Estimation of Ocean Current from Sparse GPS Data for Underwater Vehicles</td></tr><tr><td style="text-align:center">0750</td><td style="text-align:left">Model-free Online Motion Adaptation for Optimal Range and Endurance of Multicopters</td></tr><tr><td style="text-align:center">0753</td><td style="text-align:left">The Importance of Metric Learning for Robotic Vision - Open Set Recognition and Active Learning</td></tr><tr><td style="text-align:center">0754</td><td style="text-align:left">Build Your Own Hybrid thermalEO Camera for Autonomous Vehicle</td></tr><tr><td style="text-align:center">0762</td><td style="text-align:left">Dynamic Obstacles Detection for Robotic Soil Explorations</td></tr><tr><td style="text-align:center">0764</td><td style="text-align:left">Reactive Walking Based on Upper-Body Manipulability - An Application to Intention Detection and Reaction</td></tr><tr><td style="text-align:center">0780</td><td style="text-align:left">Liability Ethics and Culture-Aware Behavior Specification Using Rulebooks</td></tr><tr><td style="text-align:center">0782</td><td style="text-align:left">A Comparison of CNN-Based and Hand-Crafted Keypoint Descriptors</td></tr><tr><td style="text-align:center">0783</td><td style="text-align:left">IN2LAMA - INertial Lidar Localisation and MApping</td></tr><tr><td style="text-align:center">0789</td><td style="text-align:left">Fast Instance and Semantic Segmentation Exploiting Local Connectivity Metric Learning and One-Shot Detection for Robotics</td></tr><tr><td style="text-align:center">0798</td><td style="text-align:left">Accurate Direct Visual-Laser Odometry with Explicit Occlusion Handling and Plane Detection</td></tr><tr><td style="text-align:center">0801</td><td style="text-align:left">Automated Cell Patterning System with a Microchip Using Dielectrophoresis</td></tr><tr><td style="text-align:center">0803</td><td style="text-align:left">Discrete Rotation Equivariance for Point Cloud Recognition</td></tr><tr><td style="text-align:center">0808</td><td style="text-align:left">Coverage Path Planning in Belief Space</td></tr><tr><td style="text-align:center">0816</td><td style="text-align:left">The Doctor will See You Now - Could a Robot Be a medical Receptionist</td></tr><tr><td style="text-align:center">0817</td><td style="text-align:left">Large-Scale Object Mining for Object Discovery from Unlabeled Video</td></tr><tr><td style="text-align:center">0821</td><td style="text-align:left">Flight Testing Boustrophedon Coverage Path Planning for Fixed Wing UAVs in Wind</td></tr><tr><td style="text-align:center">0822</td><td style="text-align:left">Mixed-Granularity Human-Swarm Interaction</td></tr><tr><td style="text-align:center">0824</td><td style="text-align:left">Handling Robot Constraints within a Set-Based Multi-Task Priority Inverse Kinematics Framework</td></tr><tr><td style="text-align:center">0826</td><td style="text-align:left">Generalization through Simulation - Integrating Simulated and Real Data into Deep Reinforcement Learning for Vision-Based Autonomous Flight</td></tr><tr><td style="text-align:center">0827</td><td style="text-align:left">Improved Proximity Contact and Force Sensing Via Optimization of Elastomer-Air Interface Geometry</td></tr><tr><td style="text-align:center">0836</td><td style="text-align:left">Detect in RGB Optimize in Edge - Accurate 6D Pose Estimation for Texture-Less Industrial Parts</td></tr><tr><td style="text-align:center">0840</td><td style="text-align:left">A Reconfigurable Variable Stiffness Manipulator by a Sliding Layer Mechanism</td></tr><tr><td style="text-align:center">0841</td><td style="text-align:left">Echinoderm Inspired Variable Stiffness Soft Actuator with Connected Ossicle Structure</td></tr><tr><td style="text-align:center">0844</td><td style="text-align:left">A Friction-Based Kinematic Model for Skid-Steer Wheeled Mobile Robots</td></tr><tr><td style="text-align:center">0846</td><td style="text-align:left">Robust Object Grasping in Clutter Via Singulation</td></tr><tr><td style="text-align:center">0850</td><td style="text-align:left">OmniDRL - Robust Pedestrian Detection Using Deep Reinforcement Learning on Omnidirectional Cameras</td></tr><tr><td style="text-align:center">0851</td><td style="text-align:left">Safe Teleoperation of a Laparoscope Holder with Dynamic Precision but Low Stiffness</td></tr><tr><td style="text-align:center">0856</td><td style="text-align:left">Empty Cities - Image Inpainting for a Dynamic-Object-Invariant Space</td></tr><tr><td style="text-align:center">0857</td><td style="text-align:left">Spatiotemporal and Kinetic Gait Analysis System Based on Multisensor Fusion of Laser Range Sensor and Instrumented Insoles</td></tr><tr><td style="text-align:center">0860</td><td style="text-align:left">Semantic Mapping for View-Invariant Relocalization</td></tr><tr><td style="text-align:center">0862</td><td style="text-align:left">Robotic Forceps without Position Sensors Using Visual SLAM</td></tr><tr><td style="text-align:center">0864</td><td style="text-align:left">Manipulation Using Microrobot Driven by Optothermally Generated Surface Bubble</td></tr><tr><td style="text-align:center">0867</td><td style="text-align:left">Environment Driven Underwater Camera-IMU Calibration for Monocular Visual-Inertial SLAM</td></tr><tr><td style="text-align:center">0868</td><td style="text-align:left">Improving Collective Decision Accuracy Via Time-Varying Cross-Inhibition</td></tr><tr><td style="text-align:center">0871</td><td style="text-align:left">BLVD - Building a Large-Scale 5D Semantics Benchmark for Autonomous Driving</td></tr><tr><td style="text-align:center">0873</td><td style="text-align:left">Path Following Controller for Differentially Driven Planar Robots with Limited Torques and Uncertain and Changing Dynamics</td></tr><tr><td style="text-align:center">0875</td><td style="text-align:left">Solving Methods for Multi-Robot Missions Planning with Energy Capacity Consideration</td></tr><tr><td style="text-align:center">0878</td><td style="text-align:left">Improved Optical Flow for Gesture-Based Human Robot Interaction</td></tr><tr><td style="text-align:center">0879</td><td style="text-align:left">Plug-And-Play - Improve Depth Prediction Via Sparse Data Propagation</td></tr><tr><td style="text-align:center">0883</td><td style="text-align:left">Customized Object Recognition and Segmentation by One Shot Learning with Human Robot Interaction</td></tr><tr><td style="text-align:center">0887</td><td style="text-align:left">Fast Terminal Sliding Mode Super Twisting Controller for Position and Altitude Tracking of the Quadrotor</td></tr><tr><td style="text-align:center">0888</td><td style="text-align:left">Continuous Value Iteration (CVI) Reinforcement Learning and Imaginary Experience Replay (IER) for Learning Multi-Goal Continuous Action and State Space Controllers</td></tr><tr><td style="text-align:center">0890</td><td style="text-align:left">Gaussian Processes Model-Based Control of Underactuated Balance Robots</td></tr><tr><td style="text-align:center">0892</td><td style="text-align:left">Set-Based Inverse Kinematics Control of an Anthropomorphic Dual Arm Aerial Manipulator</td></tr><tr><td style="text-align:center">0893</td><td style="text-align:left">Optimization-Based Terrain Analysis and Path Planning in Unstructured Environments</td></tr><tr><td style="text-align:center">0894</td><td style="text-align:left">Designing a Personality-Driven Robot for a Human-Robot Interaction Scenario</td></tr><tr><td style="text-align:center">0897</td><td style="text-align:left">Dense 3D Visual Mapping Via Semantic Simplification</td></tr><tr><td style="text-align:center">0900</td><td style="text-align:left">Mobile Robotic Painting of Texture</td></tr><tr><td style="text-align:center">0903</td><td style="text-align:left">Redundant Perception and State Estimation for Reliable Autonomous Racing</td></tr><tr><td style="text-align:center">0904</td><td style="text-align:left">Diffraction-Aware Sound Localization for a Non-Line-Of-Sight Source</td></tr><tr><td style="text-align:center">0905</td><td style="text-align:left">Incremental Learning of Spatial-Temporal Features in Human Motion Patterns with Mixture Model for Planning Motion of a Collaborative Robot in</td></tr><tr><td style="text-align:center">0907</td><td style="text-align:left">Semi Supervised Deep Quick Instance Detection and Segmentation</td></tr><tr><td style="text-align:center">0908</td><td style="text-align:left">DFNet - Semantic Segmentation on Panoramic Images with Dynamic Loss Weights and Residual Fusion Block</td></tr><tr><td style="text-align:center">0911</td><td style="text-align:left">MoveIt Task Constructor for Task-Level Motion Planning</td></tr><tr><td style="text-align:center">0914</td><td style="text-align:left">Efficient Exact Collision Detection between Ellipsoids and Superquadrics via Closed-form Minkowski Sums</td></tr><tr><td style="text-align:center">0916</td><td style="text-align:left">SEG-VoxelNet for 3D Vehicle Detection from RGB and LiDAR Data</td></tr><tr><td style="text-align:center">0918</td><td style="text-align:left">Deep N-Shot Transfer Learning for Tactile Material Classification with a Flexible Pressure-Sensitive Skin</td></tr><tr><td style="text-align:center">0921</td><td style="text-align:left">Realizing Learned Quadruped Locomotion Behaviors through Kinematic Motion Primitives</td></tr><tr><td style="text-align:center">0923</td><td style="text-align:left">Sampling-Based Polytopic Trees for Approximate Optimal Control of Piecewise Affine Systems</td></tr><tr><td style="text-align:center">0926</td><td style="text-align:left">A New Soft Fingertip Based on Electroactive Hydrogels</td></tr><tr><td style="text-align:center">0931</td><td style="text-align:left">Active Damping of Parallel Robots Driven by Flexible Cables Using Cold-Gas Thrusters</td></tr><tr><td style="text-align:center">0932</td><td style="text-align:left">Experiments with Human-inspired Behaviors in a Humanoid Robot - Quasi-static Balancing using Toe-off Motion and Stretched Knees</td></tr><tr><td style="text-align:center">0939</td><td style="text-align:left">Controllability Pre-Verification of Silicon Soft Robots Based on Finite-Element Method</td></tr><tr><td style="text-align:center">0946</td><td style="text-align:left">Passivity Based Control of Antagonistic Tendon-Driven Mechanism</td></tr><tr><td style="text-align:center">0947</td><td style="text-align:left">Experimental Demonstration of High-Performance Robotic Balancing</td></tr><tr><td style="text-align:center">0949</td><td style="text-align:left">Predicting the Layout of Partially Observed Rooms from Grid Maps</td></tr><tr><td style="text-align:center">0951</td><td style="text-align:left">Development of Informative Path Planning for Inspection of the Hanford Tank Farm</td></tr><tr><td style="text-align:center">0953</td><td style="text-align:left">Lazy Evaluation of Goal Specifications Guided by Motion Planning</td></tr><tr><td style="text-align:center">0954</td><td style="text-align:left">Semantic Mapping Extension for OpenStreetMap Applied to Indoor Robot Navigation</td></tr><tr><td style="text-align:center">0955</td><td style="text-align:left">Learning Discriminative Embeddings for Object Recognition On-The-Fly</td></tr><tr><td style="text-align:center">0956</td><td style="text-align:left">Spatio-Temporal Representation for Long-Term Anticipation of Human Presence in Service Robotics</td></tr><tr><td style="text-align:center">0957</td><td style="text-align:left">Adaptive H8734 Controller for Precise Manoeuvring of a Space Robot</td></tr><tr><td style="text-align:center">0959</td><td style="text-align:left">Vision-Based Teleoperation of Shadow Dexterous Hand Using End-To-End Deep Neural Network</td></tr><tr><td style="text-align:center">0963</td><td style="text-align:left">A Fleet of Miniature Cars for Experiments in Cooperative Driving</td></tr><tr><td style="text-align:center">0966</td><td style="text-align:left">Design and Analysis of a Miniature Two-Wheg Climbing Robot with Robust Internal and External Transitioning Capabilities</td></tr><tr><td style="text-align:center">0968</td><td style="text-align:left">Multirotor Dynamics Based Online Scale Estimation for Monocular SLAM</td></tr><tr><td style="text-align:center">0970</td><td style="text-align:left">UWBLiDAR Fusion for Cooperative Range-Only SLAM</td></tr><tr><td style="text-align:center">0973</td><td style="text-align:left">A Motion Planning Scheme for Cooperative Loading Using Heterogeneous Robotic Agents</td></tr><tr><td style="text-align:center">0975</td><td style="text-align:left">Energy Optimal Control Allocation in a Redundantly Actuated Omnidirectional UAV</td></tr><tr><td style="text-align:center">0977</td><td style="text-align:left">Versatile Reactive Bipedal Locomotion Planning through Hierarchical Optimization</td></tr><tr><td style="text-align:center">0979</td><td style="text-align:left">A Supervised Approach to Predicting Noise in Depth Images</td></tr><tr><td style="text-align:center">0991</td><td style="text-align:left">Practical Guide to Solve the Minimum-Effort Problem with Geometric Algorithms and B-Splines</td></tr><tr><td style="text-align:center">0996</td><td style="text-align:left">Learning from Transferable Mechanics Models - Generalizable Online Mode Detection in Underactuated Dexterous Manipulation</td></tr><tr><td style="text-align:center">0999</td><td style="text-align:left">Dynamic Hilbert Maps - Real-Time Occupancy Predictions in Changing Environments</td></tr><tr><td style="text-align:center">1001</td><td style="text-align:left">Soft Hands with Embodied Constraints - The Soft ScoopGripper</td></tr><tr><td style="text-align:center">1003</td><td style="text-align:left">Robot Communication Via Motion - Closing the Human-Robot Interaction Loop Underwater</td></tr><tr><td style="text-align:center">1006</td><td style="text-align:left">Streaming Scene Maps for Co-Robotic Exploration in Bandwidth Limited Environments</td></tr><tr><td style="text-align:center">1007</td><td style="text-align:left">Design and Implementation of Computer Vision Based In-Row Weeding System</td></tr><tr><td style="text-align:center">1008</td><td style="text-align:left">Learning Monocular Visual Odometry through Geometry-Aware Curriculum Learning</td></tr><tr><td style="text-align:center">1009</td><td style="text-align:left">Designing Worm-Inspired Neural Networks for Interpretable Robotic Control</td></tr><tr><td style="text-align:center">1011</td><td style="text-align:left">POSEAMM - A Unified Framework for Solving Pose Problems Using an Alternating Minimization Method</td></tr><tr><td style="text-align:center">1012</td><td style="text-align:left">A Novel Robotic Suturing System for Flexible Endoscopic Surgery</td></tr><tr><td style="text-align:center">1018</td><td style="text-align:left">Diagonally-Decoupled Direct Visual Servoing</td></tr><tr><td style="text-align:center">1019</td><td style="text-align:left">Formal Policy Learning from Demonstrations for Reachability Properties</td></tr><tr><td style="text-align:center">1020</td><td style="text-align:left">Knowledge Is Never Enough - Towards Web Aided Deep Open World Recognition</td></tr><tr><td style="text-align:center">1021</td><td style="text-align:left">Model-Based On-Line Estimation of Time-Varying Nonlinear Joint Stiffness on an E-Series Universal Robots Manipulator</td></tr><tr><td style="text-align:center">1026</td><td style="text-align:left">A Novel Multi-Layer Framework for Tiny Obstacle Discovery</td></tr><tr><td style="text-align:center">1027</td><td style="text-align:left">Using Deep Reinforcement Learning to Learn High-Level Policies on the ATRIAS Biped</td></tr><tr><td style="text-align:center">1030</td><td style="text-align:left">Adaptive Critic Based Optimal Kinematic Control for a Robot Manipulator</td></tr><tr><td style="text-align:center">1036</td><td style="text-align:left">A Unified Framework for Mutual Improvement of SLAM and Semantic Segmentation</td></tr><tr><td style="text-align:center">1038</td><td style="text-align:left">Online Deep Learning for Improved Trajectory Tracking of Unmanned Aerial Vehicles Using Expert Knowledge</td></tr><tr><td style="text-align:center">1043</td><td style="text-align:left">Orientation-Aware Motion Planning in Complex Workspaces Using Adaptive Harmonic Potential Fields</td></tr><tr><td style="text-align:center">1045</td><td style="text-align:left">Leveraging Structural Regularity of Atlanta World for Monocular SLAM</td></tr><tr><td style="text-align:center">1046</td><td style="text-align:left">Adaptive Gait Planning for Walking Assistance Lower Limb Exoskeletons in Slope Scenarios</td></tr><tr><td style="text-align:center">1050</td><td style="text-align:left">Sleeve Pneumatic Artificial Muscles for Antagonistically Actuated Joints</td></tr><tr><td style="text-align:center">1061</td><td style="text-align:left">Manipulability Optimization Control of a Serial Redundant Robot for Robot-Assisted Minimally Invasive Surgery</td></tr><tr><td style="text-align:center">1065</td><td style="text-align:left">2D3D-MatchNet - Learning to Match Keypoints across 2D Image and 3D Point Cloud</td></tr><tr><td style="text-align:center">1066</td><td style="text-align:left">An Integrated Approach to Navigation and Control in Micro Underwater Robotics using Radio-Frequency Localization</td></tr><tr><td style="text-align:center">1070</td><td style="text-align:left">LSTM-Based Network for Human Gait Stability Prediction in an Intelligent Robotic Rollator</td></tr><tr><td style="text-align:center">1071</td><td style="text-align:left">An Extrinsic Calibration Tool for Radar Camera and Lidar</td></tr><tr><td style="text-align:center">1072</td><td style="text-align:left">Improving the Robustness of Visual-Inertial Extended Kalman Filtering</td></tr><tr><td style="text-align:center">1073</td><td style="text-align:left">ATLAS FaST - Fast and Simple Scheduled TDOA for Reliable Ultra-Wideband Localization</td></tr><tr><td style="text-align:center">1074</td><td style="text-align:left">Modal Dynamics and Analysis of a Vertical Stretch-Retractable Continuum Manipulator with Large Deflection</td></tr><tr><td style="text-align:center">1076</td><td style="text-align:left">Whole-Body Active Compliance Control for Humanoid Robots with Robot Skin</td></tr><tr><td style="text-align:center">1079</td><td style="text-align:left">Drift-Free Roll and Pitch Estimation for High-Acceleration Hopping</td></tr><tr><td style="text-align:center">1080</td><td style="text-align:left">Exploiting Environment Contacts of Serial Manipulators</td></tr><tr><td style="text-align:center">1081</td><td style="text-align:left">LVIS - Learning from Value Function Intervals for Contact-Aware Robot Controllers</td></tr><tr><td style="text-align:center">1086</td><td style="text-align:left">Visual Appearance Analysis of Forest Scenes for Monocular SLAM</td></tr><tr><td style="text-align:center">1088</td><td style="text-align:left">Decentralized Collaborative Transport of Fabrics Using Micro-UAVs</td></tr><tr><td style="text-align:center">1090</td><td style="text-align:left">Closed-Loop MPC with Dense Visual SLAM - Stability through Reactive Stepping</td></tr><tr><td style="text-align:center">1092</td><td style="text-align:left">Pedestrian Dominance Modeling for Socially-Aware Robot Navigation</td></tr><tr><td style="text-align:center">1094</td><td style="text-align:left">Robust Link Position Tracking Control for Robot Manipulators with Series Elastic Actuators Using Time-Delay Estimation</td></tr><tr><td style="text-align:center">1097</td><td style="text-align:left">Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks</td></tr><tr><td style="text-align:center">1099</td><td style="text-align:left">Optimal Leg Sequencing for a Hexapod Subject to External Forces and Slopes</td></tr><tr><td style="text-align:center">1100</td><td style="text-align:left">A Decentralized Heterogeneous Control Strategy for a Class of Infinitesimally Shape-Similar Formations</td></tr><tr><td style="text-align:center">1101</td><td style="text-align:left">Leveraging Contact Forces for Learning to Grasp</td></tr><tr><td style="text-align:center">1104</td><td style="text-align:left">One-To-Many Bipartite Matching Based Coalition Formation for Multi-Robot Task Allocation</td></tr><tr><td style="text-align:center">1105</td><td style="text-align:left">Energy-Aware Temporal Logic Motion Planning for Mobile Robots</td></tr><tr><td style="text-align:center">1113</td><td style="text-align:left">A Fault Diagnosis Framework for MAVLink-Enabled UAVs Using Structural Analysis</td></tr><tr><td style="text-align:center">1114</td><td style="text-align:left">SMT-Based Control and Feedback for Social Navigation</td></tr><tr><td style="text-align:center">1116</td><td style="text-align:left">Making Sense of Vision and Touch - Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks</td></tr><tr><td style="text-align:center">1117</td><td style="text-align:left">Four-Wheeled Dead-Reckoning Model Calibration Using RTS Smoothing</td></tr><tr><td style="text-align:center">1119</td><td style="text-align:left">A Multi-Modal Sensor Array for Safe Human-Robot Interaction and Mapping</td></tr><tr><td style="text-align:center">1126</td><td style="text-align:left">Real-Time Dense Mapping for Self-Driving Vehicles Using Fisheye Cameras</td></tr><tr><td style="text-align:center">1128</td><td style="text-align:left">Mechanical Fourier Transform Using an Array of Additively Manufactured Soft Whisker-Like Sensors</td></tr><tr><td style="text-align:center">1129</td><td style="text-align:left">RESLAM - A Real-Time Robust Edge-Based SLAM System</td></tr><tr><td style="text-align:center">1131</td><td style="text-align:left">Autonomous Sheet Pile Driving Robots for Soil Stabilization</td></tr><tr><td style="text-align:center">1133</td><td style="text-align:left">Search-Based 3D Planning and Trajectory Optimization for Safe Micro Aerial Vehicle Flight under Sensor Visibility Constraints</td></tr><tr><td style="text-align:center">1134</td><td style="text-align:left">Estimating Loads Along Elastic Rods</td></tr><tr><td style="text-align:center">1136</td><td style="text-align:left">Turning a Corner with a Dubins Car</td></tr><tr><td style="text-align:center">1138</td><td style="text-align:left">Design and Experiments for MultI-Section-Transformable (MIST) UAV</td></tr><tr><td style="text-align:center">1139</td><td style="text-align:left">Generating Adversarial Driving Scenarios in High-Fidelity Simulators</td></tr><tr><td style="text-align:center">1143</td><td style="text-align:left">Dense Surface Reconstruction from Monocular Vision and LiDAR</td></tr><tr><td style="text-align:center">1144</td><td style="text-align:left">A Distributed Predictive Control Approach for Cooperative Manipulation of Multiple Underwater Vehicle Manipulator Systems</td></tr><tr><td style="text-align:center">1145</td><td style="text-align:left">Goal-Oriented Object Importance Estimation in On-Road Driving Videos</td></tr><tr><td style="text-align:center">1147</td><td style="text-align:left">Estimating the Localizability in Tunnel-like Environments using LiDAR and UWB</td></tr><tr><td style="text-align:center">1148</td><td style="text-align:left">Networked Operation of a UAV Using Gaussian Process-Based Delay Compensation and Model Predictive Control</td></tr><tr><td style="text-align:center">1150</td><td style="text-align:left">Part Segmentation for Highly Accurate Deformable Tracking in Occlusions Via Fully Convolutional Neural Networks</td></tr><tr><td style="text-align:center">1151</td><td style="text-align:left">Dynamics Consensus between Centroidal and Whole-Body Models in Locomotion of Legged Robots</td></tr><tr><td style="text-align:center">1152</td><td style="text-align:left">Analysis of Robust Functions for Registration Algorithms</td></tr><tr><td style="text-align:center">1153</td><td style="text-align:left">Combined Task and Motion Planning under Partial Observability - An Optimization-Based Approach</td></tr><tr><td style="text-align:center">1156</td><td style="text-align:left">The Mechanics and Control of Leaning to Lift Heavy Objects with a Dynamically Stable Mobile Robot</td></tr><tr><td style="text-align:center">1157</td><td style="text-align:left">Asynchronous Network Formation in Unknown Unbounded Environments</td></tr><tr><td style="text-align:center">1158</td><td style="text-align:left">Improving Haptic Adjective Recognition with Unsupervised Feature Learning</td></tr><tr><td style="text-align:center">1168</td><td style="text-align:left">Modeling and Analysis of Motion Data from Dynamically Positioned Vessels for Sea State Estimation</td></tr><tr><td style="text-align:center">1169</td><td style="text-align:left">Prediction Maps for Real-Time 3D Footstep Planning in Dynamic Environments</td></tr><tr><td style="text-align:center">1173</td><td style="text-align:left">Depth Completion with Deep Geometry and Context Guidance</td></tr><tr><td style="text-align:center">1174</td><td style="text-align:left">Energy Optimization for a Robust and Flexible Interaction Control</td></tr><tr><td style="text-align:center">1176</td><td style="text-align:left">Learned Map Prediction for Enhanced Mobile Robot Exploration</td></tr><tr><td style="text-align:center">1180</td><td style="text-align:left">See and Be Seen — Rapid and Likeable High-Definition Camera-Eye for Anthropomorphic Robots</td></tr><tr><td style="text-align:center">1184</td><td style="text-align:left">Coordinated Control of a Reconfigurable Multi-Vessel Platform - Robust Control Approach</td></tr><tr><td style="text-align:center">1185</td><td style="text-align:left">Real-time Teleoperation of Flexible Beveled-tip Needle Insertion using Haptic Force Feedback and 3D Ultrasound Guidance</td></tr><tr><td style="text-align:center">1186</td><td style="text-align:left">Detection and Tracking of Small Objects in Sparse 3D Laser Range Data</td></tr><tr><td style="text-align:center">1192</td><td style="text-align:left">A Miniature Suction-Gripper with Passive and Active Microneedle Arrays to Manipulate Peripheral Nerves</td></tr><tr><td style="text-align:center">1193</td><td style="text-align:left">Object Detection Approach for Robot Grasp Detection</td></tr><tr><td style="text-align:center">1198</td><td style="text-align:left">Internal Array Electrodes Improve the Spatial Resolution of Soft Tactile Sensors Based on Electrical Resistance Tomography</td></tr><tr><td style="text-align:center">1199</td><td style="text-align:left">Augmenting Action Model Learning by Non-Geometric Features</td></tr><tr><td style="text-align:center">1202</td><td style="text-align:left">How Shall I Drive Interaction Modeling and Motion Planning towards Empathetic and Socially-Graceful Driving</td></tr><tr><td style="text-align:center">1203</td><td style="text-align:left">Wormhole Learning</td></tr><tr><td style="text-align:center">1204</td><td style="text-align:left">DeepFusion - Real-Time Dense 3D Reconstruction for Monocular SLAM Using Single-View Depth and Gradient Predictions</td></tr><tr><td style="text-align:center">1205</td><td style="text-align:left">CELLO-3D - Estimating the Covariance of ICP in the Real World</td></tr><tr><td style="text-align:center">1207</td><td style="text-align:left">Quantum Computation in Robotic Science and Applications</td></tr><tr><td style="text-align:center">1209</td><td style="text-align:left">Safe 3D Bipedal Walking through Linear MPC with 3D Capturability</td></tr><tr><td style="text-align:center">1210</td><td style="text-align:left">Object Transfer Point Estimation for Fluent Human-Robot Handovers</td></tr><tr><td style="text-align:center">1211</td><td style="text-align:left">Real Time Dense Depth Estimation by Fusing Stereo with Sparse Depth Measurements</td></tr><tr><td style="text-align:center">1213</td><td style="text-align:left">Ambient Light Based Depth Control of Underwater Robotic Unit AMussel</td></tr><tr><td style="text-align:center">1223</td><td style="text-align:left">GPS-Denied UAV Localization Using Pre-Existing Satellite Imagery</td></tr><tr><td style="text-align:center">1224</td><td style="text-align:left">Night-To-Day Image Translation for Retrieval-Based Localization</td></tr><tr><td style="text-align:center">1225</td><td style="text-align:left">Coordinated Multi-Robot Planning While Preserving Individual Privacy</td></tr><tr><td style="text-align:center">1226</td><td style="text-align:left">Removing Leaking Corners to Reduce Dimensionality in Hamilton-Jacobi Reachability</td></tr><tr><td style="text-align:center">1230</td><td style="text-align:left">Crowd-Robot Interaction - Crowd-Aware Robot Navigation with Attention-Based Deep Reinforcement Learning</td></tr><tr><td style="text-align:center">1233</td><td style="text-align:left">Multi-View Reconstruction of Wires Using a Catenary Model</td></tr><tr><td style="text-align:center">1235</td><td style="text-align:left">Inferring Compact Representations for Efficient Natural Language Understanding of Robot Instructions</td></tr><tr><td style="text-align:center">1237</td><td style="text-align:left">Accurate and Efficient Self-Localization on Roads Using Basic Geometric Primitives</td></tr><tr><td style="text-align:center">1238</td><td style="text-align:left">Using Comanipulation with Active Force Feedback to Undistort Stiffness Perception in Laparoscopy</td></tr><tr><td style="text-align:center">1240</td><td style="text-align:left">ChainQueen - A Real-Time Differentiable Physical Simulator for Soft Robotics</td></tr><tr><td style="text-align:center">1245</td><td style="text-align:left">Adapting Everyday Manipulation Skills to Varied Scenarios</td></tr><tr><td style="text-align:center">1247</td><td style="text-align:left">Towards Fully Dense Direct Filter-Based Monocular Visual-Inertial Odometry</td></tr><tr><td style="text-align:center">1248</td><td style="text-align:left">A Cane-Based Low Cost Sensor to Implement Attention Mechanisms in Telecare Robots</td></tr><tr><td style="text-align:center">1249</td><td style="text-align:left">Object Classification Based on Unsupervised Learned Multi-Modal Features for Overcoming Sensor Failures</td></tr><tr><td style="text-align:center">1251</td><td style="text-align:left">Magnetic-Field-Inspired Navigation for Quadcopter Robot in Unknown Environments</td></tr><tr><td style="text-align:center">1254</td><td style="text-align:left">Positioning Uncertainty Reduction of Magnetically Guided Actuation on Planar Surfaces</td></tr><tr><td style="text-align:center">1256</td><td style="text-align:left">Real-Time Minimum Snap Trajectory Generation for Quadcopters - Algorithm Speed-Up through Machine Learning</td></tr><tr><td style="text-align:center">1257</td><td style="text-align:left">Energy Tank-Based WrenchImpedance Control of a Fully-Actuated Hexarotor - A Geometric Port-Hamiltonian Approach</td></tr><tr><td style="text-align:center">1259</td><td style="text-align:left">Enhancing the Force Transparency of Time Domain Passivity Approach - Observer-Based Gradient Controller</td></tr><tr><td style="text-align:center">1262</td><td style="text-align:left">Combining Physical Simulators and Object-Based Networks for Control</td></tr><tr><td style="text-align:center">1264</td><td style="text-align:left">Effects of Foot Stiffness and Damping on Walking Robot Performance</td></tr><tr><td style="text-align:center">1265</td><td style="text-align:left">Adaptive Bingham Distribution Based Filter for SE(3) Estimation</td></tr><tr><td style="text-align:center">1267</td><td style="text-align:left">MID-Fusion - Octree-Based Object-Level Multi-Instance Dynamic SLAM</td></tr><tr><td style="text-align:center">1269</td><td style="text-align:left">Tactile Mapping and Localization from High-Resolution Tactile Imprints</td></tr><tr><td style="text-align:center">1278</td><td style="text-align:left">Autonomous Exploration Reconstruction and Surveillance of 3D Environments Aided by Deep Learning</td></tr><tr><td style="text-align:center">1280</td><td style="text-align:left">A Clustering Approach to Categorizing 7 Degree-Of-Freedom Arm Motions During Activities of Daily Living</td></tr><tr><td style="text-align:center">1281</td><td style="text-align:left">CARA System Architecture - a Click and Assemble Robotic Assembly System</td></tr><tr><td style="text-align:center">1282</td><td style="text-align:left">IX-BSP - Belief Space Planning through Incremental Expectation</td></tr><tr><td style="text-align:center">1288</td><td style="text-align:left">Unsupervised Gait Phase Estimation for Humanoid Robot Walking</td></tr><tr><td style="text-align:center">1289</td><td style="text-align:left">Towards an Integrated Autonomous Data-Driven Grasping System with a Mobile Manipulator</td></tr><tr><td style="text-align:center">1291</td><td style="text-align:left">Towards Effective Tactile Identification of Textures Using a Hybrid Touch Approach</td></tr><tr><td style="text-align:center">1295</td><td style="text-align:left">An Energy-Shared Two-Layer Approach for Multi-Master-Multi-Slave Bilateral Teleoperation Systems</td></tr><tr><td style="text-align:center">1296</td><td style="text-align:left">Adaptive Motor Control and Learning in a Spiking Neural Network Realised on a Mixed-Signal Neuromorphic Processor</td></tr><tr><td style="text-align:center">1298</td><td style="text-align:left">Using Variable Natural Environment Brain-Computer Interface Stimuli for Real-Time Humanoid Robot Navigation</td></tr><tr><td style="text-align:center">1299</td><td style="text-align:left">Deep Object-Centric Policies for Autonomous Driving</td></tr><tr><td style="text-align:center">1303</td><td style="text-align:left">Mitigating Energy Loss in a Robot Hopping on a Physically Emulated Dissipative Substrate</td></tr><tr><td style="text-align:center">1306</td><td style="text-align:left">Single-Shot Foothold Selection and Constraint Evaluation for Quadruped Locomotion</td></tr><tr><td style="text-align:center">1309</td><td style="text-align:left">Global Localization with Object-Level Semantics and Topology</td></tr><tr><td style="text-align:center">1311</td><td style="text-align:left">A Simple Electric Soft Robotic Gripper with High-Deformation Haptic Feedback</td></tr><tr><td style="text-align:center">1312</td><td style="text-align:left">Learning Latent Space Dynamics for Tactile Servoing</td></tr><tr><td style="text-align:center">1314</td><td style="text-align:left">Reconfigurable Motion Planning and Control in Obstacle Cluttered Environments under Timed Temporal Tasks</td></tr><tr><td style="text-align:center">1317</td><td style="text-align:left">Skill Acquisition Via Automated Multi-Coordinate Cost Balancing</td></tr><tr><td style="text-align:center">1318</td><td style="text-align:left">Robust Learning of Tactile Force Estimation through Robot Interaction</td></tr><tr><td style="text-align:center">1322</td><td style="text-align:left">Speeding up Iterative Closest Point Using Stochastic Gradient Descent</td></tr><tr><td style="text-align:center">1324</td><td style="text-align:left">Building a Winning Self-Driving Car in Six Months</td></tr><tr><td style="text-align:center">1327</td><td style="text-align:left">Obstacle-Aware Adaptive Informative Path Planning for UAV-Based Target Search</td></tr><tr><td style="text-align:center">1330</td><td style="text-align:left">Balancing Global Exploration and Local-Connectivity Exploitation with Rapidly-exploring Random Disjointed-Trees</td></tr><tr><td style="text-align:center">1333</td><td style="text-align:left">Neural Autonomous Navigation with Riemannian Motion Policy</td></tr><tr><td style="text-align:center">1334</td><td style="text-align:left">Dynamic Friction Model with Thermal and Load Dependency - Modeling Compensation and External Force Estimation</td></tr><tr><td style="text-align:center">1335</td><td style="text-align:left">HG-DAgger - Interactive Imitation Learning with Human Experts</td></tr><tr><td style="text-align:center">1336</td><td style="text-align:left">Generalized Orientation Learning in Robot Task Space</td></tr><tr><td style="text-align:center">1338</td><td style="text-align:left">Soft Robotic Glove with Integrated Sensing for Intuitive Grasping Assistance Post Spinal Cord Injury</td></tr><tr><td style="text-align:center">1339</td><td style="text-align:left">Development of a Low Inertia Parallel Actuated Shoulder Exoskeleton Robot for the Characterization of Neuromuscular Property During Static Posture and Dynamic Movement</td></tr><tr><td style="text-align:center">1340</td><td style="text-align:left">OVPC Mesh - 3D Free-Space Representation for Local Ground VehicleNavigation</td></tr><tr><td style="text-align:center">1342</td><td style="text-align:left">Coverage Control for Multiple Event Types with Heterogeneous Robots</td></tr><tr><td style="text-align:center">1343</td><td style="text-align:left">Feedback Motion Planning of Legged Robots by Composing Orbital Lyapunov Functions Using Rapidly-Exploring Random Trees</td></tr><tr><td style="text-align:center">1344</td><td style="text-align:left">Teaching Robots to Draw</td></tr><tr><td style="text-align:center">1347</td><td style="text-align:left">What Am I Touching Learning to Classify Terrain Via Haptic Sensing</td></tr><tr><td style="text-align:center">1348</td><td style="text-align:left">Egocentric Vision-Based Future Vehicle Localization for Intelligent Driving Assistance Systems</td></tr><tr><td style="text-align:center">1350</td><td style="text-align:left">Active Perception in Adversarial Scenarios Using Maximum Entropy Deep Reinforcement Learning</td></tr><tr><td style="text-align:center">1351</td><td style="text-align:left">3D Control of Rotating Millimeter-Scale Swimmers through Obstacles</td></tr><tr><td style="text-align:center">1352</td><td style="text-align:left">Compound Micromachines Powered by Acoustic Streaming</td></tr><tr><td style="text-align:center">1356</td><td style="text-align:left">Contact-Driven Posture Behavior for Safe and Interactive Robot Operation</td></tr><tr><td style="text-align:center">1357</td><td style="text-align:left">Variable Damping Control of the Robotic Ankle Joint to Improve Trade-Off between Performance and Stability</td></tr><tr><td style="text-align:center">1358</td><td style="text-align:left">Multi-Robot Informative Path Planning with Continuous Connectivity Constraints</td></tr><tr><td style="text-align:center">1359</td><td style="text-align:left">UAV Pose Estimation Using Cross-View Geolocalization with Satellite Imagery</td></tr><tr><td style="text-align:center">1361</td><td style="text-align:left">Underwater Communication Using Full-Body Gestures and Optimal Variable-Length Prefix Codes</td></tr><tr><td style="text-align:center">1362</td><td style="text-align:left">Nonlinear Tire Cornering Stiffness Observer for a Double Steering Off-Road Mobile Robot</td></tr><tr><td style="text-align:center">1365</td><td style="text-align:left">Look No Deeper - Recognizing Places from Opposing Viewpoints under Varying Scene Appearance Using Single-View Depth Estimation</td></tr><tr><td style="text-align:center">1367</td><td style="text-align:left">Formalized Task Characterization for Human-Robot Autonomy Allocation</td></tr><tr><td style="text-align:center">1369</td><td style="text-align:left">A Self-Modulated Impedance Multimodal Interaction Framework for Human-Robot Collaboration</td></tr><tr><td style="text-align:center">1370</td><td style="text-align:left">Air-To-Ground Surveillance Using Predictive Pursuit</td></tr><tr><td style="text-align:center">1371</td><td style="text-align:left">Acting Is Seeing - Navigating Tight Space Using Flapping Wings</td></tr><tr><td style="text-align:center">1375</td><td style="text-align:left">Attention-Based Lane Change Prediction</td></tr><tr><td style="text-align:center">1376</td><td style="text-align:left">Modeling and Control of a Passively-Coupled Tilt-Rotor Vertical Takeoff and Landing Aircraft</td></tr><tr><td style="text-align:center">1380</td><td style="text-align:left">GANVO - Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks</td></tr><tr><td style="text-align:center">1381</td><td style="text-align:left">Efficient Constellation-Based Map-Merging for Semantic SLAM</td></tr><tr><td style="text-align:center">1382</td><td style="text-align:left">Generative Deformation - Procedural Perforation for Elastic Structures</td></tr><tr><td style="text-align:center">1383</td><td style="text-align:left">Multimodal Semantic SLAM with Probabilistic Data Association</td></tr><tr><td style="text-align:center">1385</td><td style="text-align:left">Motion Scaling Solutions for Improved Performance in High Delay Surgical Teleoperation</td></tr><tr><td style="text-align:center">1386</td><td style="text-align:left">PointNetGPD - Detecting Grasp Configurations from Point Sets</td></tr><tr><td style="text-align:center">1389</td><td style="text-align:left">Design of Versatile and Low-Cost Shaft Sensor for Health Monitoring</td></tr><tr><td style="text-align:center">1395</td><td style="text-align:left">Complete and Near-Optimal Path Planning for Simultaneous Sensor-Based Inspection and Footprint Coverage in Robotic Crack Filling</td></tr><tr><td style="text-align:center">1399</td><td style="text-align:left">A Benchmarking Framework for Systematic Evaluation of Robotic Pick-And-Place Systems in an Industrial Grocery Setting</td></tr><tr><td style="text-align:center">1400</td><td style="text-align:left">A Generic Optimization Based Cartesian Controller for Robotic Mobile Manipulation</td></tr><tr><td style="text-align:center">1401</td><td style="text-align:left">A Multi-Sensor Next-Best-View Framework for Geometric Model-Based Robotics Applications</td></tr><tr><td style="text-align:center">1406</td><td style="text-align:left">Design Principles and Optimization of a Planar Underactuated Hand for Caging Grasps</td></tr><tr><td style="text-align:center">1407</td><td style="text-align:left">Compliant Limb Sensing and Control for Safe Human-Robot Interactions</td></tr><tr><td style="text-align:center">1408</td><td style="text-align:left">Visual Recognition in the Wild by Sampling Deep Similarity Functions</td></tr><tr><td style="text-align:center">1409</td><td style="text-align:left">Localization and Tracking of Uncontrollable Underwater Agents - Particle Filter Based Fusion of On-Body IMUs and Stationary Cameras</td></tr><tr><td style="text-align:center">1410</td><td style="text-align:left">Urban Swarms - A New Approach for Autonomous Waste Management</td></tr><tr><td style="text-align:center">1412</td><td style="text-align:left">Visual Localization at Intersections with Digital Maps</td></tr><tr><td style="text-align:center">1414</td><td style="text-align:left">Using Local Experiences for Global Motion Planning</td></tr><tr><td style="text-align:center">1415</td><td style="text-align:left">WISDOM - WIreless Sensing-Assisted Distributed Offline Mapping</td></tr><tr><td style="text-align:center">1419</td><td style="text-align:left">Tool Macgyvering - Tool Construction Using Geometric Reasoning</td></tr><tr><td style="text-align:center">1422</td><td style="text-align:left">Surfel-Based Dense RGB-D Reconstruction with Global and Local Consistency</td></tr><tr><td style="text-align:center">1423</td><td style="text-align:left">Voluntary Retreat for Decentralized Interference Reduction in Robot Swarms</td></tr><tr><td style="text-align:center">1426</td><td style="text-align:left">Working towards Adaptive Sensing for Terrain-Aided Navigation</td></tr><tr><td style="text-align:center">1428</td><td style="text-align:left">Locomotion Planning through a Hybrid Bayesian Trajectory Optimization</td></tr><tr><td style="text-align:center">1429</td><td style="text-align:left">ALMA - Articulated Locomotion and Manipulation for a Torque-Controllable Robot</td></tr><tr><td style="text-align:center">1430</td><td style="text-align:left">Shape Sensing of Variable Stiffness Soft Robots Using Electrical Impedance Tomography</td></tr><tr><td style="text-align:center">1431</td><td style="text-align:left">Dynamic Walking on Slippery Surfaces - Demonstrating Stable Bipedal Gaits with Planned Ground Slippage</td></tr><tr><td style="text-align:center">1434</td><td style="text-align:left">Robotics Education and Research at Scale - A Remotely Accessible Robotics Development Platform</td></tr><tr><td style="text-align:center">1438</td><td style="text-align:left">Automated Seedling Height Assessment for Tree Nurseries Using Point Cloud Processing</td></tr><tr><td style="text-align:center">1439</td><td style="text-align:left">Effort Estimation in Robot-Aided Training with a Neural Network</td></tr><tr><td style="text-align:center">1444</td><td style="text-align:left">An Algorithm for Odor Source Localization based on Source Term Estimation</td></tr><tr><td style="text-align:center">1445</td><td style="text-align:left">Multi-Object Search Using Object-Oriented POMDPs</td></tr><tr><td style="text-align:center">1447</td><td style="text-align:left">Simulated Annealing-Optimized Trajectory Planning within Non-Collision Nominal Intervals for Highway Autonomous Driving</td></tr><tr><td style="text-align:center">1448</td><td style="text-align:left">3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM</td></tr><tr><td style="text-align:center">1455</td><td style="text-align:left">Inferring Robot Morphology from Observation of Unscripted Movement</td></tr><tr><td style="text-align:center">1458</td><td style="text-align:left">Characterizing Visual Localization and Mapping Datasets</td></tr><tr><td style="text-align:center">1459</td><td style="text-align:left">Automated Aortic Pressure Regulation in Ex Vivo Heart Perfusion</td></tr><tr><td style="text-align:center">1460</td><td style="text-align:left">Real-Time Robot-Assisted Ergonomics</td></tr><tr><td style="text-align:center">1461</td><td style="text-align:left">The Open Vision Computer - An Integrated Sensing and Compute System for Mobile Robots</td></tr><tr><td style="text-align:center">1462</td><td style="text-align:left">Sensor Coverage Control Using Robots Constrained to a Curve</td></tr><tr><td style="text-align:center">1466</td><td style="text-align:left">Controlling AeroBot - Development of a Motion Planner for an Actively Articulated Wheeled Humanoid Robot</td></tr><tr><td style="text-align:center">1467</td><td style="text-align:left">Efficient Humanoid Contact Planning Using Learned Centroidal Dynamics Prediction</td></tr><tr><td style="text-align:center">1473</td><td style="text-align:left">Distributed Multi-Robot Formation Splitting and Merging in Dynamic Environments</td></tr><tr><td style="text-align:center">1475</td><td style="text-align:left">Exploiting Bistability for High Force Density Reflexive Gripping</td></tr><tr><td style="text-align:center">1476</td><td style="text-align:left">Fabric Soft Poly-Limbs for Physical Assistance of Daily Living Tasks</td></tr><tr><td style="text-align:center">1486</td><td style="text-align:left">Multi-Agent Synchronization Using Online Model-Free Action Dependent Dual Heuristic Dynamic Programming Approach</td></tr><tr><td style="text-align:center">1487</td><td style="text-align:left">OpenRoACH - A Durable Open-Source Hexapedal Platform with Onboard Robot Operating System (ROS)</td></tr><tr><td style="text-align:center">1490</td><td style="text-align:left">Exact Modal Characterization of the Non Conservative Non Linear Radial Mass Spring System</td></tr><tr><td style="text-align:center">1491</td><td style="text-align:left">Evaluating Merging Strategies for Sampling-Based Uncertainty Techniques in Object Detection</td></tr><tr><td style="text-align:center">1494</td><td style="text-align:left">MVX-Net - Multimodal VoxelNet for 3D Object Detection</td></tr><tr><td style="text-align:center">1495</td><td style="text-align:left">Online Estimation of Geometric and Inertia Parameters for Multirotor Aerial Vehicles</td></tr><tr><td style="text-align:center">1496</td><td style="text-align:left">Dentronics - Review First Concepts and Pilot Study of a New Application Domain for Collaborative Robots in Dental Assistance</td></tr><tr><td style="text-align:center">1497</td><td style="text-align:left">A Framework for Self-Training Perceptual Agents in Simulated Photorealistic Environments</td></tr><tr><td style="text-align:center">1510</td><td style="text-align:left">Robust Execution of Contact-Rich Motion Plans by Hybrid Force-Velocity Control</td></tr><tr><td style="text-align:center">1514</td><td style="text-align:left">Discrete Layer Jamming for Safe Co-Robots</td></tr><tr><td style="text-align:center">1515</td><td style="text-align:left">3D Path Planning from a Single 2D Fluoroscopic Image for Robot Assisted Fenestrated Endovascular Aortic Repair</td></tr><tr><td style="text-align:center">1516</td><td style="text-align:left">Torque and Velocity Controllers to Perform Jumps with a Humanoid Robot - Theory and Implementation on the iCub Robot</td></tr><tr><td style="text-align:center">1517</td><td style="text-align:left">Continuous Control for High-Dimensional State Spaces - An Interactive Learning Approach</td></tr><tr><td style="text-align:center">1518</td><td style="text-align:left">Decentralized Formation Coordination of Multiple Quadcopters under Communication Constraints</td></tr><tr><td style="text-align:center">1519</td><td style="text-align:left">Stair Climbing Stabilization of the HRP-4 Humanoid Robot Using Whole-Body Admittance Control</td></tr><tr><td style="text-align:center">1521</td><td style="text-align:left">End-User Robot Programming Using Mixed Reality</td></tr><tr><td style="text-align:center">1527</td><td style="text-align:left">Multimodal Trajectory Predictions for Autonomous Driving Using Deep Convolutional Networks</td></tr><tr><td style="text-align:center">1529</td><td style="text-align:left">Adaptive Genomic Evolution of Neural Network Topologies (AGENT) for State-To-Action Mapping in Autonomous Agents</td></tr><tr><td style="text-align:center">1530</td><td style="text-align:left">Non-Gaussian SLAM Utilizing Synthetic Aperture Sonar</td></tr><tr><td style="text-align:center">1532</td><td style="text-align:left">Transfer Learning for Surgical Task Segmentation</td></tr><tr><td style="text-align:center">1535</td><td style="text-align:left">Admittance Control for Human-Robot Interaction Using an Industrial Robot Equipped with a FT Sensor</td></tr><tr><td style="text-align:center">1538</td><td style="text-align:left">Exploitation of Environment Support Contacts for Manipulation Effort Reduction of a Robot Arm</td></tr><tr><td style="text-align:center">1539</td><td style="text-align:left">Learning from Demonstration in the Wild</td></tr><tr><td style="text-align:center">1542</td><td style="text-align:left">Improving Grounded Natural Language Understanding through Human-Robot Dialog</td></tr><tr><td style="text-align:center">1545</td><td style="text-align:left">Design and Characterization of a Novel Robotic Surface for Application to Compressed Physical Environments</td></tr><tr><td style="text-align:center">1547</td><td style="text-align:left">External Wrench Estimation for Multilink Aerial Robot by Center of Mass Estimator Based on Distributed IMU System</td></tr><tr><td style="text-align:center">1549</td><td style="text-align:left">A-SLAM - Human-In-The-Loop Augmented SLAM</td></tr><tr><td style="text-align:center">1550</td><td style="text-align:left">Fast and Precise Detection of Object Grasping Positions with Eigenvalue Templates</td></tr><tr><td style="text-align:center">1551</td><td style="text-align:left">Steering Co-Centered and Co-Directional Optical and Acoustic Beams with a Water-Immersible MEMS Scanning Mirror for Underwater Ranging and Communication</td></tr><tr><td style="text-align:center">1552</td><td style="text-align:left">Mechanical Search - Multi-Step Retrieval of a Target Object Occluded by Clutter</td></tr><tr><td style="text-align:center">1554</td><td style="text-align:left">Unsupervised Learning of Assistive Camera Views by an Aerial Co-Robot in Augmented Reality Multitasking Environments</td></tr><tr><td style="text-align:center">1555</td><td style="text-align:left">Dynamic Channel - A Planning Framework for Crowd Navigation</td></tr><tr><td style="text-align:center">1557</td><td style="text-align:left">Maintaining Grasps within Slipping Bounds by Monitoring Incipient Slip</td></tr><tr><td style="text-align:center">1560</td><td style="text-align:left">2D LiDAR Map Prediction Via Estimating Motion Flow with GRU</td></tr><tr><td style="text-align:center">1565</td><td style="text-align:left">Multi-Task Sensorization of Soft Actuators Using Prior Knowledge</td></tr><tr><td style="text-align:center">1567</td><td style="text-align:left">Efficient 2D-3D Matching for Multi-Camera Visual Localization</td></tr><tr><td style="text-align:center">1569</td><td style="text-align:left">Detecting Invasive Insects with Unmanned Aerial Vehicles</td></tr><tr><td style="text-align:center">1570</td><td style="text-align:left">Robotic Detection of Marine Litter Using Deep Visual Detection Models</td></tr><tr><td style="text-align:center">1572</td><td style="text-align:left">Memory Efficient Experience Replay for Streaming Learning</td></tr><tr><td style="text-align:center">1574</td><td style="text-align:left">Shape Memory Structures - Automated Design of Monolithic Soft Robot Structures with Pre-defined End Poses</td></tr><tr><td style="text-align:center">1576</td><td style="text-align:left">Learning Object Localization and 6D Pose Estimation from Simulation and Weakly Labeled Real Images</td></tr><tr><td style="text-align:center">1580</td><td style="text-align:left">Real-Time Planning with Multi-Fidelity Models for Agile Flights in Unknown Environments</td></tr><tr><td style="text-align:center">1582</td><td style="text-align:left">Safe Adaptive Switching among Dynamical Movement Primitives - Application to 3D Limit-Cycle Walkers</td></tr><tr><td style="text-align:center">1584</td><td style="text-align:left">A Simple but Robust Impedance Controller for Series Elastic Actuators</td></tr><tr><td style="text-align:center">1585</td><td style="text-align:left">Learning Motion Trajectories from Phase Space Analysis of the Demonstration</td></tr><tr><td style="text-align:center">1587</td><td style="text-align:left">Adaptive Control of Sclera Force and Insertion Depth for Safe Robot-Assisted Retinal Surgery</td></tr><tr><td style="text-align:center">1590</td><td style="text-align:left">A Rolling Flexure Mechanism for Progressive Stiffness Actuators</td></tr><tr><td style="text-align:center">1593</td><td style="text-align:left">Where Should We Place LiDARs on the Autonomous Vehicle - An Optimal Design Approach</td></tr><tr><td style="text-align:center">1594</td><td style="text-align:left">A Robust Tracking Controller for Robot Manipulators - Embedding Internal Model of Disturbances</td></tr><tr><td style="text-align:center">1596</td><td style="text-align:left">Adaptive Probabilistic Vehicle Trajectory Prediction through Physically Feasible Bayesian Recurrent Neural Network</td></tr><tr><td style="text-align:center">1597</td><td style="text-align:left">A Deployable Soft Robotic Arm with Stiffness Modulation for Assistive Living Applications</td></tr><tr><td style="text-align:center">1599</td><td style="text-align:left">Efficient Trajectory Planning for High Speed Flight in Unknown Environments</td></tr><tr><td style="text-align:center">1602</td><td style="text-align:left">Robust 3D Distributed Formation Control with Collision Avoidance and Application to Multirotor Aerial Vehicles</td></tr><tr><td style="text-align:center">1604</td><td style="text-align:left">Learning Probabilistic Multi-Modal Actor Models for Vision-Based Robotic Grasping</td></tr><tr><td style="text-align:center">1605</td><td style="text-align:left">What Lies in the Shadows Safe and Computation-Aware Motion Planning for Autonomous Vehicles Using Intent-Aware Dynamic Shadow Regions</td></tr><tr><td style="text-align:center">1607</td><td style="text-align:left">Visual-Odometric Localization and Mapping for Ground Vehicles Using SE(2)-XYZ Constraints</td></tr><tr><td style="text-align:center">1608</td><td style="text-align:left">A Coordinate-Based Approach for Static Balancing and Walking Control of Compliantly Actuated Legged Robots</td></tr><tr><td style="text-align:center">1609</td><td style="text-align:left">UWStereoNet - Unsupervised Learning for Depth Estimation and Color Correction of Underwater Stereo Imagery</td></tr><tr><td style="text-align:center">1612</td><td style="text-align:left">A Competitive Algorithm for Online Multi-Robot Exploration of a Translating Plume</td></tr><tr><td style="text-align:center">1613</td><td style="text-align:left">Prospection - Interpretable Plans from Language by Predicting the Future</td></tr><tr><td style="text-align:center">1615</td><td style="text-align:left">Julia for Robotics - Simulation and Real-Time Control in a High-Level Programming Language</td></tr><tr><td style="text-align:center">1616</td><td style="text-align:left">Learning Quickly to Plan Quickly Using Modular Meta-Learning</td></tr><tr><td style="text-align:center">1620</td><td style="text-align:left">A Validated Physical Model for Real-Time Simulation of Soft Robotic Snakes</td></tr><tr><td style="text-align:center">1625</td><td style="text-align:left">Inverse Reinforcement Learning of Interaction Dynamics from Demonstrations</td></tr><tr><td style="text-align:center">1626</td><td style="text-align:left">A Unified Closed-Loop Motion Planning Approach for an I-AUV in Cluttered Environment with Localization Uncertainty</td></tr><tr><td style="text-align:center">1627</td><td style="text-align:left">A Data-Driven Predictive Model of Individual-Specific Effects of FES on Human Gait Dynamics</td></tr><tr><td style="text-align:center">1629</td><td style="text-align:left">A Framework for Robot Manipulation - Skill Formalism Meta Learning and Adaptive Control</td></tr><tr><td style="text-align:center">1630</td><td style="text-align:left">A Fuzzy Based Accessibility Model for Disaster Environment</td></tr><tr><td style="text-align:center">1631</td><td style="text-align:left">Approximate Stability Analysis for Drystacked Structures</td></tr><tr><td style="text-align:center">1632</td><td style="text-align:left">SqueezeSegV2 - Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud</td></tr><tr><td style="text-align:center">1634</td><td style="text-align:left">Video Object Segmentation Using Teacher-Student Adaptation in a Human Robot Interaction (HRI) Setting</td></tr><tr><td style="text-align:center">1636</td><td style="text-align:left">Depth Generation Network - Estimating Real World Depth from Stereo and Depth Images</td></tr><tr><td style="text-align:center">1638</td><td style="text-align:left">Vision-Based Control of a Quadrotor in User Proximity - Mediated vs End-To-End Learning Approaches</td></tr><tr><td style="text-align:center">1639</td><td style="text-align:left">Classifying Pedestrian Actions in Advance Using Predicted Video Of Urban Driving Scenes</td></tr><tr><td style="text-align:center">1640</td><td style="text-align:left">Turn-Minimizing Multirobot Coverage</td></tr><tr><td style="text-align:center">1641</td><td style="text-align:left">RoboCSE - Robot Common Sense Embedding</td></tr><tr><td style="text-align:center">1642</td><td style="text-align:left">Experimental Learning of a Lift-Maximizing Central Pattern Generator for a Flapping Robotic Wing</td></tr><tr><td style="text-align:center">1644</td><td style="text-align:left">Easily Deployable Underwater Acoustic Navigation System for Multi-Vehicle Environmental Sampling Applications</td></tr><tr><td style="text-align:center">1645</td><td style="text-align:left">Learning to Predict the Wind for Safe Aerial Vehicle Planning</td></tr><tr><td style="text-align:center">1646</td><td style="text-align:left">Residual Reinforcement Learning for Robot Control</td></tr><tr><td style="text-align:center">1648</td><td style="text-align:left">Stability Optimization of Two-Fingered Anthropomorphic Hands for Precision Grasping with a Single Actuator</td></tr><tr><td style="text-align:center">1649</td><td style="text-align:left">Open-Loop Collective Assembly Using a Light Field to Power and Control a Phototaxic Mini-Robot Swarm</td></tr><tr><td style="text-align:center">1650</td><td style="text-align:left">HD Map Change Detection with a Boosted Particle Filter</td></tr><tr><td style="text-align:center">1651</td><td style="text-align:left">Characterizing Architectures of Soft Pneumatic Actuators for a Cable-Driven Shoulder Exoskeleton</td></tr><tr><td style="text-align:center">1655</td><td style="text-align:left">Saltyi 12 A Domain Specific Language for GR(1) Specifications and Designs</td></tr><tr><td style="text-align:center">1657</td><td style="text-align:left">Online Walking Pattern Generation for Humanoid Robot with Compliant Motion Control</td></tr><tr><td style="text-align:center">1659</td><td style="text-align:left">A Novel Development of Robots with Cooperative Strategy for Long-Term and Close-Proximity Autonomous Transmission-Line Inspection</td></tr><tr><td style="text-align:center">1663</td><td style="text-align:left">Three-Dimensionally Maneuverable Robotic Fish Enabled by Servo Motor and Water Electrolyser</td></tr><tr><td style="text-align:center">1664</td><td style="text-align:left">Online Planning for Target Object Search in Clutter under Partial Observability</td></tr><tr><td style="text-align:center">1665</td><td style="text-align:left">The H3D Dataset for Full-Surround 3D Multi-Object Detection and Tracking in Crowded Urban Scenes</td></tr><tr><td style="text-align:center">1667</td><td style="text-align:left">Beauty and the Beast - Optimal Methods Meet Learning for Drone Racing</td></tr><tr><td style="text-align:center">1668</td><td style="text-align:left">Flappy Hummingbird - An Open Source Dynamic Simulation of Flapping Wing Robots and Animals</td></tr><tr><td style="text-align:center">1670</td><td style="text-align:left">Power-Minimizing Control of a Variable-Pitch Propulsion System for Versatile Unmanned Aerial Vehicles</td></tr><tr><td style="text-align:center">1675</td><td style="text-align:left">Robotic Cutting - Mechanics and Control of Knife Motion</td></tr><tr><td style="text-align:center">1677</td><td style="text-align:left">Quantifying the Reality Gap in Robotic Manipulation Tasks</td></tr><tr><td style="text-align:center">1680</td><td style="text-align:left">Modeling and State Estimation of a Micro Ball-Balancing Robot Using a High Yaw-Rate Dynamic Model and an Extended Kalman Filter</td></tr><tr><td style="text-align:center">1681</td><td style="text-align:left">Decentralization of Multiagent Policies by Learning What to Communicate</td></tr><tr><td style="text-align:center">1682</td><td style="text-align:left">Yaw Torque Authority for a Flapping-Wing Micro-Aerial Vehicle</td></tr><tr><td style="text-align:center">1683</td><td style="text-align:left">Persistent Multi-Robot Mapping in an Uncertain Environment</td></tr><tr><td style="text-align:center">1684</td><td style="text-align:left">On the Role of Wearable Haptics for Force Feedback in Teleimpedance Control for Dual-Arm Robotic Teleoperation</td></tr><tr><td style="text-align:center">1685</td><td style="text-align:left">Optimized Jumping on the MIT Cheetah 3 Robot</td></tr><tr><td style="text-align:center">1686</td><td style="text-align:left">Spline Based Curve Path Following of Underactuated Snake Robots</td></tr><tr><td style="text-align:center">1688</td><td style="text-align:left">Localizing Discriminative Visual Landmarks for Place Recognition</td></tr><tr><td style="text-align:center">1690</td><td style="text-align:left">Energy Gradient-Based Graphs for Planning Within-Hand Caging Manipulation</td></tr><tr><td style="text-align:center">1692</td><td style="text-align:left">A Data-Efficient Framework for Training and Sim-To-Real Transfer of Navigation Policies</td></tr><tr><td style="text-align:center">1693</td><td style="text-align:left">Dynamic Risk Density for Autonomous Navigation in Cluttered Environments without Object Detection</td></tr><tr><td style="text-align:center">1694</td><td style="text-align:left">Robot Eye-Hand Coordination Learning by Watching Human Demonstrations - A Task Function Approximation Approach</td></tr><tr><td style="text-align:center">1697</td><td style="text-align:left">ROVO - Robust Omnidirectional Visual Odometry for Wide-Baseline Wide-FOV Camera Systems</td></tr><tr><td style="text-align:center">1698</td><td style="text-align:left">Uncertainty-Aware Driver Trajectory Prediction at Urban Intersections</td></tr><tr><td style="text-align:center">1699</td><td style="text-align:left">FSMI - Fast Computation of Shannon Mutual Information for Information-Theoretic Mapping</td></tr><tr><td style="text-align:center">1700</td><td style="text-align:left">Adaptive View Planning for Aerial 3D Reconstruction</td></tr><tr><td style="text-align:center">1701</td><td style="text-align:left">Energy Efficient Navigation for Running Legged Robots</td></tr><tr><td style="text-align:center">1702</td><td style="text-align:left">A Constrained Control-Planning Strategy for Redundant Manipulators</td></tr><tr><td style="text-align:center">1704</td><td style="text-align:left">A Noninvasive Approach to Recovering the Lost Force Feedback for a Robotic-Assisted Insertable Laparoscopic Surgical Camera</td></tr><tr><td style="text-align:center">1705</td><td style="text-align:left">Analysis of 3D Position Control for a Multi-Agent System of Self-Propelled Agents Steered by a Shared Global Control Input</td></tr><tr><td style="text-align:center">1710</td><td style="text-align:left">Priority Maps for Surveillance and Intervention of Wildfires and Other Spreading Processes</td></tr><tr><td style="text-align:center">1712</td><td style="text-align:left">High-Bandwidth Control of Twisted String Actuators</td></tr><tr><td style="text-align:center">1715</td><td style="text-align:left">Parity-Based Diagnosis in UAVs - Detectability and Robustness Analyses</td></tr><tr><td style="text-align:center">1717</td><td style="text-align:left">Gaze-Based Context-Aware Robotic System for Assisted Reaching and Grasping</td></tr><tr><td style="text-align:center">1721</td><td style="text-align:left">Receding horizon estimation and control with structured noise blocking for mobile robot slip compensation</td></tr><tr><td style="text-align:center">1722</td><td style="text-align:left">Detection and Reconstruction of Wires Using Cameras for Aircraft Safety Systems</td></tr><tr><td style="text-align:center">1724</td><td style="text-align:left">Design of a Soft Ankle-Foot Orthosis Exosuit for Foot Drop Assistance</td></tr><tr><td style="text-align:center">1726</td><td style="text-align:left">Touching to See and Seeing to Feel - Robotic Cross-Modal Sensory Data Generation for Visual-Tactile Perception</td></tr><tr><td style="text-align:center">1728</td><td style="text-align:left">A Predictive Reward Function for Human-Like Driving Based on a Transition Model of Surrounding Environment</td></tr><tr><td style="text-align:center">1729</td><td style="text-align:left">Real-Time Multisensory Affordance-Based Control for Adaptive Object Manipulation</td></tr><tr><td style="text-align:center">1730</td><td style="text-align:left">Dense Tactile Force Estimation Using GelSlim and Inverse FEM</td></tr><tr><td style="text-align:center">1738</td><td style="text-align:left">Dynamic Traffic Scene Classification with Space-Time Coherence</td></tr><tr><td style="text-align:center">1739</td><td style="text-align:left">DMP Based Trajectory Tracking for a Nonholonomic Mobile Robot with Automatic Goal Adaptation and Obstacle Avoidance</td></tr><tr><td style="text-align:center">1742</td><td style="text-align:left">Design and Fabrication of Transformable Head Structures for Endoscopic Catheters</td></tr><tr><td style="text-align:center">1743</td><td style="text-align:left">Factored Pose Estimation of Articulated Objects Using Efficient Nonparametric Belief Propagation</td></tr><tr><td style="text-align:center">1745</td><td style="text-align:left">Open Loop Position Control of Soft Continuum Arm Using Deep Reinforcement Learning</td></tr><tr><td style="text-align:center">1746</td><td style="text-align:left">A Novel Robotic System for Finishing of Freeform Surfaces</td></tr><tr><td style="text-align:center">1747</td><td style="text-align:left">Learning Extreme Hummingbird Maneuvers on Flapping Wing Robots</td></tr><tr><td style="text-align:center">1748</td><td style="text-align:left">Proximity Human-Robot Interaction Using Pointing Gestures and a Wrist-Mounted IMU</td></tr><tr><td style="text-align:center">1750</td><td style="text-align:left">Distributed Radiation Field Estimation and Informative Path Planning for Nuclear Environment Characterization</td></tr><tr><td style="text-align:center">1751</td><td style="text-align:left">Non-Parametric Error Modeling for Ultra-Wideband Localization Networks</td></tr><tr><td style="text-align:center">1755</td><td style="text-align:left">Modeling Variable Curvature Parallel Continuum Robots Using Euler Curves</td></tr><tr><td style="text-align:center">1756</td><td style="text-align:left">Efficient Kinodynamic Multi-Robot Replanning in Known Workspaces</td></tr><tr><td style="text-align:center">1757</td><td style="text-align:left">Development of SAM - cable-Suspended Aerial Manipulator</td></tr><tr><td style="text-align:center">1758</td><td style="text-align:left">Safe Reinforcement Learning with Model Uncertainty Estimates</td></tr><tr><td style="text-align:center">1760</td><td style="text-align:left">RCM-SLAM - Visual Localisation and Mapping under Remote Centre of Motion Constraints</td></tr><tr><td style="text-align:center">1762</td><td style="text-align:left">Improved Coverage Path Planning Using a Virtual Sensor Footprint - A Case Study on Demining</td></tr><tr><td style="text-align:center">1763</td><td style="text-align:left">Stanford Doggo - An Open-Source Quasi-Direct-Drive Quadruped</td></tr><tr><td style="text-align:center">1765</td><td style="text-align:left">Optimization-Based Human-In-The-Loop Manipulation Using Joint Space Polytopes</td></tr><tr><td style="text-align:center">1767</td><td style="text-align:left">Mixed Frame-Event-Driven Fast Pedestrian Detection</td></tr><tr><td style="text-align:center">1768</td><td style="text-align:left">Joint Learning of Instance and Semantic Segmentation for Robotic Pick-And-Place with Heavy Occlusions in Clutter</td></tr><tr><td style="text-align:center">1769</td><td style="text-align:left">Activity recognition in manufacturing: The roles of motion capture and sEMG+inertial wearables in detecting fine vs. gross motion</td></tr><tr><td style="text-align:center">1772</td><td style="text-align:left">Learning Motion Planning Policies in Uncertain Environments through Repeated Task Executions</td></tr><tr><td style="text-align:center">1774</td><td style="text-align:left">ModQuad-Vi - A Vision-Based Self-Assembling Modular Quadrotor</td></tr><tr><td style="text-align:center">1775</td><td style="text-align:left">Belief Space Planning for Reducing Terrain Relative Localization Uncertainty in Noisy Elevation Maps</td></tr><tr><td style="text-align:center">1778</td><td style="text-align:left">Feedback Control and 3D Motion of Heterogeneous Janus Particles</td></tr><tr><td style="text-align:center">1780</td><td style="text-align:left">The (Sensorized) Hand Is Quicker Than the Eye - Restoring Grasping Speed and Confidence for Amputees with Tactile Reflexes</td></tr><tr><td style="text-align:center">1782</td><td style="text-align:left">Hierarchical Optimization for Whole-Body Control of Wheeled Inverted Pendulum Humanoids</td></tr><tr><td style="text-align:center">1784</td><td style="text-align:left">Multi-Camera Visual-Inertial Navigation with Online Intrinsic and Extrinsic Calibration</td></tr><tr><td style="text-align:center">1786</td><td style="text-align:left">Stampede - A Discrete-Optimization Method for Solving Pathwise-Inverse Kinematics</td></tr><tr><td style="text-align:center">1787</td><td style="text-align:left">User-Guided Offline Synthesis of Robot Arm Motion from 6-DoF Paths</td></tr><tr><td style="text-align:center">1789</td><td style="text-align:left">Pose and Posture Estimation of Aerial Skeleton Systems for Outdoor Flying</td></tr><tr><td style="text-align:center">1790</td><td style="text-align:left">Domain Randomization for Active Pose Estimation</td></tr><tr><td style="text-align:center">1792</td><td style="text-align:left">Composition of Local Potential Functions with Reflection</td></tr><tr><td style="text-align:center">1793</td><td style="text-align:left">Context-Dependent Compensation Scheme to Reduce Trajectory Execution Errors for Industrial Manipulators</td></tr><tr><td style="text-align:center">1795</td><td style="text-align:left">Early Failure Detection of Deep End-To-End Control Policy by Reinforcement Learning</td></tr><tr><td style="text-align:center">1796</td><td style="text-align:left">The Phoenix Drone - An Open-Source Dual-Rotor Tail-Sitter Platform for Research and Education</td></tr><tr><td style="text-align:center">1797</td><td style="text-align:left">Effect of Mechanical Resistance on Cognitive Conflict in Physical Human-Robot Collaboration</td></tr><tr><td style="text-align:center">1799</td><td style="text-align:left">TREE - A Variable Topology Branching Continuum Robot</td></tr><tr><td style="text-align:center">1804</td><td style="text-align:left">Adjustable Power Modulation for a Leg Mechanism Suitable for Running</td></tr><tr><td style="text-align:center">1806</td><td style="text-align:left">A Rolling-Tip Flexible Instrument for Minimally Invasive Surgery</td></tr><tr><td style="text-align:center">1807</td><td style="text-align:left">Model-Free Optimal Estimation and Sensor Placement Framework for Elastic Kinematic Chain</td></tr><tr><td style="text-align:center">1808</td><td style="text-align:left">CoLo - A Performance Evaluation System for Multi-Robot Cooperative Localization Algorithms</td></tr><tr><td style="text-align:center">1810</td><td style="text-align:left">Real-Time Optimal Planning and Model Predictive Control of a Multi-Rotor with a Suspended Load</td></tr><tr><td style="text-align:center">1814</td><td style="text-align:left">Generation of Synchronized Configuration Space Trajectories of Multi-Robot Systems</td></tr><tr><td style="text-align:center">1815</td><td style="text-align:left">Contact-Implicit Trajectory Optimization Based on a Variable Smooth Contact Model and Successive Convexification</td></tr><tr><td style="text-align:center">1821</td><td style="text-align:left">Joint Kinematic Configuration Influence on the Passivity of an Impedance-Controlled Robotic Leg</td></tr><tr><td style="text-align:center">1822</td><td style="text-align:left">Deep Visuo-Tactile Learning - Estimation of Tactile Properties from Images</td></tr><tr><td style="text-align:center">1823</td><td style="text-align:left">Gesture Recognition Via Flexible Capacitive Touch Electrodes</td></tr><tr><td style="text-align:center">1825</td><td style="text-align:left">Visual Coverage Control for Teams of Quadcopters via Control Barrier Functions</td></tr><tr><td style="text-align:center">1826</td><td style="text-align:left">GuSTO - Guaranteed Sequential Trajectory Optimization Via Sequential Convex Programming</td></tr><tr><td style="text-align:center">1827</td><td style="text-align:left">Variational End-To-End Navigation and Localization</td></tr><tr><td style="text-align:center">1828</td><td style="text-align:left">Data-Driven Contact Clustering for Robot Simulation</td></tr><tr><td style="text-align:center">1830</td><td style="text-align:left">Improving Underwater Obstacle Detection Using Semantic Image Segmentation</td></tr><tr><td style="text-align:center">1832</td><td style="text-align:left">Identifying Feasible Workpiece Placement with Respect to Redundant Manipulator for Complex Manufacturing Tasks</td></tr><tr><td style="text-align:center">1834</td><td style="text-align:left">Offline Policy Iteration Based Reinforcement Learning Controller for Online Robotic Knee Prosthesis Parameter Tuning</td></tr><tr><td style="text-align:center">1837</td><td style="text-align:left">Adsorption Pad using capillary force for Uneven Surface</td></tr><tr><td style="text-align:center">1841</td><td style="text-align:left">Efficient Computation of Feedback Control for Equality-Constrained LQR</td></tr><tr><td style="text-align:center">1844</td><td style="text-align:left">Optimizing Vehicle Distributions and Fleet Sizes for Shared Mobility-On-Demand</td></tr><tr><td style="text-align:center">1849</td><td style="text-align:left">A Classification-Based Approach for Approximate Reachability</td></tr><tr><td style="text-align:center">1853</td><td style="text-align:left">Self-Supervised Learning for Single View Depth and Surface Normal Estimation</td></tr><tr><td style="text-align:center">1855</td><td style="text-align:left">Online Utility-Optimal Trajectory Design for Time-Varying Ocean Environments</td></tr><tr><td style="text-align:center">1856</td><td style="text-align:left">Interaction-Aware Multi-Agent Tracking and Probabilistic Behavior Prediction Via Adversarial Learning</td></tr><tr><td style="text-align:center">1858</td><td style="text-align:left">Design and Implementation of the CCRobot-II - A Palm-Based Cable Climbing Robot for Inspection on the Cable-Stayed Bridge</td></tr><tr><td style="text-align:center">1860</td><td style="text-align:left">Bioinspired Direct Visual Estimation of Attitude Rates with Very Low Resolution Images Using Deep Networks</td></tr><tr><td style="text-align:center">1862</td><td style="text-align:left">Reinforcement Learning on Variable Impedance Controller for High-Precision Robotic Assembly</td></tr><tr><td style="text-align:center">1867</td><td style="text-align:left">A Learning Framework for High Precision Industrial Assembly</td></tr><tr><td style="text-align:center">1869</td><td style="text-align:left">Propagation Networks for Model-Based Control under Partial Observation</td></tr><tr><td style="text-align:center">1870</td><td style="text-align:left">SLAMBench 3.0: Systematic Automated Reproducible Evaluation of SLAM Systems for Robot Vision Challenges and Scene Understanding</td></tr><tr><td style="text-align:center">1871</td><td style="text-align:left">Panthera - Design of a Reconfigurable Pavement Sweeping Robot</td></tr><tr><td style="text-align:center">1873</td><td style="text-align:left">Automatic Targeting of Plant Cells via Cell Segmentation and Robust Scene-Adaptive Tracking</td></tr><tr><td style="text-align:center">1874</td><td style="text-align:left">Workspace CPG with Body Pose Control for Stable Directed Vision During Omnidirectional Locomotion</td></tr><tr><td style="text-align:center">1879</td><td style="text-align:left">Rigid Body Motion Prediction with Planar Non-Convex Contact Patch</td></tr><tr><td style="text-align:center">1883</td><td style="text-align:left">Guaranteed Globally Optimal Planar Pose Graph and Landmark SLAM Via Sparse-Bounded Sums-Of-Squares Programming</td></tr><tr><td style="text-align:center">1885</td><td style="text-align:left">Weakly Supervised Recognition of Surgical Gestures</td></tr><tr><td style="text-align:center">1886</td><td style="text-align:left">WheeLeR - Wheel-Leg Reconfigurable Mechanism with Passive Gears for Mobile Robot Applications</td></tr><tr><td style="text-align:center">1887</td><td style="text-align:left">A Vacuum-Driven Origami Magic-Ball Soft Gripper</td></tr><tr><td style="text-align:center">1888</td><td style="text-align:left">A Dual-Bladder Buoyancy Engine for a Cephalopod-Inspired AUV</td></tr><tr><td style="text-align:center">1890</td><td style="text-align:left">Pavilion - Bridging Photo-Realism and Robotics</td></tr><tr><td style="text-align:center">1891</td><td style="text-align:left">Real-Time Monocular Object-Model Aware Sparse SLAM</td></tr><tr><td style="text-align:center">1895</td><td style="text-align:left">Development of a Multi-Level Stiffness Soft Robotics Module with Force Haptic Feedback for Endoscopic Applications</td></tr><tr><td style="text-align:center">1900</td><td style="text-align:left">Learning Behavior Trees from Demonstration</td></tr><tr><td style="text-align:center">1901</td><td style="text-align:left">Reinforcement Learning Meets Hybrid Zero Dynamics - A Case Study for RABBIT</td></tr><tr><td style="text-align:center">1903</td><td style="text-align:left">Rapid Inertial Reorientation of an Aerial Insect-Sized Robot Using a Piezo-Actuated Tail</td></tr><tr><td style="text-align:center">1905</td><td style="text-align:left">Visual Robot Task Planning</td></tr><tr><td style="text-align:center">1906</td><td style="text-align:left">Lift Your Leg - Mechanics of Running through Fluids</td></tr><tr><td style="text-align:center">1910</td><td style="text-align:left">Contact-based Navigation Path Planning for Aerial Robots</td></tr><tr><td style="text-align:center">1911</td><td style="text-align:left">Automatic Optical Coherence Tomography Imaging of Stationary and Moving Eyes with a Robotically-Aligned Scanner</td></tr><tr><td style="text-align:center">1913</td><td style="text-align:left">Steering a Multi-Armed Robotic Sheath Using Eccentric Precurved Tubes</td></tr><tr><td style="text-align:center">1914</td><td style="text-align:left">A Depth Camera-Based Soft Fingertip Device for Contact Region Estimation and Perception-Action Coupling</td></tr><tr><td style="text-align:center">1918</td><td style="text-align:left">Consolidated Control Framework to Control a Powered Transfemoral Prosthesis Over Inclined Terrain Conditions</td></tr><tr><td style="text-align:center">1919</td><td style="text-align:left">Control of Delayed Bilateral Teleoperation System for Robotic Tele-Echography</td></tr><tr><td style="text-align:center">1920</td><td style="text-align:left">Multi-Robot Region-Of-Interest Reconstruction with Dec-MCTS</td></tr><tr><td style="text-align:center">1921</td><td style="text-align:left">A Robotic Cell for Multi-Resolution Additive Manufacturing</td></tr><tr><td style="text-align:center">1923</td><td style="text-align:left">Learning Deep Visuomotor Policies for Dexterous Hand Manipulation</td></tr><tr><td style="text-align:center">1924</td><td style="text-align:left">Comparing Physical and Simulated Performance of a Deterministic and a Bio-Inspired Stochastic Foraging Strategy for Robot Swarms</td></tr><tr><td style="text-align:center">1925</td><td style="text-align:left">Bayesian Optimization of Soft Exosuits Using a Metabolic Estimator Stopping Process</td></tr><tr><td style="text-align:center">1929</td><td style="text-align:left">A Fog Robotic System for Dynamic Visual Servoing</td></tr><tr><td style="text-align:center">1932</td><td style="text-align:left">GraspFusion - Realizing Complex Motion by Learning and Fusing Grasp Modalities with Instance Segmentation</td></tr><tr><td style="text-align:center">1933</td><td style="text-align:left">Towards Semi-Autonomous and Soft-Robotics Enabled Upper-Limb Exoprosthetics - First Concepts and Robot-Based Emulation Prototype</td></tr><tr><td style="text-align:center">1935</td><td style="text-align:left">A Reinforcement Learning Approach for Control of a Nature-Inspired Aerial Vehicle</td></tr><tr><td style="text-align:center">1937</td><td style="text-align:left">Tightly-Coupled Aided Inertial Navigation with Point and Plane Features</td></tr><tr><td style="text-align:center">1939</td><td style="text-align:left">Accounting for Part Pose Estimation Uncertainties During Trajectory Generation for Part Pick-Up Using Mobile Manipulators</td></tr><tr><td style="text-align:center">1942</td><td style="text-align:left">RaD-VIO - Rangefinder-aided Downward Visual-Inertial Odometry</td></tr><tr><td style="text-align:center">1946</td><td style="text-align:left">Beyond Point Clouds - Fisher Information Field for Active Visual Localization</td></tr><tr><td style="text-align:center">1947</td><td style="text-align:left">Underwater Terrain Reconstruction from Forward-Looking Sonar Imagery</td></tr><tr><td style="text-align:center">1950</td><td style="text-align:left">Investigating Design Elements of Companion Robots for Older Adults</td></tr><tr><td style="text-align:center">1953</td><td style="text-align:left">Flight Camera Action Using Natural Language and Mixed Reality to Control a Drone</td></tr><tr><td style="text-align:center">1954</td><td style="text-align:left">Deep Local Trajectory Replanning and Control for Robot Navigation</td></tr><tr><td style="text-align:center">1956</td><td style="text-align:left">Acquisition of Word-Object Associations from Human-Robot and Human-Human Dialogues</td></tr><tr><td style="text-align:center">1960</td><td style="text-align:left">Large-Scale Multi-Object Rearrangement</td></tr><tr><td style="text-align:center">1962</td><td style="text-align:left">Data-Efficient Learning of Morphology and Controller for a Microrobot</td></tr><tr><td style="text-align:center">1966</td><td style="text-align:left">Fast and in Sync - Periodic Swarm Patterns for Quadrotors</td></tr><tr><td style="text-align:center">1968</td><td style="text-align:left">Switched Topology for Resilient Consensus Using Wi-Fi Signals</td></tr><tr><td style="text-align:center">1969</td><td style="text-align:left">Learning Recursive Bayesian Nonparametric Modeling of Moving Targets Via Mobile Decentralized Sensors</td></tr><tr><td style="text-align:center">1971</td><td style="text-align:left">Priming Deep Pedestrian Detection with Geometric Context</td></tr><tr><td style="text-align:center">1972</td><td style="text-align:left">BaRC - Backward Reachability Curriculum for Robotic Reinforcement Learning</td></tr><tr><td style="text-align:center">1973</td><td style="text-align:left">Anytime Stereo Image Depth Estimation on Mobile Devices</td></tr><tr><td style="text-align:center">1977</td><td style="text-align:left">FastDepth - Fast Monocular Depth Estimation on Embedded Systems</td></tr><tr><td style="text-align:center">1978</td><td style="text-align:left">Predictive Collision Avoidance for the Dynamic Window Approach</td></tr><tr><td style="text-align:center">1979</td><td style="text-align:left">Simulating Emergent Properties of Human Driving Behavior Using Multi-Agent Reward Augmented Imitation Learning</td></tr><tr><td style="text-align:center">1980</td><td style="text-align:left">A Real-Time Interactive Augmented Reality Depth Estimation Technique for Surgical Robotics</td></tr><tr><td style="text-align:center">1981</td><td style="text-align:left">Vision-Based Automated Sorting of C. Elegans on a Microfluidic Device</td></tr><tr><td style="text-align:center">1987</td><td style="text-align:left">ChevBot i 12 an Untethered Microrobot Powered by Laser for Microfactory Applications</td></tr><tr><td style="text-align:center">1989</td><td style="text-align:left">Integral Backstepping Position Control for Quadrotors in Tunnel-Like Confined Environments</td></tr><tr><td style="text-align:center">1991</td><td style="text-align:left">A Floating-Piston Hydrostatic Linear Actuator and Remote-Direct-Drive 2-DOF Gripper</td></tr><tr><td style="text-align:center">1995</td><td style="text-align:left">An Approach for Semantic Segmentation of Tree-Like Vegetation</td></tr><tr><td style="text-align:center">1996</td><td style="text-align:left">Improved Generalization of Heading Direction Estimation for Aerial Filming Using Semi-Supervised Regression</td></tr><tr><td style="text-align:center">1998</td><td style="text-align:left">Neural Lander - Stable Drone Landing Control Using Learned Dynamics</td></tr><tr><td style="text-align:center">2000</td><td style="text-align:left">Interactive Trajectory Prediction for Autonomous Driving Via Recurrent Meta Induction Neural Network</td></tr><tr><td style="text-align:center">2003</td><td style="text-align:left">Are We Ready for Autonomous Drone Racing The UZH-FPV Drone Racing Dataset</td></tr><tr><td style="text-align:center">2005</td><td style="text-align:left">Force-Controllable Quadruped Robot System with Capacitive-Type Joint Torque Sensor</td></tr><tr><td style="text-align:center">2006</td><td style="text-align:left">Probabilistic Projective Association and Semantic Guided Relocalization for Dense Reconstruction</td></tr><tr><td style="text-align:center">2007</td><td style="text-align:left">Automatic Real-Time Anomaly Detection for Autonomous Aerial Vehicles</td></tr><tr><td style="text-align:center">2009</td><td style="text-align:left">Kinematic Constraints Based Bi-Directional RRT (KB-RRT) with Parameterized Trajectories for Robot Path Planning in Cluttered Environment</td></tr><tr><td style="text-align:center">2010</td><td style="text-align:left">Development of a Soft Power Suit for Lower Back Assistance</td></tr><tr><td style="text-align:center">2011</td><td style="text-align:left">Joint Inference of Physics-Based Tracking andForce Estimation in Planar Pushing</td></tr><tr><td style="text-align:center">2012</td><td style="text-align:left">Morphology-Specific Convolutional Neural Networks for Tactile Object Recognition with a Multi-Fingered Hand</td></tr><tr><td style="text-align:center">2013</td><td style="text-align:left">Hunting Drones with Other Drones - Tracking a Moving Radio Target</td></tr><tr><td style="text-align:center">2014</td><td style="text-align:left">Segmenting Unknown 3D Objects from Real Depth Images Using Mask R-CNN Trained on Synthetic Point Clouds</td></tr><tr><td style="text-align:center">2015</td><td style="text-align:left">A Pipe-Climbing Soft Robot</td></tr><tr><td style="text-align:center">2023</td><td style="text-align:left">UAVUGV Autonomous Cooperation - UAV Assists UGV to Climb a Cliff by Attaching a Tether</td></tr><tr><td style="text-align:center">2025</td><td style="text-align:left">A Multimodal Aerial Underwater Vehicle with Extended Endurance and Capabilities</td></tr><tr><td style="text-align:center">2030</td><td style="text-align:left">Hierarchical Game-Theoretic Planning for Autonomous Vehicles</td></tr><tr><td style="text-align:center">2036</td><td style="text-align:left">Soil Displacement Terramechanics for Wheel-Based Trenching with a Planetary Rover</td></tr><tr><td style="text-align:center">2038</td><td style="text-align:left">Sharing the Load - Human-Robot Team Lifting Using Muscle Activity</td></tr><tr><td style="text-align:center">2039</td><td style="text-align:left">Robot Object Referencing through Situated Legible Projections</td></tr><tr><td style="text-align:center">2040</td><td style="text-align:left">IceVisionSet - lossless video dataset collected on Russian winter roads with traffic sign annotations</td></tr><tr><td style="text-align:center">2044</td><td style="text-align:left">MRS-VPR - A Multi-Resolution Sampling Based Visual Place Recognition Method</td></tr><tr><td style="text-align:center">2045</td><td style="text-align:left">Integrated UWB-Vision Approach for Autonomous Docking of UAVs in GPS-Denied Environments</td></tr><tr><td style="text-align:center">2046</td><td style="text-align:left">Nitinol Living Hinges for Millimeter-Sized Robots and Medical Devices</td></tr><tr><td style="text-align:center">2051</td><td style="text-align:left">Real-Time Model Predictive Control for Versatile Dynamic Motions in Quadrupedal Robots</td></tr><tr><td style="text-align:center">2052</td><td style="text-align:left">Safe and Fast Path Planning in Cluttered Environment Using Contiguous Free-Space Partitioning</td></tr><tr><td style="text-align:center">2055</td><td style="text-align:left">Automatic Leg Regeneration for Robot Mobility Recovery</td></tr><tr><td style="text-align:center">2057</td><td style="text-align:left">Geometric Search Based Inverse Kinematics of 7-DoF Redundant Manipulator with Multiple Joint Offsets</td></tr><tr><td style="text-align:center">2058</td><td style="text-align:left">Model-Based Estimation of the Gravity-Loaded Shape and Scene Depth for a Slim 3-Actuator Continuum Robot with Monocular Visual Feedback</td></tr><tr><td style="text-align:center">2059</td><td style="text-align:left">Active Sampling Based Safe Identification of Dynamical Systems Using Extreme Learning Machines and Barrier Certificates</td></tr><tr><td style="text-align:center">2064</td><td style="text-align:left">Robust Area Coverage with Connectivity Maintenance</td></tr><tr><td style="text-align:center">2065</td><td style="text-align:left">REPLAB - A Reproducible Low-Cost Arm Benchmark for Robotic Learning</td></tr><tr><td style="text-align:center">2067</td><td style="text-align:left">An Interactive Scene Generation Using Natural Language</td></tr><tr><td style="text-align:center">2068</td><td style="text-align:left">Capillary Ionic Transistor and Precise Transport Control for Nano Manipulation</td></tr><tr><td style="text-align:center">2069</td><td style="text-align:left">Spatial Coverage without Computation</td></tr><tr><td style="text-align:center">2071</td><td style="text-align:left">A Fog Robotics Approach to Deep Robot Learning - Application to Object Recognition and Grasp Planning in Surface Decluttering</td></tr><tr><td style="text-align:center">2073</td><td style="text-align:left">Towards Robust Product Packing with a Minimalistic End-Effector</td></tr><tr><td style="text-align:center">2076</td><td style="text-align:left">Continuous Occupancy Map Fusion with Fast Bayesian Hilbert Maps</td></tr><tr><td style="text-align:center">2083</td><td style="text-align:left">Distributional Deep Reinforcement Learning with a Mixture of Gaussians</td></tr><tr><td style="text-align:center">2084</td><td style="text-align:left">Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning</td></tr><tr><td style="text-align:center">2087</td><td style="text-align:left">Multi-Vehicle Trajectory Optimisation on Road Networks</td></tr><tr><td style="text-align:center">2088</td><td style="text-align:left">Task-Driven Estimation and Control Via Information Bottlenecks</td></tr><tr><td style="text-align:center">2090</td><td style="text-align:left">Compliant Bistable Gripper for Aerial Perching and Grasping</td></tr><tr><td style="text-align:center">2095</td><td style="text-align:left">Model Predictive Control of Ride-Sharing Autonomous Mobility-On-Demand Systems</td></tr><tr><td style="text-align:center">2098</td><td style="text-align:left">Cargo Transportation Strategy Using T3-Multirotor UAV</td></tr><tr><td style="text-align:center">2099</td><td style="text-align:left">Design and Experiments of a Squid-Like Aquatic-Aerial Vehicle with Soft Morphing Fins and Arms</td></tr><tr><td style="text-align:center">2100</td><td style="text-align:left">Using Geometric Features to Represent Near-Contact Behavior in Robotic Grasping</td></tr><tr><td style="text-align:center">2102</td><td style="text-align:left">Evaluating the Effectiveness of Perspective Aware Planning with Panoramas</td></tr><tr><td style="text-align:center">2103</td><td style="text-align:left">Nonlinear Orientation Controller for a Compliant Robotic Fish Based on Asymmetric Actuation</td></tr><tr><td style="text-align:center">2106</td><td style="text-align:left">User Centric Device Registration for Streamlined Workflows in Surgical Navigation Systems</td></tr><tr><td style="text-align:center">2108</td><td style="text-align:left">Lightweight Contrast Modeling for Attention-Aware Visual Localization</td></tr><tr><td style="text-align:center">2111</td><td style="text-align:left">Keyframe-Based Direct Thermali 12 Inertial Odometry</td></tr><tr><td style="text-align:center">2119</td><td style="text-align:left">Learning to Identify Object Instances by Touch - Tactile Recognition Via Multimodal Matching</td></tr><tr><td style="text-align:center">2120</td><td style="text-align:left">Manipulation by Feel - Touch-Based Control with Deep Predictive Models</td></tr><tr><td style="text-align:center">2121</td><td style="text-align:left">Feasibility Study of Robotic Needles with a Rotational Tip-Joint and Notch Patterns</td></tr><tr><td style="text-align:center">2125</td><td style="text-align:left">Development of a Novel Gait Rehabilitation Device with Hip Interaction and a Single DOF Mechanism</td></tr><tr><td style="text-align:center">2128</td><td style="text-align:left">Sensing Shear Forces During Food Manipulation - Resolving the Trade-Off Between Range and Sensitivity</td></tr><tr><td style="text-align:center">2139</td><td style="text-align:left">Self-Supervised Sparse-To-Dense - Self-Supervised Depth Completion from LiDAR and Monocular Camera</td></tr><tr><td style="text-align:center">2141</td><td style="text-align:left">Neural Network Pile Loading Controller Trained by Demonstration</td></tr><tr><td style="text-align:center">2143</td><td style="text-align:left">A Multi-Domain Feature Learning Method for Visual Place Recognition</td></tr><tr><td style="text-align:center">2150</td><td style="text-align:left">Learning to Write Anywhere with Spatial Transformer Image-To-Motion Encoder-Decoder Networks</td></tr><tr><td style="text-align:center">2154</td><td style="text-align:left">Human-Care Rounds Robot with Contactless Breathing Measurement</td></tr><tr><td style="text-align:center">2159</td><td style="text-align:left">Motion Planning for High-DOF Manipulation Using Hierarchical System Identification</td></tr><tr><td style="text-align:center">2161</td><td style="text-align:left">Beyond Photometric Loss for Self-Supervised Ego-Motion Estimation</td></tr><tr><td style="text-align:center">2162</td><td style="text-align:left">Real-Time Scalable Dense Surfel Mapping</td></tr><tr><td style="text-align:center">2167</td><td style="text-align:left">Azimuthal Shear Deformation of a Novel Soft Fiber-Reinforced Rotary Pneumatic Actuator</td></tr><tr><td style="text-align:center">2176</td><td style="text-align:left">In-Hand Object Scanning Via RGB-D Video Segmentation</td></tr><tr><td style="text-align:center">2178</td><td style="text-align:left">DSNet - Joint Learning for Scene Segmentation and Disparity Estimation</td></tr><tr><td style="text-align:center">2180</td><td style="text-align:left">Coverage of an Environment Using Energy-Constrained Unmanned Aerial Vehicles</td></tr><tr><td style="text-align:center">2181</td><td style="text-align:left">ADAPS - Autonomous Driving Via Principled Simulations</td></tr><tr><td style="text-align:center">2183</td><td style="text-align:left">Navigating Dynamically Unknown Environments Leveraging past Experience</td></tr><tr><td style="text-align:center">2186</td><td style="text-align:left">Global Vision-Based Reconstruction of Three-Dimensional Road Surfaces Using Adaptive Extended Kalman Filter</td></tr><tr><td style="text-align:center">2189</td><td style="text-align:left">Online Vehicle Trajectory Prediction Using Policy Anticipation Network and Optimization-Based Context Reasoning</td></tr><tr><td style="text-align:center">2192</td><td style="text-align:left">Transferring Grasp Configurations Using Active Learning and Local Replanning</td></tr><tr><td style="text-align:center">2195</td><td style="text-align:left">A Hierarchical Framework for Coordinating Large-Scale Robot Networks</td></tr><tr><td style="text-align:center">2197</td><td style="text-align:left">A Data-Driven Approach for Fast Simulation of Robot Locomotion on Granular Media</td></tr><tr><td style="text-align:center">2198</td><td style="text-align:left">Planning Coordinated Event Observation for Structured Narratives</td></tr><tr><td style="text-align:center">2199</td><td style="text-align:left">Autonomous Laparoscopic Robotic Suturing with a Novel Actuated Suturing Tool and 3D Endoscope</td></tr><tr><td style="text-align:center">2201</td><td style="text-align:left">Motion Planning Templates - A Motion Planning Framework for Robots with Low-Power CPUs</td></tr><tr><td style="text-align:center">2203</td><td style="text-align:left">Using DP towards a Shortest Path Problem-Related Application</td></tr><tr><td style="text-align:center">2204</td><td style="text-align:left">DoS-Resilient Multi-Robot Temporal Logic Motion Planning</td></tr><tr><td style="text-align:center">2206</td><td style="text-align:left">Toward Lateral Aerial Grasping  Manipulation Using Scalable Suction</td></tr><tr><td style="text-align:center">2207</td><td style="text-align:left">An Autonomous Loop-Closure Approach for Simultaneous Exploration and Coverage of Unknown Infrastructure Using MAVs</td></tr><tr><td style="text-align:center">2208</td><td style="text-align:left">Security-Aware Synthesis of Human-UAV Protocols</td></tr><tr><td style="text-align:center">2209</td><td style="text-align:left">Efficient Generation of Motion Plans from Attribute-Based Natural Language Instructions Using Dynamic Constraint Mapping</td></tr><tr><td style="text-align:center">2210</td><td style="text-align:left">Using Data-Driven Domain Randomization to Transfer Robust Control Policies to Mobile Robots</td></tr><tr><td style="text-align:center">2211</td><td style="text-align:left">Real-Time Vehicle Detection from Short-Range Aerial Image with Compressed MobileNet</td></tr><tr><td style="text-align:center">2219</td><td style="text-align:left">Online Plan Repair in Multi-Robot Coordination with Disturbances</td></tr><tr><td style="text-align:center">2223</td><td style="text-align:left">A Novel Laser Scalpel System for Computer-Assisted Laser Surgery</td></tr><tr><td style="text-align:center">2225</td><td style="text-align:left">Stable Bin Packing of Non-Convex 3D Objects with a Robot Manipulator</td></tr><tr><td style="text-align:center">2230</td><td style="text-align:left">Fast and Efficient Aerial Climbing of Vertical Surfaces Using Fixed-Wing UAVs</td></tr><tr><td style="text-align:center">2312</td><td style="text-align:left">Automated Abstraction of Manipulation Domains for Cost-Based Reactive Synthesis</td></tr><tr><td style="text-align:center">2317</td><td style="text-align:left">Geometric Interpretation of the General POE Model for a Serial-Link Robot Via Conversion into D-H Parameterization</td></tr><tr><td style="text-align:center">2321</td><td style="text-align:left">Spatial Change Detection Using Voxel Classification by Normal Distributions Transform</td></tr><tr><td style="text-align:center">2322</td><td style="text-align:left">The Foldable Drone - A Morphing Quadrotor that can Squeeze and Fly</td></tr><tr><td style="text-align:center">2334</td><td style="text-align:left">Probabilistic Appearance-Based Place Recognition Through Bag of Tracked Words</td></tr><tr><td style="text-align:center">2335</td><td style="text-align:left">Robust Pose-Graph SLAM Using Absolute Orientation Sensing</td></tr><tr><td style="text-align:center">2340</td><td style="text-align:left">Deconfliction of Motion Paths with Traffic Inspired Rules in Roboti 12 Robot and Humani 12 Robot Interactions</td></tr><tr><td style="text-align:center">2343</td><td style="text-align:left">Shallow-Depth Insertion - Peg in Shallow Hole through Robotic In-Hand Manipulation</td></tr><tr><td style="text-align:center">2344</td><td style="text-align:left">High-Speed Small-Deformation Catching of Soft Objects Based on Active Vision and Proximity Sensing</td></tr><tr><td style="text-align:center">2347</td><td style="text-align:left">Design Guarantees for Resilient Robot Formations on Lattices</td></tr><tr><td style="text-align:center">2348</td><td style="text-align:left">Resilient Active Target Tracking with Multiple Robots</td></tr><tr><td style="text-align:center">2349</td><td style="text-align:left">Self-Assembly Magnetic Chain Unit for Bulk Biomaterial Actuation</td></tr><tr><td style="text-align:center">2354</td><td style="text-align:left">Monocular Semantic Occupancy Grid Mapping with Convolutional Variational Encoder-Decoder Networks</td></tr><tr><td style="text-align:center">2355</td><td style="text-align:left">Effects of Different Hand-Grounding Locations on Haptic Performance with a Wearable Kinesthetic Haptic Device</td></tr><tr><td style="text-align:center">2358</td><td style="text-align:left">Sparse2Dense - From Direct Sparse Odometry to Dense 3D Reconstruction</td></tr><tr><td style="text-align:center">2359</td><td style="text-align:left">Robust low-overlap 3-D point cloud registration for outlier rejection</td></tr><tr><td style="text-align:center">2363</td><td style="text-align:left">Nanoliter Fluid Handling for Microbiology via Levitated Magnetic Microrobots</td></tr><tr><td style="text-align:center">2364</td><td style="text-align:left">Unified Representation and Registration of Heterogeneous Sets of Geometric Primitives</td></tr><tr><td style="text-align:center">2365</td><td style="text-align:left">Through-Water Stereo SLAM with Refraction Correction for AUV Localization</td></tr><tr><td style="text-align:center">2367</td><td style="text-align:left">CENTAURO - A Hybrid Locomotion and High Power Resilient Manipulation Platform</td></tr><tr><td style="text-align:center">2368</td><td style="text-align:left">Motion Planning Networks</td></tr><tr><td style="text-align:center">2372</td><td style="text-align:left">Towards Robot Interaction Autonomy - Explore Identify and Interact</td></tr><tr><td style="text-align:center">2373</td><td style="text-align:left">Hybrid Nonsmooth Barrier Functions with Applications to Provably Safe and Composable Collision Avoidance for Robotic Systems</td></tr><tr><td style="text-align:center">2375</td><td style="text-align:left">Design Optimisation of Sparse Sensing Array for Extended Aerial Robot Navigation in Deep Hazardous Tunnels</td></tr><tr><td style="text-align:center">2377</td><td style="text-align:left">Thermal Recovery of Multi-Limbed Robots with Electric Actuators</td></tr><tr><td style="text-align:center">2381</td><td style="text-align:left">Local Descriptor for Robust Place Recognition Using LiDAR Intensity</td></tr><tr><td style="text-align:center">2384</td><td style="text-align:left">It Would Make Me Happy If You Used My Guess - Comparing Robot Persuasive Strategies in Social Human-Robot Interaction</td></tr><tr><td style="text-align:center">2386</td><td style="text-align:left">Specifying Dual-Arm Robot Planning Problems through Natural Language and Demonstration</td></tr><tr><td style="text-align:center">2387</td><td style="text-align:left">Distributed Motion Tomography for Reconstruction of Flow Fields</td></tr><tr><td style="text-align:center">2388</td><td style="text-align:left">Adaptive Sampling and Reduced Order Modeling of Dynamic Processes by Robot Teams</td></tr><tr><td style="text-align:center">2389</td><td style="text-align:left">Safe and Efficient High Dimensional Motion Planning in Space-Time with Time Parameterized Prediction</td></tr><tr><td style="text-align:center">2390</td><td style="text-align:left">Decentralized Full Coverage of Unknown Areas by Multiple Robots with Limited Visibility Sensing</td></tr><tr><td style="text-align:center">2392</td><td style="text-align:left">Automated Laser Ablation of Motile Sperm for Immobilization</td></tr><tr><td style="text-align:center">2393</td><td style="text-align:left">Context-Aware Depth and Pose Estimation for Bronchoscopic Navigation</td></tr><tr><td style="text-align:center">2394</td><td style="text-align:left">Enhancing V-SLAM Keyframe Selection with an Efficient ConvNet for Semantic Analysis</td></tr><tr><td style="text-align:center">2400</td><td style="text-align:left">Dexterous Manipulation with Deep Reinforcement Learning - Efficient General and Low-Cost</td></tr><tr><td style="text-align:center">2401</td><td style="text-align:left">Learning to Drive from Simulation without Real World Labels</td></tr><tr><td style="text-align:center">2405</td><td style="text-align:left">Inertial Yaw-Independent Velocity and Attitude Estimation for High Speed Quadrotor Flight</td></tr><tr><td style="text-align:center">2408</td><td style="text-align:left">Regeneration of Normal Distributions Transform for Target Lattice Based on Fusion of Truncated Gaussian Components</td></tr><tr><td style="text-align:center">2410</td><td style="text-align:left">Loosely-Coupled Semi-Direct Monocular SLAM</td></tr><tr><td style="text-align:center">2413</td><td style="text-align:left">End-Effector Pose Correction for Versatile Large-Scale Multi-Robotic Systems</td></tr><tr><td style="text-align:center">2414</td><td style="text-align:left">A Novel Efficient Big Data Processing Scheme for Feature Extraction in Electrical Discharge Machining</td></tr><tr><td style="text-align:center">2416</td><td style="text-align:left">End to End Learning of a Multi-Layered SNN Based on R-STDP for a Target Tracking Snake-Like Robot</td></tr><tr><td style="text-align:center">2418</td><td style="text-align:left">Go with the Flow - Exploration and Mapping of Pedestrian Flow Patterns from Partial Observations</td></tr><tr><td style="text-align:center">2419</td><td style="text-align:left">Energy-Aware Optimal Control of Variable Stiffness Actuated Robots</td></tr><tr><td style="text-align:center">2424</td><td style="text-align:left">A Gradual Refreshing Scheme to Improve Tool Utilization</td></tr><tr><td style="text-align:center">2425</td><td style="text-align:left">MetaGrasp - Data Efficient Grasping by Affordance Interpreter Network</td></tr><tr><td style="text-align:center">2426</td><td style="text-align:left">Field Deployment of a Plume Monitoring UAV Flock</td></tr><tr><td style="text-align:center">2428</td><td style="text-align:left">Chance-Constrained Collision Avoidance for MAVs in Dynamic Environments</td></tr><tr><td style="text-align:center">2429</td><td style="text-align:left">Toward Fingertip Non-Contact Material Recognition and Near-Distance Ranging for Robotic Grasping</td></tr><tr><td style="text-align:center">2431</td><td style="text-align:left">Trajectory Generation for Multiagent Point-To-Point Transitions Via Distributed Model Predictive Control</td></tr><tr><td style="text-align:center">2432</td><td style="text-align:left">PRIMAL - Pathfinding Via Reinforcement and Imitation Multi-Agent Learning</td></tr><tr><td style="text-align:center">2436</td><td style="text-align:left">Persistent and Robust Execution of MAPF Schedules in Warehouses</td></tr><tr><td style="text-align:center">2440</td><td style="text-align:left">Video-Based Prediction of Hand-Grasp Preshaping with Application to Prosthesis Control</td></tr><tr><td style="text-align:center">2441</td><td style="text-align:left">Color-Coded Fiber-Optic Tactile Sensor for an Elastomeric Robot Skin</td></tr><tr><td style="text-align:center">2442</td><td style="text-align:left">Shear-invariant Sliding Contact Perception with a Soft Tactile Sensor</td></tr><tr><td style="text-align:center">2444</td><td style="text-align:left">A White-Noise-On-Jerk Motion Prior for Continuous-Time Trajectory Estimation on SE(3)</td></tr><tr><td style="text-align:center">2449</td><td style="text-align:left">Design of a Miniature Series Elastic Actuator for Bilateral Teleoperations Requiring Accurate Torque Sensing and Control</td></tr><tr><td style="text-align:center">2452</td><td style="text-align:left">Real-Time Surface Shape Sensing for Soft and Flexible Structures Using Fiber Bragg Gratings</td></tr><tr><td style="text-align:center">2456</td><td style="text-align:left">Application of a Redundant Haptic Interface in Enhancing Soft-Tissue Stiffness Discrimination</td></tr><tr><td style="text-align:center">2457</td><td style="text-align:left">Autonomous Parallelization of Resource-Aware Robotic Task Nodes</td></tr><tr><td style="text-align:center">2461</td><td style="text-align:left">Dense-ArthroSLAM - Dense Intra-Articular 3D Reconstruction with Robust Localization Prior for Arthroscopy</td></tr><tr><td style="text-align:center">2463</td><td style="text-align:left">A Unified Framework for the Teleoperation of Surgical Robots in Constrained Workspaces</td></tr><tr><td style="text-align:center">2464</td><td style="text-align:left">Cable-Less Magnetically-Driven Forceps for Minimally Invasive Surgery</td></tr><tr><td style="text-align:center">2468</td><td style="text-align:left">A Hand-Held Robot for Precise and Safe Pivc</td></tr><tr><td style="text-align:center">2469</td><td style="text-align:left">On the Development of Adaptive Tendon-Driven Wearable Exo-Gloves for Grasping Capabilities Enhancement</td></tr><tr><td style="text-align:center">2471</td><td style="text-align:left">A Variational Approach to Minimum Jerk Trajectories for Psychological Safety in Collaborative Assembly Stations</td></tr><tr><td style="text-align:center">2474</td><td style="text-align:left">The Role of Closed-Loop Hand Control in Handshaking Interactions</td></tr><tr><td style="text-align:center">2475</td><td style="text-align:left">Improved Human-Robot Collaborative Control of Redundant Robot for Teleoperated Minimally Invasive Surgery</td></tr><tr><td style="text-align:center">2476</td><td style="text-align:left">Object Centered Teleoperation of Mobile Manipulators with Remote Center of Motion Constraint</td></tr><tr><td style="text-align:center">2484</td><td style="text-align:left">3D Image Reconstruction of Biological Organelles with a Robot-Aided Microscopy System for Intracellular Surgery</td></tr><tr><td style="text-align:center">2485</td><td style="text-align:left">Context-Aware Modelling for Augmented Reality Display Behaviour</td></tr><tr><td style="text-align:center">2486</td><td style="text-align:left">Optical Force Sensing in Minimally Invasive Robotic Surgery</td></tr><tr><td style="text-align:center">2487</td><td style="text-align:left">Contactless Robotic Micromanipulation in Air Using a Magneto-Acoustic System</td></tr><tr><td style="text-align:center">2488</td><td style="text-align:left">A Self-Adaptive Motion Scaling Framework for Surgical Robot Remote Control</td></tr><tr><td style="text-align:center">2489</td><td style="text-align:left">An Improved Control-Oriented Modeling of the Magnetic Field</td></tr><tr><td style="text-align:center">2492</td><td style="text-align:left">The Oxford Multimotion Dataset - Multiple SE(3) Motions with Ground Truth</td></tr><tr><td style="text-align:center">2493</td><td style="text-align:left">Asynchronous Spatial Image Convolutions for Event Cameras</td></tr><tr><td style="text-align:center">2496</td><td style="text-align:left">Learning to Predict Ego-Vehicle Poses for Sampling-Based Nonholonomic Motion Planning</td></tr><tr><td style="text-align:center">2498</td><td style="text-align:left">Pre-Grasp Sliding Manipulation of Thin Objects Using Soft Compliant or Underactuated Hands</td></tr><tr><td style="text-align:center">2499</td><td style="text-align:left">A Hand Combining Two Simple Grippers to Pick up and Arrange Objects for Assembly</td></tr><tr><td style="text-align:center">2502</td><td style="text-align:left">A Magnetically Steered Endolaser Probe for Automated Panretinal Photocoagulation</td></tr><tr><td style="text-align:center">2504</td><td style="text-align:left">Focal Loss in 3D Object Detection</td></tr><tr><td style="text-align:center">2505</td><td style="text-align:left">Towards Blended Reactive Planning and Acting Using Behavior Trees</td></tr><tr><td style="text-align:center">2506</td><td style="text-align:left">Design of a Compliant Mechanical Device for Upper-Leg Rehabilitation</td></tr><tr><td style="text-align:center">2508</td><td style="text-align:left">Autonomous Data-Driven Manipulation of Unknown Anisotropic Deformable Tissues Using Unmodelled Continuum Manipulators</td></tr><tr><td style="text-align:center">2510</td><td style="text-align:left">Tetherless Mobile Micro-Surgical Scissors Using Magnetic Actuation</td></tr><tr><td style="text-align:center">2512</td><td style="text-align:left">A Lightweight and Efficient Fully-Powered Knee Prosthesis with Actively Variable Transmission</td></tr><tr><td style="text-align:center">2515</td><td style="text-align:left">Capturing the Frictional State of a Soft Tactile Sensor Via Subtractive Color Mixing</td></tr><tr><td style="text-align:center">2516</td><td style="text-align:left">Mechanical Framework Design with Experimental Verification of a Wearable Exoskeleton Chair</td></tr><tr><td style="text-align:center">2517</td><td style="text-align:left">Vision-Based Online Learning Kinematic Control for Soft Robots Using Local Gaussian Process Regression</td></tr><tr><td style="text-align:center">2518</td><td style="text-align:left">Towards Robot-Assisted Photoacoustic Imaging - Implementation Using the da Vinci Research Kit and Virtual Fixtures</td></tr><tr><td style="text-align:center">2523</td><td style="text-align:left">Disturbance-Observer-Based Compliance Control of Electro-Hydraulic Actuators with Backdrivability</td></tr><tr><td style="text-align:center">2525</td><td style="text-align:left">Long-Stroke Rolling Diaphragm Actuators for Haptic Display of Forces in Teleoperation</td></tr><tr><td style="text-align:center">2526</td><td style="text-align:left">Fluidic Elastomer Actuators for Haptic Interactions in Virtual Reality</td></tr><tr><td style="text-align:center">2530</td><td style="text-align:left">Design and Implementation of a Two-DOF Robotic System with an Adjustable Force Limiting Mechanism for Ankle Rehabilitation</td></tr><tr><td style="text-align:center">2531</td><td style="text-align:left">An Autonomous Exoskeleton for Ankle Plantarflexion Assistance</td></tr><tr><td style="text-align:center">2533</td><td style="text-align:left">Unsupervised Learning of Monocular Depth and Ego-Motion Using Multiple Masks</td></tr><tr><td style="text-align:center">2534</td><td style="text-align:left">A Microrobotic System for Simultaneous Measurement of Turgor Pressure and Cell-Wall Elasticity of Individual Growing Plant Cells</td></tr><tr><td style="text-align:center">2535</td><td style="text-align:left">On the Similarities and Differences among Contact Models in Robot Simulation</td></tr><tr><td style="text-align:center">2537</td><td style="text-align:left">Light-Weight Whiskers for Contact Pre-Contact and Fluid Velocity Sensing</td></tr><tr><td style="text-align:center">2538</td><td style="text-align:left">Rendezvous Planning for Multiple AUVs with Mobile Charging Stations in Dynamic Currents</td></tr><tr><td style="text-align:center">2539</td><td style="text-align:left">UVDAR System for Visual Relative Localization with Application to Leader-Follower Formations of Multirotor UAVs</td></tr><tr><td style="text-align:center">2540</td><td style="text-align:left">On-Line 3D Active Pose-Graph SLAM Based on Key Poses Using Graph Topology and Sub-Maps</td></tr><tr><td style="text-align:center">2541</td><td style="text-align:left">Event-Based Direct Camera Tracking from a Photometric 3D Map Using Nonlinear Optimization</td></tr><tr><td style="text-align:center">2545</td><td style="text-align:left">Low-Latency Visual SLAM with Appearance-Enhanced Local Map Building</td></tr><tr><td style="text-align:center">2552</td><td style="text-align:left">Experimental Comparison of Visual-Aided Odometry Methods for Rail Vehicles</td></tr><tr><td style="text-align:center">2554</td><td style="text-align:left">Iteratively Reweighted Midpoint Method for Fast Multiple View Triangulation</td></tr><tr><td style="text-align:center">2555</td><td style="text-align:left">Sizing the Aortic Annulus with a Robotised Commercially Available Soft Balloon Catheter - In Vitro Study on Idealised Phantoms</td></tr><tr><td style="text-align:center">2558</td><td style="text-align:left">Endoscope Force Generation and Intrinsic Sensing with Environmental Scaffolding</td></tr><tr><td style="text-align:center">2559</td><td style="text-align:left">Unified Motion-Based Calibration of Mobile Multi-Sensor Platforms with Time Delay Estimation</td></tr><tr><td style="text-align:center">2561</td><td style="text-align:left">Towards Robotic Feeding - Role of Haptics in Fork-based Food Manipulation</td></tr><tr><td style="text-align:center">2562</td><td style="text-align:left">Near-Optimal Path Planning for a Car-Like Robot Visiting a Set of Waypoints with Field of View Constraints</td></tr><tr><td style="text-align:center">2563</td><td style="text-align:left">Optimal Proactive Path Planning for Collaborative Robots in Industrial Contexts</td></tr><tr><td style="text-align:center">2564</td><td style="text-align:left">Vision-Based Control and Stability Analysis of a Cable-Driven Parallel Robot</td></tr><tr><td style="text-align:center">2565</td><td style="text-align:left">A Novel Skin-Stretch Haptic Device for Intuitive Control of Robotic Prostheses and Avatars</td></tr><tr><td style="text-align:center">2568</td><td style="text-align:left">Passive Task-Prioritized Shared-Control Teleoperation with Haptic Guidance</td></tr><tr><td style="text-align:center">2570</td><td style="text-align:left">Robot-Based Training for People with Mild Cognitive Impairment</td></tr><tr><td style="text-align:center">2571</td><td style="text-align:left">Data-Driven Haptic Modeling of Normal Interactions on Viscoelastic Deformable Objects Using a Random Forest</td></tr><tr><td style="text-align:center">2573</td><td style="text-align:left">Degenerate Motion Analysis for Aided INS with Online Spatial and Temporal Sensor Calibration</td></tr><tr><td style="text-align:center">2574</td><td style="text-align:left">Sparse Optimization of Contact Forces for Balancing Control of Multi-Legged Humanoids</td></tr><tr><td style="text-align:center">2579</td><td style="text-align:left">Efficient Micro Waveguide Coupling Based on Microrobotic Positioning</td></tr><tr><td style="text-align:center">2580</td><td style="text-align:left">Coordinated control of spacecrafts attitude and end-effector for space robots</td></tr><tr><td style="text-align:center">2581</td><td style="text-align:left">Theres No Place Like Home - Visual Teach and Repeat for Emergency Return of Multirotor UAVs During GPS Failure</td></tr><tr><td style="text-align:center">2583</td><td style="text-align:left">Towards a Generic Diver-Following Algorithm - Balancing Robustness and Efficiency in Deep Visual Detection</td></tr><tr><td style="text-align:center">2584</td><td style="text-align:left">Haptic Inspection of Planetary Soils with Legged Robots</td></tr><tr><td style="text-align:center">2585</td><td style="text-align:left">Central Pattern Generators Control of Momentum Driven Compliant Structures</td></tr><tr><td style="text-align:center">2586</td><td style="text-align:left">Rover-IRL - Inverse Reinforcement Learning with Soft Value Iteration Networks for Planetary Rover Path Planning</td></tr><tr><td style="text-align:center">2587</td><td style="text-align:left">Experimental Evaluation of Teleoperation Interfaces for Cutting of Satellite Insulation</td></tr><tr><td style="text-align:center">2588</td><td style="text-align:left">A Truly Redundant Aerial Manipulator System with Application to Push-And-Slide Inspection in Industrial Plants</td></tr><tr><td style="text-align:center">2589</td><td style="text-align:left">Human Gaze-Driven Spatial Tasking of an Autonomous MAV</td></tr><tr><td style="text-align:center">2594</td><td style="text-align:left">3-PSR Mechanism Design Parameter Optimization and Low-Cost Method for Replicating Wave and Boat Motion</td></tr><tr><td style="text-align:center">2596</td><td style="text-align:left">Avoidance of Convex and Concave Obstacles with Convergence Ensured through Contraction</td></tr><tr><td style="text-align:center">2597</td><td style="text-align:left">An Adaptive Walking Robot with Reconfigurable Mechanisms using Shape Morphing Joints</td></tr><tr><td style="text-align:center">2601</td><td style="text-align:left">Learning Affordance Segmentation for Real-World Robotic Manipulation Via Synthetic Images</td></tr><tr><td style="text-align:center">2602</td><td style="text-align:left">Cloth Manipulation Using Random-Forest-Based Imitation Learning</td></tr><tr><td style="text-align:center">2606</td><td style="text-align:left">Modeling Grasp Type Improves Learning-Based Grasp Planning</td></tr><tr><td style="text-align:center">2609</td><td style="text-align:left">A Novel Rotating Beam Link for Variable Stiffness Robotic Arms</td></tr><tr><td style="text-align:center">2610</td><td style="text-align:left">Design and Fabrication of a 3D Printed Metallic Flexible Joint for Snake-Like Surgical Robot</td></tr><tr><td style="text-align:center">2611</td><td style="text-align:left">A Large-Deflection FBG Bending Sensor for SMA Bending Modules for Steerable Surgical Robots</td></tr><tr><td style="text-align:center">2612</td><td style="text-align:left">Differentially-Clutched Series Elastic Actuator for Robot-Aided Musculoskeletal Rehabilitation</td></tr><tr><td style="text-align:center">2613</td><td style="text-align:left">Combining a Bio-Inspired Reflexive Neuromuscular Controller with a Trajectory Controller for Active Lower-Extremity Gait-Assistive Devices</td></tr><tr><td style="text-align:center">2614</td><td style="text-align:left">Autonomous Flexible Endoscope for Minimally Invasive Surgery with Enhanced Safety</td></tr><tr><td style="text-align:center">2616</td><td style="text-align:left">Using Augmentation to Improve the Robustness to Rotation of Deep Learning Segmentation in Robotic-Assisted Surgical Data</td></tr><tr><td style="text-align:center">2618</td><td style="text-align:left">Pneumatically Attachable Flexible Rails for Track-Guided Ultrasound Scanning in Robotic-Assisted Partial Nephrectomy i 12 A Preliminary Design Study</td></tr><tr><td style="text-align:center">2620</td><td style="text-align:left">Everybody Needs Somebody Sometimes - Validation of Adaptive Recovery in Robotic Space Operations</td></tr><tr><td style="text-align:center">2622</td><td style="text-align:left">Collision Detection for Industrial Collaborative Robots - A Deep Learning Approach</td></tr><tr><td style="text-align:center">2623</td><td style="text-align:left">Dynamic Primitives in Human Manipulation of Non-Rigid Objects</td></tr><tr><td style="text-align:center">2629</td><td style="text-align:left">Quasi-Direct Drive for Low-Cost Compliant Robotic Manipulation</td></tr><tr><td style="text-align:center">2631</td><td style="text-align:left">Getting Robots Unfrozen and Unlost in Dense Pedestrian Crowds</td></tr><tr><td style="text-align:center">2634</td><td style="text-align:left">Direct Relative Edge Optimization a Robust Alternative for Pose Graph Optimization</td></tr><tr><td style="text-align:center">2635</td><td style="text-align:left">Learning to See the Wood for the Trees - Deep Laser Localization in Urban and Natural Environments on a CPU</td></tr><tr><td style="text-align:center">2637</td><td style="text-align:left">Modeling Perceptual Aliasing in SLAM Via Discrete-Continuous Graphical Models</td></tr><tr><td style="text-align:center">2642</td><td style="text-align:left">New Automated Guided Vehicle System Using Real-Time Holonic Scheduling for Warehouse Picking</td></tr><tr><td style="text-align:center">2643</td><td style="text-align:left">Efficient Autonomous Exploration Planning of Large Scale 3D-Environments</td></tr><tr><td style="text-align:center">2645</td><td style="text-align:left">Deep Reinforcement Learning Robot for Search and Rescue Applications - Exploration in Unknown Cluttered Environments</td></tr><tr><td style="text-align:center">2647</td><td style="text-align:left">Acausal Approach to Motion Cueing</td></tr><tr><td style="text-align:center">2648</td><td style="text-align:left">A Robotic Microscope System to Examine TCR Quality against Tumor Neoantigens - A New Tool for Cancer Immunotherapy Research</td></tr><tr><td style="text-align:center">2649</td><td style="text-align:left">A Multi-Vehicle Trajectories Generator to Simulate Vehicle-To-Vehicle Encountering Scenarios</td></tr><tr><td style="text-align:center">2652</td><td style="text-align:left">Explicit Model Predictive Control of a Magnetic Tethered Capsule</td></tr><tr><td style="text-align:center">2653</td><td style="text-align:left">A Sense of Touch for the Shadow Modular Grasper</td></tr><tr><td style="text-align:center">2654</td><td style="text-align:left">Super Dragon - A 10-m-long Coupled Tendon-driven Articulated Manipulator</td></tr><tr><td style="text-align:center">2655</td><td style="text-align:left">Bundled Wire Drive - Proposal and Feasibility Study of a Novel Tendon-Driven Mechanism Using Synthetic Fiber Ropes</td></tr><tr><td style="text-align:center">2656</td><td style="text-align:left">Soft Tactile Sensing - Retrieving Force Torque and Contact Point Information from Deformable Surfaces</td></tr><tr><td style="text-align:center">2657</td><td style="text-align:left">Robot Co-Design - Beyond the Monotone Case</td></tr><tr><td style="text-align:center">2660</td><td style="text-align:left">Optimal Stochastic Vehicle Path Planning Using Covariance Steering</td></tr><tr><td style="text-align:center">2664</td><td style="text-align:left">A Constraint Programming Approach to Simultaneous Task Allocation and Motion Scheduling for Industrial Dual-Arm Manipulation Tasks</td></tr><tr><td style="text-align:center">2668</td><td style="text-align:left">Safe Navigation with Human Instructions in Complex Scenes</td></tr><tr><td style="text-align:center">2670</td><td style="text-align:left">ConFusion - Sensor Fusion for Complex Robotic Systems Using Nonlinear Optimization</td></tr><tr><td style="text-align:center">2675</td><td style="text-align:left">Task-Based Design of Ad-Hoc Modular Manipulators</td></tr><tr><td style="text-align:center">2683</td><td style="text-align:left">Flexible Collaborative Transportation by a Team of Rotorcraft</td></tr><tr><td style="text-align:center">2685</td><td style="text-align:left">Integrated Mapping and Path Planning for Very Large-Scale Robotic (VLSR) Systems</td></tr><tr><td style="text-align:center">2687</td><td style="text-align:left">A Comparison between Decentralized Local and Global Methods for Connectivity Maintenance of Multi-Robot Networks</td></tr><tr><td style="text-align:center">2689</td><td style="text-align:left">High-Bandwidth 3D Multi-Trap Actuation Technique for 6-DoF Real-Time Control of Optical Robots</td></tr><tr><td style="text-align:center">2690</td><td style="text-align:left">IPMC Monolithic Thin Film Robots Fabricated through a Multi-Layer Casting Process</td></tr><tr><td style="text-align:center">2691</td><td style="text-align:left">Caterpillar-Inspired Crawling Robot Using Both Compression and Bending Deformations</td></tr><tr><td style="text-align:center">2693</td><td style="text-align:left">AgriColMap - Aerial-Ground Collaborative 3D Mapping for Precision Farming</td></tr><tr><td style="text-align:center">2699</td><td style="text-align:left">Force-Based Heterogeneous Traffic Simulation for Autonomous Vehicle Testing</td></tr><tr><td style="text-align:center">2700</td><td style="text-align:left">Thermal Image Based Navigation System for Skid-Steering Mobile Robots in Sugarcane Crops</td></tr><tr><td style="text-align:center">2703</td><td style="text-align:left">Geometric Relation Distribution for Place Recognition</td></tr><tr><td style="text-align:center">2705</td><td style="text-align:left">Proprioceptive Localization Assisted by Magnetoreception - A Minimalist Intermittent Heading-Based Approach</td></tr><tr><td style="text-align:center">2706</td><td style="text-align:left">Incremental Visual-Inertial 3D Mesh Generation with Structural Regularities</td></tr><tr><td style="text-align:center">2709</td><td style="text-align:left">Hybrid Open-Loop Closed-Loop Control of Coupled Human-Robot Balance During Assisted Stance Transition with Extra Robotic Legs</td></tr><tr><td style="text-align:center">2710</td><td style="text-align:left">Shape Locking Mechanism of Flexible Joint Using Mechanical Latch with Electromagnetic Force</td></tr><tr><td style="text-align:center">2711</td><td style="text-align:left">Grasping Interface with Wet Adhesion and Patterned Morphology - Case of Thin Shell</td></tr><tr><td style="text-align:center">2713</td><td style="text-align:left">Comparison of Modeling Approaches for a Tendon Actuated Continuum Robot with Three Extensible Segments</td></tr><tr><td style="text-align:center">2714</td><td style="text-align:left">Contact-Event-Triggered Mode Estimation for Dynamic Rigid Body Impedance-Controlled Capture</td></tr><tr><td style="text-align:center">2715</td><td style="text-align:left">Relative Autonomy and Navigation for Command and Control of Low-Cost Autonomous Underwater Vehicles</td></tr><tr><td style="text-align:center">2717</td><td style="text-align:left">Communication-Efficient Planning and Mapping for Multi-Robot Exploration in Large Environments</td></tr><tr><td style="text-align:center">2718</td><td style="text-align:left">Minimum-Time Trajectory Planning under Intermittent Measurements</td></tr><tr><td style="text-align:center">2719</td><td style="text-align:left">Compensation of Measurement Noise and Bias in Geometric Attitude Estimation</td></tr><tr><td style="text-align:center">2722</td><td style="text-align:left">Optimal Trajectory Generation for Quadrotor Teach-And-Repeat</td></tr><tr><td style="text-align:center">2723</td><td style="text-align:left">Interaction Force Estimation Using Extended State Observers - An Application to Impedance Based Assistive and Rehabilitation Robotics</td></tr><tr><td style="text-align:center">2724</td><td style="text-align:left">Autonomous Navigation for Unmanned Underwater Vehicles - Real-Time Experiments Using Computer Vision</td></tr><tr><td style="text-align:center">2726</td><td style="text-align:left">Optimization-Based Non-Impact Rolling Locomotion of a Variable Geometry Truss</td></tr><tr><td style="text-align:center">2728</td><td style="text-align:left">Multi-Rate Tracking Control for a Space Robot on a Controlled Satellite - A Passivity-Based Strategy</td></tr><tr><td style="text-align:center">2730</td><td style="text-align:left">Development of Performance System with Musical Dynamics Expression on Humanoid Saxophonist Robot</td></tr><tr><td style="text-align:center">2731</td><td style="text-align:left">Non-Destructive Robotic Assessment of Mango Ripeness Via Multi-Point Soft Haptics</td></tr><tr><td style="text-align:center">2732</td><td style="text-align:left">Control and Configuration Planning of an Aerial Cable Towed System</td></tr><tr><td style="text-align:center">2738</td><td style="text-align:left">Active Localization of Gas Leaks Using Fluid Simulation</td></tr><tr><td style="text-align:center">2744</td><td style="text-align:left">Capacitive Sensing for a Gripper with Gecko-Inspired Adhesive Film</td></tr><tr><td style="text-align:center">2745</td><td style="text-align:left">Classification of Household Materials Via Spectroscopy</td></tr><tr><td style="text-align:center">2747</td><td style="text-align:left">Precision Stationary Flight of a Robotic Hummingbird</td></tr><tr><td style="text-align:center">2751</td><td style="text-align:left">Four Wings - A New Insect-Sized Aerial Robot with Steering ability and Payload Capacity for Autonomy</td></tr><tr><td style="text-align:center">2752</td><td style="text-align:left">Benchmarking Resilience of Artificial Hands</td></tr><tr><td style="text-align:center">2754</td><td style="text-align:left">Circular and Concentric Formation of Kinematic Unicycles</td></tr><tr><td style="text-align:center">2755</td><td style="text-align:left">Point-Based Policy Synthesis for POMDPs with Boolean and Quantitative Objectives</td></tr><tr><td style="text-align:center">2757</td><td style="text-align:left">Dynamic Manipulation of Gear Ratio and Ride Height for a Novel Compliant Wheel Using Pneumatic Actuators</td></tr><tr><td style="text-align:center">2758</td><td style="text-align:left">CHiMP - A Contact Based Hilbert Map Planner</td></tr><tr><td style="text-align:center">2759</td><td style="text-align:left">From Pixels to Percepts - Highly Robust Perception and Exploration Using Deep Learning and an Optical Biomimetic Tactile Sensor</td></tr><tr><td style="text-align:center">2760</td><td style="text-align:left">Control from the Cloud - Edge Computing Services and Digital Shadow for Automation Technologies</td></tr><tr><td style="text-align:center">2761</td><td style="text-align:left">Learning to Serve - An Experimental Study for a New Learning from Demonstrations Framework</td></tr><tr><td style="text-align:center">2762</td><td style="text-align:left">Imitating Human Search Strategies for Assembly</td></tr><tr><td style="text-align:center">2764</td><td style="text-align:left">Bayesian Active Learning for Collaborative Task Specification Using Equivalence Regions</td></tr><tr><td style="text-align:center">2765</td><td style="text-align:left">Combining Imitation Learning with Constraint-Based Task Specification and Control</td></tr><tr><td style="text-align:center">2772</td><td style="text-align:left">Compliant Four Degree-Of-Freedom Manipulator with Locally Deformable Elastic Elements for Minimally Invasive Surgery</td></tr><tr><td style="text-align:center">2773</td><td style="text-align:left">Modular FBG Bending Sensor for Continuum Neurosurgical Robot</td></tr><tr><td style="text-align:center">2774</td><td style="text-align:left">Motion Control of Cable-Driven Continuum Catheter Robot through Contacts</td></tr><tr><td style="text-align:center">2775</td><td style="text-align:left">Ways to Learn a Therapists Patient-Specific Intervention - Robotics vs Telerobotics-Mediated Hands-On Teaching</td></tr><tr><td style="text-align:center">2783</td><td style="text-align:left">Vision-Based High Speed Driving with a Deep Dynamic Observer</td></tr><tr><td style="text-align:center">2790</td><td style="text-align:left">Accelerated Inference in Markov Random Fields Via Smooth Riemannian Optimization</td></tr><tr><td style="text-align:center">2793</td><td style="text-align:left">Reinforcement Learning in Topology-Based Representation for Human Body Movement with Whole Arm Manipulation</td></tr><tr><td style="text-align:center">2795</td><td style="text-align:left">DispSegNet - Leveraging Semantics for End-To-End Learning of Disparity Estimation from Stereo Imagery</td></tr><tr><td style="text-align:center">2800</td><td style="text-align:left">Long-Term Occupancy Grid Prediction Using Recurrent Neural Networks</td></tr><tr><td style="text-align:center">2801</td><td style="text-align:left">Deep Metadata Fusion for Traffic Light to Lane Assignment</td></tr><tr><td style="text-align:center">2803</td><td style="text-align:left">Modeling Design and Test-Bench Validation of a Semi-Active Propulsive Ankle Prosthesis with a Clutched Series Elastic Actuator</td></tr><tr><td style="text-align:center">2804</td><td style="text-align:left">Torque-Based Balancing for a Humanoid Robot Performing High-Force Interaction Tasks</td></tr><tr><td style="text-align:center">2806</td><td style="text-align:left">Design of Anti-Skid Foot with Passive Slip Detection Mechanism for Conditional Utilization of Heterogeneous Foot Pads</td></tr><tr><td style="text-align:center">2807</td><td style="text-align:left">Humanoid Robot HRP-5P - an Electrically Actuated Humanoid Robot with High Power and Wide Range Joints</td></tr><tr><td style="text-align:center">2810</td><td style="text-align:left">Learning from humans how to grasp - a data-driven architecture for autonomous grasping with anthropomorphic soft hands</td></tr><tr><td style="text-align:center">2811</td><td style="text-align:left">Robot Self-Calibration Using Multiple Kinematic Chains - A Simulation Study on the iCub Humanoid Robot</td></tr><tr><td style="text-align:center">2812</td><td style="text-align:left">Online Gait Transitions and Disturbance Recovery for Legged Robots via the Feasible Impulse Set</td></tr><tr><td style="text-align:center">2815</td><td style="text-align:left">Frequency-Aware Model Predictive Control</td></tr><tr><td style="text-align:center">2817</td><td style="text-align:left">Trajectory Optimization for Wheeled-Legged Quadrupedal Robots Using Linearized ZMP Constraints</td></tr><tr><td style="text-align:center">2819</td><td style="text-align:left">Demonstration-Guided Deep Reinforcement Learning of Control Policies for Dexterous Human-Robot Interaction</td></tr><tr><td style="text-align:center">2820</td><td style="text-align:left">Where Should I Walk Predicting Terrain Properties from Images Via Self-Supervised Learning</td></tr><tr><td style="text-align:center">2821</td><td style="text-align:left">Jointly Learning to Construct and Control Agents Using Deep Reinforcement Learning</td></tr><tr><td style="text-align:center">2823</td><td style="text-align:left">Compensation of Environmental Influences on Sensorized-Forceps for Practical Surgical Tasks</td></tr><tr><td style="text-align:center">2826</td><td style="text-align:left">Miniaturization of Multistage High Dynamic Range Six-Axis Force Sensor Composed of Resin Material</td></tr><tr><td style="text-align:center">2827</td><td style="text-align:left">Towards the Design of Robotic Drivers for Full-Scale Self-Driving Racing Cars</td></tr><tr><td style="text-align:center">2830</td><td style="text-align:left">Fast Online Segmentation of Activities from Partial Trajectories</td></tr><tr><td style="text-align:center">2833</td><td style="text-align:left">Reconstructing Human Hand Pose and Configuration using a Fixed-Base Exoskeleton</td></tr><tr><td style="text-align:center">2834</td><td style="text-align:left">Activity Recognition for Ergonomics Assessment of Industrial Tasks with Automatic Feature Selection</td></tr><tr><td style="text-align:center">2835</td><td style="text-align:left">Augmented Reality Predictive Displays to Help Mitigate the Effects of Delayed Telesurgery</td></tr><tr><td style="text-align:center">2838</td><td style="text-align:left">Development of a Novel Force Sensing System to Measure the Ground Reaction Force of Rats with Complete Spinal Cord Injury</td></tr><tr><td style="text-align:center">2839</td><td style="text-align:left">Miniature Robotic Tubes with Rotational Tip-Joints As a Medical Delivery Platform</td></tr><tr><td style="text-align:center">2840</td><td style="text-align:left">Swarm Aggregation without Communication and Global Positioning</td></tr><tr><td style="text-align:center">2842</td><td style="text-align:left">Body Lift and Drag for a Legged Millirobot in Compliant Beam Environment</td></tr><tr><td style="text-align:center">2844</td><td style="text-align:left">Retrieval of Magnetic Medical Microrobots from the Bloodstream</td></tr><tr><td style="text-align:center">2845</td><td style="text-align:left">Reconsidering Six-degree-of-freedom Magnetic Actuation Across Scales</td></tr><tr><td style="text-align:center">2846</td><td style="text-align:left">Dynamic Modeling and Gait Analysis for Miniature Robots in the Absence of Foot Placement Control</td></tr><tr><td style="text-align:center">2847</td><td style="text-align:left">RoboScallop - A Bivalve Inspired Swimming Robot</td></tr><tr><td style="text-align:center">2849</td><td style="text-align:left">Exploiting Symmetries in Reinforcement Learning of Bimanual Robotic Tasks</td></tr><tr><td style="text-align:center">2850</td><td style="text-align:left">Multimodal Bin Picking System with Compliant Tactile Sensor Arrays for Flexible Part Handling</td></tr><tr><td style="text-align:center">2852</td><td style="text-align:left">Tightly-Coupled Visual-Inertial Localization and 3D Rigid-Body Target Tracking</td></tr><tr><td style="text-align:center">2858</td><td style="text-align:left">Tree Search Techniques for Minimizing Detectability and Maximizing Visibility</td></tr><tr><td style="text-align:center">2861</td><td style="text-align:left">Training a Binary Weight Object Detector by Knowledge Transfer for Autonomous Driving</td></tr><tr><td style="text-align:center">2864</td><td style="text-align:left">Learning to Drive in a Day</td></tr><tr><td style="text-align:center">2866</td><td style="text-align:left">Iteratively Refined Feasibility Checks in Robotic Assembly Sequence Planning</td></tr><tr><td style="text-align:center">2867</td><td style="text-align:left">INFORA - A Novel Inflatable Origami-Based Actuator</td></tr><tr><td style="text-align:center">2869</td><td style="text-align:left">Toward Grasping against the Environment - Locking Polygonal Objects against a Wall Using Two-Finger Robot Hands</td></tr><tr><td style="text-align:center">2873</td><td style="text-align:left">Multi-Process Fusion - Visual Place Recognition Using Multiple Image Processing Methods</td></tr><tr><td style="text-align:center">2874</td><td style="text-align:left">A Maximum Likelihood Approach to Extract Finite Planes from 3-D Laser Scans</td></tr><tr><td style="text-align:center">2877</td><td style="text-align:left">Geo-Supervised Visual Depth Prediction</td></tr><tr><td style="text-align:center">2879</td><td style="text-align:left">Two-Stage Transfer Learning for Heterogeneous Robot Detection and 3D Joint Position Estimation in a 2D Camera Image Using CNN</td></tr><tr><td style="text-align:center">2881</td><td style="text-align:left">Fully Automated Annotation with Noise-Masked Visual Markers for Deep Learning-Based Object Detection</td></tr><tr><td style="text-align:center">2882</td><td style="text-align:left">PedX - Benchmark Dataset for Metric 3D Pose Estimation of Pedestrians in Complex Urban Intersections</td></tr><tr><td style="text-align:center">2883</td><td style="text-align:left">Learning Pose Estimation for High-Precision Robotic Assembly Using Simulated Depth Images</td></tr><tr><td style="text-align:center">2885</td><td style="text-align:left">Distinguishing Refracted Features Using Light Field Cameras with Application to Structure From Motion</td></tr><tr><td style="text-align:center">2886</td><td style="text-align:left">Effective Visual Place Recognition Using Multi-Sequence Maps</td></tr><tr><td style="text-align:center">2888</td><td style="text-align:left">Inferring 3D Shapes of Unknown Rigid Objects in Clutter through Inverse Physics Reasoning</td></tr><tr><td style="text-align:center">2890</td><td style="text-align:left">Bi-Directional Value Learning for Risk-Aware Planning under Uncertainty</td></tr><tr><td style="text-align:center">2891</td><td style="text-align:left">Collision Avoidance of Arbitrarily Shaped Deforming Objects Using Collision Cones</td></tr><tr><td style="text-align:center">2893</td><td style="text-align:left">A Hybrid Approach of Learning and Model-Based Channel Prediction for Communication Relay UAVs in Dynamic Urban Environments</td></tr><tr><td style="text-align:center">2894</td><td style="text-align:left">Probabilistic Completeness of RRT for Geometric and Kinodynamic Planning with Forward Propagation</td></tr><tr><td style="text-align:center">2897</td><td style="text-align:left">On the Impact of Uncertainty for Path Planning</td></tr><tr><td style="text-align:center">2900</td><td style="text-align:left">Learning Navigation Behaviors End to End with AutoRL</td></tr><tr><td style="text-align:center">2901</td><td style="text-align:left">Multi-Robot Motion Planning with Dynamics Via Coordinated Sampling-Based Expansion Guided by Multi-Agent Search</td></tr><tr><td style="text-align:center">2903</td><td style="text-align:left">Multi-Vehicle Close Enough Orienteering Problem with BA(c)zier Curves and Multi-Rotor Aerial Vehicles</td></tr><tr><td style="text-align:center">2905</td><td style="text-align:left">Fast Heuristics for the 3D Multi-Goal Path Planning based on the Generalized Traveling Salesman Problem with Neighborhoods</td></tr><tr><td style="text-align:center">2906</td><td style="text-align:left">Contact-Implicit Trajectory Optimization Using Orthogonal Collocation</td></tr><tr><td style="text-align:center">2909</td><td style="text-align:left">Continuous Signed Distance Computation for Polygonal Robots in 3D</td></tr><tr><td style="text-align:center">2910</td><td style="text-align:left">Mid-Air Conflict Avoidance and Recovery - An Acceleration-Based Approach for Unmanned Aircraft</td></tr><tr><td style="text-align:center">2911</td><td style="text-align:left">Energy-Efficient Coverage Path Planning for General Terrain Surfaces</td></tr><tr><td style="text-align:center">2916</td><td style="text-align:left">On-Policy Dataset Synthesis for Learning Robot Grasping Policies Using Fully Convolutional Deep Networks</td></tr><tr><td style="text-align:center">2917</td><td style="text-align:left">A Model-Free Extremum-Seeking Approach to Autonomous Excavator Control Based on Output Power Maximization</td></tr><tr><td style="text-align:center">2919</td><td style="text-align:left">Comparing Task Simplifications to Learn Closed-Loop Object Picking Using Deep Reinforcement Learning</td></tr><tr><td style="text-align:center">2920</td><td style="text-align:left">Position Estimation of Multiple Robots - Provable Practical Approximation Algorithm</td></tr><tr><td style="text-align:center">2922</td><td style="text-align:left">Vision-Based Dynamic Control of Car-Like Mobile Robots</td></tr><tr><td style="text-align:center">2924</td><td style="text-align:left">Autonomous Exploration of Complex Underwater Environments Using a Probabilistic Next-Best-View Planner</td></tr><tr><td style="text-align:center">2926</td><td style="text-align:left">Learning Long-Range Perception Using Self-Supervision from Short-Range Sensors and Odometry</td></tr><tr><td style="text-align:center">2927</td><td style="text-align:left">Play Me Back - A Unified Training Platform for Robotic and Laparoscopic Surgery</td></tr><tr><td style="text-align:center">2928</td><td style="text-align:left">Designing Prototyping and Testing a Flexible Suturing Robot for Transanal Endoscopic Micro-Surgery</td></tr><tr><td style="text-align:center">2929</td><td style="text-align:left">A Compact Dental Robotic System Using Soft Bracing Technique</td></tr><tr><td style="text-align:center">2930</td><td style="text-align:left">Simultaneous Localization and Layout Model Selection in Manhattan Worlds</td></tr><tr><td style="text-align:center">2932</td><td style="text-align:left">Improving the Performance of Auxiliary Null Space Tasks via Time Scaling-Based Relaxation of the Primary Task</td></tr><tr><td style="text-align:center">2935</td><td style="text-align:left">General Hand-Eye Calibration Based on Reprojection Error Minimization</td></tr><tr><td style="text-align:center">2938</td><td style="text-align:left">Continuous Task Transition Approach for Robot Controller Based on Hierarchical Quadratic Programming</td></tr><tr><td style="text-align:center">2939</td><td style="text-align:left">Feasibility Analysis for Constrained Model Predictive Control Based Motion Cueing Algorithm</td></tr><tr><td style="text-align:center">2940</td><td style="text-align:left">Low-Cost Continuously Variable Strain Wave TransmissionUsing Gecko-Inspired Adhesives</td></tr><tr><td style="text-align:center">2942</td><td style="text-align:left">Magnetic Levitation for Soft-Tethered Capsule Colonoscopy Actuated with a Single Permanent Magnet - A Dynamic Control Approach</td></tr><tr><td style="text-align:center">2943</td><td style="text-align:left">VUNet - Dynamic Scene View Synthesis for Traversability Estimation Using an RGB Camera</td></tr><tr><td style="text-align:center">2944</td><td style="text-align:left">A Framework for On-Line Learning of Underwater Vehicles Dynamic Models</td></tr><tr><td style="text-align:center">2946</td><td style="text-align:left">Data Information Fusion from Multiple Access Points for WiFi-Based Self-Localization</td></tr><tr><td style="text-align:center">2948</td><td style="text-align:left">Robust Attitude Estimation Using an Adaptive Unscented Kalman Filter</td></tr><tr><td style="text-align:center">2949</td><td style="text-align:left">Adapting Semantic Segmentation Models for Changes in Illumination and Camera Perspective</td></tr><tr><td style="text-align:center">2950</td><td style="text-align:left">Accurate and Efficient Seafloor Observations with Multiple Autonomous Underwater Vehicles - Theory and Experiments in a Hydrothermal Vent Field</td></tr><tr><td style="text-align:center">2953</td><td style="text-align:left">Task-Based Control and Design of a BLDC Actuator for Robotics</td></tr><tr><td style="text-align:center">2954</td><td style="text-align:left">Pedestrian Motion Model Using Non-Parametric Trajectory Clustering and Discrete Transition Points</td></tr><tr><td style="text-align:center">2956</td><td style="text-align:left">Overpressure Compensation for Hydraulic Hybrid Servo Booster Applied to Hydraulic Manipulator</td></tr><tr><td style="text-align:center">2957</td><td style="text-align:left">Learning a State Transition Model of an Underactuated Adaptive Hand</td></tr><tr><td style="text-align:center">2959</td><td style="text-align:left">The SlothBot - A Novel Design for a Wire-Traversing Robot</td></tr><tr><td style="text-align:center">2960</td><td style="text-align:left">Task-Specific Manipulator Design and Trajectory Synthesis</td></tr><tr><td style="text-align:center">2961</td><td style="text-align:left">Adaptive Control of Aerobatic Quadrotor Maneuvers in the Presence of Propeller-Aerodynamic-Coefficient and Torque-Latency Time-Variations</td></tr><tr><td style="text-align:center">2965</td><td style="text-align:left">Development and Experimental Validation of Aerial Vehicle with Passive Rotating Shell on Each Rotor</td></tr><tr><td style="text-align:center">2967</td><td style="text-align:left">High-Performance Continuous Hydraulic Motor for MR Safe Robotic Teleoperation</td></tr><tr><td style="text-align:center">2969</td><td style="text-align:left">Incorporating Safety into Parametric Dynamic Movement Primitives</td></tr><tr><td style="text-align:center">2970</td><td style="text-align:left">Learn Fast Forget Slow - Safe Predictive Learning Control for Systems with Unknown and Changing Dynamics Performing Repetitive Tasks</td></tr><tr><td style="text-align:center">2971</td><td style="text-align:left">VPE - Variational Policy Embedding for Transfer Reinforcement Learning</td></tr><tr><td style="text-align:center">2974</td><td style="text-align:left">Fast and Continuous Foothold Adaptation for Dynamic Locomotion through CNNs</td></tr><tr><td style="text-align:center">2977</td><td style="text-align:left">Using Human Attention to Address Human-Robot Motion</td></tr><tr><td style="text-align:center">2978</td><td style="text-align:left">Bayesian Optimization for Whole-Body Control of High Degrees of Freedom Robots through Reduction of Dimensionality</td></tr><tr><td style="text-align:center">2980</td><td style="text-align:left">Keep Rollini 12 i 12 Whole-Body Motion Control and Planning for Wheeled Quadrupedal Robots</td></tr><tr><td style="text-align:center">2981</td><td style="text-align:left">Practical Resolution Methods for MDPs in Robotics Exemplified with Disassembly Planning</td></tr><tr><td style="text-align:center">2985</td><td style="text-align:left">1-Day Learning 1-Year Localization - Long-Term LiDAR Localization Using Scan Context Image</td></tr><tr><td style="text-align:center">2988</td><td style="text-align:left">Walking Posture Adaptation for Legged Robot Navigation in Confined Spaces</td></tr><tr><td style="text-align:center">2992</td><td style="text-align:left">Robust Global Structure from Motion Pipeline with Parallax on Manifold Bundle Adjustment and Initialization</td></tr><tr><td style="text-align:center">2995</td><td style="text-align:left">Stable Torque Optimization for Redundant Robots Using a Short Preview</td></tr><tr><td style="text-align:center">2996</td><td style="text-align:left">Decoupled Control of Position and  or Force of Tendon Driven Fingers</td></tr><tr><td style="text-align:center">2997</td><td style="text-align:left">Enabling Robots to Infer how End-Users Teach and Learn through Human-Robot Interaction</td></tr><tr><td style="text-align:center">2999</td><td style="text-align:left">Relationship between the Order for Motor Skill Transfer and Motion Complexity in Reinforcement Learning</td></tr><tr><td style="text-align:center">3005</td><td style="text-align:left">Scalable Closed-Form Trajectories for Periodic and Non-Periodic Human-Like Walking</td></tr><tr><td style="text-align:center">3007</td><td style="text-align:left">Wrinkled Soft Sensor with Variable Afferent Morphology</td></tr><tr><td style="text-align:center">3009</td><td style="text-align:left">Pellicular Morphing Surfaces for Soft Robots</td></tr><tr><td style="text-align:center">3013</td><td style="text-align:left">Resilient Task Planning and Execution for Reactive Soft Robots</td></tr><tr><td style="text-align:center">3014</td><td style="text-align:left">A Novel Variable Stiffness Actuator Based on Pneumatic Actuation and Supercoiled Polymer Artificial Muscles</td></tr><tr><td style="text-align:center">3016</td><td style="text-align:left">Feedforward Control of the Rate-Dependent Viscoelastic Hysteresis Nonlinearity in Dielectric Elastomer Actuators</td></tr><tr><td style="text-align:center">3017</td><td style="text-align:left">Design and Analysis of Pneumatic 2-DoF Soft Haptic Devices for Shear Display</td></tr><tr><td style="text-align:center">3018</td><td style="text-align:left">3D Printed Ferrofluid Based Soft Actuators</td></tr><tr><td style="text-align:center">3019</td><td style="text-align:left">Morphing Robots Using Robotic Skins That Sculpt Clay</td></tr><tr><td style="text-align:center">3020</td><td style="text-align:left">Dynamic Morphological Computation through Damping Design of Soft Material Robots - Application to Under-Actuated Grippers</td></tr><tr><td style="text-align:center">3021</td><td style="text-align:left">Pre-Charged Pneumatic Soft Gripper with Close Loop Control</td></tr><tr><td style="text-align:center">3022</td><td style="text-align:left">Adaptive Update of Reference Capacitances in Conductive Fabric Based Robotic Skin</td></tr><tr><td style="text-align:center">3025</td><td style="text-align:left">A Novel Iterative Learning Model Predictive Control Method for Soft Bending Actuators</td></tr><tr><td style="text-align:center">3027</td><td style="text-align:left">Bio-Inspired Terrestrial Motion of Magnetic Soft Millirobots</td></tr><tr><td style="text-align:center">3030</td><td style="text-align:left">Calibration and External Force Sensing for Soft Robots Using an RGB-D Camera</td></tr><tr><td style="text-align:center">3031</td><td style="text-align:left">A Simple Tripod Mobile Robot Using Soft Membrane Vibration Actuators</td></tr><tr><td style="text-align:center">3033</td><td style="text-align:left">Soft Electrically Actuated Quadruped (SEAQ) i 12 Integrating a Flex Circuit Board and Elastomeric Limbs for Versatile Mobility</td></tr><tr><td style="text-align:center">3034</td><td style="text-align:left">Stiffness Control of Deformable Robots Using Finite Element Modeling</td></tr><tr><td style="text-align:center">3036</td><td style="text-align:left">Expanding Foam As the Material for Fabrication Prototyping and Experimental Assessment of Low Cost Soft Robots with Embedded Sensing</td></tr><tr><td style="text-align:center">3043</td><td style="text-align:left">Humani 12 Robot Collaborative Site Inspection under Resource Constraints</td></tr><tr><td style="text-align:center">3044</td><td style="text-align:left">Symmetric Subspace Motion Generators</td></tr><tr><td style="text-align:center">3045</td><td style="text-align:left">Model-Based Reinforcement Learning for Closed-Loop Dynamic Control of Soft Robotic Manipulators</td></tr><tr><td style="text-align:center">3046</td><td style="text-align:left">Navigation Functions with Time-Varying Destination Manifolds in Star Worlds</td></tr><tr><td style="text-align:center">3047</td><td style="text-align:left">Continuous-Phase Control of a Powered Kneei 12 Ankle Prosthesis - Amputee Experiments across Speeds and Inclines</td></tr><tr><td style="text-align:center">3048</td><td style="text-align:left">Dynamic Point-To-Point Trajectory Planning Beyond the Static Workspace for Six-DOF Cable-Suspended Parallel Robots</td></tr><tr><td style="text-align:center">3049</td><td style="text-align:left">Periodic Trajectory Planning Beyond the Static Workspace for 6-DOF Cable-Suspended Parallel Robots</td></tr><tr><td style="text-align:center">3050</td><td style="text-align:left">Geometric Calibration of Continuum Robots - Joint Space and Equilibrium Shape Deviations</td></tr><tr><td style="text-align:center">3051</td><td style="text-align:left">Multimodal Sensorimotor Integration for Expert-In-The-Loop Telerobotic Surgical Training</td></tr><tr><td style="text-align:center">3052</td><td style="text-align:left">Cable-Based Robotic Crane (CBRC) - Design and Implementation of Overhead Traveling Cranes Based on Variable Radius Drums</td></tr><tr><td style="text-align:center">3053</td><td style="text-align:left">Multirobot Reconnection on Graphs - Problem Complexity and Algorithms</td></tr><tr><td style="text-align:center">3054</td><td style="text-align:left">Computational Design of Robotic Devices from High-Level Motion Specifications</td></tr><tr><td style="text-align:center">3055</td><td style="text-align:left">A New Approach to Time-Optimal Path Parameterization Based on Reachability Analysis</td></tr><tr><td style="text-align:center">3056</td><td style="text-align:left">Force Impedance and Trajectory Learning for Contact Tooling and Haptic Identification</td></tr><tr><td style="text-align:center">3057</td><td style="text-align:left">Fundamental Actuation Properties of Multirotors - Force-Moment Decoupling and Fail-Safe Robustness</td></tr><tr><td style="text-align:center">3058</td><td style="text-align:left">Toward Controllable Hydraulic Coupling of Joints in a Wearable Robot</td></tr><tr><td style="text-align:center">3059</td><td style="text-align:left">An Analytical Loading Model for N-Tendon Continuum Robots</td></tr><tr><td style="text-align:center">3060</td><td style="text-align:left">A Biomimetic Radar System for Autonomous Navigation</td></tr><tr><td style="text-align:center">3061</td><td style="text-align:left">Decentralized Trajectory Tracking Control for Soft Robots Interacting with the Environment</td></tr><tr><td style="text-align:center">3062</td><td style="text-align:left">Tactile-Based Whole-Body Compliance with Force Propagation for Mobile Manipulators</td></tr><tr><td style="text-align:center">3063</td><td style="text-align:left">Efficient and Stable Locomotion for Impulse-Actuated Robots Using Strictly Convex Foot Shapes</td></tr><tr><td style="text-align:center">3064</td><td style="text-align:left">Continuum Robot Stiffness under External Loads and Prescribed Tendon Displacements</td></tr><tr><td style="text-align:center">3065</td><td style="text-align:left">Geometric Construction-Based Realization of Spatial Elastic Behaviors in Parallel and Serial Manipulators</td></tr><tr><td style="text-align:center">3066</td><td style="text-align:left">Fast Generic and Reliable Control and Simulation of Soft Robots Using Model Order Reduction</td></tr><tr><td style="text-align:center">3067</td><td style="text-align:left">Learning Task Priorities from Demonstrations</td></tr><tr><td style="text-align:center">3068</td><td style="text-align:left">Humanoid Dynamic Synchronization through Whole-Body Bilateral Feedback Teleoperation</td></tr><tr><td style="text-align:center">3069</td><td style="text-align:left">A Mechanics-Based Model for 3-D Steering of Programmable Bevel-Tip Needles</td></tr><tr><td style="text-align:center">3070</td><td style="text-align:left">On Optimal Pursuit Trajectories for Visibility-Based Target-Tracking Game</td></tr><tr><td style="text-align:center">3073</td><td style="text-align:left">VIKINGS - An Autonomous Inspection Robot for the ARGOS Challenge</td></tr><tr><td style="text-align:center">3074</td><td style="text-align:left">Coordinated Control of a Dual-Arm Space Robot</td></tr><tr><td style="text-align:center">3075</td><td style="text-align:left">Working with Walt - How a Cobot Was Developed and Inserted on an Auto Assembly Line</td></tr><tr><td style="text-align:center">3076</td><td style="text-align:left">The Task Motion Kit</td></tr><tr><td style="text-align:center">3077</td><td style="text-align:left">An Empirical Evaluation of Ten Depth Cameras for Indoor Environments</td></tr><tr><td style="text-align:center">3078</td><td style="text-align:left">Intuitive Physical Human-Robot Interaction Using a Passive Parallel Mechanism</td></tr><tr><td style="text-align:center">3079</td><td style="text-align:left">SMErobotics - Smart Robots for Flexible Manufacturing</td></tr><tr><td style="text-align:center">3080</td><td style="text-align:left">A Soft Modular End-Effector for Underwater Manipulation</td></tr><tr><td style="text-align:center">3081</td><td style="text-align:left">Radiological Monitoring of Nuclear Facilities Using the Continuous Autonomous Radiation Monitoring Assistance (CARMA) Robot</td></tr><tr><td style="text-align:center">3082</td><td style="text-align:left">Robot Foraging - Autonomous Sample Return in a Large Outdoor Environment</td></tr><tr><td style="text-align:center">3083</td><td style="text-align:left">Multimodal Aerial Locomotion - An Approach to Active Tool Handling</td></tr><tr><td style="text-align:center">3084</td><td style="text-align:left">The Playful Software Platform - Reactive Programming for Orchestrating Robotic Behavior</td></tr><tr><td style="text-align:center">3085</td><td style="text-align:left">Tele-MAGMaS - An Aerial-Ground Co-Manipulator System</td></tr><tr><td style="text-align:center">3086</td><td style="text-align:left">Pictobot - A Cooperative Painting Robot for Interior Finishing of Industrial Developments</td></tr><tr><td style="text-align:center">3087</td><td style="text-align:left">Better Teaming Through Visual Cues - How Projecting Imagery in a Workspace Can Improve Human-Robot Collaboration</td></tr><tr><td style="text-align:center">3088</td><td style="text-align:left">A Lower-Back Robotic Exoskeleton - Industrial Handling Augmentation Used to Provide Spinal Support</td></tr><tr><td style="text-align:center">3089</td><td style="text-align:left">A Smart Companion Robot for Heavy Payload Transport and Manipulation in Automotive Assembly</td></tr><tr><td style="text-align:center">3090</td><td style="text-align:left">Walking and Running with Passive Compliance - Lessons from Engineering a Live Demonstration of the ATRIAS Biped</td></tr><tr><td style="text-align:center">3091</td><td style="text-align:left">Teleoperated In-Situ Repair of an Aeroengine</td></tr><tr><td style="text-align:center">3092</td><td style="text-align:left">Online Multilayered Motion Planning with Dynamic Constraints for Autonomous Underwater Vehicles</td></tr><tr><td style="text-align:center">3102</td><td style="text-align:left">LineRanger Analysis and Field Testing of an Innovative Robot for Efficient Assessment of Bundled High-Voltage Powerlines</td></tr><tr><td style="text-align:center">3103</td><td style="text-align:left">Adjustable Power Modulation for a Leg Mechanism Suitable for Running</td></tr><tr><td style="text-align:center">3104</td><td style="text-align:left">Development and Experimental Validation of Aerial Vehicle with Passive Rotating Shell on Each Rotor</td></tr><tr><td style="text-align:center">3105</td><td style="text-align:left">Robotic Orientation Control of Deformable Cells</td></tr><tr><td style="text-align:center">3106</td><td style="text-align:left">Towards Robust Product Packing with a Minimalistic End-Effector</td></tr><tr><td style="text-align:center">3107</td><td style="text-align:left">Contactless Robotic Micromanipulation in Air Using a Magneto-Acoustic System</td></tr><tr><td style="text-align:center">3108</td><td style="text-align:left">Gesture Recognition Via Flexible Capacitive Touch Electrodes</td></tr><tr><td style="text-align:center">3109</td><td style="text-align:left">Deconfliction of Motion Paths with Traffic Inspired Rules in Roboti 12 Robot and Humani 12 Robot Interactions</td></tr><tr><td style="text-align:center">3110</td><td style="text-align:left">The Role of Closed-Loop Hand Control in Handshaking Interactions</td></tr><tr><td style="text-align:center">3111</td><td style="text-align:left">Soft Robotic Glove with Integrated Sensing for Intuitive Grasping Assistance Post Spinal Cord Injury</td></tr><tr><td style="text-align:center">3112</td><td style="text-align:left">Shape Sensing of Variable Stiffness Soft Robots Using Electrical Impedance Tomography</td></tr><tr><td style="text-align:center">3113</td><td style="text-align:left">Adaptive Control of Sclera Force and Insertion Depth for Safe Robot-Assisted Retinal Surgery</td></tr><tr><td style="text-align:center">3114</td><td style="text-align:left">Eagle Shoal - A New Designed Modular Tactile Sensing Dexterous Hand for Domestic Service Robots</td></tr><tr><td style="text-align:center">3115</td><td style="text-align:left">Classification of Household Materials Via Spectroscopy</td></tr><tr><td style="text-align:center">3116</td><td style="text-align:left">Multi-Robot Region-Of-Interest Reconstruction with Dec-MCTS</td></tr><tr><td style="text-align:center">3117</td><td style="text-align:left">Learning Scene Geometry for Visual Localization in Challenging Conditions</td></tr><tr><td style="text-align:center">3118</td><td style="text-align:left">Geo-Supervised Visual Depth Prediction</td></tr><tr><td style="text-align:center">3119</td><td style="text-align:left">Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks</td></tr><tr><td style="text-align:center">3120</td><td style="text-align:left">Combined Task and Motion Planning under Partial Observability - An Optimization-Based Approach</td></tr><tr><td style="text-align:center">3121</td><td style="text-align:left">Making Sense of Vision and Touch - Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks</td></tr><tr><td style="text-align:center">3122</td><td style="text-align:left">Deep Visuo-Tactile Learning - Estimation of Tactile Properties from Images</td></tr><tr><td style="text-align:center">3123</td><td style="text-align:left">Variational End-To-End Navigation and Localization</td></tr><tr><td style="text-align:center">3124</td><td style="text-align:left">Closing the Sim-To-Real Loop - Adapting Simulation Randomization with Real World Experience</td></tr><tr><td style="text-align:center">3125</td><td style="text-align:left">Drift-Free Roll and Pitch Estimation for High-Acceleration Hopping</td></tr><tr><td style="text-align:center">3126</td><td style="text-align:left">Robust Learning of Tactile Force Estimation through Robot Interaction</td></tr><tr><td style="text-align:center">3127</td><td style="text-align:left">Shallow-Depth Insertion - Peg in Shallow Hole through Robotic In-Hand Manipulation</td></tr><tr><td style="text-align:center">3128</td><td style="text-align:left">Pre-Grasp Sliding Manipulation of Thin Objects Using Soft Compliant or Underactuated Hands</td></tr><tr><td style="text-align:center">3129</td><td style="text-align:left">Design and Control of a Passively Morphing Quadcopter</td></tr><tr><td style="text-align:center">3130</td><td style="text-align:left">Search-Based 3D Planning and Trajectory Optimization for Safe Micro Aerial Vehicle Flight under Sensor Visibility Constraints</td></tr><tr><td style="text-align:center">3131</td><td style="text-align:left">Fast and in Sync - Periodic Swarm Patterns for Quadrotors</td></tr><tr><td style="text-align:center">3132</td><td style="text-align:left">Distributed Multi-Robot Formation Splitting and Merging in Dynamic Environments</td></tr></tbody></table></div>]]></content>
      
      
      
        <tags>
            
            <tag> ICRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IROS2019文章目录</title>
      <link href="/2022/01/03/iros2019-paper-list/"/>
      <url>/2022/01/03/iros2019-paper-list/</url>
      
        <content type="html"><![CDATA[<h1 id="IROS2019-paper-list"><a href="#IROS2019-paper-list" class="headerlink" title="IROS2019-paper-list"></a>IROS2019-paper-list</h1><p>The 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) has been held on November 4 – 8, 2019 in The Venetian Macao, Macau, China. IROS is one of the largest and most impacting robotics research conferences worldwide. It brings an international community of researchers, educators and practitioners to explore the frontier of science and technology in intelligent robots and systems, and discuss the latest advancements in this fast growing and exciting field.</p><p>This list is edited by <a href="https://github.com/PaoPaoRobot">PaopaoRobot, 泡泡机器人</a> , the Chinese academic nonprofit organization. Recently we will classify these papers by topics. Welcome to follow our github and our WeChat Public Platform Account ( <a href="https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&amp;mid=100000102&amp;idx=1&amp;sn=0a8a831a4f2c18443dbf436ef5d5ff8c&amp;chksm=6c10bf625b6736748c9612879e166e510f1fe301b72ed5c5d7ecdd0f40726c5d757e975f37af&amp;mpshare=1&amp;scene=1&amp;srcid=0530KxSLjUE9I38yLgfO2nVm&amp;pass_ticket=0aB5tcjeTfmcl9u0eSVzN4Ag4tkpM2RjRFH8DG9vylE%3D#rd">paopaorobot_slam</a> ). Of course, you could contact with <a href="https://github.com/yvonshong">Yvon Shong</a>.</p><div class="table-container"><table><thead><tr><th style="text-align:left">title</th><th style="text-align:right">index</th></tr></thead><tbody><tr><td style="text-align:left">Outlier-Robust Manifold Pre-Integration for INS/GPS Fusion</td><td style="text-align:right">0688</td></tr><tr><td style="text-align:left">Autonomous Steering of Concentric Tube Robots for Enhanced Force/Velocity Manipulability</td><td style="text-align:right">0813</td></tr><tr><td style="text-align:left">A 2-piece six-axis force/torque sensor capable of measuring loads applied to tools of complex shapes</td><td style="text-align:right">1744</td></tr><tr><td style="text-align:left">Autonomous Hybrid Ground/Aerial Mobility in Unknown Environments</td><td style="text-align:right">2028</td></tr><tr><td style="text-align:left">A Hybrid Active/Passive Wrist Approach for Increasing Virtual Fixture Stiffness in Comanipulated Robotic Minimally Invasive Surgery</td><td style="text-align:right">2255</td></tr><tr><td style="text-align:left">6-Axis Hybrid Sensing and Estimation of Tip Forces/Torques on a Hyper-Redundant Robotic Surgical Instrument</td><td style="text-align:right">2324</td></tr><tr><td style="text-align:left">Hybrid Force/Motion Control and Implementation of an Aerial Manipulator towards Sustained Contact Operations</td><td style="text-align:right">2586</td></tr><tr><td style="text-align:left">XL-laser: Large-Scale Cable-Driven Laser Cutting/Engraving Robot</td><td style="text-align:right">2742</td></tr><tr><td style="text-align:left">2D Contour Following with an Unmanned Aerial Manipulator: Towards Tactile-Based Aerial Navigation</td><td style="text-align:right">1391</td></tr><tr><td style="text-align:left">2-DOF Transformable Wheel Design for Various Sized Stair and Step Climbing</td><td style="text-align:right">2643</td></tr><tr><td style="text-align:left">2-Entity RANSAC for Robust Visual Localization in Changing Environment</td><td style="text-align:right">0982</td></tr><tr><td style="text-align:left">3D Canonical Pose Estimation and Abnormal Gait Recognition with a Single RGB-D Camera</td><td style="text-align:right">2323</td></tr><tr><td style="text-align:left">3D Deformable Object Manipulation Using Deep Neural Networks</td><td style="text-align:right">2307</td></tr><tr><td style="text-align:left">3D LiDAR and Stereo Fusion Using Stereo Matching Network with Conditional Cost Volume Normalization</td><td style="text-align:right">1026</td></tr><tr><td style="text-align:left">3D Micromanipulation of Particle Swarm Using a Hexapole Magnetic Tweezer</td><td style="text-align:right">1134</td></tr><tr><td style="text-align:left">3D Move to See: Multi-Perspective Visual Servoing towards the Next Best View within Unstructured and Occluded Environments</td><td style="text-align:right">1719</td></tr><tr><td style="text-align:left">3-DOF Gravity Compensation Mechanism for Robot Waists with the Variations of Center of Mass</td><td style="text-align:right">0992</td></tr><tr><td style="text-align:left">3-DOF Manipulator Design for a Slender-Shaped Wide End-Effector</td><td style="text-align:right">2630</td></tr><tr><td style="text-align:left">3D Point Cloud Data Acquisition Using a Synchronized In-Air Imaging Sonar Sensor Network</td><td style="text-align:right">0969</td></tr><tr><td style="text-align:left">3D Printed Single Incision Laparoscopic Manipulator System Adapted to the Required Forces in Laparoscopic Surgery</td><td style="text-align:right">0964</td></tr><tr><td style="text-align:left">3D Reconstruction by Single Camera Omnidirectional Multi-Stereo System</td><td style="text-align:right">0095</td></tr><tr><td style="text-align:left">3D Shape Control of Linear Deformable Objects by Robot Manipulator</td><td style="text-align:right">2664</td></tr><tr><td style="text-align:left">A 3D Static Modeling Method and Experimental Verification of Continuum Robots Based on Pseudo-Rigid Body Theory</td><td style="text-align:right">1362</td></tr><tr><td style="text-align:left">A Behavior Driven Approach for Sampling Rare-Event Situations for Autonomous Vehicles</td><td style="text-align:right">0265</td></tr><tr><td style="text-align:left">A Behavior Tree Cognitive Assistant System for Emergency Medical Services</td><td style="text-align:right">0449</td></tr><tr><td style="text-align:left">A Benchmark for Visual-Inertial Odometry Systems Employing Onboard Illumination</td><td style="text-align:right">1770</td></tr><tr><td style="text-align:left">A Bi-Directional Multiple Timescales LSTM Model for Grounding of Actions and Verbs</td><td style="text-align:right">0344</td></tr><tr><td style="text-align:left">Absolute Localization through Orbital Maps and Surface Perspective Imagery: A Synthetic Lunar Dataset and Neural Network Approach</td><td style="text-align:right">1712</td></tr><tr><td style="text-align:left">A Capability-Aware Role Allocation Approach to Industrial Assembly Tasks</td><td style="text-align:right">2472</td></tr><tr><td style="text-align:left">Accelerated Visual Inertial Navigation Via Fragmented Structure Updates</td><td style="text-align:right">0363</td></tr><tr><td style="text-align:left">Accelerating the Construction of Boundaries of Feasibility in Three Classes of Robot Design Problems</td><td style="text-align:right">1434</td></tr><tr><td style="text-align:left">Accurate Pouring Using Model Predictive Control Enabled by Recurrent Neural Network</td><td style="text-align:right">1981</td></tr><tr><td style="text-align:left">A Challenge of Deformation Control for Cloth Actuators</td><td style="text-align:right">2740</td></tr><tr><td style="text-align:left">Achievement of Online Agile Manipulation Task for Aerial Transformable Multilink Robot</td><td style="text-align:right">1396</td></tr><tr><td style="text-align:left">A Compact Laser-Steering End-Effector for Transoral Robotic Surgery</td><td style="text-align:right">1804</td></tr><tr><td style="text-align:left">A Compact Soft Articulated Parallel Wrist for Grasping in Narrow Spaces</td><td style="text-align:right">2170</td></tr><tr><td style="text-align:left">A Comparative Analysis on the Use of Autoencoders for Robot Security Anomaly Detection</td><td style="text-align:right">0417</td></tr><tr><td style="text-align:left">A Comparison of Action Spaces for Learning Manipulation Tasks</td><td style="text-align:right">1513</td></tr><tr><td style="text-align:left">A Comparison of Visual Servoing from Features Velocity and Acceleration Interaction Models</td><td style="text-align:right">0827</td></tr><tr><td style="text-align:left">A Convex-Combinatorial Model for Planar Caging</td><td style="text-align:right">0896</td></tr><tr><td style="text-align:left">A Convolutional Network for Joint Deraining and Dehazing from A Single Image for Autonomous Driving in Rain</td><td style="text-align:right">0696</td></tr><tr><td style="text-align:left">A Convolutional Neural Network Feature Detection Approach to Autonomous Quadrotor Indoor Navigation</td><td style="text-align:right">1540</td></tr><tr><td style="text-align:left">Acoustic Length Sensor for Soft Extensible Pneumatic Actuators with a Frequency Characteristics Model</td><td style="text-align:right">2535</td></tr><tr><td style="text-align:left">Action Recognition Based on 3D Skeleton and RGB Frame Fusion</td><td style="text-align:right">1903</td></tr><tr><td style="text-align:left">Active Incremental Learning of a Contextual Skill Model</td><td style="text-align:right">0480</td></tr><tr><td style="text-align:left">Active Infrared Coded Target Design and Pose Estimation for Multiple Objects</td><td style="text-align:right">0310</td></tr><tr><td style="text-align:left">Active Inverse Model Learning with Error and Reachable Set Estimates</td><td style="text-align:right">1235</td></tr><tr><td style="text-align:left">Active Learning of Reward Dynamics from Hierarchical Queries</td><td style="text-align:right">1879</td></tr><tr><td style="text-align:left">Active SLAM Using Connectivity Graphs As Priors</td><td style="text-align:right">0630</td></tr><tr><td style="text-align:left">Active Whisker Placement and Exploration for Rapid Object Recognition</td><td style="text-align:right">1329</td></tr><tr><td style="text-align:left">Actuation and Stiffening in Fluid-Driven Soft Robots Using Low-Melting-Point Material</td><td style="text-align:right">0489</td></tr><tr><td style="text-align:left">Adapting Weed Growth Predictions for Mechanical Weeding Agbots</td><td style="text-align:right">2616</td></tr><tr><td style="text-align:left">Adaptive Adversarial Videos on Roadside Billboards: Dynamically Modifying Trajectories of Autonomous Vehicles</td><td style="text-align:right">1939</td></tr><tr><td style="text-align:left">Adaptive Assist-As-Needed Control Based on Actor-Critic Reinforcement Learning</td><td style="text-align:right">1191</td></tr><tr><td style="text-align:left">Adaptive Deep Path: Efficient Coverage of a Known Environment under Various Configurations</td><td style="text-align:right">1142</td></tr><tr><td style="text-align:left">Adaptive Dynamic Control for Magnetically Actuated Medical Robots</td><td style="text-align:right">2435</td></tr><tr><td style="text-align:left">Adaptive Leader-Follower Formation Control and Obstacle Avoidance Via Deep Reinforcement Learning</td><td style="text-align:right">1241</td></tr><tr><td style="text-align:left">Adaptive Loss Balancing for Multitask Learning of Object Instance Recognition and 3D Pose Estimation</td><td style="text-align:right">0698</td></tr><tr><td style="text-align:left">Adaptive Navigation Scheme for Optimal Deep-Sea Localization Using Multimodal Perception Cues</td><td style="text-align:right">1565</td></tr><tr><td style="text-align:left">Adaptive Neural Admittance Control for Collision Avoidance in Human-Robot Collaborative Tasks</td><td style="text-align:right">0510</td></tr><tr><td style="text-align:left">Adaptive Outcome Selection for Planning with Reduced Models</td><td style="text-align:right">1181</td></tr><tr><td style="text-align:left">Adaptive Risk-Based Replanning for Human-Aware Multi-Robot Task Allocation with Local Perception</td><td style="text-align:right">2188</td></tr><tr><td style="text-align:left">Adaptive Swept Volumes Generation for Human-Robot Coexistence Using Gaussian Processes</td><td style="text-align:right">0789</td></tr><tr><td style="text-align:left">Adaptive Trajectory Planning and Optimization at Limits of Handling</td><td style="text-align:right">1698</td></tr><tr><td style="text-align:left">Adaptive Unscented Kalman Filter-Based Disturbance Rejection with Application to High Precision Hydraulic Robotic Control</td><td style="text-align:right">0817</td></tr><tr><td style="text-align:left">Adaptive Vision-Based Control for Rope-Climbing Robot Manipulator</td><td style="text-align:right">0712</td></tr><tr><td style="text-align:left">A Data-Driven Framework for Learning Dexterous Manipulation of Unknown Objects</td><td style="text-align:right">1014</td></tr><tr><td style="text-align:left">A Deep Learning Approach for Multi-View Engagement Estimation of Children in a Child-Robot Joint Attention Task</td><td style="text-align:right">0522</td></tr><tr><td style="text-align:left">A Deep Learning Approach for Probabilistic Security in Multi-Robot Teams</td><td style="text-align:right">2576</td></tr><tr><td style="text-align:left">A Deep Learning Approach for Robust Corridor Following</td><td style="text-align:right">1158</td></tr><tr><td style="text-align:left">A Density Map Estimation Model with DropBlock Regularization for Clustered-Fruit Counting</td><td style="text-align:right">1774</td></tr><tr><td style="text-align:left">A Development of Inertial-2D LiDAR SLAM on Manifolds towards AGV</td><td style="text-align:right">2764</td></tr><tr><td style="text-align:left">A Distributed Reconfiguration Planning Algorithm for SMORES-EP, a Modular Robot</td><td style="text-align:right">2565</td></tr><tr><td style="text-align:left">Adjusting Weight of Action Decision in Exploration for Logistics Warehouse Picking Learning</td><td style="text-align:right">0213</td></tr><tr><td style="text-align:left">Admittance Control Based on Stiffness Ellipse for Collision Force Control of Object Manipulation</td><td style="text-align:right">2758</td></tr><tr><td style="text-align:left">Advanced Autonomy on a Low-Cost Educational Drone Platform</td><td style="text-align:right">1806</td></tr><tr><td style="text-align:left">Advection and Diffusion Effects towards a Bio-Inspired Artificial Pheromone System</td><td style="text-align:right">2626</td></tr><tr><td style="text-align:left">A Dynamic Optimization Approach for Sloshing Free Transport of Liquid Filled Containers Using an Industrial Robot</td><td style="text-align:right">1405</td></tr><tr><td style="text-align:left">Aerial Animal Biometrics: Individual Friesian Cattle Recovery and Visual Identification Via an Autonomous UAV with Onboard Deep Inference</td><td style="text-align:right">0851</td></tr><tr><td style="text-align:left">Aerial Robot Control in Close Proximity to Ceiling: A Force Estimation-Based Nonlinear MPC</td><td style="text-align:right">0450</td></tr><tr><td style="text-align:left">Aerial Robots with Advanced Manipulation Capabilities for Inspection and Maintenance: The AEROARMS Project</td><td style="text-align:right">2610</td></tr><tr><td style="text-align:left">Aerodynamic Model Identification of a Quadrotor Subject to Rotor Failures in the High-Speed Flight Regime</td><td style="text-align:right">2433</td></tr><tr><td style="text-align:left">A-EXP4: Online Social Policy Learning for Adaptive Robot-Pedestrian Interaction</td><td style="text-align:right">0034</td></tr><tr><td style="text-align:left">A Fast Free-Viewpoint Video Synthesis Algorithm for Sports Scenes</td><td style="text-align:right">0318</td></tr><tr><td style="text-align:left">A Fast Heuristic Path Planning Algorithm for Mobile Robots</td><td style="text-align:right">2747</td></tr><tr><td style="text-align:left">A fast online frequency adaptation mechanism for CPG-based robot motion control</td><td style="text-align:right">2346</td></tr><tr><td style="text-align:left">Affordance Learning for End-To-End Visuomotor Robot Control</td><td style="text-align:right">1257</td></tr><tr><td style="text-align:left">A Flexible Sensor for Suture Training</td><td style="text-align:right">2545</td></tr><tr><td style="text-align:left">A Force-Controlled Robotic Wrist Module for the Macro-Micro Manipulation of Industrial Robots</td><td style="text-align:right">2707</td></tr><tr><td style="text-align:left">A Framework for Depth Estimation and Relative Localization of Ground Robots Using Computer Vision</td><td style="text-align:right">0115</td></tr><tr><td style="text-align:left">A Fully-Integrated Sensing and Control System for High-Accuracy Mobile Robotic Building Construction</td><td style="text-align:right">1219</td></tr><tr><td style="text-align:left">A Gear-Driven Prosthetic Hand with Major Grasp Functions for Toddlers</td><td style="text-align:right">1869</td></tr><tr><td style="text-align:left">A Generative Model of Underwater Images for Active Landmark Detection and Docking</td><td style="text-align:right">0113</td></tr><tr><td style="text-align:left">Agent Prioritization for Autonomous Navigation</td><td style="text-align:right">0560</td></tr><tr><td style="text-align:left">Agile Standing-Up Control of Humanoids: Energy-Based Reactive Contact Wrench Optimization with Strict Dynamic Consistency</td><td style="text-align:right">1646</td></tr><tr><td style="text-align:left">A GPS-Aided Omnidirectional Visual-Inertial State Estimator in Ubiquitous Environments</td><td style="text-align:right">2174</td></tr><tr><td style="text-align:left">A Handheld Master Controller for Robot-Assisted Microsurgery</td><td style="text-align:right">1992</td></tr><tr><td style="text-align:left">Air to Ground Collaboration for Energy-Efficient Path Planing for Ground Robots</td><td style="text-align:right">1520</td></tr><tr><td style="text-align:left">A Joint Optimization Approach of LiDAR-Camera Fusion for Accurate Dense 3D Reconstructions</td><td style="text-align:right">2268</td></tr><tr><td style="text-align:left">A Kernelized Approach for Learning and Adapting Symmetric Positive Definite Profiles</td><td style="text-align:right">2684</td></tr><tr><td style="text-align:left">A Learning-Based Inverse Kinematics Solver for Two-Segment Continuum Robot Models</td><td style="text-align:right">2750</td></tr><tr><td style="text-align:left">A Linear Series Elastic Actuator for Accurate Force and Impedance Control with High Torque-To-Rotor-Inertia Ratios</td><td style="text-align:right">2724</td></tr><tr><td style="text-align:left">ALTRO: A Fast Solver for Constrained Trajectory Optimization</td><td style="text-align:right">1603</td></tr><tr><td style="text-align:left">A Magnetically Transduced Whisker for Angular Displacement and Moment Sensing</td><td style="text-align:right">2105</td></tr><tr><td style="text-align:left">Ambiguity Poses Estimation for Objects with Symmetry</td><td style="text-align:right">2773</td></tr><tr><td style="text-align:left">A Mechanical Approach to Suppress the Oscillation of a Long Continuum Robot Flying with Water Jets</td><td style="text-align:right">2564</td></tr><tr><td style="text-align:left">A Method for Designing Low-Profile Compliant Transmission Mechanisms</td><td style="text-align:right">2463</td></tr><tr><td style="text-align:left">A Method for Guiding a Person Combining Robot Movement and Projection</td><td style="text-align:right">0155</td></tr><tr><td style="text-align:left">A Methodology for Formulating and Exploiting Innovative Technologies for Collaborative Robots in a Manufacturing Setting</td><td style="text-align:right">2683</td></tr><tr><td style="text-align:left">A Mobile Extendable Robot Arm: Singularity Analysis and Design</td><td style="text-align:right">1526</td></tr><tr><td style="text-align:left">A Model-Based Human Activity Recognition for Human-Robot Collaboration</td><td style="text-align:right">0569</td></tr><tr><td style="text-align:left">A Model for Simulating the Robotic Pushing of Dirt</td><td style="text-align:right">0860</td></tr><tr><td style="text-align:left">A Multi-Channel Embedded DSP Closed-Loop Control System for Musical Robots</td><td style="text-align:right">0096</td></tr><tr><td style="text-align:left">A Multiclass EEG Signal Classification Model Using Spatial Feature Extraction and XGBoost Algorithm</td><td style="text-align:right">0926</td></tr><tr><td style="text-align:left">A Multi-DOF Human-Powered Robot Using Regenerative Clutches and Constant-Force Springs</td><td style="text-align:right">0914</td></tr><tr><td style="text-align:left">A Multimodal Human-Robot Interaction Manager for Assistive Robots</td><td style="text-align:right">1728</td></tr><tr><td style="text-align:left">A Multimodal Soft Crawling-Climbing Robot with the Controllable Horizontal Plane to Slope Transition</td><td style="text-align:right">1676</td></tr><tr><td style="text-align:left">A Multi-Task Convolutional Neural Network for Autonomous Robotic Grasping in Object Stacking Scenes</td><td style="text-align:right">0395</td></tr><tr><td style="text-align:left">A Multi-Trainee Architecture for Haptic Hands-On Training</td><td style="text-align:right">0762</td></tr><tr><td style="text-align:left">An Adaptive Velocity Obstacle Avoidance Algorithm for Autonomous Surface Vehicles</td><td style="text-align:right">0979</td></tr><tr><td style="text-align:left">Analysis and Exploitation of Synchronized Parallel Executions in Behavior Trees</td><td style="text-align:right">0845</td></tr><tr><td style="text-align:left">Analysis of Ground Effect for Small-Scale UAVs in Forward Flight</td><td style="text-align:right">2392</td></tr><tr><td style="text-align:left">Analyzing Liquid Pouring Sequences Via Audio-Visual Neural Networks</td><td style="text-align:right">0041</td></tr><tr><td style="text-align:left">An Approach of Facilitated Investigation of Active Self-healing Tension Transmission System Oriented for Legged Robots</td><td style="text-align:right">1813</td></tr><tr><td style="text-align:left">An Approximation-Free Simple Control Scheme for Uncertain Quadrotor Systems: Theory and Validations</td><td style="text-align:right">1074</td></tr><tr><td style="text-align:left">An Assisted Telemanipulation Approach: Combining Autonomous Grasp Planning with Haptic Cues</td><td style="text-align:right">0501</td></tr><tr><td style="text-align:left">An Assistive Low-Vision Platform That Augments Spatial Cognition through Proprioceptive Guidance: Point-To-Tell-And-Touch</td><td style="text-align:right">1252</td></tr><tr><td style="text-align:left">An Asynchronous Multi-Body Simulation Framework for Real-Time Dynamics, Haptics and Learning with Application to Surgical Robots</td><td style="text-align:right">2113</td></tr><tr><td style="text-align:left">An Augmented Reality Interface for Human-Robot Interaction in Unconstrained Environments</td><td style="text-align:right">1080</td></tr><tr><td style="text-align:left">An Automated Learning-Based Procedure for Large-Scale Vehicle Dynamics Modeling on Baidu Apollo Platform</td><td style="text-align:right">0508</td></tr><tr><td style="text-align:left">An Autonomous Exploration Algorithm Using Environment-Robot Interacted Traversability Analysis</td><td style="text-align:right">0723</td></tr><tr><td style="text-align:left">An Autonomous Quadrotor System for Robust High-Speed Flight through Cluttered Environments without GPS</td><td style="text-align:right">2166</td></tr><tr><td style="text-align:left">An Educational Robotic Platform with Multimodal Perception for Teaching Sensor Servoing Controls</td><td style="text-align:right">2629</td></tr><tr><td style="text-align:left">An Efficient and Accurate Algorithm for the Perspective-N-Point Problem</td><td style="text-align:right">1972</td></tr><tr><td style="text-align:left">An Efficient Scheduling Algorithm for Multi-Robot Task Allocation in Assembling Aircraft Structures</td><td style="text-align:right">2571</td></tr><tr><td style="text-align:left">A Neurologically Inspired Sequence Processing Model for Mobile Robot Place Recognition</td><td style="text-align:right">2115</td></tr><tr><td style="text-align:left">An Evaluation of Robot-To-Human Handover Configurations for Commercial Robots</td><td style="text-align:right">0766</td></tr><tr><td style="text-align:left">A New Time-Varying Feedback RISE Control of PKMs: Theory and Application</td><td style="text-align:right">0088</td></tr><tr><td style="text-align:left">An Experimental Study of Parameters Influencing Physical Human-Robot Negotiation in Comanipulative Tracking Task</td><td style="text-align:right">0224</td></tr><tr><td style="text-align:left">Angle of Arrival Estimation Based on Channel Impulse Response Measurements</td><td style="text-align:right">2093</td></tr><tr><td style="text-align:left">An In-Pipe Inspection Module with an Omnidirectional Bent-Pipe Self-Adaptation Mechanism Using a Joint Torque Control</td><td style="text-align:right">0551</td></tr><tr><td style="text-align:left">An Integrated Delta Manipulator for Aerial Repair: A New Aerial Robotic System</td><td style="text-align:right">2608</td></tr><tr><td style="text-align:left">An Interactive Indoor Drone Assistant</td><td style="text-align:right">1038</td></tr><tr><td style="text-align:left">An Interactive Method for Virtual Fixture Generation in Unstructured Environments</td><td style="text-align:right">2704</td></tr><tr><td style="text-align:left">An Interactive Physically-Based Model for Active Suction Phenomenon Simulation</td><td style="text-align:right">1385</td></tr><tr><td style="text-align:left">An Intuitive, Affordances Oriented Telemanipulation Framework for a Dual Robot Arm Hand System: On the Execution of Bimanual Tasks</td><td style="text-align:right">1177</td></tr><tr><td style="text-align:left">Ankle Torque During Mid-Stance Does Not Lower Energy Requirements of Steady Gaits</td><td style="text-align:right">1265</td></tr><tr><td style="text-align:left">An Object Attribute Guided Framework for Robot Learning Manipulations from Human Demonstration Videos</td><td style="text-align:right">0936</td></tr><tr><td style="text-align:left">Anonymous Hedonic Game for Task Allocation in a Large-Scale Multiple Agent System</td><td style="text-align:right">2598</td></tr><tr><td style="text-align:left">An Open-Source 7-Axis, Robotic Platform to Enable Dexterous Procedures within CT Scanners</td><td style="text-align:right">1428</td></tr><tr><td style="text-align:left">An Optimal Algorithm to Solve the Combined Task Allocation and Path Finding Problem</td><td style="text-align:right">0471</td></tr><tr><td style="text-align:left">An Optimization Framework for Simulation and Kinematic Control of Constrained Collaborative Mobile Agents (CCMA) System</td><td style="text-align:right">2393</td></tr><tr><td style="text-align:left">A Novel 4-DoF Robotic Link Mechanism with E-CoSMo : Kinematics Based Torque Analysis</td><td style="text-align:right">0775</td></tr><tr><td style="text-align:left">A Novel Approach for Outlier Detection and Robust Sensory Data Model Learning</td><td style="text-align:right">0340</td></tr><tr><td style="text-align:left">A Novel Capabilities of Quadruped Robot Moving through Vertical Ladder without Handrail Support</td><td style="text-align:right">0329</td></tr><tr><td style="text-align:left">A Novel Four-Degree-Of-Freedom versus a Conventional Foot Interface for Controlling a Robotic Assistive Arm in Surgery</td><td style="text-align:right">2658</td></tr><tr><td style="text-align:left">A novel rescue system using multi-agent SLAM framework</td><td style="text-align:right">2759</td></tr><tr><td style="text-align:left">A Novel Robust Approach for Correspondence-Free Extrinsic Calibration</td><td style="text-align:right">1541</td></tr><tr><td style="text-align:left">A Novel Semi-Autonomous Control Framework for Retina Confocal Endomicroscopy Scanning</td><td style="text-align:right">0483</td></tr><tr><td style="text-align:left">A Novel Small-Scale Turtle-Inspired Amphibious Spherical Robot</td><td style="text-align:right">1467</td></tr><tr><td style="text-align:left">ANYexo: A Versatile and Dynamic Upper-Limb Rehabilitation Robot</td><td style="text-align:right">2123</td></tr><tr><td style="text-align:left">A Parallel Gripper with a Universal Fingertip Device Using Optical Sensing and Jamming Transition for Maintaining Stable Grasps</td><td style="text-align:right">1496</td></tr><tr><td style="text-align:left">A Passive Closing, Tendon Driven, Adaptive Robot Hand for Ultra-Fast, Aerial Grasping and Perching</td><td style="text-align:right">0015</td></tr><tr><td style="text-align:left">A Penetration Metric for Deforming Tetrahedra Using Object Norm</td><td style="text-align:right">0064</td></tr><tr><td style="text-align:left">Application of Digging Control based on the Center-of-Mass Velocity of the Attachment of a Hydraulic Excavator</td><td style="text-align:right">0719</td></tr><tr><td style="text-align:left">Applying the Interaction of Walking-Emotion to an Assistive Device for Rehabilitation and Exercise</td><td style="text-align:right">0238</td></tr><tr><td style="text-align:left">Approximating Cfree Space Topology by Constructing Vietoris-Rips Complex</td><td style="text-align:right">1486</td></tr><tr><td style="text-align:left">A Pressure Field Model for Fast, Robust Approximation of Net Contact Force and Moment between Nominally Rigid Objects</td><td style="text-align:right">1597</td></tr><tr><td style="text-align:left">A Probabilistic Approach to Human-Robot Communication</td><td style="text-align:right">1359</td></tr><tr><td style="text-align:left">A Real-Time Dynamic Simulator and an Associated Front-End Representation Format for Simulating Complex Robots and Environments</td><td style="text-align:right">1766</td></tr><tr><td style="text-align:left">A Real-Time V2X Enabled Dynamic Path Planning System for Autonomous Vehicles in Road Blockage Test Scenarios</td><td style="text-align:right">2715</td></tr><tr><td style="text-align:left">A Reliable Gravity Compensation Control Strategy for dVRK Robotic Arms with Nonlinear Disturbance Forces</td><td style="text-align:right">2340</td></tr><tr><td style="text-align:left">Are You Hearing or Listening? the Effect of Task Performance in Verbal Behavior with Smart Speaker</td><td style="text-align:right">0332</td></tr><tr><td style="text-align:left">Are You with Me? Determining the Associationof Individuals and the Collective Social Space</td><td style="text-align:right">0902</td></tr><tr><td style="text-align:left">Arguing Security of Autonomous Robots</td><td style="text-align:right">0158</td></tr><tr><td style="text-align:left">A Ring Network Protocol for Articulated Robots</td><td style="text-align:right">1955</td></tr><tr><td style="text-align:left">ARMCL: ARM Contact Point Localization Via Monte Carlo Localization</td><td style="text-align:right">0132</td></tr><tr><td style="text-align:left">A Robotic Surgery Approach to Mitochondrial Transfer Amongst Single Cells</td><td style="text-align:right">0604</td></tr><tr><td style="text-align:left">A Robust Biped Locomotion Based on Linear-Quadratic-Gaussian Controller and Divergent Component of Motion</td><td style="text-align:right">0243</td></tr><tr><td style="text-align:left">A Robust Extrinsic Calibration Framework for Vehicles with Unscaled Sensors</td><td style="text-align:right">1578</td></tr><tr><td style="text-align:left">A Robust Laser-Inertial Odometry and Mapping Method for Large-Scale Highway Environments</td><td style="text-align:right">1670</td></tr><tr><td style="text-align:left">A Robustness Analysis of Inverse Optimal Control of Bipedal Walking</td><td style="text-align:right">2583</td></tr><tr><td style="text-align:left">A Robust Position and Posture Measurement System Using Visual Markers and an Inertia Measurement Unit</td><td style="text-align:right">0584</td></tr><tr><td style="text-align:left">A Robust Stereo Semi-Direct SLAM System Based on Hybrid Pyramid</td><td style="text-align:right">1883</td></tr><tr><td style="text-align:left">Articulated Multi-Perspective Cameras and Their Application to Truck Motion Estimation</td><td style="text-align:right">1440</td></tr><tr><td style="text-align:left">Artificial Intelligent Navigation Technology for a Robotic Vacuum Cleaner in an Indoor Environment</td><td style="text-align:right">2749</td></tr><tr><td style="text-align:left">Artificial Lateral Line Based Longitudinal Separation Sensing for Two Swimming Robotic Fish with Leader-Follower Formation</td><td style="text-align:right">0629</td></tr><tr><td style="text-align:left">A RUGD Dataset for Autonomous Navigation and Visual Perception in Unstructured Outdoor Environments</td><td style="text-align:right">1126</td></tr><tr><td style="text-align:left">A Simple Approach on Global Control of a Class of Underactuated Mechanical Robotic Systems</td><td style="text-align:right">1681</td></tr><tr><td style="text-align:left">A Soft Exoglove Equipped with a Wearable Muscle-Machine Interface Based on Forcemyography and Electromyography</td><td style="text-align:right">2234</td></tr><tr><td style="text-align:left">A Spring-Aided Two-Dimensional Electromechanical Spine Architecture for Bio-Inspired Robots</td><td style="text-align:right">2000</td></tr><tr><td style="text-align:left">A Stabilization Analysis of Omni-Mobile Manipulator with 4K Camera</td><td style="text-align:right">2650</td></tr><tr><td style="text-align:left">A Study of a Class of Vibration-Driven Robots: Modeling, Analysis, Control and Design of the Brushbot</td><td style="text-align:right">1866</td></tr><tr><td style="text-align:left">A Study on the Electric Wheelchair-Humanoid Collaboration for Clothing Assistance of the Elderly</td><td style="text-align:right">2769</td></tr><tr><td style="text-align:left">A Sweeping and Grinding Methods Combined Hybrid Sampler for Asteroid Exploration</td><td style="text-align:right">1759</td></tr><tr><td style="text-align:left">Asynchronous Behavior Trees with Memory Aimed at Aerial Vehicles with Redundancy in Flight Controller</td><td style="text-align:right">1485</td></tr><tr><td style="text-align:left">A Systematic Comparison of Affective Robot Expression Modalities</td><td style="text-align:right">0607</td></tr><tr><td style="text-align:left">A Tactile Stimulation System for Robot-Assisted Hand Rehabilitation</td><td style="text-align:right">2751</td></tr><tr><td style="text-align:left">A Taxonomy for Characterizing Modes of Interactions in Goal-Driven, Human-Robot Teams</td><td style="text-align:right">1548</td></tr><tr><td style="text-align:left">A Teleoperated Hexapod Robot for Imitation Learning Task Training</td><td style="text-align:right">0454</td></tr><tr><td style="text-align:left">A Teleoperation Interface for Loco-Manipulation Control of MObile Collaborative Robotic Assistant (MOCA)</td><td style="text-align:right">2469</td></tr><tr><td style="text-align:left">A Testbed for Haptic and Magnetic Resonance Imaging-Guided Percutaneous Needle Biopsy</td><td style="text-align:right">2479</td></tr><tr><td style="text-align:left">Atomic force microscope tip localization and tracking through deep learning based vision inside an electron microscope</td><td style="text-align:right">1025</td></tr><tr><td style="text-align:left">Attention-Based Hierarchical Deep Reinforcement Learning for Lane Change Behaviors in Autonomous Driving</td><td style="text-align:right">0397</td></tr><tr><td style="text-align:left">Attitude- and Cruise Control of a VTOL Tiltwing UAV</td><td style="text-align:right">2142</td></tr><tr><td style="text-align:left">A Two-DOF Bipedal Robot Utilizing the Reuleaux Triangle Drive Mechanism</td><td style="text-align:right">0464</td></tr><tr><td style="text-align:left">Audio-Visual Sensing from a Quadcopter: Dataset and Baselines for Source Localization and Sound Enhancement</td><td style="text-align:right">0889</td></tr><tr><td style="text-align:left">Augmented Reality Controlled Smart Wheelchair Using Dynamic Signifiers for Affordance Representation</td><td style="text-align:right">0901</td></tr><tr><td style="text-align:left">Augmenting Knowledge through Statistical, Goal-Oriented Human-Robot Dialog</td><td style="text-align:right">1182</td></tr><tr><td style="text-align:left">A Unified Active Assistance Control Framework of Hip Exoskeleton for Walking and Balance Assistance</td><td style="text-align:right">1816</td></tr><tr><td style="text-align:left">A Unified Formulation for Visual Odometry</td><td style="text-align:right">0165</td></tr><tr><td style="text-align:left">Automated Boxwood Topiary Trimming with a Robotic Arm and Integrated Stereo Vision</td><td style="text-align:right">1053</td></tr><tr><td style="text-align:left">Automated Macro-Micro Manipulation for Robotic Microinjection with Computer Vision</td><td style="text-align:right">0609</td></tr><tr><td style="text-align:left">Automated Single-Particle Micropatterning System Using Dielectrophoresis</td><td style="text-align:right">2755</td></tr><tr><td style="text-align:left">Automated Sorting of Rare Cells Based on Autofocusing Visual Feedback in Fluorescence Microscopy</td><td style="text-align:right">0599</td></tr><tr><td style="text-align:left">Automatic Annotation for Semantic Segmentation in Indoor Scenes</td><td style="text-align:right">0469</td></tr><tr><td style="text-align:left">Automatic Calibration of Multiple 3D LiDARs in Urban Environments</td><td style="text-align:right">0822</td></tr><tr><td style="text-align:left">Automatic Cell Assembly by Two-Fingered Microhand</td><td style="text-align:right">0726</td></tr><tr><td style="text-align:left">Automatic Coverage Selection for Surface-Based Visual Localization</td><td style="text-align:right">2201</td></tr><tr><td style="text-align:left">Automatic Multi-Sensor Extrinsic Calibration for Mobile Robots</td><td style="text-align:right">2110</td></tr><tr><td style="text-align:left">Automatic Spatial Template Generation for Realistic 3D Modeling of Large-Scale Indoor Spaces</td><td style="text-align:right">1666</td></tr><tr><td style="text-align:left">Autonomous 3D reconstruction, mapping and exploration of indoor environments with a robotic arm</td><td style="text-align:right">2383</td></tr><tr><td style="text-align:left">Autonomous Detection of PV Panels Using Unmanned Aerial Vehicles</td><td style="text-align:right">2729</td></tr><tr><td style="text-align:left">Autonomous Free-Form Trenching Using a Walking Excavator</td><td style="text-align:right">2171</td></tr><tr><td style="text-align:left">Autonomous Human-Aware Navigation in Dense Crowds</td><td style="text-align:right">2673</td></tr><tr><td style="text-align:left">Autonomous Landing on Pipes Using Soft Gripper for Inspection and Maintenance in Outdoor Environments</td><td style="text-align:right">1291</td></tr><tr><td style="text-align:left">Autonomous Mobile Manipulation Framework for Intelligent Home Service Robots</td><td style="text-align:right">2694</td></tr><tr><td style="text-align:left">Autonomous Photogrammetry Process for Managing Stockpile Inventory with Unmanned Aerial Vehicle</td><td style="text-align:right">2780</td></tr><tr><td style="text-align:left">Autonomous Safe Locomotion System for Bipedal Robot Applying Vision and Sole Reaction Force to Footstep Planning</td><td style="text-align:right">0121</td></tr><tr><td style="text-align:left">Autonomous Search for Sources of Gamma Radiation</td><td style="text-align:right">2737</td></tr><tr><td style="text-align:left">A Variable Stiffness Elbow Joint for Upper Limb Prosthesis</td><td style="text-align:right">2266</td></tr><tr><td style="text-align:left">A Video Data-Driven Approach for the Development of Active Guidance in Robot-Assisted Minimally Invasive Surgical Training</td><td style="text-align:right">2791</td></tr><tr><td style="text-align:left">A Virtual Reality Interface for an Autonomous Spray Painting UAV</td><td style="text-align:right">2494</td></tr><tr><td style="text-align:left">Avoiding Obstacles during Push Recovery Using Real-Time Vision Feedback</td><td style="text-align:right">0628</td></tr><tr><td style="text-align:left">A VR System for Immersive Teleoperation and Live Exploration with a Mobile Robot</td><td style="text-align:right">1046</td></tr><tr><td style="text-align:left">Bag of Semantic Visual Words</td><td style="text-align:right">2762</td></tr><tr><td style="text-align:left">Basic Performance of Planar Omnidirectional Crawler During Direction Switching Using Disturbance Degree of Ground Evaluation Method</td><td style="text-align:right">2461</td></tr><tr><td style="text-align:left">Bayesian Gaussian Mixture Model for Robotic Policy Imitation</td><td style="text-align:right">2512</td></tr><tr><td style="text-align:left">Bayesian Optimization for Policy Search in High-Dimensional Systems Via Automatic Domain Selection</td><td style="text-align:right">0091</td></tr><tr><td style="text-align:left">BeBOT: Bernstein Polynomial Toolkit for Trajectory Generation</td><td style="text-align:right">1490</td></tr><tr><td style="text-align:left">Bee+: A 95-Mg Four-Winged Insect-Scale Flying Robot Driven by Twinned Unimorph Actuators</td><td style="text-align:right">2421</td></tr><tr><td style="text-align:left">Behavior Change Based on Stiffness for Haptic Interface</td><td style="text-align:right">2679</td></tr><tr><td style="text-align:left">Belief-Driven Control Policy of a Drone with Microphones for Multiple Sound Source Search</td><td style="text-align:right">1785</td></tr><tr><td style="text-align:left">Belief Space Metareasoning for Exception Recovery</td><td style="text-align:right">0836</td></tr><tr><td style="text-align:left">Benchmarking and Workload Analysis of Robot Dynamics Algorithms</td><td style="text-align:right">1641</td></tr><tr><td style="text-align:left">Better Lost in Transition Than Lost in Space: SLAM State Machine</td><td style="text-align:right">1450</td></tr><tr><td style="text-align:left">Bidirectional Heuristic Search for Motion Planning with an Extend Operator</td><td style="text-align:right">1851</td></tr><tr><td style="text-align:left">Bi-Modal Hemispherical Sensor: A Unifying Solution for Three Axis Force and Contact Angle Measurement</td><td style="text-align:right">1523</td></tr><tr><td style="text-align:left">Biomimetic Wrinkled MXene Pressure Sensors towards Collision-Aware Robots</td><td style="text-align:right">2781</td></tr><tr><td style="text-align:left">Biped Robot Pelvis Kinematics Estimation Based on the Touch-Point Updating Method</td><td style="text-align:right">0364</td></tr><tr><td style="text-align:left">Black Block Recorder: Immutable Black Box Logging for Robots Via Blockchain</td><td style="text-align:right">2303</td></tr><tr><td style="text-align:left">Boosting SLAM: Combining SLAM Methodologies for Robust Localization</td><td style="text-align:right">2746</td></tr><tr><td style="text-align:left">Boundary Effect-Aware Visual Tracking for UAV with Online Enhanced Background Learning and Multi-Frame Consensus Verification</td><td style="text-align:right">0650</td></tr><tr><td style="text-align:left">Bounded-Error LQR-Trees</td><td style="text-align:right">1519</td></tr><tr><td style="text-align:left">BP Neural Network Based On-Board Training for Real-Time Locomotion Mode Recognition in Robotic Transtibial Prostheses</td><td style="text-align:right">0393</td></tr><tr><td style="text-align:left">BTEL: A Binary Tree Encoding Approach for Visual Localization</td><td style="text-align:right">2502</td></tr><tr><td style="text-align:left">Buckling-Induced Shape Morphing Using Dielectric Elastomer Actuators Patterned with Spatially-Varying Electrodes</td><td style="text-align:right">1849</td></tr><tr><td style="text-align:left">Cable-Driven 4-DOF Upper Limb Rehabilitation Robot</td><td style="text-align:right">1599</td></tr><tr><td style="text-align:left">CALC2.0: Combining Appearance, Semantic and Geometric Information for Robust and Efficient Visual Loop Closure</td><td style="text-align:right">2006</td></tr><tr><td style="text-align:left">Camera Exposure Control for Robust Robot Vision with Noise-Aware Image Quality Assessment</td><td style="text-align:right">2210</td></tr><tr><td style="text-align:left">Camera Pose Estimation Based on PnL with a Known Vertical Direction</td><td style="text-align:right">2378</td></tr><tr><td style="text-align:left">Camera Pose Estimation with Semantic 3D Model</td><td style="text-align:right">0984</td></tr><tr><td style="text-align:left">Camera Zoom Control of Integrated Control Platform for Advancement of Performance Shooting System</td><td style="text-align:right">2651</td></tr><tr><td style="text-align:left">Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography</td><td style="text-align:right">1472</td></tr><tr><td style="text-align:left">Can a Robot Hear the Shape and Dimensions of a Room?</td><td style="text-align:right">1987</td></tr><tr><td style="text-align:left">Can a Social Robot Encourage Children’s Self-Study?</td><td style="text-align:right">0656</td></tr><tr><td style="text-align:left">Cannot Avoid Penalty for Fluctuating Order Arrival Rate? Let’s Minimize</td><td style="text-align:right">0071</td></tr><tr><td style="text-align:left">Can User-Centered Reinforcement Learning Allow a Robot to Attract Passersby without Causing Discomfort?</td><td style="text-align:right">0691</td></tr><tr><td style="text-align:left">Capillary Force Gripper for Complex Shaped Micro Objects with Fast Droplet Forming by On-Off Control of a Piston Slider</td><td style="text-align:right">2169</td></tr><tr><td style="text-align:left">Carpie: A Soft, Mechanically-Reconfigurable Worm Robot</td><td style="text-align:right">0195</td></tr><tr><td style="text-align:left">Cascaded Gaussian Processes for Data-Efficient Robot Dynamics Learning</td><td style="text-align:right">1399</td></tr><tr><td style="text-align:left">Centralized Control Architecture for Cooperative Object Transportation Using Multiple Omnidirectional AGVs</td><td style="text-align:right">0646</td></tr><tr><td style="text-align:left">Chance-Constrained Trajectory Optimization for Non-Linear Systems with Unknown Stochastic Dynamics</td><td style="text-align:right">1216</td></tr><tr><td style="text-align:left">Characterizing Environmental Interactions for Soft Growing Robots</td><td style="text-align:right">0632</td></tr><tr><td style="text-align:left">Characterizing Nanoparticle Swarms with Tuneable Concentrations for Enhanced Imaging Contrast</td><td style="text-align:right">2203</td></tr><tr><td style="text-align:left">Cheating with Robots: how at ease do they make us feel?</td><td style="text-align:right">0757</td></tr><tr><td style="text-align:left">Clock-Torqued Rolling SLIP Model and Its Application to Variable-Speed Running in a Hexapod Robot</td><td style="text-align:right">2592</td></tr><tr><td style="text-align:left">Clone Swarms: Learning to Predict and Control Multi-Robot Systems by Imitation</td><td style="text-align:right">1337</td></tr><tr><td style="text-align:left">Closed-Form Equations and Experimental Verification for Soft Robot Arm Based on Cosserat Theory</td><td style="text-align:right">0854</td></tr><tr><td style="text-align:left">Closed-Loop Force Control of a Pneumatic Gripper Actuated by Two Pressure Regulators</td><td style="text-align:right">1068</td></tr><tr><td style="text-align:left">COBRA: COllaborative Bot with multi-Rotor Actuation</td><td style="text-align:right">0533</td></tr><tr><td style="text-align:left">Cognitive Robotic Architecture for Semi-Autonomous Execution of Manipulation Tasks in a Surgical Environment</td><td style="text-align:right">1349</td></tr><tr><td style="text-align:left">Collaborative Human Augmented SLAM</td><td style="text-align:right">0359</td></tr><tr><td style="text-align:left">Collaborative Mapping with Pose Uncertainties using different Radio Frequencies and Communication Modules</td><td style="text-align:right">0042</td></tr><tr><td style="text-align:left">Collaborative Needle Insertion with Active Tissue Deformation Control</td><td style="text-align:right">2038</td></tr><tr><td style="text-align:left">Collaborative Robot Assistant for the Ergonomic Manipulation of Cumbersome Objects</td><td style="text-align:right">0169</td></tr><tr><td style="text-align:left">Collision Detection and Isolation on a Robot Using Joint Torque Sensing</td><td style="text-align:right">1378</td></tr><tr><td style="text-align:left">Combined Optimization of Gripper Finger Design and Pose Estimation Processes for Advanced Industrial Assembly</td><td style="text-align:right">0870</td></tr><tr><td style="text-align:left">Combined Task and Action Learning from Human Demonstrations for Mobile Manipulation Applications</td><td style="text-align:right">0406</td></tr><tr><td style="text-align:left">Combining Spiking Motor Primitives with a Behavior-Based Architecture to Model Locomotion for Six-Legged Robots</td><td style="text-align:right">0494</td></tr><tr><td style="text-align:left">Combining Stochastic Optimization and Frontiers for Aerial Multi-Robot Exploration of 3D Terrains</td><td style="text-align:right">1102</td></tr><tr><td style="text-align:left">Commercialization of Robot Navigation Technology for a Guidance Service in a Large and Highly-Crowded Airport</td><td style="text-align:right">2748</td></tr><tr><td style="text-align:left">Common Dimensional Autoencoder for Learning Redundant Muscle-Posture Mappings of Complex Musculoskeletal Robots</td><td style="text-align:right">1375</td></tr><tr><td style="text-align:left">Communication Constrained Cloud-Based Long-Term Visual Localization in Real Time</td><td style="text-align:right">1016</td></tr><tr><td style="text-align:left">Compact Reachability Map for Excavator Motion Planning</td><td style="text-align:right">1922</td></tr><tr><td style="text-align:left">Comparing Swimming Performances of flexible and Helical Magnetic Swimmers</td><td style="text-align:right">0058</td></tr><tr><td style="text-align:left">Comparison of Deep Reinforcement Learning Policies to Formal Methods for Moving Obstacle Avoidance</td><td style="text-align:right">1823</td></tr><tr><td style="text-align:left">Complexity Conditioned Goals for Reinforcement Learning Agents</td><td style="text-align:right">2786</td></tr><tr><td style="text-align:left">Complex Stiffness Model of Physical Human-Robot Interaction: Implications for Control of Performance Augmentation Exoskeletons</td><td style="text-align:right">1342</td></tr><tr><td style="text-align:left">Component Modularized Design of Musculoskeletal Humanoid Platform Musashi to Investigate Learning Control Systems</td><td style="text-align:right">0124</td></tr><tr><td style="text-align:left">Computational Design of Statically Balanced Planar Spring Mechanisms</td><td style="text-align:right">2462</td></tr><tr><td style="text-align:left">Computationally Efficient MPC for Cable-Driven Robot</td><td style="text-align:right">2718</td></tr><tr><td style="text-align:left">Computing 3D From-Region Visibility Using Visibility Integrity</td><td style="text-align:right">2220</td></tr><tr><td style="text-align:left">Computing a Minimal Set of T-Spanning Motion Primitives for Lattice Planners</td><td style="text-align:right">1507</td></tr><tr><td style="text-align:left">Concept and Validation of a Large-Scale Human-Machine Safety System Based on Real-Time UWB Indoor Localization</td><td style="text-align:right">0785</td></tr><tr><td style="text-align:left">Conditional Generative Neural System for Probabilistic Trajectory Prediction</td><td style="text-align:right">0952</td></tr><tr><td style="text-align:left">Configuration Modeling of a Soft Robotic Element with Selectable Bending Axes</td><td style="text-align:right">1287</td></tr><tr><td style="text-align:left">Configuration Transition Control of a Continuum Surgical Manipulator for Improved Kinematic Performance</td><td style="text-align:right">2457</td></tr><tr><td style="text-align:left">Connectivity-Preserving Swarm Teleoperation with a Tree Network</td><td style="text-align:right">0477</td></tr><tr><td style="text-align:left">Constrained Heterogeneous Vehicle Path Planning for Large-Area Coverage</td><td style="text-align:right">1465</td></tr><tr><td style="text-align:left">Constructing a Highly Interactive Vehicle Motion Dataset</td><td style="text-align:right">1827</td></tr><tr><td style="text-align:left">Contact-Based Bridge Inspection Multirotors: Design, Modelling and Control Considering the Ceiling Effect</td><td style="text-align:right">2390</td></tr><tr><td style="text-align:left">Contact Distance Estimation by Soft Active Bio-Whisker Sensor Based on Morphological Computation</td><td style="text-align:right">2612</td></tr><tr><td style="text-align:left">ContactGrasp: Functional Multi-Finger Grasp Synthesis from Contact</td><td style="text-align:right">1159</td></tr><tr><td style="text-align:left">Contact-Implicit Trajectory Optimization for Dynamic Object Manipulation</td><td style="text-align:right">0803</td></tr><tr><td style="text-align:left">Contact Skill Imitation Learning for Robot-Independent Assembly Programming</td><td style="text-align:right">0488</td></tr><tr><td style="text-align:left">Contamination Detection and Classification for an Automated FaÃ§ade Cleaning Operation</td><td style="text-align:right">2631</td></tr><tr><td style="text-align:left">Context and Intention Aware Planning for Urban Driving</td><td style="text-align:right">0640</td></tr><tr><td style="text-align:left">Context-Dependent Search for Generating Paths for Redundant Manipulators in Cluttered Environments</td><td style="text-align:right">1424</td></tr><tr><td style="text-align:left">Continuous Close-Range 3D Object Pose Estimation</td><td style="text-align:right">1380</td></tr><tr><td style="text-align:left">Continuous Collision Detection for a Robotic Arm Mounted on a Cable-Driven Parallel Robot</td><td style="text-align:right">1054</td></tr><tr><td style="text-align:left">Continuous Mechanical Indexing of Single Cell Spheroids Using a Robot Integrated Microfluidic Chip</td><td style="text-align:right">2204</td></tr><tr><td style="text-align:left">Continuous Modeling of Affordances in a Symbolic Knowledge Base</td><td style="text-align:right">1245</td></tr><tr><td style="text-align:left">Continuous Neural Control Based on Integration of BCI and Adaptive Controller for Steering a Vehicle</td><td style="text-align:right">2721</td></tr><tr><td style="text-align:left">Continuous Relaxation of Symbolic Planner for One-Shot Imitation Learning</td><td style="text-align:right">0565</td></tr><tr><td style="text-align:left">Continuous-Time Collision Avoidance for Trajectory Optimization in Dynamic Environments</td><td style="text-align:right">1904</td></tr><tr><td style="text-align:left">Contour Based Reconstruction of Underwater Structures Using Sonar, Visual, Inertial, and Depth Sensor</td><td style="text-align:right">1537</td></tr><tr><td style="text-align:left">Control and Perception Framework for Deep Sea Mining Exploration</td><td style="text-align:right">0999</td></tr><tr><td style="text-align:left">Control of Nonprehensile Planar Rolling Manipulation: A Passivity-Based Approach</td><td style="text-align:right">2607</td></tr><tr><td style="text-align:left">Convolutional autoencoder for feature extraction in tactile sensing</td><td style="text-align:right">2519</td></tr><tr><td style="text-align:left">Cooperative Audio-Visual System for Localizing Micro Aerial Robots</td><td style="text-align:right">1366</td></tr><tr><td style="text-align:left">Cooperative Decentralised Circumnavigation with Application to Algalbloom Tracking</td><td style="text-align:right">0864</td></tr><tr><td style="text-align:left">Cooperative Range-Only SLAM Based on Sum of Gaussian Filter in Dynamic Environments</td><td style="text-align:right">0842</td></tr><tr><td style="text-align:left">Cooperative Schedule-Driven Intersection Control with Connected and Autonomous Vehicles</td><td style="text-align:right">1677</td></tr><tr><td style="text-align:left">Co-Simulation of Mechanical Systems with Hydraulic Actuators</td><td style="text-align:right">2743</td></tr><tr><td style="text-align:left">Coupling Disturbance Compensated MIMO Control of Parallel Ankle Rehabilitation Robot Actuated by Pneumatic Muscles</td><td style="text-align:right">0745</td></tr><tr><td style="text-align:left">Covariance Pre-Integration for Delayed Measurements in Multi-Sensor Fusion</td><td style="text-align:right">1557</td></tr><tr><td style="text-align:left">Coverage Path Planning Using Path Primitive Sampling and Primitive Coverage Graph for Visual Inspection</td><td style="text-align:right">0337</td></tr><tr><td style="text-align:left">Coverage Sampling Planner for UAV-Enabled Environmental Exploration and Field Mapping</td><td style="text-align:right">1408</td></tr><tr><td style="text-align:left">Criteria for Maintaining Desired Contacts for Quasi-Static Systems</td><td style="text-align:right">1558</td></tr><tr><td style="text-align:left">Crowd-sourced Semantic Edge Mapping for Autonomous Vehicles</td><td style="text-align:right">1701</td></tr><tr><td style="text-align:left">CubeSLAM: Monocular 3-D Object SLAM</td><td style="text-align:right">2611</td></tr><tr><td style="text-align:left">Curiosity Driven Exploration for Classification in the Dark Using Tactile Sensing</td><td style="text-align:right">2761</td></tr><tr><td style="text-align:left">Curved-Voxel Clustering for Accurate Segmentation of 3D LiDAR Point Clouds with Real-Time Performance</td><td style="text-align:right">1780</td></tr><tr><td style="text-align:left">Data Association Aware Semantic Mapping and Localization Via a Viewpoint-Dependent Classifier Model</td><td style="text-align:right">0627</td></tr><tr><td style="text-align:left">Data-Based Modeling of Contact State in Robotic Assembly</td><td style="text-align:right">2698</td></tr><tr><td style="text-align:left">Data-Driven Model Predictive Control for Trajectory Tracking with a Robotic Arm</td><td style="text-align:right">2403</td></tr><tr><td style="text-align:left">Data Flow ORB-SLAM for Real-Time Performance on Embedded GPU Boards</td><td style="text-align:right">0413</td></tr><tr><td style="text-align:left">Decentralized Control for 3D M-Blocks for Path Following, Line Formation, and Light Gradient Aggregation</td><td style="text-align:right">1308</td></tr><tr><td style="text-align:left">Decentralized Pose Control of Modular Reconfigurable Robots Operating in Liquid Environments</td><td style="text-align:right">1996</td></tr><tr><td style="text-align:left">Decentralized Visual-Inertial Localization and Mapping on Mobile Devices for Augmented Reality</td><td style="text-align:right">0461</td></tr><tr><td style="text-align:left">Decoding the Perceived Difficulty of Communicated Contents by Older People: Toward Conversational Robot-Assistive Elderly Care</td><td style="text-align:right">2507</td></tr><tr><td style="text-align:left">DEDUCE: Diverse scEne Detection Methods in Unseen Challenging Environments</td><td style="text-align:right">0590</td></tr><tr><td style="text-align:left">DeepControl: Energy-Efficient Control of a Quadrotor Using a Deep Neural Network</td><td style="text-align:right">1839</td></tr><tr><td style="text-align:left">Deep Dive into Faces: Pose &amp; Illumination Invariant Multi-Face Emotion Recognition System</td><td style="text-align:right">0742</td></tr><tr><td style="text-align:left">Deep Generative Modeling of LiDAR Data</td><td style="text-align:right">1601</td></tr><tr><td style="text-align:left">Deep Imitation Learning for Autonomous Driving in Generic Urban Scenarios with Enhanced Safety</td><td style="text-align:right">1371</td></tr><tr><td style="text-align:left">Deep Lagrangian Networks for End-To-End Learning of Energy-Based Control for Under-Actuated Systems</td><td style="text-align:right">1042</td></tr><tr><td style="text-align:left">Deep Learning-Based Mutual Detection and Collaborative Localization for Mobile Robot Fleets Using Solely 2D LIDAR Sensors</td><td style="text-align:right">1175</td></tr><tr><td style="text-align:left">Deep Learning Based Robotic Tool Detection and Articulation Estimation with Spatio-Temporal Layers</td><td style="text-align:right">2384</td></tr><tr><td style="text-align:left">Deep Learning of Proprioceptive Models for Robotic Force Estimation</td><td style="text-align:right">0372</td></tr><tr><td style="text-align:left">DeepLocNet: Deep Observation Classification and Ranging Bias Regression for Radio Positioning Systems</td><td style="text-align:right">1961</td></tr><tr><td style="text-align:left">Deep Multi-Task Learning for Anomalous Driving Detection Using CAN Bus Scalar Sensor Data</td><td style="text-align:right">1665</td></tr><tr><td style="text-align:left">Deep Neural Network Approach in Electrical Impedance Tomography-Based Real-Time Soft Tactile Sensor</td><td style="text-align:right">0574</td></tr><tr><td style="text-align:left">Deep Neural Network Based Visual Inspection with 3D Metric Measurement of Concrete Defects Using Wall-Climbing Robot</td><td style="text-align:right">2008</td></tr><tr><td style="text-align:left">Deep Orientation: Fast and Robust Upper Body Orientation Estimation for Mobile Robotic Applications</td><td style="text-align:right">1070</td></tr><tr><td style="text-align:left">DeepPCO: End-To-End Point Cloud Odometry through Deep Parallel Neural Network</td><td style="text-align:right">1056</td></tr><tr><td style="text-align:left">Deep Predictive Autonomous Driving Using Multi-Agent Joint Trajectory Prediction and Traffic Rules</td><td style="text-align:right">2013</td></tr><tr><td style="text-align:left">Deep Reinforcement Learning for Robotic Pushing and Picking in Cluttered Environment</td><td style="text-align:right">1325</td></tr><tr><td style="text-align:left">Deep Sensor Fusion for Real-Time Odometry Estimation</td><td style="text-align:right">0421</td></tr><tr><td style="text-align:left">Deep Supervised Hashing with Similar Hierarchy for Place Recognition</td><td style="text-align:right">0365</td></tr><tr><td style="text-align:left">DeepVIO: Self-Supervised Deep Learning of Monocular Visual Inertial Odometry Using 3D Geometric Constraints</td><td style="text-align:right">0978</td></tr><tr><td style="text-align:left">Deep Visual MPC-Policy Learning for Navigation</td><td style="text-align:right">2120</td></tr><tr><td style="text-align:left">Degeneracy-Aware Factors with Applications to Underwater SLAM</td><td style="text-align:right">1187</td></tr><tr><td style="text-align:left">Degeneracy in Self-Calibration Revisited and a Deep Learning Solution for Uncalibrated SLAM</td><td style="text-align:right">1031</td></tr><tr><td style="text-align:left">Delayed Output Feedback Control for Gait Assistance and Resistance Using a Robotic Exoskeleton</td><td style="text-align:right">2338</td></tr><tr><td style="text-align:left">Delayed Output Feedback Control for Gait Assistance with a Robotic Hip Exoskeleton</td><td style="text-align:right">2609</td></tr><tr><td style="text-align:left">Delivering Cognitive Behavioral Therapy Using a Conversational Social Robot</td><td style="text-align:right">1394</td></tr><tr><td style="text-align:left">Dempster Shafer Grid-Based Hybrid Fusion of Virtual Lanes for Autonomous Driving</td><td style="text-align:right">0437</td></tr><tr><td style="text-align:left">Dense 3D Reconstruction for Visual Tunnel Inspection Using Unmanned Aerial Vehicle</td><td style="text-align:right">0336</td></tr><tr><td style="text-align:left">DensePeds: Pedestrian Tracking in Dense Crowds Using FRVO and Sparse Features</td><td style="text-align:right">1295</td></tr><tr><td style="text-align:left">Dense, Sonar-Based Reconstruction of Underwater Scenes</td><td style="text-align:right">1471</td></tr><tr><td style="text-align:left">Depth-Image-Based Textureless-Object Picking by DCNN and Visual Servoing</td><td style="text-align:right">2619</td></tr><tr><td style="text-align:left">Design a Dexterous Hand for the Logistic Robot in Bin Picking</td><td style="text-align:right">2730</td></tr><tr><td style="text-align:left">Design and Analysis of a New 3-DOF Active-Type Constant-Force Compliant Parallel Stage</td><td style="text-align:right">0545</td></tr><tr><td style="text-align:left">Design and Analysis of the All-In-One Actuation Module with Multi-Sensors</td><td style="text-align:right">2670</td></tr><tr><td style="text-align:left">Design and Characterization of a Fully Autonomous Under-Actuated Soft Batoid-Like Robot</td><td style="text-align:right">1374</td></tr><tr><td style="text-align:left">Design and Comparative Analysis of 1D Hopping Robots</td><td style="text-align:right">1831</td></tr><tr><td style="text-align:left">Design and Control of Aerial Modules for Inflight Self-disassembly</td><td style="text-align:right">2389</td></tr><tr><td style="text-align:left">Design and Control of a High-Torque and Highly-Backdrivable Hybrid Soft Exoskeleton for Knee Injury Prevention during Squatting</td><td style="text-align:right">2493</td></tr><tr><td style="text-align:left">Design and Control of a Multifunctional Ankle Exoskeleton Powered by Magnetorheological Actuators to Assist Walking, Jumping and Landing</td><td style="text-align:right">2227</td></tr><tr><td style="text-align:left">Design and Development of Compactly Folding Parallel Open-Close Gripper with Wide Stroke</td><td style="text-align:right">1926</td></tr><tr><td style="text-align:left">Design and Experiment of Dragonfly Inspired Flexible Blade to Improve Safety of Drones</td><td style="text-align:right">2331</td></tr><tr><td style="text-align:left">Design and Implementation of a Contact Aerial Manipulator System for Glass-Wall Inspection Tasks</td><td style="text-align:right">0740</td></tr><tr><td style="text-align:left">Design and Take-Off Flight of a Samara-Inspired Revolving-Wing Robot</td><td style="text-align:right">0797</td></tr><tr><td style="text-align:left">Design and Verification of a Gravity Compensated Tool Handler for Supporting an Automatic Hair Implanting Device</td><td style="text-align:right">2367</td></tr><tr><td style="text-align:left">Design and Verification of a Portable Master Manipulator Based on an Effective Workspace Analysis Framework</td><td style="text-align:right">2096</td></tr><tr><td style="text-align:left">Design, Characterization, and Mechanical Programming of Fabric-Reinforced Textile Actuators for a Soft Robotic Hand</td><td style="text-align:right">1585</td></tr><tr><td style="text-align:left">Design, Fabrication, and Characterization of an Untethered Amphibious Sea Urchin-Inspired Robot</td><td style="text-align:right">2276</td></tr><tr><td style="text-align:left">Design for Cobot-Assisted Manufacturing and Assembly (DFcoMA)</td><td style="text-align:right">2738</td></tr><tr><td style="text-align:left">Designing a Mechanical Tool for Robots with 2-Finger Parallel Grippers</td><td style="text-align:right">2293</td></tr><tr><td style="text-align:left">Design, Modeling and Control of Fully Actuated 2D Transformable Aerial Robot with 1 DoF Thrust Vectorable Link Module</td><td style="text-align:right">1461</td></tr><tr><td style="text-align:left">Design, Modeling and Testing of a Flagellum-Inspired Soft Underwater Propeller Exploiting Passive Elasticity</td><td style="text-align:right">0641</td></tr><tr><td style="text-align:left">Design, Modelling and Adaptive Control of a Novel Autonomous Underwater Vehicle Equipped with Vectored Thrusters</td><td style="text-align:right">2660</td></tr><tr><td style="text-align:left">Design, modelling and control of a novel agricultural robot with iInterlock drive system</td><td style="text-align:right">2195</td></tr><tr><td style="text-align:left">Design of a 3-DOF Linkage-Driven Underactuated Finger for Multiple Grasping</td><td style="text-align:right">1645</td></tr><tr><td style="text-align:left">Design of a Ballistically-Launched Foldable Multirotor</td><td style="text-align:right">0511</td></tr><tr><td style="text-align:left">Design of a Bipedal Hopping Robot with Morphable Inertial Tail for Agile Locomotion</td><td style="text-align:right">2717</td></tr><tr><td style="text-align:left">Design of a Compact SMA-Actuated MRI-Compatible Steerable Neurosurgical Robot</td><td style="text-align:right">2768</td></tr><tr><td style="text-align:left">Design of a Fail-Safe Wearable Robot with Novel Extendable Arms for Ergonomic Accommodation During Floor Work</td><td style="text-align:right">1696</td></tr><tr><td style="text-align:left">Design of a Growing Robot Inspired by Plant Growth</td><td style="text-align:right">1653</td></tr><tr><td style="text-align:left">Design of a Mobile Robot for the Treatment, Reuse and Removal of Manure with Monitoring of Environmental Variables for Poultry Farms</td><td style="text-align:right">2783</td></tr><tr><td style="text-align:left">Design of a Modular Continuum-Articulated Laparoscopic Robotic Tool with Decoupled Kinematics</td><td style="text-align:right">2231</td></tr><tr><td style="text-align:left">Design of an Adhesion-Aware FaÃ§ade Cleaning Robot</td><td style="text-align:right">0151</td></tr><tr><td style="text-align:left">Design of a Novel Gripper System with 3D and Inkjet-Printed Multimodal Sensors for Automated Grasping of a Forestry Robot</td><td style="text-align:right">2306</td></tr><tr><td style="text-align:left">Design of a Novel Leg for a Small Tree Climbing Robot Driven by Shape Memory Alloy</td><td style="text-align:right">2709</td></tr><tr><td style="text-align:left">Design of a Semi-Humanoid Telepresence Robot for Plant Disaster Response and Prevention</td><td style="text-align:right">1936</td></tr><tr><td style="text-align:left">Design of a Variable Counterbalance Mechanism to Minimize Required Torque of Robot Arm</td><td style="text-align:right">2622</td></tr><tr><td style="text-align:left">Design of Compact Variable Gravity Compensator (CVGC) Based on Cam and Variable Pivot of a Lever Mechanism</td><td style="text-align:right">0541</td></tr><tr><td style="text-align:left">Design of Robot Leg with Variable Reduction Ratio Crossed Four-bar Linkage Mechanism</td><td style="text-align:right">1784</td></tr><tr><td style="text-align:left">Design of Soft Flexible Wire-Driven Finger Mechanism for Contact Pressure Distribution</td><td style="text-align:right">0909</td></tr><tr><td style="text-align:left">Design of Wearable Robot Focused on Contact State with Wearer</td><td style="text-align:right">2756</td></tr><tr><td style="text-align:left">DESK: A Robotic Activity Dataset for Dexterous Surgical Skills Transfer to Medical Robots</td><td style="text-align:right">1757</td></tr><tr><td style="text-align:left">Detecting Layered Structures of Partially Occluded Objects for Bin Picking</td><td style="text-align:right">1934</td></tr><tr><td style="text-align:left">Development of 3DoF Manipulators with Cable-Hydraulic Driven Actuation Modules for Large Workspace and High Payload-To-Weight</td><td style="text-align:right">2771</td></tr><tr><td style="text-align:left">Development of a Continuous Vertical-Pulling Automatic Doffing Robot for the Ring Spinning</td><td style="text-align:right">1921</td></tr><tr><td style="text-align:left">Development of Adjustable Knee Assist Device for Wearable Robot Based on Linkage and Rolling Joint</td><td style="text-align:right">0387</td></tr><tr><td style="text-align:left">Development of a Location Finding System for Minute Sound Source by Using Human Acoustic System with Stochastic Resonance</td><td style="text-align:right">1857</td></tr><tr><td style="text-align:left">Development of an adaptive hexapod robot based on Follow-the-contact-point gait control and Timekeeper control</td><td style="text-align:right">0559</td></tr><tr><td style="text-align:left">Development of an Arm Curl Machine with Variable Resistance Using Pneumatic Artificial Rubber Muscle</td><td style="text-align:right">1928</td></tr><tr><td style="text-align:left">Development of an Autonomous Sanding Robot with Structured-Light Technology</td><td style="text-align:right">0660</td></tr><tr><td style="text-align:left">Development of a Navigation Algorithm for Optimal Path Planning for Autonomous Electric Vehicles</td><td style="text-align:right">1110</td></tr><tr><td style="text-align:left">Development of a Steel Bridge Climbing Robot</td><td style="text-align:right">1315</td></tr><tr><td style="text-align:left">Development of Flexible Dual-Type Proximity Sensor with Resonant Frequency for Robotic Applications</td><td style="text-align:right">0821</td></tr><tr><td style="text-align:left">Development of Immersive VR Interface of Finger Motion without Restriction of Real Environment</td><td style="text-align:right">2676</td></tr><tr><td style="text-align:left">Development of Joint Module with Two-Speed Gear Transmission and Joint Lock Mechanism during Driving for Task Adaptable Robot</td><td style="text-align:right">0296</td></tr><tr><td style="text-align:left">Development of Load Weight and Height Classifier in Lifting-Up Task Using Body Motion Metrics</td><td style="text-align:right">2555</td></tr><tr><td style="text-align:left">Development of Micro Ultrasonic Actuator and Micro Rotor Blade for Micro Aerial Vehicle</td><td style="text-align:right">0623</td></tr><tr><td style="text-align:left">Development of Novel Bevel-Geared 5mm Articulating Wrist for Micro-Laparoscopy Instrument</td><td style="text-align:right">2238</td></tr><tr><td style="text-align:left">Did You Miss the Sign? a False Negative Alarm System for Traffic Sign Detectors</td><td style="text-align:right">1156</td></tr><tr><td style="text-align:left">Directional TSDF: Modeling Surface Orientation for Coherent Meshes</td><td style="text-align:right">1151</td></tr><tr><td style="text-align:left">Disaster Response Robot’s Autonomous Manipulation of Valves in Disaster Sites Based on Visual Analyses of RGBD Images</td><td style="text-align:right">0514</td></tr><tr><td style="text-align:left">DISC: A Large-Scale Virtual Dataset for Simulating Disaster Scenarios</td><td style="text-align:right">0018</td></tr><tr><td style="text-align:left">DISCOMAN: Dataset of Indoor SCenes for Odometry, Mapping and Navigation</td><td style="text-align:right">1019</td></tr><tr><td style="text-align:left">Discrete N-Dimensional Entropy of Behavior: DNDEB</td><td style="text-align:right">1377</td></tr><tr><td style="text-align:left">DISR: Deep Infrared Spectral Restoration Algorithm for Robot Sensing and Intelligent Visual Tracking Systems</td><td style="text-align:right">0403</td></tr><tr><td style="text-align:left">Distance-Based Cooperative Relative Localization for Leader-Following Control of MAVs</td><td style="text-align:right">2397</td></tr><tr><td style="text-align:left">Distributed Dynamic Sensor Assignment of Multiple Mobile Targets</td><td style="text-align:right">0716</td></tr><tr><td style="text-align:left">Disturbance Estimation and Rejection for High-Precision Multirotor Position Control</td><td style="text-align:right">2361</td></tr><tr><td style="text-align:left">DLD: A Deep Learning Based Line Descriptor for Line Feature Matching</td><td style="text-align:right">0049</td></tr><tr><td style="text-align:left">Do Intermediate Gaits Matter When Rapidly Accelerating?</td><td style="text-align:right">2284</td></tr><tr><td style="text-align:left">Domain-Independent Unsupervised Detection of Grasp Regions to grasp Novel Objects</td><td style="text-align:right">1689</td></tr><tr><td style="text-align:left">Dot-to-Dot: Explainable Hierarchical Reinforcement Learning for Robotic Manipulation</td><td style="text-align:right">0887</td></tr><tr><td style="text-align:left">Double Refinement Network for Efficient Monocular Depth Estimation</td><td style="text-align:right">1041</td></tr><tr><td style="text-align:left">Driving with Style: Inverse Reinforcement Learning in General-Purpose Planning for Automated Driving</td><td style="text-align:right">1356</td></tr><tr><td style="text-align:left">Dual-Arm Assembly Planning Considering Gravitational Constraints</td><td style="text-align:right">1859</td></tr><tr><td style="text-align:left">Duckiepond: An Open Education and Research Environment for a Fleet of Autonomous Maritime Vehicles</td><td style="text-align:right">2301</td></tr><tr><td style="text-align:left">Dynamic Control for Soft Robots with Internal Constraints in the Presence of Obstacles</td><td style="text-align:right">1384</td></tr><tr><td style="text-align:left">Dynamic Density Topological Structure Generation for Real-Time Ladder Affordance Detection</td><td style="text-align:right">0831</td></tr><tr><td style="text-align:left">Dynamic Flex-And-Flip Manipulation of Deformable Linear Objects</td><td style="text-align:right">1515</td></tr><tr><td style="text-align:left">Dynamic Identification of the Franka Emika Panda Robot with Retrieval of Feasible Parameters Using Penalty-based Optimization</td><td style="text-align:right">2443</td></tr><tr><td style="text-align:left">Dynamic Input for Deep Reinforcement Learning in Autonomous Driving</td><td style="text-align:right">1229</td></tr><tr><td style="text-align:left">Dynamic Locomotion on Slippery Ground</td><td style="text-align:right">2528</td></tr><tr><td style="text-align:left">Dynamic Spatiotemporal Pattern Identification and Analysis Using a Fingertip-Based Electro-Tactile Display Array</td><td style="text-align:right">1716</td></tr><tr><td style="text-align:left">Dynamic Task Control Method of a Flexible Manipulator Using a Deep Recurrent Neural Network</td><td style="text-align:right">0566</td></tr><tr><td style="text-align:left">Dynamic Whole-Body Control of Unstable Wheeled Humanoid Robots</td><td style="text-align:right">2252</td></tr><tr><td style="text-align:left">Early Fusion for Goal Directed Robotic Vision</td><td style="text-align:right">1150</td></tr><tr><td style="text-align:left">Edge-Preserving Camera Trajectories for Improved Optical Character Recognition on Static Scenes with Text</td><td style="text-align:right">2280</td></tr><tr><td style="text-align:left">Effective Estimation of Contact Force and Torque for Vision-based Tactile Sensors with Helmholtz-Hodge Decomposition</td><td style="text-align:right">2464</td></tr><tr><td style="text-align:left">Effect of Arm Swinging and Trunk Twisting on Bipedal Locomotion</td><td style="text-align:right">0557</td></tr><tr><td style="text-align:left">Effect of Planning Period on MPC-Based Navigation for a Biped Robot in a Crowd</td><td style="text-align:right">0382</td></tr><tr><td style="text-align:left">Effect of Vibration on Twisted String Actuation through Conduit at High Bending Angles</td><td style="text-align:right">1529</td></tr><tr><td style="text-align:left">Effects of a Bio-mimicked Flapping Path on Propulsion Efficiency of Two-segmental Fish Robots</td><td style="text-align:right">1034</td></tr><tr><td style="text-align:left">Effects of a Person-Following Light-Touch Device During Overground Walking with Visual Perturbations in a Virtual Reality Environment</td><td style="text-align:right">2498</td></tr><tr><td style="text-align:left">Effects of Limb Morphology on Transient Locomotion in Quadruped Robots</td><td style="text-align:right">2336</td></tr><tr><td style="text-align:left">Efficient and Accurate Operational Space Control with Dual-Haptic Interface for Large Workspace Teleoperation</td><td style="text-align:right">2708</td></tr><tr><td style="text-align:left">Efficient and Guaranteed Planar Pose Graph Optimization Using the Complex Number Representation</td><td style="text-align:right">0987</td></tr><tr><td style="text-align:left">Efficient Autonomous Robotic Exploration with Semantic Road Map in Indoor Environments</td><td style="text-align:right">2225</td></tr><tr><td style="text-align:left">Efficient Environment Guided Approach for Exploration of Complex Environments</td><td style="text-align:right">1085</td></tr><tr><td style="text-align:left">Efficient Grasp Planning and Execution with Multi-Fingered Hands by Surface Fitting</td><td style="text-align:right">2424</td></tr><tr><td style="text-align:left">Efficient Quadrupedal Walking Via Decentralized Coordination Mechanism between Limbs and Neck</td><td style="text-align:right">0606</td></tr><tr><td style="text-align:left">Eigen-Factors: Plane Estimation for Multi-Frame and Time-Continuous Point Cloud Alignment</td><td style="text-align:right">1499</td></tr><tr><td style="text-align:left">Electrical Bio-Impedance Proximity Sensing for Vitreo-Retinal Micro-Surgery</td><td style="text-align:right">2320</td></tr><tr><td style="text-align:left">ElevateNet: A Convolutional Neural Network for Estimating the Missing Dimension in 2D Underwater Sonar Images</td><td style="text-align:right">1249</td></tr><tr><td style="text-align:left">Empirical Characterization of a High-Performance Exterior-Rotor Type Brushless DC Motor and Drive</td><td style="text-align:right">2477</td></tr><tr><td style="text-align:left">Employing Magnets to Improve the Force Exertion Capabilities of Adaptive Robot Hands in Precision Grasps</td><td style="text-align:right">0290</td></tr><tr><td style="text-align:left">Employing Whole-Body Control in Assistive Robotics</td><td style="text-align:right">1269</td></tr><tr><td style="text-align:left">Empowered Optical Inspection by Using Robotic Manipulator in Industrial Applications</td><td style="text-align:right">1004</td></tr><tr><td style="text-align:left">Enabling human-like task identification from natural conversation</td><td style="text-align:right">0079</td></tr><tr><td style="text-align:left">Endoscopic Bi-Manual Robotic Instrument Design Using a Genetic Algorithm</td><td style="text-align:right">0816</td></tr><tr><td style="text-align:left">End-To-End Driving Model for Steering Control of Autonomous Vehicles with Future Spatiotemporal Features</td><td style="text-align:right">1524</td></tr><tr><td style="text-align:left">End-To-End Sensorimotor Control Problems of AUVs with Deep Reinforcement Learning</td><td style="text-align:right">0245</td></tr><tr><td style="text-align:left">Energy-Based Adaptive Control and Learning for Patient-Aware Rehabilitation</td><td style="text-align:right">1918</td></tr><tr><td style="text-align:left">Energy-Based Hybrid Control of a Ball-Dribbling Robot</td><td style="text-align:right">2739</td></tr><tr><td style="text-align:left">Energy-Efficient Locomotion Strategies and Performance Benchmarks Using Point Mass Tensegrity Dynamics</td><td style="text-align:right">1919</td></tr><tr><td style="text-align:left">Energy Harvesting across Temporal Temperature Gradients Using Vaporization</td><td style="text-align:right">0714</td></tr><tr><td style="text-align:left">EnsembleDAgger: A Bayesian Approach to Safe Imitation Learning</td><td style="text-align:right">0294</td></tr><tr><td style="text-align:left">Enthusiastic Robots Make Better Contact</td><td style="text-align:right">0924</td></tr><tr><td style="text-align:left">Entropic Risk Measure in Policy Search</td><td style="text-align:right">1298</td></tr><tr><td style="text-align:left">Environmental Sound Segmentation Utilizing Mask U-Net</td><td style="text-align:right">1814</td></tr><tr><td style="text-align:left">Episodic Learning with Control Lyapunov Functions for Uncertain Robotic Systems</td><td style="text-align:right">1943</td></tr><tr><td style="text-align:left">EPN: Edge-Aware PointNet for Object Recognition from Multi-View 2.5D Point Clouds</td><td style="text-align:right">1436</td></tr><tr><td style="text-align:left">Ergodic Flocking</td><td style="text-align:right">1807</td></tr><tr><td style="text-align:left">Escaping Local Minima in Search-Based Planning Using Soft Duplicate Detection</td><td style="text-align:right">1931</td></tr><tr><td style="text-align:left">ESKO6d - a Binocular and RGB-D Dataset of Stored Kitchen Objects with 6d Poses</td><td style="text-align:right">1055</td></tr><tr><td style="text-align:left">Establishing Safer Human-Vehicle Visual Interaction at Night</td><td style="text-align:right">2659</td></tr><tr><td style="text-align:left">Estimating Metric Scale Visual Odometry from Videos Using 3D Convolutional Networks</td><td style="text-align:right">1923</td></tr><tr><td style="text-align:left">Estimating the Center of Mass and the Angular Momentum Derivative for Legged Locomotion ‘ a Recursive Approach</td><td style="text-align:right">2585</td></tr><tr><td style="text-align:left">Evaluating the Acceptability of Assistive Robots for Early Detection of Mild Cognitive Impairment</td><td style="text-align:right">0468</td></tr><tr><td style="text-align:left">Evaluation of a Large-Scale Event-Driven Robot Skin</td><td style="text-align:right">2181</td></tr><tr><td style="text-align:left">Evaluation of Hopping Robot Performance with Novel Foot Pad Design on Natural Terrain for Hopper Development</td><td style="text-align:right">2326</td></tr><tr><td style="text-align:left">Evaluation System for Hydraulic Excavator Operation Skill Using Remote Controlled Excavator and Virtual Reality</td><td style="text-align:right">2465</td></tr><tr><td style="text-align:left">EV-IMO: Motion Segmentation Dataset and Learning Pipeline for Event Cameras</td><td style="text-align:right">1351</td></tr><tr><td style="text-align:left">Executing Underspecified Actions in Real World Based on Online Projection</td><td style="text-align:right">1112</td></tr><tr><td style="text-align:left">Exo Wrist: A Soft Tendon Driven Wrist Wearable Robot with Active Anchor for Dart Throwing Motion in Hemiplegic Patients</td><td style="text-align:right">2482</td></tr><tr><td style="text-align:left">Experience Reuse with Probabilistic Movement Primitives</td><td style="text-align:right">0485</td></tr><tr><td style="text-align:left">Experimental Analysis of the Influence of Olfactory Property on Chemical Plume Tracing Performance</td><td style="text-align:right">2126</td></tr><tr><td style="text-align:left">Experimental Comparison of Open Source Visual-Inertial-Based State Estimation Algorithms in the Underwater Domain</td><td style="text-align:right">0500</td></tr><tr><td style="text-align:left">Experimental Study on Microfluidic Mixing with Trapezoidal Obstacles in a 1000-Fold Span of Reynolds Number</td><td style="text-align:right">0099</td></tr><tr><td style="text-align:left">Experimental Study on the Parameters of High-Pressure Water-Jet Cleaning on a Facade</td><td style="text-align:right">2637</td></tr><tr><td style="text-align:left">Experimental Validation of Hydraulic Interlocking Drive System for Biped Humanoid Robot</td><td style="text-align:right">2460</td></tr><tr><td style="text-align:left">Explainable One-Shot Meta-Learning to Imitate Motion Segments of Unseen Human-Robot Interactions</td><td style="text-align:right">2765</td></tr><tr><td style="text-align:left">Exploiting linearity in dynamics solvers for the design of composable robotic manipulation architectures</td><td style="text-align:right">1717</td></tr><tr><td style="text-align:left">Exploiting Sparse Semantic HD Maps for Self-Driving Vehicle Localization</td><td style="text-align:right">0272</td></tr><tr><td style="text-align:left">Explore, Approach, and Terminate: Evaluating Subtasks in Active Visual Object Search Based on Deep Reinforcement Learning</td><td style="text-align:right">1123</td></tr><tr><td style="text-align:left">Exploring Logical Consistency and Viewport Sensitivity in Compositional VQA Models</td><td style="text-align:right">1250</td></tr><tr><td style="text-align:left">Exploring Low-Level and High-Level Transfer Learning for Multi-Task Facial Recognition with a Semi-Supervised Neural Network</td><td style="text-align:right">0765</td></tr><tr><td style="text-align:left">Extending Monocular Visual Odometry to Stereo Camera Systems by Scale Optimization</td><td style="text-align:right">1173</td></tr><tr><td style="text-align:left">External Force Estimation of Human-Cooperative Robot During Object Manipulation Using Recurrent Neural Network</td><td style="text-align:right">2614</td></tr><tr><td style="text-align:left">Extrinsic Calibration of Thermal IR Camera and mmWave Radar by Exploiting Depth from RGB-D Camera</td><td style="text-align:right">2697</td></tr><tr><td style="text-align:left">FA-Harris: A Fast and Asynchronous Corner Detector for Event Cameras</td><td style="text-align:right">1843</td></tr><tr><td style="text-align:left">Fast Adaptation with Meta-Reinforcement Learning for Trust Modelling in Human-Robot Interaction</td><td style="text-align:right">1576</td></tr><tr><td style="text-align:left">Fast and Incremental Loop Closure Detection Using Proximity Graphs</td><td style="text-align:right">0330</td></tr><tr><td style="text-align:left">Fast and Robust 3-D Sound Source Localization with DSVD-PHAT</td><td style="text-align:right">0271</td></tr><tr><td style="text-align:left">Fast and Safe Policy Adaptation via Alignment-based Transfer</td><td style="text-align:right">0563</td></tr><tr><td style="text-align:left">FASTER: Fast and Safe Trajectory Planner for Flights in Unknown Environments</td><td style="text-align:right">1577</td></tr><tr><td style="text-align:left">Fast Handovers with a Robot Character: Small Sensorimotor Delays Improve Perceived Qualities</td><td style="text-align:right">1613</td></tr><tr><td style="text-align:left">Fast Manipulability Maximization Using Continuous-Time Trajectory Optimization</td><td style="text-align:right">2317</td></tr><tr><td style="text-align:left">Fast Motion Planning via Free C-space Estimation Based on Deep Neural Network</td><td style="text-align:right">0832</td></tr><tr><td style="text-align:left">Fast Perception, Planning, and Execution for a Robotic Butler: Wheeled Humanoid M-Hubo</td><td style="text-align:right">1637</td></tr><tr><td style="text-align:left">Fast Run-Time Monitoring, Replanning, and Recovery for Safe Autonomous System Operations</td><td style="text-align:right">1274</td></tr><tr><td style="text-align:left">Fast Time-Optimal Avoidance of Moving Obstacles for High-Speed MAV Flight</td><td style="text-align:right">0030</td></tr><tr><td style="text-align:left">Fast Trajectory Planning for Multiple Quadrotors Using Relative Safe Flight Corridor</td><td style="text-align:right">1460</td></tr><tr><td style="text-align:left">Fault-Tolerant Force Tracking for a Multi-Legged Robot</td><td style="text-align:right">2672</td></tr><tr><td style="text-align:left">Feasibility of Gait Entrainment to Hip Mechanical Perturbation for Locomotor Rehabilitation</td><td style="text-align:right">0462</td></tr><tr><td style="text-align:left">Feasibility of Wireless Power Transfer for Mobile Robots</td><td style="text-align:right">2655</td></tr><tr><td style="text-align:left">Feasibility Test of Exoskeleton Ankle Robot for Gait Training on Stairs for Sub-Acute Stroke Patients</td><td style="text-align:right">2779</td></tr><tr><td style="text-align:left">Feedback-Based Fabric Strip Folding</td><td style="text-align:right">0932</td></tr><tr><td style="text-align:left">Feedback MPC for Torque-Controlled Legged Robots</td><td style="text-align:right">1021</td></tr><tr><td style="text-align:left">Fiber Optic Fabry-Perot Interferometry for a Biopsy Needle with Tip Force Sensing</td><td style="text-align:right">2710</td></tr><tr><td style="text-align:left">FIESTA: Fast Incremental Euclidean Distance Fields for Online Quadrotor Motion Planning</td><td style="text-align:right">1758</td></tr><tr><td style="text-align:left">Filter Early, Match Late: Improving Network-Based Visual Place Recognition</td><td style="text-align:right">0618</td></tr><tr><td style="text-align:left">First Steps towards Full Model Based Motion Planning and Control of Quadrupeds: A Hybrid Zero Dynamics Approach</td><td style="text-align:right">1761</td></tr><tr><td style="text-align:left">FLAME: Feature-Likelihood Based Mapping and Localization for Autonomous Vehicles</td><td style="text-align:right">0770</td></tr><tr><td style="text-align:left">Flexible Layouts for Fiducial Tags</td><td style="text-align:right">1503</td></tr><tr><td style="text-align:left">Flexible Trinocular: Non-rigid Multi-Camera-IMU Dense Reconstruction for UAV Navigation and Mapping</td><td style="text-align:right">0615</td></tr><tr><td style="text-align:left">Flexure Mechanisms with Variable Stiffness and Damping Using Layer Jamming</td><td style="text-align:right">1292</td></tr><tr><td style="text-align:left">FlightGoggles: Photorealistic Sensor Simulation for Perception-Driven Robotics Using Photogrammetry and Virtual Reality</td><td style="text-align:right">1834</td></tr><tr><td style="text-align:left">Flight Recovery of MAVs with Compromised IMU</td><td style="text-align:right">1352</td></tr><tr><td style="text-align:left">Flower Interaction Subsystem for a Precision Pollination Robot</td><td style="text-align:right">1332</td></tr><tr><td style="text-align:left">Fluid Lubricated Dexterous Finger Mechanism for Human-Like Impact Absorbing Capability</td><td style="text-align:right">2404</td></tr><tr><td style="text-align:left">Flying through a Narrow Gap Using Neural Network: An End-To-End Planning and Control Approach</td><td style="text-align:right">0784</td></tr><tr><td style="text-align:left">Follow the Robot: Modeling Coupled Human-Robot Dyads During Navigation</td><td style="text-align:right">0878</td></tr><tr><td style="text-align:left">Foot with a Core-shell Structural Six-axis Force Sensor for Pedal Depressing and Recovering from Foot Slipping during Pedal Pushing Toward Autonomous Driving by Humanoids</td><td style="text-align:right">0763</td></tr><tr><td style="text-align:left">Force-And-Motion Constrained Planning for Tool Use</td><td style="text-align:right">1619</td></tr><tr><td style="text-align:left">Force Field-Based Indirect Manipulation Of UAV Flight Trajectories</td><td style="text-align:right">1531</td></tr><tr><td style="text-align:left">Force Sensitive Robotic End-Effector Using Embedded Fiber Optics andDeep Learning Characterization for Dexterous Remote Manipulation</td><td style="text-align:right">2179</td></tr><tr><td style="text-align:left">Forecasting Time-To-Collision from Monocular Video: Feasibility, Dataset, and Challenges</td><td style="text-align:right">1358</td></tr><tr><td style="text-align:left">Forest Tree Detection and Segmentation Using High Resolution Airborne LiDAR</td><td style="text-align:right">0536</td></tr><tr><td style="text-align:left">Formation of PVDF Piezoelectric Film on 3D Bellows Surface of Robotic Suction Cup for Providing Force Sensing Ability -Feasibility Study on Two Methods of Dip-Coating and Lamination</td><td style="text-align:right">1347</td></tr><tr><td style="text-align:left">Free-Space Features: Global Localization in 2D Laser SLAM Using Distance Function Maps</td><td style="text-align:right">0438</td></tr><tr><td style="text-align:left">From Pixels to Buildings: End-To-End Probabilistic Deep Networks for Large-Scale Semantic Mapping</td><td style="text-align:right">1737</td></tr><tr><td style="text-align:left">Frustum ConvNet: Sliding Frustums to Aggregate Local Point-Wise Features for Amodal 3D Object Detection</td><td style="text-align:right">0835</td></tr><tr><td style="text-align:left">Fusing Body Posture with Facial Expressions for Joint Recognition of Affect in Child-Robot Interaction</td><td style="text-align:right">2449</td></tr><tr><td style="text-align:left">Fusing Lidar Data and Aerial Imagery with Perspective Correction for Precise Localization in Urban Canyons</td><td style="text-align:right">1311</td></tr><tr><td style="text-align:left">Fusion of Passive Ferromagnetic Sensors with the Navigational Data for the Improvement of the Detection of Underwater Metal-Containing Objects</td><td style="text-align:right">0918</td></tr><tr><td style="text-align:left">GAPLE: Generalizable Approaching Policy LEarning for Robotic Object Searching in Indoor Environment</td><td style="text-align:right">2275</td></tr><tr><td style="text-align:left">Gaussian Mixture Model (GMM) Based Object Detection and Tracking Using Dynamic Patch Estimation</td><td style="text-align:right">1013</td></tr><tr><td style="text-align:left">Gaze-Based Intention Anticipation Over Driving Manoeuvres in Semi-Autonomous Vehicles</td><td style="text-align:right">1667</td></tr><tr><td style="text-align:left">Gaze Training by Modulated Dropout Improves Imitation Learning</td><td style="text-align:right">0474</td></tr><tr><td style="text-align:left">General Hand Guidance Framework Using Microsoft HoloLens</td><td style="text-align:right">0814</td></tr><tr><td style="text-align:left">Generalized Contact Constraints of Hybrid Trajectory Optimization for Different Terrains and Analysis of Sensitivity to Randomized Initial Guesses</td><td style="text-align:right">1704</td></tr><tr><td style="text-align:left">Generalized Multiple Correlation Coefficient As a Similarity Measurement between Trajectories</td><td style="text-align:right">1020</td></tr><tr><td style="text-align:left">Generalized Ray-Based Lattice Generation and Graph Representation of Wrench-Closure Workspace for Arbitrary Cable-Driven Robots</td><td style="text-align:right">2589</td></tr><tr><td style="text-align:left">Generate What You Can’t See - a View-Dependent Image Generation</td><td style="text-align:right">1170</td></tr><tr><td style="text-align:left">Generating a Key Pose Sequence Based on Kinematics and Statics Optimization for Manipulating a Heavy Object by a Humanoid Robot</td><td style="text-align:right">1048</td></tr><tr><td style="text-align:left">Generating an Image of an Object’s Appearance from Somatosensory Information During Haptic Exploration</td><td style="text-align:right">1339</td></tr><tr><td style="text-align:left">Generating Coordinated Reach-Grasp Motions with Neural Networks</td><td style="text-align:right">2794</td></tr><tr><td style="text-align:left">Generating Grasp Poses for a High-DOF Gripper Using Neural Networks</td><td style="text-align:right">0196</td></tr><tr><td style="text-align:left">Geometric and Physical Constraints for Drone-Based Head Plane Crowd Density Estimation</td><td style="text-align:right">0262</td></tr><tr><td style="text-align:left">Geo-Referenced Semantic Point Cloud Map Using the USyd Campus Dataset</td><td style="text-align:right">2690</td></tr><tr><td style="text-align:left">GlassLoc: Plenoptic Grasp Pose Detection in Transparent Clutter</td><td style="text-align:right">1636</td></tr><tr><td style="text-align:left">GLFP: Global Localization from a Floor Plan</td><td style="text-align:right">0727</td></tr><tr><td style="text-align:left">Global Vision-Based Impedance Control for Robotic Wall Polishing</td><td style="text-align:right">0558</td></tr><tr><td style="text-align:left">Goal-Directed Behavior under Variational Predictive Coding: Dynamic Organization of Visual Attention and Working Memory</td><td style="text-align:right">0133</td></tr><tr><td style="text-align:left">GPU Accelerated Robust Scene Reconstruction</td><td style="text-align:right">0279</td></tr><tr><td style="text-align:left">GQ-STN: Optimizing One-Shot Grasp Detection Based on Robustness Classifier</td><td style="text-align:right">1065</td></tr><tr><td style="text-align:left">Graph-Based Design of Hierarchical Reinforcement Learning Agents</td><td style="text-align:right">1226</td></tr><tr><td style="text-align:left">Graph-Based Path Planning for Autonomous Robotic Exploration in Subterranean Environments</td><td style="text-align:right">1749</td></tr><tr><td style="text-align:left">Graph Element Networks: A Flexible Model for Robotic Applications</td><td style="text-align:right">2726</td></tr><tr><td style="text-align:left">Grasping Unknown Objects Based on Gripper Workspace Spheres</td><td style="text-align:right">1656</td></tr><tr><td style="text-align:left">GRIP: Generative Robust Inference and Perception for Semantic Robot Manipulation in Adversarial Environments</td><td style="text-align:right">1598</td></tr><tr><td style="text-align:left">Grounding Language Attributes to Objects Using Bayesian Eigenobjects</td><td style="text-align:right">1368</td></tr><tr><td style="text-align:left">Guinea Fowl Jumping Robot with Balance Control Mechanism: Modeling, Simulation, and Experiment Results</td><td style="text-align:right">0309</td></tr><tr><td style="text-align:left">Hand-eye calibration with a remote centre of motion</td><td style="text-align:right">2216</td></tr><tr><td style="text-align:left">Hand Movement Intention Recognition Based on EMG Intensity Map and Convolutional Neural Networks</td><td style="text-align:right">2728</td></tr><tr><td style="text-align:left">Handover Process of Autonomous Driver Assist Systems - a Call for Critical Performance Assessment</td><td style="text-align:right">2693</td></tr><tr><td style="text-align:left">Haptic Guidance for Robot-Assisted Endovascular Procedures: Implementation and Evaluation on Surgical Simulator</td><td style="text-align:right">0495</td></tr><tr><td style="text-align:left">Haptic-Guided Shared Control for Needle Grasping Optimization in Minimally Invasive Robotic Surgery</td><td style="text-align:right">1234</td></tr><tr><td style="text-align:left">Haptic Perception of Liquids Enclosed in Containers</td><td style="text-align:right">1169</td></tr><tr><td style="text-align:left">Haptic Shared-Control Methods for Robotic Cutting under Nonholonomic Constraints</td><td style="text-align:right">2480</td></tr><tr><td style="text-align:left">HaptiCube: A Compact 5-DoF Finger-Wearable Tactile Interface</td><td style="text-align:right">0603</td></tr><tr><td style="text-align:left">Harmonious Sampling for Mobile Manipulation Planning</td><td style="text-align:right">1306</td></tr><tr><td style="text-align:left">Heuristic-Based Multiple Mobile Depots Route Planning for Recharging Persistent Surveillance Robots</td><td style="text-align:right">1402</td></tr><tr><td style="text-align:left">Hierarchical Reinforcement Learning for Concurrent Discovery of Compound and Composable Policies</td><td style="text-align:right">0988</td></tr><tr><td style="text-align:left">Hierarchical Reinforcement Learning for Quadruped Locomotion</td><td style="text-align:right">1783</td></tr><tr><td style="text-align:left">Hierarchical Segmentation of Continuous Motions through sEMG Signal Analysis</td><td style="text-align:right">2525</td></tr><tr><td style="text-align:left">High-Dimensional Motion Segmentation by Variational Autoencoder and Gaussian Processes</td><td style="text-align:right">0297</td></tr><tr><td style="text-align:left">High-Fidelity Dexterous Tactile Telerobot for Intuitive Teleoperation</td><td style="text-align:right">2727</td></tr><tr><td style="text-align:left">High-Speed Humanoid Robot Arm for Badminton Using Pneumatic-Electric Hybrid Actuators</td><td style="text-align:right">2311</td></tr><tr><td style="text-align:left">High-Speed On-Chip Mixing by Micro-Vortex Generated by Controlling Local Jet Flow Using Dual Membrane Pumps</td><td style="text-align:right">2104</td></tr><tr><td style="text-align:left">High-Speed Sliding Locomotion Generation on Slippery Surface of an Indirectly Controlled Robot With Viscoelastic Body</td><td style="text-align:right">2251</td></tr><tr><td style="text-align:left">Homography-Based Deep Visual Servoing Methods for Planar Grasps</td><td style="text-align:right">1691</td></tr><tr><td style="text-align:left">Hong Hu - an Efficient and Versatile Tail-Sitter VTOL UAV Platform: Design, Implementation and Control</td><td style="text-align:right">2678</td></tr><tr><td style="text-align:left">HouseExpo: A Large-Scale 2D Indoor Layout Dataset for Learning-Based Algorithms</td><td style="text-align:right">2719</td></tr><tr><td style="text-align:left">Hovering Control of a TTURT with Thrust Vector Decomposition Technique</td><td style="text-align:right">2640</td></tr><tr><td style="text-align:left">How Can Robot’s Gaze Ratio and Gaze Type Show an Awareness of Power Dynamics to the People with Whom It Is Interacting?</td><td style="text-align:right">2506</td></tr><tr><td style="text-align:left">HTetran ‘ a Polyabolo Inspired Self Reconfigurable Tiling Robot</td><td style="text-align:right">1790</td></tr><tr><td style="text-align:left">Human Intention Inference and On-Line Human Hand Motion Prediction for Human-Robot Collaboration</td><td style="text-align:right">1604</td></tr><tr><td style="text-align:left">Human Interactive Motion Planning for Shared Teleoperation</td><td style="text-align:right">2703</td></tr><tr><td style="text-align:left">Humanoid Robot’s Force-Based Heavy Manipulation Tasks with Torque-Controlled Arms and Wrist Force Sensors</td><td style="text-align:right">0776</td></tr><tr><td style="text-align:left">Humanoid Robot Next Best View Planning under Occlusions Using Body Movement Primitives</td><td style="text-align:right">2250</td></tr><tr><td style="text-align:left">Human Robot Visual Interface for 3D Steering of a Flexible, Bio-Inspired Needle for Brain Surgery</td><td style="text-align:right">0392</td></tr><tr><td style="text-align:left">Hybrid Visual Servoing for Autonomous Robotic Laser Tattoo Removal</td><td style="text-align:right">1208</td></tr><tr><td style="text-align:left">Hysteresis Compensator with Learning-Based Pose Estimation for a Flexible Endoscopic Surgery Robot</td><td style="text-align:right">0934</td></tr><tr><td style="text-align:left">‘Why Don’t You Have a Wife?!’ Free Format Dialogue in CRI*</td><td style="text-align:right">2753</td></tr><tr><td style="text-align:left">Identification of Rat Ultrasonic Vocalizations from Mix Sounds of a Robotic Rat in Non-Silent Environments</td><td style="text-align:right">0746</td></tr><tr><td style="text-align:left">Identification of Time-Varying and Time-Scalable Synergies from Continuous Electromyographic Patterns</td><td style="text-align:right">2237</td></tr><tr><td style="text-align:left">Identifying Opportunities for Relationship-Focused Robotic Interventions in Strained Hierarchical Relationships</td><td style="text-align:right">0139</td></tr><tr><td style="text-align:left">Ignorance Is Not Bliss: An Analysis of Central-Place Foraging Algorithms</td><td style="text-align:right">1591</td></tr><tr><td style="text-align:left">Implementation of a Natural Dynamic Controller on an Under-Actuated Compass-Biped Robot</td><td style="text-align:right">1259</td></tr><tr><td style="text-align:left">Implementing Regularized Predictive Control for Simultaneous Real-Time Footstep and Ground Reaction Force Optimization</td><td style="text-align:right">0946</td></tr><tr><td style="text-align:left">Improved Energy Efficiency Via Parallel Elastic Elements for theStraight-Legged Vertically-Compliant Robot SLIDER</td><td style="text-align:right">2734</td></tr><tr><td style="text-align:left">Improved Exploration through Latent Trajectory Optimization in Deep Deterministic Policy Gradient</td><td style="text-align:right">1584</td></tr><tr><td style="text-align:left">Improved Learning Accuracy for Learning Stable Control from Human Demonstrations</td><td style="text-align:right">0589</td></tr><tr><td style="text-align:left">Improved Mechanical Design and Simplified Motion Planning of Hybrid Active and Passive Cable-Driven Segmented Manipulator with Coupled Motion</td><td style="text-align:right">0760</td></tr><tr><td style="text-align:left">Improved Planetary Rover Inertial Navigation and Wheel Odometry Performance through Periodic Use of Zero-Type Constraints</td><td style="text-align:right">0886</td></tr><tr><td style="text-align:left">Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation</td><td style="text-align:right">1574</td></tr><tr><td style="text-align:left">Improving Learning-Based Ego-Motion Estimation with Homomorphism-Based Losses and Drift Correction</td><td style="text-align:right">1310</td></tr><tr><td style="text-align:left">Improving Local Trajectory Optimization by Probabilistic Movement Primitives</td><td style="text-align:right">1128</td></tr><tr><td style="text-align:left">Improving Robot Success Detection Using Static Object Data</td><td style="text-align:right">0143</td></tr><tr><td style="text-align:left">Improving Task-Parameterised Movement Learning Generalisation with Frame-Weighted Trajectory Generation</td><td style="text-align:right">1448</td></tr><tr><td style="text-align:left">IMU-Based Spectrogram Approach with Deep Convolutional Neural Networks for Gait Classification</td><td style="text-align:right">2775</td></tr><tr><td style="text-align:left">Inchworm-Inspired Soft Climbing Robot Using Microspine Arrays</td><td style="text-align:right">0327</td></tr><tr><td style="text-align:left">Inertial-Based Motion Capturing and Smart Training System</td><td style="text-align:right">0587</td></tr><tr><td style="text-align:left">Inference of User-Intention in Remote Robot Wheelchair Assistance Using Multimodal Interfaces</td><td style="text-align:right">1710</td></tr><tr><td style="text-align:left">INFER: INtermediate representations for FuturE pRediction</td><td style="text-align:right">1417</td></tr><tr><td style="text-align:left">Inferring Distributions Over Depth from a Single Image</td><td style="text-align:right">0118</td></tr><tr><td style="text-align:left">Influence of Parameters Uncertainties on the Positioning of Cable-Driven Parallel Robots</td><td style="text-align:right">1005</td></tr><tr><td style="text-align:left">Information Filter Occupancy Mapping Using Decomposable Radial Kernels</td><td style="text-align:right">0695</td></tr><tr><td style="text-align:left">Information-Guided Robotic Maximum Seek-And-Sample in Partially Observable Continuous Environments</td><td style="text-align:right">2385</td></tr><tr><td style="text-align:left">Informed Region Selection for Efficient UAV-Based Object Detectors: Altitude-Aware Vehicle Detection with CyCAR Dataset</td><td style="text-align:right">1463</td></tr><tr><td style="text-align:left">Infrastructure-Free NLoS Obstacle Detection for Autonomous Cars</td><td style="text-align:right">0031</td></tr><tr><td style="text-align:left">Integer Programming As a General Solution Methodology for Path-Based Optimization in Robotics: Principles, Best Practices, and Applications</td><td style="text-align:right">0849</td></tr><tr><td style="text-align:left">Intention-Driven Shoulder Rehabilitation for Targeted Neuro-Muscular Training Using an Exo-Musculoskeletal Robot</td><td style="text-align:right">2777</td></tr><tr><td style="text-align:left">Interaction-Aware Decision Making with Adaptive Strategies under Merging Scenarios</td><td style="text-align:right">1650</td></tr><tr><td style="text-align:left">Interactions with an Empathetic Agent: Regulating Emotions and Improving Engagement in Autism</td><td style="text-align:right">2606</td></tr><tr><td style="text-align:left">Interaction Templates for Multi-Robot Systems</td><td style="text-align:right">2292</td></tr><tr><td style="text-align:left">Interactive Trajectory Adaptation through Force-Guided Bayesian Optimization</td><td style="text-align:right">0811</td></tr><tr><td style="text-align:left">Introducing a Scalable and Modular Control Framework for Low-Cost Monocular Robots in Hazardous Environments</td><td style="text-align:right">0983</td></tr><tr><td style="text-align:left">Intuitive Control of a Robotic Arm and Hand System with Pneumatic Haptic Feedback</td><td style="text-align:right">2587</td></tr><tr><td style="text-align:left">Inverse Dynamics Modeling of Robotic Manipulator with Hierarchical Recurrent Network</td><td style="text-align:right">1999</td></tr><tr><td style="text-align:left">Inverse Kinematics and Sensitivity Minimization of an N-Stack Stewart Platform</td><td style="text-align:right">1063</td></tr><tr><td style="text-align:left">Inverse Optimal Planning for Air Traffic Control</td><td style="text-align:right">1258</td></tr><tr><td style="text-align:left">IRonCub: Towards Aerial Humanoid Robotics</td><td style="text-align:right">2733</td></tr><tr><td style="text-align:left">Iterative Learning Control for Fast and Accurate Position Tracking with an Articulated Soft Robotic Arm</td><td style="text-align:right">0235</td></tr><tr><td style="text-align:left">IVOA: Introspective Vision for Obstacle Avoidance</td><td style="text-align:right">1560</td></tr><tr><td style="text-align:left">JISAP: Joint Inference for Surgeon Attributes Prediction During Robot-Assisted Surgery</td><td style="text-align:right">0540</td></tr><tr><td style="text-align:left">Jointly Learnable Behavior and Trajectory Planning for Self-Driving Vehicles</td><td style="text-align:right">1301</td></tr><tr><td style="text-align:left">Joint Offset Optimization of Hip Joints in Humanoid Robots</td><td style="text-align:right">2701</td></tr><tr><td style="text-align:left">Joint Torque Estimation Toward Dynamic and Compliant Control for Gear-Driven Torque Sensorless Quadruped Robot</td><td style="text-align:right">0201</td></tr><tr><td style="text-align:left">Joint Velocity and Acceleration Estimation in Serial Chain Rigid Body and Flexible Joint Manipulators</td><td style="text-align:right">1959</td></tr><tr><td style="text-align:left">Kinematically Redundant Hybrid Robots with Simple Singularity Conditions and Analytical Inverse Kinematic Solutions</td><td style="text-align:right">2402</td></tr><tr><td style="text-align:left">Kinematic Modeling of a Soft Pneumatic Actuator Using Cubic Hermite Splines</td><td style="text-align:right">0717</td></tr><tr><td style="text-align:left">Kinematics, Design and Experimental Validation of a Novel Parallel Robot for Two-Fingered Dexterous Manipulation</td><td style="text-align:right">0900</td></tr><tr><td style="text-align:left">Kinematic Synthesis of a Serial Robotic Manipulator by Using Generalized Differential Inverse Kinematics</td><td style="text-align:right">2579</td></tr><tr><td style="text-align:left">Lambda-Field: A Continuous Counterpart of the Bayesian Occupancy Grid for Risk Assessment</td><td style="text-align:right">0423</td></tr><tr><td style="text-align:left">Laminated Foam-Based Soft Actuator for Actuatable Flexible Structure</td><td style="text-align:right">0089</td></tr><tr><td style="text-align:left">Landing of a Multirotor Aerial Vehicle on an Uneven Surface Using Multiple On-Board Manipulators</td><td style="text-align:right">0804</td></tr><tr><td style="text-align:left">Lane Marking Learning Based on Crowdsourced Data</td><td style="text-align:right">1148</td></tr><tr><td style="text-align:left">Large-Scale 6D Object Pose Estimation Dataset for Industrial Bin-Picking</td><td style="text-align:right">0857</td></tr><tr><td style="text-align:left">Lazy Compilation of Variants of Multi-Robot Path Planning with Satisfiability Modulo Theory (SMT) Approach</td><td style="text-align:right">1422</td></tr><tr><td style="text-align:left">LDLS: 3-D Object Segmentation through Label Diffusion from 2-D Images</td><td style="text-align:right">2164</td></tr><tr><td style="text-align:left">Learning 2D to 3D Lifting for Object Detection in 3D for Autonomous Vehicles</td><td style="text-align:right">1917</td></tr><tr><td style="text-align:left">Learning Actions from Human Demonstration Video for Robotic Manipulation</td><td style="text-align:right">0994</td></tr><tr><td style="text-align:left">Learning Barrier Functions for Constrained Motion Planning with Dynamical Systems</td><td style="text-align:right">2374</td></tr><tr><td style="text-align:left">Learning-Based Model Predictive Control for Autonomous Racing</td><td style="text-align:right">2310</td></tr><tr><td style="text-align:left">Learning-Based Nonlinear Model Predictive Control of Reconfigurable Autonomous Robotic Boats: Roboats</td><td style="text-align:right">0476</td></tr><tr><td style="text-align:left">Learning Based Robotic Bin-Picking for Potentially Tangled Objects</td><td style="text-align:right">2408</td></tr><tr><td style="text-align:left">Learning by Demonstration and Robust Control of Dexterous In-Hand Robotic Manipulation Skills</td><td style="text-align:right">1966</td></tr><tr><td style="text-align:left">Learning Continuous Time Control Policies by Minimizing the Hamilton-Jacobi-Bellman Residual</td><td style="text-align:right">2685</td></tr><tr><td style="text-align:left">Learning Event-Based Height from Plane and Parallax</td><td style="text-align:right">1144</td></tr><tr><td style="text-align:left">Learning Footstep Planning on Irregular Surfaces with Partial Placements</td><td style="text-align:right">0597</td></tr><tr><td style="text-align:left">Learning from Demonstration Based on a Mechanism to Utilize an Object’s Invisibility</td><td style="text-align:right">2516</td></tr><tr><td style="text-align:left">Learning Generalisable Coupling Terms for Obstacle Avoidance Via Low-Dimensional Geometric Descriptors</td><td style="text-align:right">2418</td></tr><tr><td style="text-align:left">Learning Generative Socially-Aware Models of Pedestrian Motion</td><td style="text-align:right">2395</td></tr><tr><td style="text-align:left">Learning Grasp Affordance Reasoning through Semantic Relations</td><td style="text-align:right">2527</td></tr><tr><td style="text-align:left">Learning Intention Aware Online Adaptation of Movement Primitives</td><td style="text-align:right">2468</td></tr><tr><td style="text-align:left">Learning Interactive Behaviors for Musculoskeletal Robots Using Bayesian Interaction Primitives</td><td style="text-align:right">0481</td></tr><tr><td style="text-align:left">Learning Local Feature Descriptor with Motion Attribute for Vision-based Localization</td><td style="text-align:right">0823</td></tr><tr><td style="text-align:left">Learning Multimodal Representations for Sample-Efficient Recognition of Human Actions</td><td style="text-align:right">0975</td></tr><tr><td style="text-align:left">Learning Multiple Sensorimotor Units to Complete Compound Tasks Using an RNN with Multiple Attractors</td><td style="text-align:right">2092</td></tr><tr><td style="text-align:left">Learning Object Models for Non-Prehensile Manipulation</td><td style="text-align:right">1178</td></tr><tr><td style="text-align:left">Learning Physics-Based Manipulation in Clutter: Combining Image-Based Generalization and Look-Ahead Planning</td><td style="text-align:right">1536</td></tr><tr><td style="text-align:left">Learning Q-Network for Active Information Acquisition</td><td style="text-align:right">1810</td></tr><tr><td style="text-align:left">Learning Real-Time Closed Loop Robotic Reaching from Monocular Vision by Exploiting a Control Lyapunov Function Structure</td><td style="text-align:right">0583</td></tr><tr><td style="text-align:left">Learning Real-World Robot Policies by Dreaming</td><td style="text-align:right">1155</td></tr><tr><td style="text-align:left">Learning Residual Flow as Dynamic Motion from Stereo Videos</td><td style="text-align:right">1898</td></tr><tr><td style="text-align:left">Learning Safe Unlabeled Multi-Robot Planning with Motion Constraints</td><td style="text-align:right">2531</td></tr><tr><td style="text-align:left">Learning Singularity Avoidance</td><td style="text-align:right">1516</td></tr><tr><td style="text-align:left">Learning State-Dependent Sensor Measurement Models for Localization</td><td style="text-align:right">1870</td></tr><tr><td style="text-align:left">Learning the Scope of Applicability for Task Planning Knowledge in Experience-Based Planning Domains</td><td style="text-align:right">0230</td></tr><tr><td style="text-align:left">Learning to Augment Synthetic Images for Sim2Real Policy Transfer</td><td style="text-align:right">0729</td></tr><tr><td style="text-align:left">Learning to Estimate Centers of Mass of Arbitrary Objects</td><td style="text-align:right">1592</td></tr><tr><td style="text-align:left">Learning to Estimate Pose and Shape of Hand-Held Objects from RGB Images</td><td style="text-align:right">0937</td></tr><tr><td style="text-align:left">Learning to Explore in Motion and Interaction Tasks</td><td style="text-align:right">1281</td></tr><tr><td style="text-align:left">Learning to Generate Unambiguous Spatial Referring Expressions for Real-World Environments</td><td style="text-align:right">1082</td></tr><tr><td style="text-align:left">Learning to Grasp Arbitrary Household Objects from a Single Demonstration</td><td style="text-align:right">1051</td></tr><tr><td style="text-align:left">Learning Topometric Semantic Maps from Occupancy Grids</td><td style="text-align:right">1776</td></tr><tr><td style="text-align:left">Learning to Sequence Multiple Tasks with Competing Constraints</td><td style="text-align:right">1238</td></tr><tr><td style="text-align:left">Learning Via-Point Movement Primitives with Inter and Extrapolation Capabilities</td><td style="text-align:right">1076</td></tr><tr><td style="text-align:left">Learning Virtual Borders through Semantic Scene Understanding and Augmented Reality</td><td style="text-align:right">0253</td></tr><tr><td style="text-align:left">Learning Virtual Grasp with Failed Demonstrations via Bayesian Inverse Reinforcement Learning</td><td style="text-align:right">0490</td></tr><tr><td style="text-align:left">Learn to Adapt to Human Walking: A Model-Based Reinforcement Learning Approach for a Robotic Assistant Rollator</td><td style="text-align:right">2489</td></tr><tr><td style="text-align:left">LEGO: Leveraging Experience in Roadmap Generation for Sampling-Based Planning</td><td style="text-align:right">1481</td></tr><tr><td style="text-align:left">LIC-Fusion: LiDAR-Inertial-Camera Odometry</td><td style="text-align:right">2005</td></tr><tr><td style="text-align:left">LiDAR Based Navigable Region Detection for Unmanned Surface Vehicles</td><td style="text-align:right">0582</td></tr><tr><td style="text-align:left">LiDAR-Flow: Dense Scene Flow Estimation from Sparse LiDAR and Stereo Images</td><td style="text-align:right">0972</td></tr><tr><td style="text-align:left">Lifelong Federated Reinforcement Learning: A Learning Architecture for Navigation in Cloud Robotic Systems</td><td style="text-align:right">2090</td></tr><tr><td style="text-align:left">Line-Based Absolute and Relative Camera Pose Estimation in Structured Environments</td><td style="text-align:right">0898</td></tr><tr><td style="text-align:left">Loam_livox: A Robust LiDAR Odemetry and Mapping (LOAM) Package for Livox LiDAR</td><td style="text-align:right">2663</td></tr><tr><td style="text-align:left">Localization and Mapping Using Instance-Specific Mesh Models</td><td style="text-align:right">0572</td></tr><tr><td style="text-align:left">Local Online Motor Babbling: Learning Motor Abundance of a Musculoskeletal Robot Arm</td><td style="text-align:right">0351</td></tr><tr><td style="text-align:left">Local Pose Optimization with an Attention-Based Neural Network</td><td style="text-align:right">1439</td></tr><tr><td style="text-align:left">Locomotion Planning of a Variable Geometry Robot Based on Polygon-Shaped Ground Contacts</td><td style="text-align:right">2639</td></tr><tr><td style="text-align:left">Long Range Neural Navigation Policies for the Real World</td><td style="text-align:right">2264</td></tr><tr><td style="text-align:left">Long-Term Community Social Robots to Promote Social Connectedness among Older Adults</td><td style="text-align:right">2580</td></tr><tr><td style="text-align:left">Long-Term Prediction of Motion Trajectories Using Path Homology Clusters</td><td style="text-align:right">0667</td></tr><tr><td style="text-align:left">Long-Term Visual Inertial SLAM Based on Time Series Map Prediction</td><td style="text-align:right">0893</td></tr><tr><td style="text-align:left">Long-Time Self-Body Image Acquisition and Its Application to the Control of Musculoskeletal Structures</td><td style="text-align:right">2344</td></tr><tr><td style="text-align:left">Look Further to Recognize Better: Learning Shared Topics and Category-Specific Dictionaries for Open-Ended 3D Object Recognition</td><td style="text-align:right">0127</td></tr><tr><td style="text-align:left">Low-Cost Sonar Navigation System</td><td style="text-align:right">1459</td></tr><tr><td style="text-align:left">Low Level Control of a Quadrotor with Deep Model-Based Reinforcement Learning</td><td style="text-align:right">2530</td></tr><tr><td style="text-align:left">LSwarm: Efficient Collision Avoidance for Large Swarms with Coverage Constraints in Complex Urban Scenes</td><td style="text-align:right">2370</td></tr><tr><td style="text-align:left">Macro-Micro Multi-Arm Robot for Single-Port Access Surgery</td><td style="text-align:right">2456</td></tr><tr><td style="text-align:left">Magnetic-Needle-Assisted Micromanipulation of Dynamically Self-Assembled Magnetic Droplets for Cargo Transportation</td><td style="text-align:right">2205</td></tr><tr><td style="text-align:left">Magnetic Needle Steering Model Identification Using Expectation-Maximization</td><td style="text-align:right">1099</td></tr><tr><td style="text-align:left">Magnetic Sensor Based Probe for Microrobot Detection and Localization</td><td style="text-align:right">2784</td></tr><tr><td style="text-align:left">Making Sense of Audio Vibration for Liquid Height Estimation in Robotic Pouring</td><td style="text-align:right">1118</td></tr><tr><td style="text-align:left">Manipulation Motion Taxonomy and Coding for Robots</td><td style="text-align:right">1733</td></tr><tr><td style="text-align:left">Manipulation Planning with Soft Orientation Constraints Based on Composite Configuration Space</td><td style="text-align:right">2788</td></tr><tr><td style="text-align:left">Manipulation Purpose Underwater Agent Vehicle for Ghost Net Recovery Mission</td><td style="text-align:right">1625</td></tr><tr><td style="text-align:left">Map-Aware SLAM with Sparse Map Features</td><td style="text-align:right">0178</td></tr><tr><td style="text-align:left">Map Based Human Motion Prediction for People Tracking</td><td style="text-align:right">0167</td></tr><tr><td style="text-align:left">Mapping for Planetary Rovers from Terramechanics Perspective</td><td style="text-align:right">1168</td></tr><tr><td style="text-align:left">Mathematic Modeling and Optimal Design of a Magneto-Rheological Clutch for the Compliant Actuator in Physical Robot Interactions</td><td style="text-align:right">2478</td></tr><tr><td style="text-align:left">MAVNet: An Effective Semantic Segmentation Micro-Network for MAV-Based Tasks</td><td style="text-align:right">2330</td></tr><tr><td style="text-align:left">Maximum Information Bounds for Planning Active Sensing Trajectories</td><td style="text-align:right">1273</td></tr><tr><td style="text-align:left">Maximum Likelihood Path Planning for Fast Aerial Maneuvers and Collision Avoidance</td><td style="text-align:right">0106</td></tr><tr><td style="text-align:left">Measuring Engagement Elicited by Eye Contact in Human-Robot Interaction</td><td style="text-align:right">0949</td></tr><tr><td style="text-align:left">Meta-Learning for Multi-Objective Reinforcement Learning</td><td style="text-align:right">0929</td></tr><tr><td style="text-align:left">Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning</td><td style="text-align:right">2686</td></tr><tr><td style="text-align:left">Metric Monocular Localization Using Signed Distance Fields</td><td style="text-align:right">0840</td></tr><tr><td style="text-align:left">Miniaturization of MR Safe Pneumatic Rotational Stepper Motors</td><td style="text-align:right">0892</td></tr><tr><td style="text-align:left">Minimal Sensor Setup in Lower Limb Exoskeletons for Motion Classification Based on Multi-Modal Sensor Data</td><td style="text-align:right">0722</td></tr><tr><td style="text-align:left">Minimum $k$-Connectivity Maintenance for Robust Multi-Robot Systems</td><td style="text-align:right">1935</td></tr><tr><td style="text-align:left">Misalignment Recognition Using Markov Random Fields with Fully Connected Latent Variables for Detecting Localization Failures</td><td style="text-align:right">2263</td></tr><tr><td style="text-align:left">Mixed Reality Control of the Humanoid Robot Eve</td><td style="text-align:right">2735</td></tr><tr><td style="text-align:left">Mobile Robot Learning from Human Demonstrations with Nonlinear Model Predictive Control</td><td style="text-align:right">1451</td></tr><tr><td style="text-align:left">Mobile Robot Localization with Reinforcement Learning Map Update Decision Aided by an Absolute Indoor Positioning System</td><td style="text-align:right">1223</td></tr><tr><td style="text-align:left">Model Free Calibration of Wheeled Robots Using Gaussian Process</td><td style="text-align:right">1795</td></tr><tr><td style="text-align:left">Modeling and Force Control of a Terramechanical Wheel-Soil Contact for a Robotic Manipulator Used in the Planetary Rover Design Process</td><td style="text-align:right">0754</td></tr><tr><td style="text-align:left">Modeling and Identification for the Design of a Rotary Soft Actuator Based on Wren Mechanism</td><td style="text-align:right">0652</td></tr><tr><td style="text-align:left">Modeling, Learning and Prediction of Longitudinal Behaviors of Human-Driven Vehicles by Incorporating Internal Human Decision-Making Process Using Inverse Model Predictive Control</td><td style="text-align:right">1284</td></tr><tr><td style="text-align:left">Modeling Novel Soft Mechanosensors based on Air-Flow Measurements</td><td style="text-align:right">2568</td></tr><tr><td style="text-align:left">Modeling, Simulation and Experimental Validation of Tendon-Driven Soft-Arm Robot Configuration - a Continuum Mechanics Approach</td><td style="text-align:right">1091</td></tr><tr><td style="text-align:left">Model-Less Active Compliance for Continuum Robots Using Recurrent Neural Networks</td><td style="text-align:right">2319</td></tr><tr><td style="text-align:left">Modelling and Dynamic Tracking Control of Industrial Vehicles with Tractor-trailer Structure</td><td style="text-align:right">1947</td></tr><tr><td style="text-align:left">Modelling of Uniaxial EGaIn-Based Strain Sensors for Proprioceptive Sensing of Soft Robots</td><td style="text-align:right">1933</td></tr><tr><td style="text-align:left">Model Predictive Contouring Control for Collision Avoidance in Unstructured Dynamic Environments</td><td style="text-align:right">2387</td></tr><tr><td style="text-align:left">Model Predictive Control Based Dynamic Path Tracking of a Four-Wheel Steering Mobile Robot</td><td style="text-align:right">1060</td></tr><tr><td style="text-align:left">Model Simplification for Dynamic Control of Series-Parallel Hybrid Robots - a Representative Study on the Effects of Neglected Dynamics</td><td style="text-align:right">1049</td></tr><tr><td style="text-align:left">Modular Volumetric Actuators Using Motorized Auxetics</td><td style="text-align:right">1643</td></tr><tr><td style="text-align:left">Monocular Depth Estimation in New Environments with Absolute Scale</td><td style="text-align:right">0759</td></tr><tr><td style="text-align:left">Monocular Object and Plane SLAM in Structured Environments</td><td style="text-align:right">2277</td></tr><tr><td style="text-align:left">Monocular Outdoor Semantic Mapping with a Multi-Task Network</td><td style="text-align:right">0174</td></tr><tr><td style="text-align:left">Monocular Plan View Networks for Autonomous Driving</td><td style="text-align:right">1829</td></tr><tr><td style="text-align:left">Morphing Structure for Changing Hydrodynamic Characteristics of a Soft Underwater Walking Robot</td><td style="text-align:right">2540</td></tr><tr><td style="text-align:left">Motion Decoupling and Composition Via Reduced Order Model Optimization for Dynamic Humanoid Walking with CLF-QP Based Active Force Control</td><td style="text-align:right">0625</td></tr><tr><td style="text-align:left">Motion Direction Decoding of Upper Limb from EEG Signals with a Cognitive Distraction Task</td><td style="text-align:right">2675</td></tr><tr><td style="text-align:left">Motion Planning for a Continuum Robotic Mobile Lamp: Defining and Navigating the Configuration Space</td><td style="text-align:right">1370</td></tr><tr><td style="text-align:left">Motor-Propeller Matching of Aerial Propulsion Systems for Direct Aerial-Aquatic Operation</td><td style="text-align:right">0416</td></tr><tr><td style="text-align:left">Moving Onto High Steps for a Four-Limbed Robot with Torso Contact</td><td style="text-align:right">1965</td></tr><tr><td style="text-align:left">MPERL : Hardware and Software Co-Design for Robotic Manipulators</td><td style="text-align:right">1211</td></tr><tr><td style="text-align:left">MRLift: A Semi-Active Lower Back Support Exoskeleton Based on MR Fluid and Force Retention Technology</td><td style="text-align:right">1388</td></tr><tr><td style="text-align:left">MT-RRT: A General Purpose Multithreading Library for Path Planning</td><td style="text-align:right">0806</td></tr><tr><td style="text-align:left">Multi-Agent Image Classification Via Reinforcement Learning</td><td style="text-align:right">2003</td></tr><tr><td style="text-align:left">Multicamera 3D Reconstruction of Dynamic Surgical Cavities: Non-Rigid Registration and Point Classiﬁcation</td><td style="text-align:right">0585</td></tr><tr><td style="text-align:left">Multi-Contact Stabilization of a Humanoid Robot for Realizing Dynamic Contact Transitions on Non-Coplanar Surfaces</td><td style="text-align:right">1098</td></tr><tr><td style="text-align:left">Multi-Controller Multi-Objective Locomotion Planning for Legged Robots</td><td style="text-align:right">0701</td></tr><tr><td style="text-align:left">Multi-DoF Force Characterization of Soft Actuators</td><td style="text-align:right">2554</td></tr><tr><td style="text-align:left">Multi-Hand Direct Manipulation of Complex Constrained Virtual Objects</td><td style="text-align:right">0687</td></tr><tr><td style="text-align:left">Multi-Layer Environmental Affordance Map for Robust Indoor Localization, Event Detection and Social Friendly Navigation</td><td style="text-align:right">1075</td></tr><tr><td style="text-align:left">Multilevel Incremental Roadmap Spanners for Reactive Motion Planning</td><td style="text-align:right">1878</td></tr><tr><td style="text-align:left">Multimodal Uncertainty Reduction for Intention Recognition in Human-Robot Interaction</td><td style="text-align:right">0432</td></tr><tr><td style="text-align:left">Multiple Hypothesis Semantic Mapping for Robust Data Association</td><td style="text-align:right">2279</td></tr><tr><td style="text-align:left">Multi-Robot Assembly Sequencing Via Discrete Optimization</td><td style="text-align:right">1747</td></tr><tr><td style="text-align:left">Multirobot Charging Strategies: A Game-Theoretic Approach</td><td style="text-align:right">2125</td></tr><tr><td style="text-align:left">Multi-Robot Distributed Digital Printing System</td><td style="text-align:right">2795</td></tr><tr><td style="text-align:left">Multi Robot Route Planning (MRRP): Extended Spatial-Temporal Prioritized Planning</td><td style="text-align:right">0163</td></tr><tr><td style="text-align:left">Multi-Sensor 6-DoF Localization for Aerial Robots in Complex GNSS-Denied Environments</td><td style="text-align:right">1328</td></tr><tr><td style="text-align:left">Multi-step Pick-And-Place Tasks Using Object-centric Dense Correspondences</td><td style="text-align:right">1421</td></tr><tr><td style="text-align:left">Multi-Vehicle Cooperative Local Mapping Using Split Covariance Intersection Filter</td><td style="text-align:right">0869</td></tr><tr><td style="text-align:left">MuSe: Multi-Sensor Integration Strategies Applied to Sequential Monte Carlo Methods</td><td style="text-align:right">0043</td></tr><tr><td style="text-align:left">Near-Contact Grasping Strategies from Awkward Poses: When Simply Closing Your Fingers Is Not Enough</td><td style="text-align:right">0637</td></tr><tr><td style="text-align:left">Neural Control with an Artificial Hormone System for Energy-Efficient Compliant Terrain Locomotion and Adaptation of Walking Robots</td><td style="text-align:right">2584</td></tr><tr><td style="text-align:left">Neural-Learning Trajectory Tracking Control of Flexible-Joint Robot Manipulators with Unknown Dynamics</td><td style="text-align:right">1590</td></tr><tr><td style="text-align:left">Neural Network Based Heterogeneous Sensor Fusion for Robot Motion Planning</td><td style="text-align:right">0459</td></tr><tr><td style="text-align:left">Neural Path Planning: Fixed Time, Near-Optimal Path Generation Via Oracle Imitation</td><td style="text-align:right">0194</td></tr><tr><td style="text-align:left">NeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory Learning for Autonomous Vehicles</td><td style="text-align:right">2219</td></tr><tr><td style="text-align:left">n-MeRCI: A New Metric to Evaluate the Correlation between Predictive Uncertainty and True Error</td><td style="text-align:right">1624</td></tr><tr><td style="text-align:left">Non-Contact Sensing of Respiratory Signals</td><td style="text-align:right">2754</td></tr><tr><td style="text-align:left">Nonlinear Optimization of Step Duration and Step Location</td><td style="text-align:right">0950</td></tr><tr><td style="text-align:left">Non-Myopic Planetary Exploration Combining in Situ and Remote Measurements</td><td style="text-align:right">1367</td></tr><tr><td style="text-align:left">Non-Parametric Mixed-Manifold Products Using Multiscale Kernel Densities</td><td style="text-align:right">1893</td></tr><tr><td style="text-align:left">Non-Uniform Robot Densities in Vibration Driven Swarms Using Phase Separation Theory</td><td style="text-align:right">1874</td></tr><tr><td style="text-align:left">Normal Distribution Mixture Matching Based Model Free Object Tracking Using 2D LIDAR</td><td style="text-align:right">1307</td></tr><tr><td style="text-align:left">Novel Lockable and Stackable Compliant Actuation Unit for Modular +SPEA Actuators</td><td style="text-align:right">2600</td></tr><tr><td style="text-align:left">Object Placement Planning and Optimization for Robot Manipulators</td><td style="text-align:right">1756</td></tr><tr><td style="text-align:left">Object Proposal Algorithms in the Wild: Are They Generalizable to Robot Perception?</td><td style="text-align:right">1538</td></tr><tr><td style="text-align:left">Object Rearrangement with Nested Nonprehensile Manipulation Actions</td><td style="text-align:right">1431</td></tr><tr><td style="text-align:left">Object Singulation Via Nonlinear Pushing for Robotic Grasping</td><td style="text-align:right">0428</td></tr><tr><td style="text-align:left">Observability Analysis of Position Estimation for Quadrotors with Modified Dynamics and Range Measurements</td><td style="text-align:right">1690</td></tr><tr><td style="text-align:left">Obstacle Avoidance Using a Capacitive Skin for Safe Human-Robot Interaction</td><td style="text-align:right">0903</td></tr><tr><td style="text-align:left">Obstacle Climbing by a Humanoid Robot Using Standing Jump Motion</td><td style="text-align:right">2702</td></tr><tr><td style="text-align:left">Obstacle Overcoming on a FaÃ§ade: Novel Design of a Rotating Leg Mechanism</td><td style="text-align:right">2634</td></tr><tr><td style="text-align:left">Occlusion-Robust Deformable Object Tracking without Physics Simulation</td><td style="text-align:right">1309</td></tr><tr><td style="text-align:left">Older People Prefrontal Cortex Activation Estimates Their Perceived Difficulty of a Humanoid-Mediated Conversation</td><td style="text-align:right">2281</td></tr><tr><td style="text-align:left">Omnipush: Accurate, Diverse, Real-World Dataset of Pushing Dynamics with RGB-D Video</td><td style="text-align:right">1101</td></tr><tr><td style="text-align:left">Onboard Marker-Less Detection and Localization of Non-Cooperating Drones for Their Safe Interception by an Autonomous Aerial System</td><td style="text-align:right">2327</td></tr><tr><td style="text-align:left">On-Chip Three-Dimension Cell Rotation Using Whirling Flows Generated by Oscillating Asymmetrical Microstructures</td><td style="text-align:right">0313</td></tr><tr><td style="text-align:left">On Data Sharing Strategy for Decentralized Collaborative Visual-Inertial Simultaneous Localization and Mapping</td><td style="text-align:right">0465</td></tr><tr><td style="text-align:left">On Enhancing Ground Surface Detection from Sparse Lidar Point Cloud</td><td style="text-align:right">0013</td></tr><tr><td style="text-align:left">One-Shot Composition of Vision-Based Skills from Demonstration</td><td style="text-align:right">0561</td></tr><tr><td style="text-align:left">One-Shot Object Localization Using Learnt Visual Cues Via Siamese Networks</td><td style="text-align:right">0353</td></tr><tr><td style="text-align:left">On Flying Backwards: Preventing Run-Away of Small, Low-Speed Fixed-Wing UAVs in Strong Winds</td><td style="text-align:right">1693</td></tr><tr><td style="text-align:left">Online Active Safety for Robotic Manipulators</td><td style="text-align:right">1732</td></tr><tr><td style="text-align:left">Online and Consistent Occupancy Grid Mapping for Planning in Unknown Environments</td><td style="text-align:right">1487</td></tr><tr><td style="text-align:left">Online Motion Planning Over Multiple Homotopy Classes with Gaussian Process Inference</td><td style="text-align:right">1340</td></tr><tr><td style="text-align:left">Online Optimal Impedance Planning for Legged Robots</td><td style="text-align:right">1763</td></tr><tr><td style="text-align:left">Online Performance Prediction and Profiling of Human Activities by Observation</td><td style="text-align:right">1033</td></tr><tr><td style="text-align:left">Online Planning for Autonomous Underwater Vehicles Performing Information Gathering Tasks in Large Subsea Environments</td><td style="text-align:right">0997</td></tr><tr><td style="text-align:left">Online Relative Footstep Optimization for Legged Robots Dynamic Walking Using Discrete-Time Model Predictive Control</td><td style="text-align:right">1001</td></tr><tr><td style="text-align:left">Online System Identification Algorithm without Persistent Excitation for Robotic Systems: Application to Reconfigurable Autonomous Vessels</td><td style="text-align:right">1069</td></tr><tr><td style="text-align:left">Online Trajectory Generation of a MAV for Chasing a Moving Target in 3D Dense Environments</td><td style="text-align:right">1511</td></tr><tr><td style="text-align:left">Online Trajectory Generation: Reactive Control with Return Inside an Admissible Kinematic Domain</td><td style="text-align:right">0877</td></tr><tr><td style="text-align:left">On Model-Based Adhesion Control of a Vortex Climbing Robot</td><td style="text-align:right">1401</td></tr><tr><td style="text-align:left">On Modeling the Effects of Auditory Annoyance on Driving Style and Passenger Comfort</td><td style="text-align:right">1415</td></tr><tr><td style="text-align:left">On the Bayes Filter for Shared Autonomy</td><td style="text-align:right">2304</td></tr><tr><td style="text-align:left">On the Covariance of X in AX = XB</td><td style="text-align:right">2597</td></tr><tr><td style="text-align:left">On the Effect of Semielliptical Foot Shape on the Energetic Efficiency of Passive Bipedal Gait</td><td style="text-align:right">0873</td></tr><tr><td style="text-align:left">On the Feasibility of Multi-Degree-Of-Freedom Haptic Devices Using Passive Actuators</td><td style="text-align:right">1453</td></tr><tr><td style="text-align:left">On the Tunable Sparse Graph Solver for Pose Graph Optimization in Visual SLAM Problems</td><td style="text-align:right">1595</td></tr><tr><td style="text-align:left">On Training Flexible Robots Using Deep Reinforcement Learning</td><td style="text-align:right">1855</td></tr><tr><td style="text-align:left">Operational Space Control Framework for Torque Controlled Humanoid Robots with Joint Elasticity</td><td style="text-align:right">2529</td></tr><tr><td style="text-align:left">Operation of a Pneumatic Soft Manipulator Using a Wearable Interface with Flexible Strain Sensors</td><td style="text-align:right">2132</td></tr><tr><td style="text-align:left">Opposite Treatments on Null Space: Null Space Projection vs Null Space Avoidance</td><td style="text-align:right">2711</td></tr><tr><td style="text-align:left">Optical Coherence Tomography Guided Robotic Device for Autonomous Needle Insertion in Cornea Transplant Surgery</td><td style="text-align:right">1539</td></tr><tr><td style="text-align:left">Optimal Solving of Constrained Path-Planning Problems with Graph Convolutional Networks and Optimized Tree Search</td><td style="text-align:right">1095</td></tr><tr><td style="text-align:left">Optimal Temporal Logic Planning for Multi-Robot Systems in Uncertain Semantic Maps</td><td style="text-align:right">1083</td></tr><tr><td style="text-align:left">Optimal Temporal Logic Planning with Cascading Soft Constraints</td><td style="text-align:right">1824</td></tr><tr><td style="text-align:left">Optimization Based Motion Planning for Multi-Limbed Vertical Climbing Robots</td><td style="text-align:right">0601</td></tr><tr><td style="text-align:left">Optimization Based Trajectory Planning of Mobile Cable-Driven Parallel Robots</td><td style="text-align:right">1137</td></tr><tr><td style="text-align:left">Optimization Model for Planning Precision Grasps with Multi-Fingered Hands</td><td style="text-align:right">1892</td></tr><tr><td style="text-align:left">Optimized Locomotion for Energy-Efficient Quadrupedal Robot Over Rough Terrain</td><td style="text-align:right">2646</td></tr><tr><td style="text-align:left">Optimizing Motion-Planning Problem Setup Via Bounded Evaluation with Application to Following Surgical Trajectories</td><td style="text-align:right">1635</td></tr><tr><td style="text-align:left">Orbit Characterization, Stabilization and Composition of 3D Underactuated Bipedal Walking Via Hybrid Passive Linear Inverted Pendulum Model</td><td style="text-align:right">0624</td></tr><tr><td style="text-align:left">ORBSLAM-Atlas: A Robust and Accurate Multi-Map System</td><td style="text-align:right">0830</td></tr><tr><td style="text-align:left">OREOS: Oriented Recognition of 3D Point Clouds in Outdoor Scenarios</td><td style="text-align:right">1242</td></tr><tr><td style="text-align:left">Outlier-Robust Spatial Perception: Hardness, General-Purpose Algorithms, and Guarantees</td><td style="text-align:right">1688</td></tr><tr><td style="text-align:left">Outlier-Robust State Estimation for Humanoid Robots</td><td style="text-align:right">0433</td></tr><tr><td style="text-align:left">PanopticFusion: Online Volumetric Semantic Mapping at the Level of Stuff and Things</td><td style="text-align:right">0278</td></tr><tr><td style="text-align:left">Paper-Based Modular Origami Gripper</td><td style="text-align:right">0282</td></tr><tr><td style="text-align:left">Partial Caging: A Clearance-Based Definition and Deep Learning</td><td style="text-align:right">2217</td></tr><tr><td style="text-align:left">PASS3D: Precise and Accelerated Semantic Segmentation for 3D Point Cloud</td><td style="text-align:right">1842</td></tr><tr><td style="text-align:left">Passive Inverted Ultra-Short Baseline (piUSBL) Localization: An Experimental Evaluation of Accuracy</td><td style="text-align:right">1268</td></tr><tr><td style="text-align:left">Passive Model Reduction and Switching for Fast Soft Object Simulation with Intermittent Contacts</td><td style="text-align:right">1953</td></tr><tr><td style="text-align:left">Path Planning Algorithm for a Transformation of a Shape-Morphing Wheel for a Step-Climbing</td><td style="text-align:right">2642</td></tr><tr><td style="text-align:left">Path Planning for Surgery Robot with Bidirectional Continuous Tree Search and Neural Network</td><td style="text-align:right">0812</td></tr><tr><td style="text-align:left">Path Planning with Incremental Roadmap Update for Visibility-Based Target Tracking</td><td style="text-align:right">0673</td></tr><tr><td style="text-align:left">PD based Robust Quadratic Programs for Robotic Systems</td><td style="text-align:right">1039</td></tr><tr><td style="text-align:left">Pedestrian Density Prediction for Efficient Mobile Robot Exploration</td><td style="text-align:right">0166</td></tr><tr><td style="text-align:left">People’s V-Formation and Side-by-Side Model Adapted to Accompany Groups of People by Social Robots</td><td style="text-align:right">0472</td></tr><tr><td style="text-align:left">Perception As Prediction Using General Value Functions in Autonomous Driving Applications</td><td style="text-align:right">1442</td></tr><tr><td style="text-align:left">Perception of Pedestrian Avoidance Strategies of a Self-Balancing Mobile Robot</td><td style="text-align:right">2510</td></tr><tr><td style="text-align:left">Perception System Design for Low-Cost Commercial Ground Robots: Sensor Configurations, Calibration, Localization, and Mapping</td><td style="text-align:right">2209</td></tr><tr><td style="text-align:left">Performance Guarantees for Receding Horizon Search with Terminal Cost</td><td style="text-align:right">1438</td></tr><tr><td style="text-align:left">Periodic Trajectory Planning and Robust Output Zeroing Control for Underactuated Bipedal Robots with Predicted Disturbances</td><td style="text-align:right">1623</td></tr><tr><td style="text-align:left">Permanent Magnets Based Actuator for Microrobots Navigation</td><td style="text-align:right">0839</td></tr><tr><td style="text-align:left">Person-Following for Telepresence Robots Using Web Cameras</td><td style="text-align:right">0396</td></tr><tr><td style="text-align:left">Physical Fatigue Analysis of Assistive Robot Teleoperation Via Whole-Body Motion Mapping</td><td style="text-align:right">1567</td></tr><tr><td style="text-align:left">Physical Orienteering Problem for Unmanned Aerial Vehicle Data Collection Planning in Environments with Obstacles</td><td style="text-align:right">2146</td></tr><tr><td style="text-align:left">Piecewise Rigid Scene Flow with Implicit Motion Segmentation</td><td style="text-align:right">1418</td></tr><tr><td style="text-align:left">Pixel-Attentive Policy Gradient for Multi-Fingered Grasping in Cluttered Scenes</td><td style="text-align:right">0252</td></tr><tr><td style="text-align:left">Pixels to Plans: Learning Non-Prehensile Manipulation by Imitating a Planner</td><td style="text-align:right">1386</td></tr><tr><td style="text-align:left">Planning Beyond the Sensing Horizon Using a Learned Context</td><td style="text-align:right">1586</td></tr><tr><td style="text-align:left">Planning High-Quality Motions for Concentric Tube Robots in Point Clouds via Parallel Sampling and Optimization</td><td style="text-align:right">1365</td></tr><tr><td style="text-align:left">Planning in Stochastic Environments with Goal Uncertainty</td><td style="text-align:right">0943</td></tr><tr><td style="text-align:left">Planning Reactive Manipulation in Dynamic Environments</td><td style="text-align:right">0643</td></tr><tr><td style="text-align:left">Plant Phenotyping by Deep-Learning Based Planner for Multi-Robots</td><td style="text-align:right">2176</td></tr><tr><td style="text-align:left">Plasticity in Collective Decision-Making for Robots: Creating Global Reference Frames, Detecting Dynamic Environments, and Preventing Lock-Ins</td><td style="text-align:right">1968</td></tr><tr><td style="text-align:left">PnS: A Perspective-n-Spheres Algorithm for Laparoscope Calibration in Minimally Invasive Surgery</td><td style="text-align:right">0752</td></tr><tr><td style="text-align:left">PointAtrousNet: Point Atrous Convolution for Point Cloud Analysis</td><td style="text-align:right">2290</td></tr><tr><td style="text-align:left">Policy Distillation and Value Matching in Multiagent Reinforcement Learning</td><td style="text-align:right">1867</td></tr><tr><td style="text-align:left">Port-Hamiltonian Passivity-Based Control on SE(3) of a Fully-Actuated UAV for Aerial Physical Interaction Near-Hovering</td><td style="text-align:right">2434</td></tr><tr><td style="text-align:left">Pose-Aware Placing with Semantic Labels - Brandname-Based Affordance Prediction and Cooperative Dual-Arm Active Manipulation</td><td style="text-align:right">0208</td></tr><tr><td style="text-align:left">Pose Estimation for Omni-Directional Cameras Using Sinusoid Fitting</td><td style="text-align:right">1527</td></tr><tr><td style="text-align:left">Pose-Graph Based Indoor Navigation Test for Unmanned Underwater Vehicle Navigation</td><td style="text-align:right">2760</td></tr><tr><td style="text-align:left">Position-Based Control of Under-Constrained Haptics: A System for the Dexmo Glove</td><td style="text-align:right">2496</td></tr><tr><td style="text-align:left">Position-Based Monocular Visual Servoing of an Unknown Target Using Online Self-Supervised Learning</td><td style="text-align:right">1902</td></tr><tr><td style="text-align:left">Position Control of Wire-Suspended Hand for Long-Reach Aerial Manipulation</td><td style="text-align:right">2674</td></tr><tr><td style="text-align:left">PPRNet: Point-Wise Pose Regression Network for Instance Segmentation and 6D Pose Estimation in Bin-Picking Scenarios</td><td style="text-align:right">0342</td></tr><tr><td style="text-align:left">Precise Correntropy-Based 3D Object Modelling with Geometrical Traffic Prior</td><td style="text-align:right">1593</td></tr><tr><td style="text-align:left">Precision Modeling and Optimally-Safe Design of Quadcopters for Controlled Crash Landing in Case of Rotor Failure</td><td style="text-align:right">1618</td></tr><tr><td style="text-align:left">Precision Pouring into Unknown Containers by Service Robots</td><td style="text-align:right">0756</td></tr><tr><td style="text-align:left">Predicting Grasp Success with a Soft Sensing Skin and Shape-Memory Actuated Gripper</td><td style="text-align:right">2309</td></tr><tr><td style="text-align:left">Prediction of Human Arm Target for Robot Reaching Movements</td><td style="text-align:right">0219</td></tr><tr><td style="text-align:left">Predictive and Adaptive Maps for Long-Term Visual Navigation in Changing Environments</td><td style="text-align:right">0005</td></tr><tr><td style="text-align:left">Predictive Inverse Kinematics for Redundant Manipulators with Task Scaling and Kinematic Constraints</td><td style="text-align:right">2601</td></tr><tr><td style="text-align:left">Predictive Inverse Kinematics: Optimizing Future Trajectory through Implicit Time Integration and Future Jacobian Estimation</td><td style="text-align:right">0519</td></tr><tr><td style="text-align:left">Predictive Optimization of Assistive Force on Admittance Control-Based Mobile Walking Support System</td><td style="text-align:right">2487</td></tr><tr><td style="text-align:left">Preliminary Evaluation of an Orbital Camera for Teleoperation of Remote Manipulators</td><td style="text-align:right">1088</td></tr><tr><td style="text-align:left">Preliminary Investigation about Relationship between Perceived Intimacy and Touch Characteristics</td><td style="text-align:right">2671</td></tr><tr><td style="text-align:left">Preliminary Results of Active Compression Sleeve Using Wire and Fabric Mechanism</td><td style="text-align:right">2700</td></tr><tr><td style="text-align:left">Preliminary Study for Developing a Vision-Based Detection System of Unmanned Surface Vessels</td><td style="text-align:right">2705</td></tr><tr><td style="text-align:left">Pressure-Driven Body Compliance Using Robot Skin</td><td style="text-align:right">2425</td></tr><tr><td style="text-align:left">Printing-While-Moving: A New Paradigm for Large-Scale Robotic 3D Printing</td><td style="text-align:right">0347</td></tr><tr><td style="text-align:left">Privacy-Preserving Robot Vision with Anonymized Faces by Extreme Low Resolution</td><td style="text-align:right">1845</td></tr><tr><td style="text-align:left">Probabilistic Risk Metrics for Navigating Occluded Intersections</td><td style="text-align:right">2394</td></tr><tr><td style="text-align:left">Proposal of a Peristaltic Motion Type Duct Cleaning Robot for Traveling in a Flexible Pipe</td><td style="text-align:right">2533</td></tr><tr><td style="text-align:left">Proto-Object Based Saliency for Event-Driven Cameras</td><td style="text-align:right">1195</td></tr><tr><td style="text-align:left">qpSWIFT : A Real-Time Sparse Quadratic Program Solver for Robotic Applications</td><td style="text-align:right">2157</td></tr><tr><td style="text-align:left">Quaternion-based Smooth Trajectory Generator for Via Poses in SE(3) Considering Kinematic Limits in Cartesian Space</td><td style="text-align:right">2386</td></tr><tr><td style="text-align:left">Quickly Inserting Pegs into Uncertain Holes Using Multi-View Images and Deep Network Trained on Synthetic Data</td><td style="text-align:right">2308</td></tr><tr><td style="text-align:left">Radar SLAM for Indoor Disaster Environments Via Multi-Modal Registration to Prior LiDAR Map</td><td style="text-align:right">0355</td></tr><tr><td style="text-align:left">Randomized Sensor Selection for Nonlinear Systems with Application to Target Localization</td><td style="text-align:right">2504</td></tr><tr><td style="text-align:left">Range-Limited, Distributed Algorithms on Higher-Order Voronoi Partitions in Multi-Robot Systems</td><td style="text-align:right">0509</td></tr><tr><td style="text-align:left">RangeNet++: Fast and Accurate LiDAR Semantic Segmentation</td><td style="text-align:right">0346</td></tr><tr><td style="text-align:left">Rapid and Robust Monocular Visual-Inertial Initialization with Gravity Estimation via Vertical Edges</td><td style="text-align:right">1687</td></tr><tr><td style="text-align:left">Rapid Collision Detection for Multicopter Trajectories</td><td style="text-align:right">1449</td></tr><tr><td style="text-align:left">Rapid Design of Mechanical Logic Based on Quasi-Static Electromechanical Modeling</td><td style="text-align:right">1304</td></tr><tr><td style="text-align:left">Rapid Estimation of Optical Properties for Simulation-Based Evaluation of Pose Estimation Performance</td><td style="text-align:right">0671</td></tr><tr><td style="text-align:left">Rapid Trajectory Optimization Using C-FROST with Illustration on a Cassie-Series Dynamic Walking Biped</td><td style="text-align:right">1651</td></tr><tr><td style="text-align:left">Reactive Interaction through Body Motion and the Phase-State-Machine</td><td style="text-align:right">0427</td></tr><tr><td style="text-align:left">Real-Time 6D Object Pose Estimation on CPU</td><td style="text-align:right">0189</td></tr><tr><td style="text-align:left">Real-Time Biped Walking-Pattern Generation by Spline Collocation</td><td style="text-align:right">2706</td></tr><tr><td style="text-align:left">Realtime Contact Dynamics for Continuum Arms Using Physics Engines</td><td style="text-align:right">2776</td></tr><tr><td style="text-align:left">Real-Time Dense Depth Estimation Using Semantically-Guided LIDAR Data Propagation and Motion Stereo</td><td style="text-align:right">2260</td></tr><tr><td style="text-align:left">Real-Time Detection of Distracted Driving Using Dual Cameras</td><td style="text-align:right">2668</td></tr><tr><td style="text-align:left">Real-Time Global Registration for Globally Consistent RGB-D SLAM</td><td style="text-align:right">2577</td></tr><tr><td style="text-align:left">Real-Time Model-Based Image Color Correction for Underwater Robots</td><td style="text-align:right">1775</td></tr><tr><td style="text-align:left">Real-Time Monitoring of Human Task Advancement</td><td style="text-align:right">0888</td></tr><tr><td style="text-align:left">Real-Time Quad-Rotor Path Planning Using Convex Optimization and Compound State-Triggered Constraints</td><td style="text-align:right">2315</td></tr><tr><td style="text-align:left">Real-Time Sampling-Based Optimization on FPGA for Accurate Grid Map Merging in Embedded Robotic Systems</td><td style="text-align:right">2714</td></tr><tr><td style="text-align:left">Rebellion and Obedience: The Effects of Intention Prediction in Cooperative Handheld Robots</td><td style="text-align:right">0968</td></tr><tr><td style="text-align:left">Recalling Candidates of Grasping Method from an Object Image Using Neural Network</td><td style="text-align:right">0875</td></tr><tr><td style="text-align:left">Reconfiguration Motion Planning for Variable Topology Truss</td><td style="text-align:right">1830</td></tr><tr><td style="text-align:left">Reconstructing Endovascular Catheter Interaction Forces in 3D Using Multicore Optical Shape Sensors</td><td style="text-align:right">2136</td></tr><tr><td style="text-align:left">Recurrent Convolutional Fusion for RGB-D Object Recognition</td><td style="text-align:right">2138</td></tr><tr><td style="text-align:left">Redundant Resolution Method of an Underwater Manipulation for Disturbance Rejection</td><td style="text-align:right">2641</td></tr><tr><td style="text-align:left">ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals</td><td style="text-align:right">0135</td></tr><tr><td style="text-align:left">Region-Wise Polynomial Regression for 3D Mobile Gaze Estimation</td><td style="text-align:right">0223</td></tr><tr><td style="text-align:left">Regressing Noisy Joint States from Visual Data Using CNN</td><td style="text-align:right">2665</td></tr><tr><td style="text-align:left">Reinforcement Learning Boat Autopilot: A Sample-Efficient and Model Predictive Control Based Approach</td><td style="text-align:right">2313</td></tr><tr><td style="text-align:left">Reinforcement Learning of Trajectory Distributions: Applications in Assisted Teleoperation and Motion Planning</td><td style="text-align:right">2550</td></tr><tr><td style="text-align:left">Relaxing the Conservatism of Passivity Condition for Impedance Controlled Series Elastic Actuators</td><td style="text-align:right">2312</td></tr><tr><td style="text-align:left">Remote Center Motion of a Surgical Assisted Robot for In-Situ Collaboration</td><td style="text-align:right">2654</td></tr><tr><td style="text-align:left">Representation Learning via Parallel Subset Reconstruction for 3D Point Cloud Generation</td><td style="text-align:right">0053</td></tr><tr><td style="text-align:left">Representing Robot Task Plans As Robust Logical-Dynamical Systems</td><td style="text-align:right">1703</td></tr><tr><td style="text-align:left">Research on Finite Ground Effect of a Rotor</td><td style="text-align:right">1709</td></tr><tr><td style="text-align:left">ResFlow: Multi-Tasking of Sequentially Pooling Spatiotemporal Features for Action Recognition and Optical Flow Estimation</td><td style="text-align:right">0410</td></tr><tr><td style="text-align:left">Resilience by Reconfiguration: Exploiting Heterogeneity in Robot Teams</td><td style="text-align:right">2108</td></tr><tr><td style="text-align:left">Resolving Elevation Ambiguity in 1-D Radar Array Measurements Using Deep Learning</td><td style="text-align:right">2086</td></tr><tr><td style="text-align:left">Responsive Joint Attention in Human-Robot Interaction</td><td style="text-align:right">0028</td></tr><tr><td style="text-align:left">ResQbot 2.0: A Mobile Stretcher Bed Robot with Neck Securing Device for Safe Casualty Extraction</td><td style="text-align:right">2716</td></tr><tr><td style="text-align:left">Retrieval-Based Localization Based on Domain-Invariant Feature Learning under Changing Environments</td><td style="text-align:right">1695</td></tr><tr><td style="text-align:left">RGB-To-TSDF: Direct TSDF Prediction from a Single RGB Image for Dense 3D Reconstruction</td><td style="text-align:right">0378</td></tr><tr><td style="text-align:left">Right of Way, Assertiveness and Social Recognition in Human-Robot Doorway Interaction</td><td style="text-align:right">1564</td></tr><tr><td style="text-align:left">RINS-W: Robust Inertial Navigation System on Wheels</td><td style="text-align:right">0067</td></tr><tr><td style="text-align:left">RISE-SLAM: A Resource-Aware Inverse Schmidt Estimator for SLAM</td><td style="text-align:right">0283</td></tr><tr><td style="text-align:left">Risk-Aware Motion Planning and Control Using CVaR-Constrained Optimization</td><td style="text-align:right">2316</td></tr><tr><td style="text-align:left">Riverine Coverage with an Autonomous Surface Vehicle Over Known Environments</td><td style="text-align:right">0502</td></tr><tr><td style="text-align:left">Roboat: An Autonomous Surface Vehicle for Urban Waterways</td><td style="text-align:right">0188</td></tr><tr><td style="text-align:left">Robot-Assisted Composite Manufacturing Using Deep Learning and Multi-View Computer Vision</td><td style="text-align:right">2732</td></tr><tr><td style="text-align:left">Robot Audition Approaches to Field Observation of Bird Songs</td><td style="text-align:right">2682</td></tr><tr><td style="text-align:left">Robot-Based Machining of Unmodeled Objects via Feature Detection in Dense Point Clouds</td><td style="text-align:right">0960</td></tr><tr><td style="text-align:left">Robot-Based Strategy for Objective Assessment of Motor Impairments</td><td style="text-align:right">2649</td></tr><tr><td style="text-align:left">Robot-Enhanced Therapy: Development and Validation of a Supervised Autonomous Robotic System for Autism Spectrum Disorders Therapy</td><td style="text-align:right">2500</td></tr><tr><td style="text-align:left">Robot Finger with Remote Center of Motion Mechanism for Covering Joints with Thick Skin</td><td style="text-align:right">2151</td></tr><tr><td style="text-align:left">Robot’Robot Gesturing for Anchoring Representations</td><td style="text-align:right">2605</td></tr><tr><td style="text-align:left">Robotic Cutting of Solids Based on Fracture Mechanics and FEM</td><td style="text-align:right">1501</td></tr><tr><td style="text-align:left">Robotic Laparoendoscopic Single-Site Surgery Platform on dVRK</td><td style="text-align:right">2772</td></tr><tr><td style="text-align:left">Robotic Tracking Control with Kernel Trick-Based Reinforcement Learning</td><td style="text-align:right">0381</td></tr><tr><td style="text-align:left">Robotic Ultrasound for Catheter Navigation in Endovascular Procedures</td><td style="text-align:right">0487</td></tr><tr><td style="text-align:left">Robot Learning of Shifting Objects for Grasping in Cluttered Environments</td><td style="text-align:right">0482</td></tr><tr><td style="text-align:left">Robot Learning Via Human Adversarial Games</td><td style="text-align:right">1400</td></tr><tr><td style="text-align:left">Robot Localization in Floor Plans Using a Room Layout Edge Extraction Network</td><td style="text-align:right">1403</td></tr><tr><td style="text-align:left">Robot Localization Via Odometry-Assisted Ultra-Wideband Ranging with Stochastic Guarantees</td><td style="text-align:right">1037</td></tr><tr><td style="text-align:left">Robots That Take Advantage of Human Trust</td><td style="text-align:right">1277</td></tr><tr><td style="text-align:left">Robust and Adaptive Lower Limb Prosthesis Control Via Extended Kalman Filter-Based Phase Estimation</td><td style="text-align:right">2097</td></tr><tr><td style="text-align:left">Robust and Efficient Quadrotor Trajectory Generation for Fast Autonomous Flight</td><td style="text-align:right">2377</td></tr><tr><td style="text-align:left">Robust and Efficient Vehicles Motion Estimation with Low-Cost Multi-Camera and Odometer-Gyroscope</td><td style="text-align:right">1803</td></tr><tr><td style="text-align:left">Robust, Compliant Assembly with Elastic Parts and Model Uncertainty</td><td style="text-align:right">1059</td></tr><tr><td style="text-align:left">Robust Deformation Model Approximation for Robotic Cable Manipulation</td><td style="text-align:right">1626</td></tr><tr><td style="text-align:left">Robust Grasp Planning Over Uncertain Shape Completions</td><td style="text-align:right">0761</td></tr><tr><td style="text-align:left">Robust Hand-Eye Calibration via Iteratively Re-weighted Rank-Constrained Semi-Definite Programming</td><td style="text-align:right">2026</td></tr><tr><td style="text-align:left">Robust High Accuracy Visual-Inertial-Laser SLAM System</td><td style="text-align:right">0971</td></tr><tr><td style="text-align:left">Robust Impedance Shaping of Redundant Teleoperators with Time-Delay Via Sliding Mode Control</td><td style="text-align:right">1203</td></tr><tr><td style="text-align:left">Robust Legged Robot State Estimation Using Factor Graph Optimization</td><td style="text-align:right">2582</td></tr><tr><td style="text-align:left">Robust Loop Closure Detection Based on Bag of SuperPoints and Graph Verification</td><td style="text-align:right">1544</td></tr><tr><td style="text-align:left">Robust Moving Path Following Control for Robotic Vehicles: Theory and Experiments</td><td style="text-align:right">2295</td></tr><tr><td style="text-align:left">Robust Non-Rigid Point Set Registration Algorithm Considering Anisotropic Uncertainties Based on Coherent Point Drift</td><td style="text-align:right">1673</td></tr><tr><td style="text-align:left">Robust Outdoor Self-Localization in Changing Environments</td><td style="text-align:right">1163</td></tr><tr><td style="text-align:left">Robust Real-Time RGB-D Visual Odometry in Dynamic Environments Via Rigid Motion Model</td><td style="text-align:right">1254</td></tr><tr><td style="text-align:left">Robust Trajectory Planning for a Multirotor against Disturbance based on Hamilton-Jacobi Reachability Analysis</td><td style="text-align:right">1801</td></tr><tr><td style="text-align:left">Robust UAV Localization Around the Large Scale Facilities with Multiple Subsidiary UAVs</td><td style="text-align:right">2757</td></tr><tr><td style="text-align:left">Robust UAV Position and Attitude Estimation Using Multiple GNSS Receivers for Laser-Based 3D Mapping</td><td style="text-align:right">0577</td></tr><tr><td style="text-align:left">RoFICoM — First Open-Hardware Connector for Metamorphic Robots</td><td style="text-align:right">0354</td></tr><tr><td style="text-align:left">ROI-Based Robotic Grasp Detection for Object Overlapping Scenes</td><td style="text-align:right">0190</td></tr><tr><td style="text-align:left">Rolling-Shutter Modelling for Direct Visual-Inertial Odometry</td><td style="text-align:right">0350</td></tr><tr><td style="text-align:left">RONet: Real-Time Range-Only Indoor Localization Via Stacked Bidirectional LSTM with Residual Attention</td><td style="text-align:right">2267</td></tr><tr><td style="text-align:left">Routing a Fleet of Automated Vehicles in a Capacitated Transportation Network</td><td style="text-align:right">0931</td></tr><tr><td style="text-align:left">Safe Path Planning with Gaussian Process Regulated Risk Map</td><td style="text-align:right">0706</td></tr><tr><td style="text-align:left">Safe Physical HRI: Toward a Unified Treatment of Speed and Separation Monitoring Together with Power and Force Limiting</td><td style="text-align:right">2490</td></tr><tr><td style="text-align:left">SailMAV: Design and Implementation of a Novel Multi-Modal Flying Sailing Robot</td><td style="text-align:right">2599</td></tr><tr><td style="text-align:left">Sample-Efficient Deep Reinforcement Learning with Imaginary Rollouts for Human-Robot Interaction</td><td style="text-align:right">0933</td></tr><tr><td style="text-align:left">Sample Efficient Interactive End-To-End Deep Learning for Self-Driving Cars with Selective Multi-Class Safe Dataset Aggregation</td><td style="text-align:right">1303</td></tr><tr><td style="text-align:left">Sampling-Based Motion Planning for Aerial Pick-And-Place</td><td style="text-align:right">1504</td></tr><tr><td style="text-align:left">Sampling-Based Motion Planning of 3D Solid Objects Guided by Multiple Approximate Solutions</td><td style="text-align:right">1108</td></tr><tr><td style="text-align:left">Sampling-Based Path Planning for Cooperative Autonomous Maritime Vehicles to Reduce Uncertainty in Range-Only Localisation</td><td style="text-align:right">2223</td></tr><tr><td style="text-align:left">Scaffold-Based Asynchronous Distributed Self-Reconfiguration by Continuous Module Flow</td><td style="text-align:right">0990</td></tr><tr><td style="text-align:left">Scaling Robot Supervision to Hundreds of Hours with RoboTurk: Robotic Manipulation Dataset through Human Reasoning and Dexterity</td><td style="text-align:right">1251</td></tr><tr><td style="text-align:left">Scheduling of Mobile Workstations for Overlapping Production Time and Delivery Time</td><td style="text-align:right">0586</td></tr><tr><td style="text-align:left">Seeing behind Things: Extending Semantic Segmentation to Occluded Regions</td><td style="text-align:right">1433</td></tr><tr><td style="text-align:left">Seeing Beyond Appearance ‘ Mapping Real Images into Geometrical Domains for Unsupervised CAD-Based Recognition</td><td style="text-align:right">1124</td></tr><tr><td style="text-align:left">Seeking the Analytical Approximation of the Stance Dynamics of the 3D Spring-Loaded Inverted Pendulum Model by Using Perturbation Approach</td><td style="text-align:right">0633</td></tr><tr><td style="text-align:left">Segregation and Flow of Modules in a Robot Swarm Utilising the Brazil Nut Effect</td><td style="text-align:right">0622</td></tr><tr><td style="text-align:left">Self-Calibration and Learning on Chip: Towards Neuromorphic Robots</td><td style="text-align:right">2752</td></tr><tr><td style="text-align:left">Self-Collision Detection and Avoidance for Dual-Arm Concentric Tube Robots</td><td style="text-align:right">2523</td></tr><tr><td style="text-align:left">Self-Modeling Tracking Control of Crawler Fire Fighting Robot Based on Causal Network</td><td style="text-align:right">0419</td></tr><tr><td style="text-align:left">Self-Organised Flocking in Robotic Swarm Based on Active Elastic Sheet</td><td style="text-align:right">2625</td></tr><tr><td style="text-align:left">Self-Organized Adaptive Paths in Multi-Robot Manufacturing: Reconfigurable and Pattern-Independent Fibre Deployment</td><td style="text-align:right">1952</td></tr><tr><td style="text-align:left">Self-Specialization of General Robot Plans Based on Experience</td><td style="text-align:right">2508</td></tr><tr><td style="text-align:left">Self-Supervised 3D Shape and Viewpoint Estimation from Single Images for Robotics</td><td style="text-align:right">0758</td></tr><tr><td style="text-align:left">Self-Supervised Transfer Learning for Instance Segmentation through Physical Interaction</td><td style="text-align:right">1890</td></tr><tr><td style="text-align:left">Semantically Assisted Loop Closure in SLAM Using NDT Histograms</td><td style="text-align:right">0879</td></tr><tr><td style="text-align:left">Semantic Mates: Intuitive Geometric Constraints for Efficient Assembly Specifications</td><td style="text-align:right">0478</td></tr><tr><td style="text-align:left">Semantic Segmentation Using GAN and Weakly Supervised Based on Deep Transfer Learning</td><td style="text-align:right">2618</td></tr><tr><td style="text-align:left">Semi-Autonomous Interventional Manipulation Using Pneumatically Attachable Flexible Rails</td><td style="text-align:right">0871</td></tr><tr><td style="text-align:left">Sensitivity of Legged Balance Control to Uncertainties and Sampling Period</td><td style="text-align:right">2349</td></tr><tr><td style="text-align:left">Sensor Installation and Retrieval Operations Using an Unmanned Aerial Manipulator</td><td style="text-align:right">2558</td></tr><tr><td style="text-align:left">Sensorless Estimation of the Planar Distal Shape of a Tip-Actuated Endoscope</td><td style="text-align:right">2497</td></tr><tr><td style="text-align:left">SeqLPD: Sequence Matching Enhanced Loop-Closure Detection Based on Large-Scale Point Cloud Description for Self-Driving Vehicles</td><td style="text-align:right">1907</td></tr><tr><td style="text-align:left">Sequential Clustering for Tactile Image Compression to Enable Direct Adaptive Feedback</td><td style="text-align:right">1971</td></tr><tr><td style="text-align:left">Setup and Method for Remote Center of Motion Positioning Guidance During Robot-Assisted Surgery</td><td style="text-align:right">2447</td></tr><tr><td style="text-align:left">SGANVO: Unsupervised Deep Visual Odometry and Depth Estimation with Stacked Generative Adversarial Networks</td><td style="text-align:right">2427</td></tr><tr><td style="text-align:left">Shared Autonomy of a Flexible Manipulator in Constrained Endoluminal Surgical Tasks</td><td style="text-align:right">2232</td></tr><tr><td style="text-align:left">Shared Controller for Obstacle Avoidance of Manipulator for Teleopeartion System</td><td style="text-align:right">2662</td></tr><tr><td style="text-align:left">Sharing Is Caring: Socially-Compliant Autonomous Intersection Negotiation</td><td style="text-align:right">1136</td></tr><tr><td style="text-align:left">Siamese Convolutional Neural Network for Sub-Millimeter-Accurate Camera Pose Estimation and Visual Servoing</td><td style="text-align:right">1514</td></tr><tr><td style="text-align:left">SilhoNet: An RGB Method for 6D Object Pose Estimation</td><td style="text-align:right">2334</td></tr><tr><td style="text-align:left">SIMDop: SIMD Optimized Bounding Volume Hierarchies for Collision Detection</td><td style="text-align:right">0940</td></tr><tr><td style="text-align:left">Simitate: A Hybrid Imitation Learning Benchmark</td><td style="text-align:right">0497</td></tr><tr><td style="text-align:left">Sim-To-(Multi)-Real: Transfer of Low-Level Robust Control Policies to Multiple Quadrotors</td><td style="text-align:right">1589</td></tr><tr><td style="text-align:left">Sim-To-Real Learning for Casualty Detection from Ground Projected Point Cloud Data</td><td style="text-align:right">1239</td></tr><tr><td style="text-align:left">Sim-To-Real Transfer for Biped Locomotion</td><td style="text-align:right">1040</td></tr><tr><td style="text-align:left">Simulation-Based Physics Reasoning for Consistent Scene Estimation in an HRI Context</td><td style="text-align:right">1050</td></tr><tr><td style="text-align:left">Simultaneous Drone Localisation and Wind Turbine Model Fitting During Autonomous Surface Inspection</td><td style="text-align:right">0648</td></tr><tr><td style="text-align:left">Simultaneous Transparent and Non-Transparent Objects Segmentation with Multispectral Scenes</td><td style="text-align:right">0694</td></tr><tr><td style="text-align:left">Single-Hand Movement Direction Decoding from EEG Signals under Opposite-Hand Movement Distraction</td><td style="text-align:right">2627</td></tr><tr><td style="text-align:left">Single Motor-Based Bidirectional Twisted String Actuation with Variable Radius Pulleys</td><td style="text-align:right">2412</td></tr><tr><td style="text-align:left">Situation Awareness for Proactive Robots in HRI</td><td style="text-align:right">0967</td></tr><tr><td style="text-align:left">Six DoF Pose Estimation for a Tendon-Driven Continuum Mechanism without a Deformation Model</td><td style="text-align:right">2347</td></tr><tr><td style="text-align:left">Skill Interaction Categories for Communication in Flexible Human-Robot Teams</td><td style="text-align:right">0338</td></tr><tr><td style="text-align:left">Small-Scale Compliant Dual Arm with Tail for Winged Aerial Robots</td><td style="text-align:right">1409</td></tr><tr><td style="text-align:left">Soft Action Particle Deep Reinforcement Learning for a Continuous Action Space</td><td style="text-align:right">0588</td></tr><tr><td style="text-align:left">Soft Pneumatic Helical Actuator with High Contraction Ratio</td><td style="text-align:right">2538</td></tr><tr><td style="text-align:left">Soft Polymer-Electrolyte-Fuel-Cell Tube Realizing Air-Hose-Free Thin McKibben Muscles</td><td style="text-align:right">2520</td></tr><tr><td style="text-align:left">SP2 (spherically-Stratified-Points Projection): Generating Novel Images for 3D Point Cloud Segmentation</td><td style="text-align:right">2696</td></tr><tr><td style="text-align:left">Sparse-3D Lidar Outdoor Map-Based Autonomous Vehicle Localization</td><td style="text-align:right">0595</td></tr><tr><td style="text-align:left">Sparse Depth Enhanced Direct Thermal-Infrared SLAM Beyond the Visible Spectrum</td><td style="text-align:right">2278</td></tr><tr><td style="text-align:left">Spatiotemporal Learning of Directional Uncertainty in Urban Environments with Kernel Recurrent Mixture Density Networks</td><td style="text-align:right">2197</td></tr><tr><td style="text-align:left">Spatiotemporal Representation of Dynamic Scenes</td><td style="text-align:right">1228</td></tr><tr><td style="text-align:left">Specification-Based Maneuvering of Quadcopters through Hoops</td><td style="text-align:right">1297</td></tr><tr><td style="text-align:left">Specifying and Synthesizing Human-Robot Handovers</td><td style="text-align:right">1397</td></tr><tr><td style="text-align:left">Spiking Neural Network on Neuromorphic Hardware for Energy-Efficient Unidimensional SLAM</td><td style="text-align:right">1452</td></tr><tr><td style="text-align:left">SpineBot: Pneumatically Actuated Muscle</td><td style="text-align:right">2620</td></tr><tr><td style="text-align:left">Spine-Inspired Continuum Soft Exoskeleton for Stoop Lifting Assistance</td><td style="text-align:right">2588</td></tr><tr><td style="text-align:left">Spiral Zipper Manipulator for Aerial Grasping and Manipulation</td><td style="text-align:right">1937</td></tr><tr><td style="text-align:left">Stability and Gait Switching of Underactuated Biped Walkers</td><td style="text-align:right">0520</td></tr><tr><td style="text-align:left">Stair Environment Mapping and Walk-Able Plane Detecting Algorithm for Quadrupedal Robot’s Locomotion</td><td style="text-align:right">2712</td></tr><tr><td style="text-align:left">StarNet: Pedestrian Trajectory Prediction Using Deep Neural Network in Star Topology</td><td style="text-align:right">0199</td></tr><tr><td style="text-align:left">State Representation Learning with Robotic Priors for Partially Observable Environments</td><td style="text-align:right">1302</td></tr><tr><td style="text-align:left">Static Analysis on the Modular Detachable Climbing Robot for All Wall-To-Wall Transitions</td><td style="text-align:right">2633</td></tr><tr><td style="text-align:left">Statistical Coverage Control of Mobile Sensor Networks</td><td style="text-align:right">2604</td></tr><tr><td style="text-align:left">Stereo Visual Inertial LiDAR Simultaneous Localization and Mapping</td><td style="text-align:right">2562</td></tr><tr><td style="text-align:left">Stereo Visual-Inertial SLAM Using Graph-Based Optimization</td><td style="text-align:right">2621</td></tr><tr><td style="text-align:left">Stiffness Bounds for Resilient and Stable Physical Interaction of Articulated Soft Robots</td><td style="text-align:right">2429</td></tr><tr><td style="text-align:left">Stochastic Path Planning for Autonomous Underwater Gliders with Safety Constraints</td><td style="text-align:right">1317</td></tr><tr><td style="text-align:left">Stochastic Sampling Simulation for Pedestrian Trajectory Prediction</td><td style="text-align:right">2419</td></tr><tr><td style="text-align:left">Structured Classification of Locomotion Modes for Wearable Robot Control</td><td style="text-align:right">2653</td></tr><tr><td style="text-align:left">Structured Reward Shaping Using Signal Temporal Logic Specifications</td><td style="text-align:right">1818</td></tr><tr><td style="text-align:left">Study on Elastic Elements Allocation for Energy-Efficient Robotic Cheetah Leg</td><td style="text-align:right">0928</td></tr><tr><td style="text-align:left">Study on Performance of Marker Detection Via Training Data Augmentation of Partial Distortion in Underwater Sonar Image</td><td style="text-align:right">2687</td></tr><tr><td style="text-align:left">Study on Stumbles of the Elderly from a Depth Perception Dependency Test</td><td style="text-align:right">1812</td></tr><tr><td style="text-align:left">Submodular Optimization for Coupled Task Allocation and Intermittent Deployment Problems</td><td style="text-align:right">2134</td></tr><tr><td style="text-align:left">Subspace-Based Direct Visual Servoing</td><td style="text-align:right">2161</td></tr><tr><td style="text-align:left">SuMa++: Efficient LiDAR-Based Semantic SLAM</td><td style="text-align:right">0228</td></tr><tr><td style="text-align:left">SVIn2: An Underwater SLAM System Using Sonar, Visual, Inertial, and Depth Sensor</td><td style="text-align:right">0269</td></tr><tr><td style="text-align:left">Synchronizing Virtual Constraints and Preview Controller: A Walking Pattern Generator for the Humanoid Robot COMAN+</td><td style="text-align:right">1061</td></tr><tr><td style="text-align:left">Synergy-Based Control for Multi-Fingered Hands Using Selected Joint Spaces</td><td style="text-align:right">2688</td></tr><tr><td style="text-align:left">Synthesizing Robot Manipulation Programs from a Single Observed Human Demonstration</td><td style="text-align:right">0328</td></tr><tr><td style="text-align:left">Systematic Benchmarking for Reproducibility of Computer Vision Algorithms for Real-Time Systems: The Example of Optic Flow Estimation</td><td style="text-align:right">0506</td></tr><tr><td style="text-align:left">Tactile-Based Insertion for Dense Box-Packing</td><td style="text-align:right">1881</td></tr><tr><td style="text-align:left">Tactile Localization for Unknown and Known Objects</td><td style="text-align:right">2628</td></tr><tr><td style="text-align:left">Talk to the Vehicle: Language Conditioned Autonomous Navigation of Self Driving Cars</td><td style="text-align:right">1765</td></tr><tr><td style="text-align:left">Target Classification and Prediction of Unguided Rocket Trajectories Using Deep Neural Networks</td><td style="text-align:right">2723</td></tr><tr><td style="text-align:left">Target Tracking of Moving and Rotating Object by High-Speed Monocular Active Vision</td><td style="text-align:right">2692</td></tr><tr><td style="text-align:left">Task-Motion Planning with Reinforcement Learning for Adaptable Mobile Service Robots</td><td style="text-align:right">1443</td></tr><tr><td style="text-align:left">Task-Oriented Grasping in Object Stacking Scenes with CRF-Based Semantic Model</td><td style="text-align:right">0663</td></tr><tr><td style="text-align:left">Task-Specific Self-Body Controller Acquisition by Musculoskeletal Humanoids: Application to Pedal Control in Autonomous Driving</td><td style="text-align:right">0109</td></tr><tr><td style="text-align:left">Teaching a Drone to Accompany a Person from Demonstrations Using Non-Linear ASFM</td><td style="text-align:right">1107</td></tr><tr><td style="text-align:left">Teleoperating Robots from the International Space Station: Microgravity Effects on Performance with Force Feedback</td><td style="text-align:right">0370</td></tr><tr><td style="text-align:left">TendencyRL: Multi-Stage Discriminative Hints for Efﬁcient Goal-Oriented Reverse Curriculum Learning</td><td style="text-align:right">0532</td></tr><tr><td style="text-align:left">TerrainFusion: Real-Time Digital Surface Model Reconstruction Based on Monocular SLAM</td><td style="text-align:right">0786</td></tr><tr><td style="text-align:left">The ANBOT: An Intelligent Robotic Co-Worker for Industrial Abrasive Blasting</td><td style="text-align:right">1497</td></tr><tr><td style="text-align:left">The ARMM System: Demonstrating Clinical Feasibility in Steering Magnetically Actuated Catheters in Endovascular Applications</td><td style="text-align:right">2648</td></tr><tr><td style="text-align:left">The Combination Function for Multi-Leg Modular Robot, Bio-Mimicked from Ant’s Behavior</td><td style="text-align:right">2657</td></tr><tr><td style="text-align:left">The Compliant Joint Toolbox for MATLAB: An Introduction with Examples</td><td style="text-align:right">2574</td></tr><tr><td style="text-align:left">The CoSTAR Block Stacking Dataset: Learning with Workspace Constraints</td><td style="text-align:right">1236</td></tr><tr><td style="text-align:left">The Impact of Domain Randomization on Object Detection: Case Study on Parametric Shapes and Synthetic Textures</td><td style="text-align:right">1333</td></tr><tr><td style="text-align:left">The MaSTr1325 Dataset for Training Deep USV Obstacle Detection Models</td><td style="text-align:right">1480</td></tr><tr><td style="text-align:left">Theoretical Foundation for Design of Friction-Tunable Soft Finger with Wrinkle’s Morphology</td><td style="text-align:right">2518</td></tr><tr><td style="text-align:left">The RGB-D Triathlon: Towards Agile Visual Toolboxes for Robots</td><td style="text-align:right">2357</td></tr><tr><td style="text-align:left">Thermal-Inertial Odometry for Autonomous Flight Throughout the Night</td><td style="text-align:right">1819</td></tr><tr><td style="text-align:left">The Road is Enough! Extrinsic Calibration of Non-overlapping Stereo Camera and LiDAR using Road Information</td><td style="text-align:right">2213</td></tr><tr><td style="text-align:left">The Robot Show Must Go On: Effective Responses to Robot Failures</td><td style="text-align:right">1280</td></tr><tr><td style="text-align:left">The Role of Robot Payload in the Safety Map Framework</td><td style="text-align:right">1984</td></tr><tr><td style="text-align:left">The “Smellicopter, “ a Bio-Hybrid Odor Localizing Nano Air Vehicle</td><td style="text-align:right">2245</td></tr><tr><td style="text-align:left">The Stability of Human Supervisory Control Operator Behavioral Models Using Hidden Markov Models</td><td style="text-align:right">1015</td></tr><tr><td style="text-align:left">Three-Degrees-Of-Freedom Passive Gravity Compensation Mechanism Applicable to Robotic Arm with Remote Center of Motion for Minimally Invasive Surgery</td><td style="text-align:right">2239</td></tr><tr><td style="text-align:left">Timed-Elastic Bands for Manipulation Motion Planning</td><td style="text-align:right">2371</td></tr><tr><td style="text-align:left">Timed-Elastic Smooth Curve Optimization for Mobile-Base Motion Planning</td><td style="text-align:right">1549</td></tr><tr><td style="text-align:left">Time-Delay Compensation Using Energy Tank for Satellite Dynamics Robotic Simulators</td><td style="text-align:right">1116</td></tr><tr><td style="text-align:left">Time-Optimal Path Tracking for Jerk Controlled Robots</td><td style="text-align:right">2375</td></tr><tr><td style="text-align:left">Time-Optimal Trajectory Generation for Dynamic Vehicles: A Bilevel Optimization Approach</td><td style="text-align:right">1850</td></tr><tr><td style="text-align:left">Timepix Radiation Detector for Autonomous Radiation Localization and Mapping by Micro Unmanned Vehicles</td><td style="text-align:right">2593</td></tr><tr><td style="text-align:left">Time Series Motion Generation Considering Long Short-Term Motion</td><td style="text-align:right">1608</td></tr><tr><td style="text-align:left">Time-Varying Graph Patrolling against Attackers with Locally Limited and Imperfect Observation Models</td><td style="text-align:right">0553</td></tr><tr><td style="text-align:left">TIMTAM: Tunnel-Image Texturally-Accorded Mosaic for Location Refinement of Underground Vehicles with a Single Camera</td><td style="text-align:right">2561</td></tr><tr><td style="text-align:left">TIP Model: A Combination of Unstable Subsystems for Lateral Balance in Walking</td><td style="text-align:right">1354</td></tr><tr><td style="text-align:left">Torso-Mounted Vibrotactile Interface to Experimentally Induce Illusory Own-Body Perceptions</td><td style="text-align:right">0367</td></tr><tr><td style="text-align:left">Toward a Ballbot for Physically Leading People: A Human-Centered Approach</td><td style="text-align:right">0920</td></tr><tr><td style="text-align:left">Toward a Bipedal Robot with Variable Gait Styles: Sagittal Forces Analysis in a Planar Simulation and a Prototype Ball-Tray Mechanism</td><td style="text-align:right">1446</td></tr><tr><td style="text-align:left">Toward Achieving Formal Guarantees for Human-Aware Controllers in Human-Robot Interaction</td><td style="text-align:right">1096</td></tr><tr><td style="text-align:left">Toward Affordance Detection and Ranking on Novel Objects for Real-World Robotic Manipulation</td><td style="text-align:right">2318</td></tr><tr><td style="text-align:left">Toward a Human-Machine Interface Based on Electrical Impedance Tomography for Robotic Manipulator Control</td><td style="text-align:right">0596</td></tr><tr><td style="text-align:left">Toward an Efficient Hybrid Interaction Paradigm for Object Manipulation in Optical See-Through Mixed Reality</td><td style="text-align:right">0084</td></tr><tr><td style="text-align:left">Toward a Versatile Robotic Platform for Fluoroscopy and MRI-Guided Endovascular Interventions: A Pre-Clinical Study</td><td style="text-align:right">1894</td></tr><tr><td style="text-align:left">Toward Controllable Morphogenesis in Large Robot Swarms</td><td style="text-align:right">2193</td></tr><tr><td style="text-align:left">Toward Improving Patient Safety and Surgeon Comfort in a Synergic Robot-Assisted Eye Surgery: A Comparative Study</td><td style="text-align:right">2256</td></tr><tr><td style="text-align:left">Toward Model-Based Benchmarking of Robot Components</td><td style="text-align:right">1224</td></tr><tr><td style="text-align:left">Towards Active Stabilization of Probe-Based Confocal Laser Endomicroscopy Using a Handheld Micromanipulator</td><td style="text-align:right">2680</td></tr><tr><td style="text-align:left">Towards a General Framework for Generating Stable and Flexible Locomotion Skills</td><td style="text-align:right">2736</td></tr><tr><td style="text-align:left">Towards a Generic in Vivo in Situ Camera Lens Cleaning Module for Laparoscopic Surgery</td><td style="text-align:right">0073</td></tr><tr><td style="text-align:left">Towards an Assisted Robotic Platform for Soft Neural Tissue Interaction</td><td style="text-align:right">2770</td></tr><tr><td style="text-align:left">Towards a Natural Motion Generator: A Pipeline to Control a Humanoid Based on Motion Data</td><td style="text-align:right">1573</td></tr><tr><td style="text-align:left">Towards an Autonomous Unwrapping System for Intralogistics</td><td style="text-align:right">2444</td></tr><tr><td style="text-align:left">Towards an Open-Source Micro Robot Oceanarium: A Low-Cost, Modular, and Mobile Underwater Motion-Capture System</td><td style="text-align:right">1925</td></tr><tr><td style="text-align:left">Towards a Robot Architecture for Situated Lifelong Object Learning</td><td style="text-align:right">1429</td></tr><tr><td style="text-align:left">Towards a Robust Aerial Cinematography Platform: Localizing and Tracking Moving Targets in Unstructured Environments</td><td style="text-align:right">1607</td></tr><tr><td style="text-align:left">Towards Autonomous Industrial-Scale Bathymetric Surveying</td><td style="text-align:right">1353</td></tr><tr><td style="text-align:left">Towards Ergonomic Control of Collaborative Effort in Multi-Human Mobile-Robot Teams</td><td style="text-align:right">0899</td></tr><tr><td style="text-align:left">Towards Explainable Shared Control Using Augmented Reality</td><td style="text-align:right">0448</td></tr><tr><td style="text-align:left">Towards Generalizing Sensorimotor Control Across Weather Conditions</td><td style="text-align:right">0954</td></tr><tr><td style="text-align:left">Towards Jumping Locomotion for Quadruped Robots on the Moon</td><td style="text-align:right">0801</td></tr><tr><td style="text-align:left">Towards Learning Trajectory Segmentation through Semi-Supervised Learning</td><td style="text-align:right">2767</td></tr><tr><td style="text-align:left">Towards More Realistic Human-Robot Conversation: A Seq2Seq-Based Body Gesture Interaction System</td><td style="text-align:right">1420</td></tr><tr><td style="text-align:left">Towards Reversible Dynamic Movement Primitives</td><td style="text-align:right">0753</td></tr><tr><td style="text-align:left">Towards the Design and Development of a Pediatric Neuroendoscope Tool</td><td style="text-align:right">1125</td></tr><tr><td style="text-align:left">T-PFC: A Trajectory-Optimized Perturbation Feedback Control Approach</td><td style="text-align:right">2388</td></tr><tr><td style="text-align:left">Tracking Control of Fully-Constrained Cable-Driven Parallel Robots Using Adaptive Dynamic Programming</td><td style="text-align:right">0777</td></tr><tr><td style="text-align:left">Training in Task Space to Speed Up and Guide Reinforcement Learning</td><td style="text-align:right">0186</td></tr><tr><td style="text-align:left">Trajectory Estimation for Geo-Fencing Applications on Small-Size Fixed-Wing UAVs</td><td style="text-align:right">1209</td></tr><tr><td style="text-align:left">Trajectory Optimization for Legged Robots with Slipping Motions</td><td style="text-align:right">2145</td></tr><tr><td style="text-align:left">Trajectory Optimization for Unknown Constrained Systems Using Reinforcement Learning</td><td style="text-align:right">1077</td></tr><tr><td style="text-align:left">Trajectory Planning for a Bat-Like Flapping Wing Robot</td><td style="text-align:right">0863</td></tr><tr><td style="text-align:left">Transferable Trial-Minimizing Progressive Peg-In-Hole Model</td><td style="text-align:right">0232</td></tr><tr><td style="text-align:left">Transfer learning for vision-based tactile sensing</td><td style="text-align:right">0248</td></tr><tr><td style="text-align:left">Trust but Verify: A Distributed Algorithm for Multi-Robot Wireframe Exploration and Mapping</td><td style="text-align:right">0720</td></tr><tr><td style="text-align:left">Tunable Contact Conditions and Grasp Hydrodynamics Using Gentle Fingertip Suction</td><td style="text-align:right">2575</td></tr><tr><td style="text-align:left">Twin Kinematics Approach for Robotic-Assisted Tele-Echography</td><td style="text-align:right">1979</td></tr><tr><td style="text-align:left">Two-View Fusion Based Convolutional Neural Network for Urban Road Detection</td><td style="text-align:right">0198</td></tr><tr><td style="text-align:left">TZC: Efficient Inter-Process Communication for Robotics Middleware with Partial Serialization</td><td style="text-align:right">0386</td></tr><tr><td style="text-align:left">UAV Landing at an Unknown Location Marked by a Radio Beacon</td><td style="text-align:right">1512</td></tr><tr><td style="text-align:left">Uncertainty-Aware Imitation Learning Using Kernelized Movement Primitives</td><td style="text-align:right">0255</td></tr><tr><td style="text-align:left">Underactuated Gripper with Forearm Roll Estimation for Human Limbs Manipulation in Rescue Robotics</td><td style="text-align:right">1320</td></tr><tr><td style="text-align:left">Understanding Multi-Robot Systems: On the Concept of Legibility</td><td style="text-align:right">0435</td></tr><tr><td style="text-align:left">Understanding Natural Language Instructions for Fetching Daily Objects Using GAN-Based Multimodal Target-Source Classification</td><td style="text-align:right">2288</td></tr><tr><td style="text-align:left">Unified Balance Control for Biped Robots Including Modification of Footsteps with Angular Momentum and Falling Detection Based on Capturability</td><td style="text-align:right">0126</td></tr><tr><td style="text-align:left">Unified Human-Robot Shared Control with Application to Haptic Telemanipulation</td><td style="text-align:right">1748</td></tr><tr><td style="text-align:left">Unstructured Terrain Navigation and Topographic Mapping with a Low-Cost Mobile Cuboid Robot</td><td style="text-align:right">0164</td></tr><tr><td style="text-align:left">Unsupervised Task Segmentation Approach for Bimanual Surgical Tasks Using Spatiotemporal and Variance Properties</td><td style="text-align:right">1244</td></tr><tr><td style="text-align:left">Unsupervised Traffic Accident Detection in First-Person Videos</td><td style="text-align:right">1278</td></tr><tr><td style="text-align:left">Untethered Quadrupedal Hopping on a Trampoline</td><td style="text-align:right">2677</td></tr><tr><td style="text-align:left">Upper-Limb Joint Angle Estimation Method with Commercial Depth Sensor for Planar Robot-Aided Reaching Movement</td><td style="text-align:right">2766</td></tr><tr><td style="text-align:left">Upper Limb Motion Simulation Algorithm for Prosthesis Prescription and Training</td><td style="text-align:right">1052</td></tr><tr><td style="text-align:left">Urban Street Trajectory Prediction with Multi-Class LSTM Networks</td><td style="text-align:right">2691</td></tr><tr><td style="text-align:left">Use of Deep Learning Based on Recurrent Neural Network for Modeling of Characteristics of a Pneumatic Artificial Muscle</td><td style="text-align:right">2617</td></tr><tr><td style="text-align:left">Variable Configuration Planner for Legged-Rolling Obstacle Negotiation Locomotion: Application on the CENTAURO Robot</td><td style="text-align:right">0134</td></tr><tr><td style="text-align:left">Variable Impedance in End-Effector Space: An Action Space for Reinforcement Learning in Contact-Rich Tasks</td><td style="text-align:right">1610</td></tr><tr><td style="text-align:left">Various Sized Obstacle and Stair Climbing Robot by Wheel Transformation: Prototype and Experimental Results</td><td style="text-align:right">2644</td></tr><tr><td style="text-align:left">Vehicular Multi-Camera Sensor System for Automated Visual Inspection of Electric Power Distribution Equipment</td><td style="text-align:right">1736</td></tr><tr><td style="text-align:left">View Management for Lifelong Visual Maps</td><td style="text-align:right">0649</td></tr><tr><td style="text-align:left">View Sharing to Enhance Driving Safety through Vehicle-To-Vehicle Communication</td><td style="text-align:right">2667</td></tr><tr><td style="text-align:left">ViLiVO: Virtual LiDAR-Visual Odometry for an Autonomous Vehicle with a Multi-Camera System</td><td style="text-align:right">2025</td></tr><tr><td style="text-align:left">Virtual Lane Boundary Generation for Human-Compatible Autonomous Driving: A Tight Coupling between Perception and Planning</td><td style="text-align:right">1364</td></tr><tr><td style="text-align:left">Virtual Maps for Autonomous Exploration with Pose SLAM</td><td style="text-align:right">1215</td></tr><tr><td style="text-align:left">Virtual-Mass-Ellipsoid Inverted Pendulum Model and Its Applications to 3D Bipedal Locomotion on Uneven Terrains</td><td style="text-align:right">0739</td></tr><tr><td style="text-align:left">Virtual Region Based Multi-Robot Path Planning in an Unknown Occluded Environment</td><td style="text-align:right">2127</td></tr><tr><td style="text-align:left">Vision-Aided Localization for Ground Robots</td><td style="text-align:right">0314</td></tr><tr><td style="text-align:left">Vision-Based Automatic Control of a 5-Fingered Simulated Assistive Robotic Manipulator for Activities of Daily Living</td><td style="text-align:right">0805</td></tr><tr><td style="text-align:left">Vision-Based Estimation of Driving Energy for Planetary Rovers Using Deep Learning and Terramechanics</td><td style="text-align:right">2329</td></tr><tr><td style="text-align:left">Vision-Based Magnetic Platform for Actuator Positioning and Wireless Control of Microrobots</td><td style="text-align:right">0479</td></tr><tr><td style="text-align:left">Vision-Based Virtual Fixtures Generation for Robotic-Assisted Polyp Dissection Procedures</td><td style="text-align:right">1167</td></tr><tr><td style="text-align:left">Visual-Based Autonomous Driving Deployment from a Stochastic and Uncertainty-Aware Perspective</td><td style="text-align:right">0055</td></tr><tr><td style="text-align:left">Visual Domain Adaptation Exploiting Confidence-Samples</td><td style="text-align:right">0222</td></tr><tr><td style="text-align:left">Visual-Inertial Localization with Prior LiDAR Map Constraints</td><td style="text-align:right">2271</td></tr><tr><td style="text-align:left">Visual-Inertial Odometry Tightly Coupled with Wheel Encoder Adopting Robust Initialization and Online Extrinsic Calibration</td><td style="text-align:right">0614</td></tr><tr><td style="text-align:left">Visual-Inertial Odometry with Point and Line Features</td><td style="text-align:right">1809</td></tr><tr><td style="text-align:left">Visual-Inertial On-Board Throw-And-Go Initialization for Micro Air Vehicles</td><td style="text-align:right">1957</td></tr><tr><td style="text-align:left">Visual Servo Control of a Novel Magnetic Actuated Endoscope for Uniportal Video Assisted Thoracic Surgery</td><td style="text-align:right">2228</td></tr><tr><td style="text-align:left">Visual Servoing of Miniature Magnetic Film Swimming Robots for 3D Arbitrary Path Following</td><td style="text-align:right">2521</td></tr><tr><td style="text-align:left">Voice-Controlled Flexible Exotendon (FLEXotendon) Glove for Hand Rehabilitation</td><td style="text-align:right">1130</td></tr><tr><td style="text-align:left">Volumetric Instance-Aware Semantic Mapping and 3D Object Discovery</td><td style="text-align:right">2118</td></tr><tr><td style="text-align:left">Volumetric Tree*: Adaptive Sparse Graph for Effective Exploration of Homotopy Classes</td><td style="text-align:right">1616</td></tr><tr><td style="text-align:left">Walking with Augmented Reality Real-Time Visual Feedback Wearing a Cable-Driven Active Leg Exoskeleton (C-ALEX)</td><td style="text-align:right">2485</td></tr><tr><td style="text-align:left">Walking with Confidence: Safety Regulation for Full Order Biped Models</td><td style="text-align:right">2526</td></tr><tr><td style="text-align:left">Wall-Mounted Robot Arm Equipped with 3-DOF Roll-Pitch-Pitch Counterbalance Mechanism</td><td style="text-align:right">2411</td></tr><tr><td style="text-align:left">Warped Hypertime Representations for Long-Term Autonomy of Mobile Robots</td><td style="text-align:right">2131</td></tr><tr><td style="text-align:left">Wearable Activity Recognition for Robust Human-Robot Teaming in Safety-Critical Environments Via Hybrid Neural Networks</td><td style="text-align:right">1950</td></tr><tr><td style="text-align:left">Whole-Body Control of Humanoid Robot in 3D Multi-Contact under Contact Wrench Constraints Including Joint Load Reduction with Self-Collision and Internal Wrench Distribution</td><td style="text-align:right">0670</td></tr><tr><td style="text-align:left">Whole-Body Control with (Self) Collision Avoidance Using Vector Field Inequalities</td><td style="text-align:right">2432</td></tr><tr><td style="text-align:left">Whole-Body Locomotion and Posture Control on a Torque-Controlled Hydraulic Rover</td><td style="text-align:right">2175</td></tr><tr><td style="text-align:left">Whole-Body Motion and Landing Force Control for Quadrupedal Stair Climbing</td><td style="text-align:right">1470</td></tr><tr><td style="text-align:left">Whole-Body Motion Planning for Walking Excavators</td><td style="text-align:right">0991</td></tr><tr><td style="text-align:left">Whole-Body MPC for a Dynamically Stable Mobile Manipulator</td><td style="text-align:right">2422</td></tr><tr><td style="text-align:left">Whole-Body Postural Control Approach Based on Multiple ZMP Evaluation in Humanoid Robots</td><td style="text-align:right">2638</td></tr><tr><td style="text-align:left">Wide Aperture Imaging Sonar Reconstruction Using Generative Models</td><td style="text-align:right">0138</td></tr><tr><td style="text-align:left">With Proximity Servoing towards Safe Human-Robot-Interaction</td><td style="text-align:right">1369</td></tr><tr><td style="text-align:left">WLR-II, a Hose-Less Hydraulic Wheel-Legged Robot</td><td style="text-align:right">0226</td></tr><tr><td style="text-align:left">Word2vec to Behavior: Morphology Facilitates the Grounding of Language in Machines</td><td style="text-align:right">1517</td></tr><tr><td style="text-align:left">WSRender: A Workspace Analysis and Visualization Toolbox for Robotic System Design and Verification</td><td style="text-align:right">2499</td></tr><tr><td style="text-align:left">YouWasps: Towards Autonomous Multi-Robot Mobile Deposition for Construction</td><td style="text-align:right">1282</td></tr></tbody></table></div>]]></content>
      
      
      
        <tags>
            
            <tag> IROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IROS2021文章目录</title>
      <link href="/2022/01/03/iros2021-paper-list/"/>
      <url>/2022/01/03/iros2021-paper-list/</url>
      
        <content type="html"><![CDATA[<h1 id="IROS2021PaperList"><a href="#IROS2021PaperList" class="headerlink" title="IROS2021PaperList"></a>IROS2021PaperList</h1><p>This repo lists all papers in IROS 2021. We list all papers according their themes alphabetically.</p><p>This year the conference received 2801 paper submissions, of which 45% were selected for publication. Each submission was reviewed by at least two reviewers, before receiving a summary report from an Associate Editor and a final report from the Editor. Based on these reviews and reports, the Senior Program Committee and the Program Chair made the final decisions.</p><ul><li>Actuation and Joint Mechanisms</li><li>Aerial Systems: Applications</li><li>Aerial Systems: Mechanics and Control</li><li>Aerial Systems: Perception and Autonomy</li><li>Autonomous Agents</li><li>Autonomous Vehicle Navigation</li><li>Biologically-Inspired Robots</li><li>Brain-Machine Interfaces</li><li>Calibration and Identification</li><li>Cellular and Modular Robots</li><li>Collision Avoidance</li><li>Compliance and Impedance Control</li><li>Compliant Joints and Mechanisms</li><li>Computer Vision Applications</li><li>Computer Vision for Automation</li><li>Computer Vision for Medical Robotics</li><li>Computer Vision for Transportation</li><li>Contact Modeling, Planning and Control</li><li>Control</li><li>Data Sets in Robotics</li><li>Deep Learning Methods</li><li>Deep Learning for Visual Perception</li><li>Deep Learning in Grasping and Manipulation</li><li>Dexterous Manipulation</li><li>Distributed Robot Systems</li><li>Factory Automation</li><li>Field Robots</li><li>Force and Tactile Sensing</li><li>Formal Methods in Robotics and Automation</li><li>Grasping</li><li>Grippers and Other End-Effectors</li><li>Haptics and Haptic Interfaces</li><li>Human Factors and Human-In-The-Loop</li><li>Human and Humanoid Motion Analysis and Synthesis</li><li>Human-Robot Collaboration</li><li>Humanoid Robot Systems</li><li>Humanoid and Bipedal Locomotion</li><li>Imitation Learning</li><li>Intelligent Transportation Systems</li><li>Intention Recognition</li><li>Learning from Demonstration</li><li>Learning from Experience</li><li>Legged Robots</li><li>Localization</li><li>Machine Learning for Robot Control</li><li>Manipulation Planning</li><li>Manufacturing Automation</li><li>Mapping</li><li>Marine Robotics</li><li>Mechanism Design</li><li>Medical Robots and Systems</li><li>Micro/Nano Robots</li><li>Mobile and Bimanual Manipulation</li><li>Model Learning for Control</li><li>Modeling, Control, and Learning for Soft Robots</li><li>Motion Control</li><li>Motion and Path Planning</li><li>Multi-Robot SLAM</li><li>Multi-Robot Systems</li><li>Object Detection, Segmentation and Categorization</li><li>Optimization and Optimal Control</li><li>Parallel Robots</li><li>Path Planning for Multiple Mobile Robots or Agents</li><li>Perception for Grasping and Manipulation</li><li>Perception-Action Coupling</li><li>Physical Human-Robot Interaction</li><li>Planning, Scheduling and Coordination</li><li>Prosthetics and Exoskeletons</li><li>RGB-D Perception</li><li>Range Sensing</li><li>Reactive and Sensor-Based Planning</li><li>Recognition</li><li>Reinforcement Learning</li><li>Representation Learning</li><li>Robot Safety</li><li>Robotic Systems and Benchmarking</li><li>Robotics and Automation in Agriculture and Forestry</li><li>Robotics and Automation in Agriculture, Forestry and Construction</li><li>SLAM</li><li>Semantic Scene Understanding</li><li>Sensor Fusion</li><li>Service, Art and Entertainment Robotics</li><li>Shared Autonomy for Physical Human-Robot Interaction</li><li>Simulation</li><li>Social Human-Robot Interaction</li><li>Soft Robot Applications</li><li>Soft Robot Materials and Design</li><li>Soft Sensors and Actuators</li><li>Software and Hardware</li><li>Space Robotics and Automation</li><li>Surgical Robotics</li><li>Swarm Robotics</li><li>Task and Motion Planning</li><li>Telerobotics and Teleoperation</li><li>Transfer Learning</li><li>Underactuated &amp; Redundant Robots</li><li>Vision-Based Navigation</li><li>Visual Learning</li><li>Visual Servoing</li><li>Visual Tracking</li><li>Visual-Inertial SLAM</li><li>Wearable Robotics</li><li>Wheeled Robots<h2 id="Actuation-and-Joint-Mechanisms"><a href="#Actuation-and-Joint-Mechanisms" class="headerlink" title="Actuation and Joint Mechanisms"></a>Actuation and Joint Mechanisms</h2></li><li>Convex Optimization for Spring Design in Series Elastic Actuators: From Theory to Practice</li><li>A Safe and Rapidly Switchable Stiffness Hydrostatic Actuator through Valve-Controlled Air Springs</li><li>Gear Ratio Optimization of a Multifunctional Walker Robot Using Dual-Motor Actuation</li><li>Slip Modeling and Simulation of Spiral Zipper Friction-Driven Prismatic Actuator</li><li>Design and Control of a Novel Compact Nonlinear Rotary Magnetic SEA (MSEA) for Practical Robotic Gripper Implementation</li><li>Passive Orientation Control of Nozzle Unit with Multiple Water Jets to Expand the Net Force Direction Range for Aerial Hose-Type Robots</li><li>Design and Analysis of High Stiffness Hyper-Redundant Manipulator with Sigma-Shaped Wire Path and Rolling Joints</li><li>Multi-Axis Electric Stepper Motor<h2 id="Aerial-Systems-Applications"><a href="#Aerial-Systems-Applications" class="headerlink" title="Aerial Systems: Applications"></a>Aerial Systems: Applications</h2></li><li>Design, Integration and Implementation of an Intelligent and Self-Recharging Drone System for Autonomous Power Line Inspection</li><li>GateNet: An Efficient Deep Neural Network Architecture for Gate Perception Using Fish-Eye Camera in Autonomous Drone Racing</li><li>CCRobot-IV-F: A Ducted-Fan-Driven Flying-Type Bridge Stay Cable Climbing Robot</li><li>REAL: Rapid Exploration with Active Loop-Closing Toward Large-Scale 3D Mapping Using UAVs</li><li>Stability and Robustness Analysis of Plug-Pulling Using an Aerial Manipulator</li><li>A Motion De-Coupled Aerial Robotic Manipulator for Better Inspection</li><li>Dynamic Grasping with a “Soft” Drone: From Theory to Practice</li><li>Hermes - Wind Energy Harvesting Wireless System for Sensing Angle of Attack and Wind Speed</li><li>Toward Battery-Free Flight: Duty Cycled Recharging of Small Drones</li><li>Aggressive Visual Perching with Quadrotors on Inclined Surfaces</li><li>Visibility-Aware Trajectory Optimization with Application to Aerial Tracking</li><li>Gamma-Ray Imaging with Spatially Continuous Intensity Statistics</li><li>3D Human Reconstruction in the Wild with Collaborative Aerial Cameras</li><li>Non-Prehensile Manipulation of Cuboid Objects Using a Catenary Robot<h2 id="Aerial-Systems-Mechanics-and-Control"><a href="#Aerial-Systems-Mechanics-and-Control" class="headerlink" title="Aerial Systems: Mechanics and Control"></a>Aerial Systems: Mechanics and Control</h2></li><li>Autonomous Cooperative Transportation System Involving Multi-Aerial Robots with Variable Attachment Mechanism</li><li>Decentralized Control and Teleoperation of a Multi-UAV Parallel Robot Based on Intrinsic Measurements</li><li>The New Dexterity Omnirotor Platform: Design, Modeling, and Control of a Modular, Versatile, All-Terrain Vehicle</li><li>Design, Optimal Guidance and Control of a Low-Cost Re-Usable Electric Model Rocket</li><li>Efficient Manoeuvring of Quadrotor under Constrained Space and Predefined Accuracy</li><li>Design and Comparison of Tails for Bird-Scale Flapping-Wing Robots</li><li>An Over-Actuated Multi-Rotor Aerial Vehicle with Unconstrained Attitude Angles and High Thrust Efficiencies</li><li>Nullspace-Based Control Allocation of Overactuated UAV Platforms</li><li>Vision-Encoder-Based Payload State Estimation for Autonomous MAV with a Suspended Payload</li><li>Aerodynamic Modeling of Fully-Actuated Multirotor UAVs with Nonparallel Actuators</li><li>Nonlinear Model Predictive Velocity Control of a VTOL Tiltwing UAV</li><li>Dynamic End Effector Tracking with an Omnidirectional Parallel Aerial Manipulator</li><li>Aerial Manipulator Suspended from a Cable-Driven Parallel Robot: Preliminary Experimental Results</li><li>Low-Level Pose Control of Tilting Multirotor for Wall Perching Tasks Using Reinforcement Learning</li><li>The Pursuit and Evasion of Drones Attacking an Automated Turret</li><li>A Morphing Quadrotor That Can Optimize Morphology for Transportation<h2 id="Aerial-Systems-Perception-and-Autonomy"><a href="#Aerial-Systems-Perception-and-Autonomy" class="headerlink" title="Aerial Systems: Perception and Autonomy"></a>Aerial Systems: Perception and Autonomy</h2></li><li>Why Fly Blind? Event-Based Visual Guidance for Ornithopter Robot Flight</li><li>Autonomous Flights in Dynamic Environments with Onboard Vision</li><li>Avoiding Dynamic Small Obstacles with Onboard Sensing and Computation on Aerial Robots</li><li>Target-Visible Polynomial Trajectory Generation within an MAV Team</li><li>Multi-Resolution Elevation Mapping and Safe Landing Site Detection with Applications to Planetary Rotorcraft</li><li>On the Visual-Based Safe Landing of UAVs in Populated Areas: A Crucial Aspect for Urban Deployment</li><li>Autonomous Quadrotor Landing on Inclined Surfaces Using Perception-Guided Active Asymmetric Skids</li><li>FAST-Dynamic-Vision: Detection and Tracking Dynamic Objects with Event and Depth Sensing</li><li>DarkLighter: Light up the Darkness for UAV Tracking</li><li>SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking</li><li>An Optical Spatial Localization System for Tracking Unmanned Aerial Vehicles Using a Single Dynamic Vision Sensor</li><li>Semantic-Aware Active Perception for UAVs Using Deep Reinforcement Learning</li><li>Real-Time Ellipse Detection for Robotics Applications</li><li>Topology-Guided Path Planning for Reliable Visual Navigation of MAVs</li><li>Semantically Informed Next Best View Planning for Autonomous Aerial 3D Reconstruction<h2 id="Autonomous-Agents"><a href="#Autonomous-Agents" class="headerlink" title="Autonomous Agents"></a>Autonomous Agents</h2></li><li>Fast Autonomous Robotic Exploration Using the Underlying Graph Structure</li><li>A High-Accuracy Framework for Vehicle Dynamic Modeling in Autonomous Driving</li><li>Monitoring Object Detection Abnormalities Via Data-Label and Post-Algorithm Abstractions</li><li>Agent-Aware State Estimation for Autonomous Vehicles</li><li>Designing and Deploying a Mobile UVC Disinfection Robot</li><li>The Reasonable Crowd: Towards Evidence-Based and Interpretable Models of Driving Behavior</li><li>Mobile Manipulation-Based Deployment of Micro Aerial Robot Scouts through Constricted Aperture-Like Ingress Points<h2 id="Autonomous-Vehicle-Navigation"><a href="#Autonomous-Vehicle-Navigation" class="headerlink" title="Autonomous Vehicle Navigation"></a>Autonomous Vehicle Navigation</h2></li><li>Gaussian Process-Based Interpretable Runtime Adaptation for Safe Autonomous Systems Operations in Unstructured Environments</li><li>Latent Attention Augmentation for Robust Autonomous Driving Policies</li><li>The Role of the Hercules Autonomous Vehicle During the COVID-19 Pandemic: An Autonomous Logistic Vehicle for Contactless Goods Transportation (I)</li><li>From Agile Ground to Aerial Navigation: Learning from Learned Hallucination</li><li>Robust Policy Search for an Agile Ground Vehicle under Perception Uncertainty</li><li>Road Graphical Neural Networks for Autonomous Roundabout Driving</li><li>Monitoring and Diagnosability of Perception Systems</li><li>On Fault Classification in Connected Autonomous Vehicles Using Output-Only Measurements</li><li>Autonomous Drone Racing with Deep Reinforcement Learning</li><li>Connecting Deep-Reinforcement-Learning-Based Obstacle Avoidance with Conventional Global Planners Using Waypoint Generators</li><li>A Kinematic Model for Trajectory Prediction in General Highway Scenarios</li><li>Unsupervised Traffic Scene Generation with Synthetic 3D Scene Graphs</li><li>Minimizing Safety Interference for Safe and Comfortable Automated Driving with Distributional Reinforcement Learning</li><li>Autonomous Vehicle Navigation in Semi-Structured Environments Based on Sparse Waypoints and LiDAR Road-Tracking</li><li>Deep Semantic Segmentation at the Edge for Autonomous Navigation in Vineyard Rows</li><li>Exploration-RRT: A Multi-Objective Path Planning and Exploration Framework for Unknown and Unstructured Environments</li><li>Learning Inverse Kinodynamics for Accurate High-Speed Off-Road Navigation on Unstructured Terrain</li><li>Pallet Detection and Docking Strategy for Autonomous Pallet Truck AGV Operation</li><li>Vulnerability of Connected Autonomous Vehicles Networks to Periodic Time-Varying Communication Delays of Certain Frequency</li><li>LiDAR Degradation Quantification for Autonomous Driving in Rain</li><li>Map-Aided Train Navigation with IMU Measurements</li><li>Evaluation of Long-Term LiDAR Place Recognition</li><li>KB-Tree: Learnable and Continuous Monte-Carlo Tree Search for Autonomous Driving Planning</li><li>Autonomous Mobile Robot Navigation Independent of Road Boundary Using Driving Recommendation Map</li><li>Learning-Based 3D Occupancy Prediction for Autonomous Navigation in Occluded Environments</li><li>Cooperative Autonomous Vehicles That Sympathize with Human Drivers</li><li>Shape Estimation of Negative Obstacles for Autonomous Navigation</li><li>Reinforcement Learning Based Negotiation-Aware Motion Planning of Autonomous Vehicles</li><li>Interaction-Based Trajectory Prediction Over a Hybrid Traffic Graph</li><li>Robust LiDAR Localization on an HD Vector Map without a Separate Localization Layer</li><li>Radar Odometry on SE(3) with Constant Velocity Motion Prior</li><li>AVP-Loc: Surround View Localization and Relocalization Based on HD Vector Map for Automated Valet Parking</li><li>Map Compressibility Assessment for LiDAR Registration</li><li>Online High-Level Model Estimation for Efficient Hierarchical Robot Navigation</li><li>Disentangling and Vectorization: A 3D Visual Perception Approach for Autonomous Driving Based on Surround-View Fisheye Cameras</li><li>Context and Orientation Aware Path Tracking<h2 id="Biologically-Inspired-Robots"><a href="#Biologically-Inspired-Robots" class="headerlink" title="Biologically-Inspired Robots"></a>Biologically-Inspired Robots</h2></li><li>Water Surface Stability Prediction of Amphibious Bio-Inspired Undulatory Fin Robot</li><li>Quasi-Static Motion of a New Serial Snake-Like Robot on a Water Surface: A Geometrical Approach</li><li>Simulating Ocean Wave Movement in a Soft Pneumatic Surface</li><li>Microspine-Rubber Composite for High Friction on Smooth, Rough, and Wet Surfaces</li><li>Wing Fold and Twist Greatly Improves Flight Efficiency for Bat-Scale Flapping Wing Robots</li><li>Development of a Bio-Inspired Soft Robotic Gripper Based on Tensegrity Structures</li><li>A Real-Time Motion Detection and Object Tracking Framework for Future Robot-Rat Interaction</li><li>Marine Autonomous Navigation for Biomimetic Underwater Robots Based on Deep Stereo Attention Network</li><li>Bat Bot 2.0: Bio-Inspired Anisotropic Skin, Passive Wrist Joints, and Redesigned Flapping Mechanism</li><li>Evolving Infotaxis for Meandering Environments</li><li>A Method to Use Nonlinear Dynamics in a Whisker Sensor for Terrain Identification by Mobile Robots</li><li>Robust Top-Down and Bottom-Up Visual Saliency for Mobile Robots Using Bio-Inspired Design Principles</li><li>Design of Galloping Robots with Elastic Spine: Tracking Relations between Dynamic Model Parameters Based on Motion Analysis of a Real Cheetah</li><li>Autonomous Decision Making in a Bioinspired Adaptive Robotic Anchoring Module</li><li>Design and Experimental Learning of Swimming Gaits for a Magnetic, Modular, Undulatory Robot</li><li>SENSORIMOTOR GRAPH: Action-Conditioned Graph Neural Network for Learning Robotic Soft Hand Dynamics</li><li>Insect-Inspired Odor Intake Method for Chemical Plume Tracing in an Outdoor Environment</li><li>Lateral Undulation of the Bendable Body of a Gecko-Inspired Robot for Energy-Efficient Inclined Surface Climbing</li><li>Crawl and Fly: A Bio-Inspired Robot Utilizing Unified Actuation for Hybrid Aerial-Terrestrial Locomotion</li><li>A Decentralized Bayesian Approach for Snake Robot Control</li><li>Hoop-Passing Motion for a Snake Robot to Realize Motion Transition across Different Environments (I)</li><li>Enabling Dynamic Behaviors with Aerodynamic Drag in Lightweight Tails (I)<h2 id="Brain-Machine-Interfaces"><a href="#Brain-Machine-Interfaces" class="headerlink" title="Brain-Machine Interfaces"></a>Brain-Machine Interfaces</h2></li><li>Design of an SSVEP-Based BCI Stimuli System for Attention-Based Robot Navigation in Robotic Telepresence</li><li>An Assistive Shared Control Architecture for a Robotic Arm Using EEG-Based BCI with Motor Imagery</li><li>A Wearable, Open-Source, Lightweight Forcemyography Armband: On Intuitive, Robust Muscle-Machine Interfaces</li><li>Manifold Trial Selection to Reduce Negative Transfer in Motor Imagery-Based Brain–Computer Interface</li><li>Neurointerface Implemented with Oscillator Motifs</li><li>Hybrid Graph Convolutional Neural Networks for Skeleton-Based and EEG-Based Lower Limb Action Recognition</li><li>Affect-Driven Robot Behavior Learning System Using EEG Signals for Less Negative Feelings and More Positive Outcomes<h2 id="Calibration-and-Identification"><a href="#Calibration-and-Identification" class="headerlink" title="Calibration and Identification"></a>Calibration and Identification</h2></li><li>SemAlign: Annotation-Free Camera-LiDAR Calibration with Semantic Alignment Loss</li><li>Kalibrot: A Simple-To-Use Matlab Package for Robot Kinematic Calibration</li><li>Odometry Model Calibration for Self-Driving Vehicles with Noise Correction</li><li>Pixel-Level Extrinsic Self Calibration of High Resolution LiDAR and Camera in Targetless Environments</li><li>A Two-Step Optimization for Extrinsic Calibration of Multiple Camera System (MCS) Using Depth-Weighted Normalized Points</li><li>Learning to Calibrate - Estimating the Hand-Eye Transformation without Calibration Objects</li><li>Single-Shot Is Enough: Panoramic Infrastructure Based Calibration of Multiple Cameras and 3D LiDARs</li><li>Kinodynamic Model Identification: A Unified Geometric Approach (I)<h2 id="Cellular-and-Modular-Robots"><a href="#Cellular-and-Modular-Robots" class="headerlink" title="Cellular and Modular Robots"></a>Cellular and Modular Robots</h2></li><li>Reconfiguring Metamorphic Robots Via SMT: Is It a Viable Way?</li><li>Balloon Animal Robots: Reconfigurable Isoperimetric Inflated Soft Robots</li><li>Self-Reconfiguration of Modular Robots Using Virtual Forces</li><li>CPG-Based Hierarchical Locomotion Control for Modular Quadrupedal Robots Using Deep Reinforcement Learning</li><li>Reconfiguring Non-Convex Holes in Pivoting Modular Cube Robots</li><li>Finding Structure Configurations for Flying Modular Robots</li><li>Enumeration of Polyominoes &amp; Polycubes Composed of Magnetic Cubes<h2 id="Collision-Avoidance"><a href="#Collision-Avoidance" class="headerlink" title="Collision Avoidance"></a>Collision Avoidance</h2></li><li>V-RVO: Decentralized Multi-Agent Collision Avoidance Using Voronoi Diagrams and Reciprocal Velocity Obstacles</li><li>Human-Inspired Multi-Agent Navigation Using Knowledge Distillation</li><li>Trajectory Splitting: A Distributed Formulation for Collision Avoiding Trajectory Optimization</li><li>Potential Gap: A Gap-Informed Reactive Policy for Safe Hierarchical Navigation</li><li>Comparative Analysis of Control Barrier Functions and Artificial Potential Fields for Obstacle Avoidance</li><li>DRQN-Based 3D Obstacle Avoidance with a Limited Field of View</li><li>Crowd-Aware Robot Navigation for Pedestrians with Multiple Collision Avoidance Strategies Via Map-Based Deep Reinforcement Learning</li><li>A Scalable Distributed Collision Avoidance Scheme for Multi-Agent UAV Systems</li><li>Trust Your Supervisor: Quadrotor Obstacle Avoidance Using Controlled Invariant Sets</li><li>Decentralized Multi-Robot Collision Avoidance in Complex Scenarios with Selective Communication</li><li>Toward Observation Based Least Restrictive Collision Avoidance Using Deep Meta Reinforcement Learning</li><li>Image-Based Online Command Adaptation and Guidance to Arbitrarily Shaped Objects for Robot-Assisted Medical Procedures</li><li>Continuous-Time Gaussian Process Trajectory Generation for Multi-Robot Formation Via Probabilistic Inference</li><li>Learning to Navigate in a VUCA Environment: Hierarchical Multi-Expert Approach</li><li>A Vision-Based Irregular Obstacle Avoidance Framework Via Deep Reinforcement Learning<h2 id="Compliance-and-Impedance-Control"><a href="#Compliance-and-Impedance-Control" class="headerlink" title="Compliance and Impedance Control"></a>Compliance and Impedance Control</h2></li><li>Circumventing Conceptual Flaws in Classical Interaction Control Strategies</li><li>Human Guided Trajectory and Impedance Adaptation for Tele-Operated Physical Assistance</li><li>Impedance Control for a Flexible Robot Enhanced with Energy Tanks in the Port-Hamiltonian Framework</li><li>Multi-Stage Energy-Aware Motion Control with Exteroception-Defined Dynamic Safety Metric</li><li>Online Impedance Adaptation Facilitates Manipulating a Whip</li><li>Analyzing the Performance Limits of Articulated Soft Robots Based on the ESPi Framework: Applications to Damping and Impedance Control</li><li>Adjustable Compliance and Force Feedback As Key Elements for Stable and Efficient Hopping</li><li>A Unified Approach for Virtual Fixtures and Goal-Driven Variable Admittance Control in Manual Guidance Applications<h2 id="Compliant-Joints-and-Mechanisms"><a href="#Compliant-Joints-and-Mechanisms" class="headerlink" title="Compliant Joints and Mechanisms"></a>Compliant Joints and Mechanisms</h2></li><li>A Self-Biasing Shape Memory Alloy Gripper for Lightweight Applications</li><li>A Compliant Five-Bar Legged Mechanism for Heavy-Load Legged Robots by Using Magneto-Rheological Actuators</li><li>Parallel Variable Stiffness Actuators</li><li>Novel Variable Stiffness Spring Mechanism: Modulating Stiffness Independent of the Energy Stored by the Spring</li><li>Self-Sensing McKibben Artificial Muscles Embedded with Dielectric Elastomer Sensor</li><li>An Analysis on the Modeling Accuracy of Industrial Manipulators with Inherent Joint Elasticity</li><li>Design and Analysis of a Twisted Elastic-Rail Actuator Based on a Double-Stranded Helix Structure<h2 id="Computer-Vision-Applications"><a href="#Computer-Vision-Applications" class="headerlink" title="Computer Vision Applications"></a>Computer Vision Applications</h2></li><li>Using Depth Vision for Terrain Detection During Active Locomotion</li><li>Robust and Accurate Point Set Registration with Generalized Bayesian Coherent Point Drift</li><li>Localization and Control of Magnetic Suture Needles in Cluttered Surgical Site with Blood and Tissue</li><li>LaneRCNN: Distributed Representations for Graph-Centric Motion Forecasting</li><li>StereoCNC: A Stereovision-Guided Robotic Laser System</li><li>Direct Bundle Adjustment for 3D Image Fusion with Application to Transesophageal Echocardiography</li><li>EOMVS: Event-Based Omnidirectional Multi-View Stereo<h2 id="Computer-Vision-for-Automation"><a href="#Computer-Vision-for-Automation" class="headerlink" title="Computer Vision for Automation"></a>Computer Vision for Automation</h2></li><li>Through the Looking Glass: Diminishing Occlusions in Robot Vision Systems with Mirror Reflections</li><li>Similarity-Aware Fusion Network for 3D Semantic Segmentation</li><li>RoRD: Rotation-Robust Descriptors and Orthographic Views for Local Feature Matching</li><li>Refractive Light-Field Features for Curved Transparent Objects in Structure from Motion</li><li>SRH-Net: Stacked Recurrent Hourglass Network for Stereo Matching</li><li>Phase-SLAM: Mobile Structured Light Illumination for Full Body 3D Scanning</li><li>Robotic Waste Sorting Technology: Toward a Vision-Based Categorization System for the Industrial Robotic Separation of Recyclable Waste (I)<h2 id="Computer-Vision-for-Medical-Robotics"><a href="#Computer-Vision-for-Medical-Robotics" class="headerlink" title="Computer Vision for Medical Robotics"></a>Computer Vision for Medical Robotics</h2></li><li>MBAPose: Mask and Bounding-Box Aware Pose Estimation of Surgical Instruments with Photorealistic Domain Randomization</li><li>Domain Adaptive Robotic Gesture Recognition with Unsupervised Kinematic-Visual Data Alignment</li><li>Towards a Compact Vision-Based Auto-Focusing System for Endoscopic Laser Surgery</li><li>Autonomous Scanning Target Localization for Robotic Lung Ultrasound Imaging</li><li>Semi-Supervised Vein Segmentation of Ultrasound Images for Autonomous Venipuncture</li><li>IVUS-Based Local Vessel Estimation for Robotic Intravascular Navigation</li><li>Surgical Tool Segmentation Using Generative Adversarial Networks with Unpaired Training Data</li><li>Real-Time 3D Navigation-Based Semi-Automatic Surgical Robotic System for Pelvic Fracture Reduction<h2 id="Computer-Vision-for-Transportation"><a href="#Computer-Vision-for-Transportation" class="headerlink" title="Computer Vision for Transportation"></a>Computer Vision for Transportation</h2></li><li>Unsupervised Vehicle Re-Identification Via Self-Supervised Metric Learning Using Feature Dictionary</li><li>Monocular 3D Vehicle Detection Using Uncalibrated Traffic Cameras through Homography</li><li>Drive on Pedestrian Walk. TUK Campus Dataset</li><li>Stereo Waterdrop Removal with Row-Wise Dilated Attention</li><li>Temporally-Continuous Probabilistic Prediction Using Polynomial Trajectory Parameterization</li><li>Content Disentanglement for Semantically Consistent Synthetic-To-Real Domain Adaptation</li><li>Cross-Modal 3D Object Detection and Tracking for Auto-Driving<h2 id="Contact-Modeling-Planning-and-Control"><a href="#Contact-Modeling-Planning-and-Control" class="headerlink" title="Contact Modeling, Planning and Control"></a>Contact Modeling, Planning and Control</h2></li><li>Contact Tracing: A Low Cost Reconstruction Framework for Surface Contact Interpolation</li><li>Real-Time Physically-Accurate Simulation of Robotic Snap Connection Process</li><li>Fundamental Challenges in Deep Learning for Stiff Contact Dynamics</li><li>Multi-Contact Locomotion Planning with Bilateral Contact Forces Considering Kinematics and Statics During Contact Transition</li><li>Computationally Efficient HQP-Based Whole-Body Control Exploiting the Operational-Space Formulation</li><li>Towards an Online Framework for Changing-Contact Robot Manipulation Tasks</li><li>Experimental Verification of Stability Theory for a Planar Rigid Body with Two Unilateral Frictional Contacts (I)<h2 id="Control"><a href="#Control" class="headerlink" title="Control"></a>Control</h2></li><li>Sensor Fusion-Based Anthropomorphic Control of Under-Actuated Bionic Hand in Dynamic Environment</li><li>Model-Based Trajectory Prediction and Hitting Velocity Control for a New Table Tennis Robot</li><li>Active Exploration and Mapping Via Iterative Covariance Regulation Over Continuous SE(3) Trajectories</li><li>Modeling and Control of PANTHERA Self-Reconfigurable Pavement Sweeping Robot under Actuator Constraints</li><li>Coloured Petri Nets for Monitoring Human Actions in Flexible Human-Robot Teams</li><li>Adaptive Passivity-Based Multi-Task Tracking Control for Robotic Manipulators</li><li>Amplification of Clamping Mechanism Using Internally-Balanced Magnetic Unit</li><li>Distributed Tube-Based Nonlinear MPC for Motion Control of Skid-Steer Robots with Terra-Mechanical Constraints<h2 id="Data-Sets-in-Robotics"><a href="#Data-Sets-in-Robotics" class="headerlink" title="Data Sets in Robotics"></a>Data Sets in Robotics</h2></li><li>Let’s Play for Action: Recognizing Activities of Daily Living by Learning from Life Simulation Video Games</li><li>The Radar Ghost Dataset – an Evaluation of Ghost Objects in Automotive Radar Data</li><li>ChangeSim: Towards End-To-End Online Scene Change Detection in Industrial Indoor Environments</li><li>Indoor Future Person Localization from an Egocentric Wearable Camera</li><li>Grounding Linguistic Commands to Navigable Regions</li><li>TUM-VIE: The TUM Stereo Visual-Inertial Event Dataset</li><li>Diverse Complexity Measures for Dataset Curation in Self-Driving</li><li>A Dataset for Provident Vehicle Detection at Night</li><li>Stereo Hybrid Event-Frame (SHEF) Cameras for 3D Perception</li><li>A Photorealistic Terrain Simulation Pipeline for Unstructured Outdoor Environments</li><li>NYU-VPR: Long-Term Visual Place Recognition Benchmark with View Direction and Data Anonymization Influences</li><li>Topo-Boundary: A Benchmark Dataset on Topological Road-Boundary Detection Using Aerial Images for Autonomous Driving</li><li>ROBI: A Multi-View Dataset for Reflective Objects in Robotic Bin-Picking</li><li>A Large-Scale Dataset for Water Segmentation of SAR Satellite</li><li>ESPADA: Extended Synthetic and Photogrammetric Aerial-Image Dataset<h2 id="Deep-Learning-Methods"><a href="#Deep-Learning-Methods" class="headerlink" title="Deep Learning Methods"></a>Deep Learning Methods</h2></li><li>Adversarial Training on Point Clouds for Sim-To-Real 3D Object Detection</li><li>CrossMap Transformer: A Crossmodal Masked Path TransformerUsing Double Back-Translation for Vision-And-Language Navigation</li><li>Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions</li><li>Target-Dependent UNITER: A Transformer-Based Multimodal Language Comprehension Model for Domestic Service Robots</li><li>Self-Critical Learning of Influencing Factors for Trajectory Prediction Using Gated Graph Convolutional Network</li><li>Trajectory Generation in New Environments from past Experiences</li><li>DistillPose: Lightweight Camera Localization Using Auxiliary Learning</li><li>Identifying Valid Robot Configurations Via a Deep Learning Approach</li><li>DiGNet: Learning Scalable Self-Driving Policies for Generic Traffic Scenarios with Graph Neural Networks</li><li>A General Approach to State Refinement</li><li>StyleLess Layer: Improving Robustness for Real-World Driving</li><li>Annotation Cost Reduction of Stream-Based Active Learning by Automated Weak Labeling Using a Robot Arm</li><li>Comprehension of Spatial Constraints by Neural Logic Learning from a Single RGB-D Scan</li><li>A CNN Based Vision-Proprioception Fusion Method for Robust UGV Terrain Classification</li><li>Visual-Tactile Cross-Modal Data Generation Using Residue-Fusion GAN with Feature-Matching and Perceptual Losses<h2 id="Deep-Learning-for-Visual-Perception"><a href="#Deep-Learning-for-Visual-Perception" class="headerlink" title="Deep Learning for Visual Perception"></a>Deep Learning for Visual Perception</h2></li><li>Geometry Guided Network for Point Cloud Registration</li><li>Graph Guided Deformation for Point Cloud Completion</li><li>Uncertainty-Aware Self-Supervised Learning of Spatial Perception Tasks</li><li>ADAADepth: Adapting Data Augmentation and Attention for Self-Supervised Monocular Depth Estimation</li><li>Unsupervised Image Segmentation by Mutual Information Maximization and Adversarial Regularization</li><li>MLPD: Multi-Label Pedestrian Detector in Multispectral Domain</li><li>Unsupervised Learning of Depth Estimation and Visual Odometry for Sparse Light Field Cameras</li><li>EVReflex: Dense Time-To-Impact Prediction for Event-Based Obstacle Avoidance</li><li>PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds</li><li>A Registration-Aided Domain Adaptation Network for 3D Point Cloud Based Place Recognition</li><li>INeRF: Inverting Neural Radiance Fields for Pose Estimation</li><li>RaP-Net: A Region-Wise and Point-Wise Weighting Network to Extract Robust Features for Indoor Localization</li><li>Differentiable Factor Graph Optimization for Learning Smoothers</li><li>Attention Augmented ConvLSTM for Environment Prediction</li><li>Overcoming Obstructions Via Bandwidth-Limited Multi-Agent Spatial Handshaking</li><li>Scene Descriptor Expressing Ambiguity in Information Recovery Based on Incomplete Partial Observation</li><li>Bootstrapped Self-Supervised Training with Monocular Video for Semantic Segmentation and Depth Estimation</li><li>Automatic Learning System for Object Function Points from Random Shape Generation and Physical Validation</li><li>Fast Image-Anomaly Mitigation for Autonomous Mobile Robots</li><li>Visual Identification of Articulated Object Parts</li><li>Unsupervised Monocular Depth Learning with Integrated Intrinsics and Spatio-Temporal Constraints</li><li>ViNet: Pushing the Limits of Visual Modality for Audio-Visual Saliency Prediction</li><li>MDN-VO: Estimating Visual Odometry with Confidence</li><li>Unsupervised Deep Persistent Monocular Visual Odometry and Depth Estimation in Extreme Environments</li><li>Correlate-And-Excite: Real-Time Stereo Matching Via Guided Cost Volume Excitation</li><li>Improving Robot Localisation by Ignoring Visual Distraction</li><li>Semantic Segmentation-Assisted Scene Completion for LiDAR Point Clouds</li><li>Dynamic Domain Adaptation for Single-View 3D Reconstruction</li><li>You Only Group Once: Efficient Point-Cloud Processing with Token Representation and Relation Inference Module</li><li>VIPose: Real-Time Visual-Inertial 6D Object Pose Tracking</li><li>Using Visual Anomaly Detection for Task Execution Monitoring</li><li>Moving SLAM: Fully Unsupervised Deep Learning in Non-Rigid Scenes</li><li>Pose Estimation from RGB Images of Highly Symmetric Objects Using a Novel Multi-Pose Loss and Differential Rendering</li><li>Denoising 3D Human Poses from Low-Resolution Video Using Variational Autoencoder</li><li>KDFNet: Learning Keypoint Distance Field for 6D Object Pose Estimation</li><li>All Characteristics Preservation: Single Image Dehazing Based on Hierarchical Detail Reconstruction Wavelet Decomposition Network</li><li>PCTMA-Net: Point Cloud Transformer with Morphing Atlas-Based Point Generation Network for Dense Point Cloud Completion</li><li>Superline: A Robust Line Segment Feature for Visual SLAM</li><li>ORStereo: Occlusion-Aware Recurrent Stereo Matching for 4K-Resolution Images</li><li>Model Adaptation through Hypothesis Transfer with Gradual Knowledge Distillation</li><li>VoluMon: Weakly Supervised Volumetric Monocular Estimation with Ellipsoid Representations</li><li>Cross-Modal Representation Learning for Lightweight and Accurate Facial Action Unit Detection</li><li>Stereo Matching by Self-Supervision of Multiscopic Vision<h2 id="Deep-Learning-in-Grasping-and-Manipulation"><a href="#Deep-Learning-in-Grasping-and-Manipulation" class="headerlink" title="Deep Learning in Grasping and Manipulation"></a>Deep Learning in Grasping and Manipulation</h2></li><li>Simultaneous Semantic and Collision Learning for 6-DoF Grasp Pose Estimation</li><li>Efficient Learning of Goal-Oriented Push-Grasping Synergy in Clutter</li><li>Iterative Coarse-To-Fine 6D-Pose Estimation Using Back-Propagation</li><li>Understanding Human Manipulation with the Environment: A Novel Taxonomy for Video Labelling</li><li>Excavation Learning for Rigid Objects in Clutter</li><li>Fast-Learning Grasping and Pre-Grasping Via Clutter Quantization and Q-Map Masking</li><li>Joint Space Control Via Deep Reinforcement Learning</li><li>Precise Object Placement with Pose Distance Estimations for Different Objects and Grippers</li><li>Learning to Detect Multi-Modal Grasps for Dexterous Grasping in Dense Clutter</li><li>Double-Dot Network for Antipodal Grasp Detection</li><li>Neural Motion Prediction for In-Flight Uneven Object Catching</li><li>Learning a Generative Transition Model for Uncertainty-Aware Robotic Manipulation</li><li>Occlusion-Aware Search for Object Retrieval in Clutter</li><li>Grasp Pose Detection from a Single RGB Image</li><li>DepthGrasp: Depth Completion of Transparent Objects Using Self-Attentive Adversarial Network with Spectral Residual for Grasping</li><li>Reactive Long Horizon Task Execution Via Visual Skill and Precondition Models</li><li>Efficient and Accurate Candidate Generation for Grasp Pose Detection in SE(3)</li><li>DemoGrasp: Few-Shot Learning for Robotic Grasping with Human Demonstration</li><li>Graph-Based Task-Specific Prediction Models for Interactions between Deformable and Rigid Objects</li><li>GhostPose*: Multi-View Pose Estimation of Transparent Objects for Robot Hand Grasping</li><li>Reinforcement Learning for Vision-Based Object Manipulation with Non-Parametric Policy and Action Primitives<h2 id="Dexterous-Manipulation"><a href="#Dexterous-Manipulation" class="headerlink" title="Dexterous Manipulation"></a>Dexterous Manipulation</h2></li><li>Casting Manipulation of Unknown String by Robot Arm</li><li>Deformation Control of a Deformable Object Based on Visual and Tactile Feedback</li><li>A Soft Robotic Gripper with an Active Palm and Reconfigurable Fingers for Fully Dexterous In-Hand Manipulation</li><li>The Stewart Hand: A Highly Dexterous 6-Degrees-Of-Freedom Manipulator Based on the Stewart-Gough Platform (I)</li><li>Real-Time Safety and Control of Robotic Manipulators with Torque Saturation in Operational Space</li><li>Robot Hand Based on a Spherical Parallel Mechanism for Within-Hand Rotations about a Fixed Point</li><li>Learning Compliant Grasping and Manipulation by Teleoperation with Adaptive Force Control<h2 id="Distributed-Robot-Systems"><a href="#Distributed-Robot-Systems" class="headerlink" title="Distributed Robot Systems"></a>Distributed Robot Systems</h2></li><li>Optimal Scheduling and Non-Cooperative Distributed Model Predictive Control for Multiple Robotic Manipulators</li><li>OneVision: Centralized to Distributed Controller Synthesis with Delay Compensation</li><li>Robofleet: Open Source Communication and Management for Fleets of Autonomous Robots</li><li>Learning Connectivity for Data Distribution in Robot Teams</li><li>Neural Tree Expansion for Multi-Robot Planning in Non-Cooperative Environments</li><li>Deadlock Prediction and Recovery for Distributed Collision Avoidance with Buffered Voronoi Cells</li><li>Scalable Distributed Planning for Multi-Robot, Multi-Target Tracking<h2 id="Factory-Automation"><a href="#Factory-Automation" class="headerlink" title="Factory Automation"></a>Factory Automation</h2></li><li>State Estimation and Model-Predictive Control for Multi-Robot Handling and Tracking of AGV Motions Using IGPS</li><li>Benchmarking Off-The-Shelf Solutions to Robotic Assembly Tasks</li><li>Assembly Sequence Generation for New Objects Via Experience Learned from Similar Object</li><li>Combining Learning from Demonstration with Learning by Exploration to Facilitate Contact-Rich Tasks</li><li>Learn to Differ: Sim2Real Small Defection Segmentation Network</li><li>Control Strategy for Jam and Wedge-Free 3D Precision Insertion of Heavy Objects Suspended with a Multi-Cable Crane</li><li>Combining Unsupervised Muscle Co-Contraction Estimation with Bio-Feedback Allows Augmented Kinesthetic Teaching<h2 id="Field-Robots"><a href="#Field-Robots" class="headerlink" title="Field Robots"></a>Field Robots</h2></li><li>3D Reactive Control and Frontier-Based Exploration for Unstructured Environments</li><li>Adaptive Terrain Traversability Prediction Based on Multi-Source Transfer Gaussian Processes</li><li>Multiclass Terrain Classification Using Sound and Vibration from Mobile Robot Terrain Interaction</li><li>Perceptive Autonomous Stair Climbing for Quadrupedal Robots</li><li>Trajectory Selection for Power-Over-Tether Atmospheric Sensing UAS</li><li>CCRobot-IV: An Obstacle-Free Split-Type Quad-Ducted Propeller-Driven Bridge Stay Cable-Climbing Robot</li><li>An Industrial Robot for Firewater Piping Inspection and Mapping</li><li>A Mixed Reality Supervision and Telepresence Interface for Outdoor Field Robotics<h2 id="Force-and-Tactile-Sensing"><a href="#Force-and-Tactile-Sensing" class="headerlink" title="Force and Tactile Sensing"></a>Force and Tactile Sensing</h2></li><li>A Soft Somesthetic Robotic Finger Based on Conductive Working Liquid and an Origami Structure</li><li>Extended Tactile Perception: Vibration Sensing through Tools and Grasped Objects</li><li>AuraSense: Robot Collision Avoidance by Full Surface Proximity Detection</li><li>A Low-Cost Modular System of Customizable, Versatile, and Flexible Tactile Sensor Arrays</li><li>Self-Contained Kinematic Calibration of a Novel Whole-Body Artificial Skin for Human-Robot Collaboration</li><li>A Multi-Chamber Smart Suction Cup for Adaptive Gripping and Haptic Exploration</li><li>A Multi-Axis FBG-Based Tactile Sensor for Gripping in Space</li><li>Active Visuo-Tactile Point Cloud Registration for Accurate Pose Estimation of Objects in an Unknown Workspace</li><li>High Dynamic Range 6-Axis Force Sensor Employing a Semiconductor-Metallic Foil Strain Gauge Combination</li><li>Tactile Scanning for Detecting Micro Bump by Strain-Sensitive Artificial Skin</li><li>A Force Recognition System for Distinguishing Click Responses of Various Objects</li><li>A Robust Controller for Stable 3D Pinching Using Tactile Sensing</li><li>Dynamic Modeling of Hand-Object Interactions Via Tactile Sensing</li><li>A Local Filtering Technique for Robot Skin Data</li><li>Energy Generating Electronic Skin with Intrinsic Tactile Sensing without Touch Sensors (I)<h2 id="Formal-Methods-in-Robotics-and-Automation"><a href="#Formal-Methods-in-Robotics-and-Automation" class="headerlink" title="Formal Methods in Robotics and Automation"></a>Formal Methods in Robotics and Automation</h2></li><li>Sensor Selection for Detecting Deviations from a Planned Itinerary</li><li>Autonomous Decision-Making with Incomplete Information and Safety Rules Based on Non-Monotonic Reasoning</li><li>Automata-Based Optimal Planning with Relaxed Specifications</li><li>Probabilistically Guaranteed Satisfaction of Temporal Logic Constraints During Reinforcement Learning</li><li>Learning from Demonstrations Using Signal Temporal Logic in Stochastic and Continuous Domains</li><li>Attainment Regions in Feature-Parameter Space for High-Level Debugging in Autonomous Robots</li><li>A Topological Approach to Finding Coarsely Diverse Paths</li><li>Probabilistic Specification Learning for Planning with Safety Constraints</li><li>Modular Deep Reinforcement Learning for Continuous Motion Planning with Temporal Logic</li><li>Safe Linear Temporal Logic Motion Planning in Dynamic Environments</li><li>Decentralized Classification with Assume-Guarantee Planning</li><li>Wasserstein-Splitting Gaussian Process Regression for Heterogeneous Online Bayesian Inference</li><li>Formalizing the Execution Context of Behavior Trees for Runtime Verification of Deliberative Policies</li><li>Probabilistic Trajectory Prediction with Structural Constraints</li><li>Formalizing Trajectories in Human-Robot Encounters Via Probabilistic STL Inference</li><li>Convex Approximation for LTL-Based Planning<h2 id="Grasping"><a href="#Grasping" class="headerlink" title="Grasping"></a>Grasping</h2></li><li>Temporal Force Synergies in Human Grasping</li><li>Trajectory-Based Split Hindsight Reverse Curriculum Learning</li><li>Detecting Grasp Phases and Adaption of Object-Hand Interaction Forces of a Soft Humanoid Hand Based on Tactile Feedback</li><li>SpectGRASP: Robotic Grasping by Spectral Correlation</li><li>Assessing Grasp Quality Using Local Sensitivity Analysis</li><li>Geometry-Based Grasping Pipeline for Bi-Modal Pick and Place</li><li>Computing a Task-Dependent Grasp Metric Using Second-Order Cone Programs</li><li>Multi-Object Grasping — Estimating the Number of Objects in a Robotic Grasp</li><li>PackerBot: Variable-Sized Product Packing with Heuristic Deep Reinforcement Learning</li><li>Geometric Characterization of the Planar Multi-Finger Equilibrium Grasps</li><li>Formulation and Validation of an Intuitive Quality Measure for Antipodal Grasp Pose Evaluation</li><li>Scooping Manipulation Via Motion Control with a Two-Fingered Gripper and Its Application to Bin Picking</li><li>DDGC: Generative Deep Dexterous Grasping in Clutter</li><li>Planning Grasps with Suction Cups and Parallel Grippers Using Superimposed Segmentation of Object Meshes (I)<h2 id="Grippers-and-Other-End-Effectors"><a href="#Grippers-and-Other-End-Effectors" class="headerlink" title="Grippers and Other End-Effectors"></a>Grippers and Other End-Effectors</h2></li><li>A Three-Fingered Adaptive Gripper with Multiple Grasping Modes</li><li>Dexterous Textile Manipulation Using Electroadhesive Fingers</li><li>A Series Elastic, Compact Differential Mechanism: On the Development of Adaptive, Lightweight Robotic Grippers and Hands</li><li>Computational Design of Reconfigurable Underactuated Linkages for Adaptive Grippers</li><li>A Multi-Modal Robotic Gripper with a Reconfigurable Base: Improving Dexterous Manipulation without Compromising Grasping Efficiency</li><li>Grasping with Embedded Synergies through a Reconfigurable Electric Actuation Topology</li><li>An Under-Actuated Whippletree Mechanism Gripper Based on Multi-Objective Design Optimization with Auto-Tuned Weights</li><li>A Caging Inspired Gripper Using Flexible Fingers and a Movable Palm</li><li>The Role of Digit Arrangement in Soft Robotic In-Hand Manipulation</li><li>A Dexterous, Reconfigurable Robot Hand Combining Anthropomorphic and Interdigitated Configurations</li><li>A Computational Framework for Robot Hand Design Via Reinforcement Learning</li><li>Variable-Grasping-Mode Gripper with Different Finger Structures for Grasping Small-Sized Items</li><li>Force Control with Friction Compensation in a Pneumatic Gripper</li><li>Analysis of Fingertip Force Vector for Pinch-Lifting Gripper with Robust Adaptation to Environments (I)<h2 id="Haptics-and-Haptic-Interfaces"><a href="#Haptics-and-Haptic-Interfaces" class="headerlink" title="Haptics and Haptic Interfaces"></a>Haptics and Haptic Interfaces</h2></li><li>Design and Validation of a Smartphone-Based Haptic Feedback System for Gait Training</li><li>Robotic Guidance System for Visually Impaired Users Running Outdoors Using Haptic Feedback</li><li>Variable Stiffness Folding Joints for Haptic Feedback</li><li>Can a Vibrotactile Stimulation on Fingertips Make an Illusion of Elbow Joint Movement?</li><li>Two-Stage Optimization of a Reconfigurable Asymmetric 6-DOF Haptic Robot for Task-Specific Workspace</li><li>Stable Haptic Teleoperation of UAVs Via Small L2 Gain and Control Barrier Functions</li><li>A Novel Testbed for Investigating the Impact of Teleoperator Dynamics on Perceived Environment Dynamics<h2 id="Human-Factors-and-Human-In-The-Loop"><a href="#Human-Factors-and-Human-In-The-Loop" class="headerlink" title="Human Factors and Human-In-The-Loop"></a>Human Factors and Human-In-The-Loop</h2></li><li>Effect of Display Response Time on Brain Activity in Human–Machine Interface Commander Operation</li><li>Improving Driver Situation Awareness Prediction Using Human Visual Sensory and Memory Mechanism</li><li>Asking the Right Questions: Facilitating Semantic Constraint Specification for Robot Skill Learning and Repair</li><li>Using Bayesian Optimization to Identify Optimal Exoskeleton Parameters Targeting Propulsion Mechanics: A Simulation Study</li><li>What Information Should a Robot Convey?</li><li>Not All Users Are the Same: Providing Personalized Explanations for Sequential Decision Making Problems</li><li>Online Recognition of Bimanual Coordination Provides Important Context for Movement Data in Bimanual Teleoperated Robots</li><li>Iterative Program Synthesis for Adaptable Social Navigation<h2 id="Human-and-Humanoid-Motion-Analysis-and-Synthesis"><a href="#Human-and-Humanoid-Motion-Analysis-and-Synthesis" class="headerlink" title="Human and Humanoid Motion Analysis and Synthesis"></a>Human and Humanoid Motion Analysis and Synthesis</h2></li><li>Multitask Variational Autoencoding of Human-To-Human Object Handover</li><li>Synergetic Gait Prediction for Stroke Rehabilitation with Varying Walking Speeds</li><li>Organization and Understanding of a Tactile Information Dataset TacAct for Physical Human-Robot Interactions</li><li>Towards Human Haptic Gesture Interpretation for Robotic Systems</li><li>State Estimation of a Partially Observable Multi-Link System with No Joint Encoders Incorporating External Dead-Reckoning</li><li>Computationally Affordable Hierarchical Framework for Humanoid Robot Control</li><li>Domain and View-Point Agnostic Hand Action Recognition<h2 id="Human-Robot-Collaboration"><a href="#Human-Robot-Collaboration" class="headerlink" title="Human-Robot Collaboration"></a>Human-Robot Collaboration</h2></li><li>Online Verification of Impact-Force-Limiting Control for Physical Human-Robot Interaction</li><li>Dual-Filtering for On-Line Simultaneously Estimate Weights and Phase Parameter of Probabilistic Movement Primitives for Human-Robot Collaboration</li><li>Sampling-Based Inverse Reinforcement Learning Algorithms with Safety Constraints</li><li>Radar Based Target Tracking and Classification for Efficient Robot Speed Control in Fenceless Environments</li><li>“Safe Skin” - a Low-Cost Capacitive Proximity-Force-Fusion Sensor for Safety in Robots</li><li>Real-Time Obstacle Avoidance Using Dual-Type Proximity Sensor for Safe Human-Robot Interaction</li><li>Human-Robot Collaboration: Optimizing Stress and Productivity Based on Game Theory</li><li>Learning to Share Autonomy across Repeated Interaction</li><li>Cooperative Assistance in Robotic Surgery through Multi-Agent Reinforcement Learning</li><li>Improving Competence Via Iterative State Space Refinement</li><li>An Analysis of Human-Robot Information Streams to Inform Dynamic Autonomy Allocation</li><li>Extending Referring Expression Generation through Shared Knowledge about past Human-Robot Collaborative Activity</li><li>Learning and Interactive Design of Shared Control Templates</li><li>A Safety-Aware Architecture for Task Scheduling and Execution for Human-Robot Collaboration</li><li>Human-Robot Collaboration for Heavy Object Manipulation: Kinesthetic Teaching of the Role of Wheeled Mobile Manipulator</li><li>Non-Local Graph Convolutional Network for Joint Prediction of Activity Recognition and Future Motion</li><li>PiPo-Net: A Semi-Automatic and Polygon-Based Annotation Method for Pathological Images</li><li>Multi-Scenario Contacts Handling for Collaborative Robots Applications</li><li>Generating Active Explicable Plans in Human-Robot Teaming</li><li>Telemanipulation Via Virtual Reality Interfaces with Enhanced Environment Models</li><li>A Transformable Human-Carrying Wheel–leg Mobility for Daily Use</li><li>Probabilistic Decision Model for Adaptive Task Planning in Human-Robot Collaborative Assembly Based on Designer and Operator Intents<h2 id="Humanoid-Robot-Systems"><a href="#Humanoid-Robot-Systems" class="headerlink" title="Humanoid Robot Systems"></a>Humanoid Robot Systems</h2></li><li>Dynamical Effect of Elastically Supported Wobbling Mass on Biped Running</li><li>Dynamic Fall Recovery Motion Generation on Biped Robot with Shell Protector</li><li>Human Trajectory Prediction Model and Its Coupling with a Walking Pattern Generator of a Humanoid Robot</li><li>Communicative Learning with Natural Gestures for Embodied Navigation Agents with Human-In-The-Scene</li><li>The ARoA Platform: An Autonomous Robotic Assistant with a Reconfigurable Torso System and Dexterous Manipulation Capabilities</li><li>Dynamic Humanoid Locomotion Over Rough Terrain with Streamlined Perception-Control Pipeline</li><li>Drop Prevention Control for Humanoid Robots Carrying Stacked Boxes<h2 id="Humanoid-and-Bipedal-Locomotion"><a href="#Humanoid-and-Bipedal-Locomotion" class="headerlink" title="Humanoid and Bipedal Locomotion"></a>Humanoid and Bipedal Locomotion</h2></li><li>Fast Online Planning for Bipedal Locomotion Via Centroidal Model Predictive Gait Synthesis</li><li>Knee-Stretched Biped Gait Generation Along Spatially Quantized Curves</li><li>Humanoid Loco-Manipulations Pattern Generation and Stabilization Control</li><li>Robust Feedback Motion Policy Design Using Reinforcement Learning on a 3D Digit Bipedal Robot</li><li>Learning When to Switch: Composing Controllers to Traverse a Sequence of Terrain Artifacts</li><li>Impact Invariant Control with Applications to Bipedal Locomotion</li><li>Learning Linear Policies for Robust Bipedal Locomotion on Terrains with Varying Slopes<h2 id="Imitation-Learning"><a href="#Imitation-Learning" class="headerlink" title="Imitation Learning"></a>Imitation Learning</h2></li><li>Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement Learning</li><li>Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos</li><li>Contrastively Learning Visual Attention As Affordance Cues from Demonstrations for Robotic Grasping</li><li>Seeing All the Angles: Learning Multiview Manipulation Policies for Contact-Rich Tasks from Demonstrations</li><li>Adaptive T-Momentum-Based Optimization for Unknown Ratio of Outliers in Amateur Data in Imitation Learning</li><li>Robust Behavior Cloning with Adversarial Demonstration Detection</li><li>State-Only Imitation Learning for Dexterous Manipulation</li><li>Generalization through Hand-Eye Coordination: An Action Space for Learning Spatially-Invariant Visuomotor Control</li><li>Imitation Learning with Approximated Behavior Cloning Loss</li><li>Risk Averse Bayesian Reward Learning for Autonomous Navigation from Human Demonstration</li><li>Decentralized, Unlabeled Multi-Agent Navigation in Obstacle-Rich Environments Using Graph Neural Networks</li><li>Multi-Robot Coverage and Exploration Using Spatial Graph Neural Networks</li><li>Unsupervised Temporal Segmentation Using Models That Discriminate between Demonstrations and Unintentional Actions</li><li>Imitation Learning with Additional Constraints on Motion Style Using Parametric Bias</li><li>Transformer-Based Deep Imitation Learning for Dual-Arm Robot Manipulation<h2 id="Intelligent-Transportation-Systems"><a href="#Intelligent-Transportation-Systems" class="headerlink" title="Intelligent Transportation Systems"></a>Intelligent Transportation Systems</h2></li><li>Dynamic Lambda-Field: A Counterpart of the Bayesian Occupancy Grid for Risk Assessment in Dynamic Environments</li><li>3D Radar Velocity Maps for Uncertain Dynamic Environments</li><li>Extended VINS-Mono: A Systematic Approach for Absolute and Relative Vehicle Localization in Large-Scale Outdoor Environments</li><li>Automated Type-Aware Traffic Speed Prediction Based on Sparse Intelligent Camera System</li><li>Vision-Based Control of an Unknown Suspended Payload with a Multirotor</li><li>Gridlock-Free Autonomous Parking Lots for Autonomous Vehicles</li><li>Maneuver-Based Trajectory Prediction for Self-Driving Cars Using Spatio-Temporal Convolutional Networks</li><li>Decoder Fusion RNN: Context and Interaction Aware Decoders for Trajectory Prediction</li><li>Finding Failures in High-Fidelity Simulation Using Adaptive Stress Testing and the Backward Algorithm</li><li>Fine-Grained Off-Road Semantic Segmentation and Mapping Via Contrastive Learning</li><li>Multiple Contextual Cues Integrated Trajectory Prediction for Autonomous Driving</li><li>Vehicle Dispatch in On-Demand Ride-Sharing with Stochastic Travel Times</li><li>BEV-Net: A Bird’s Eye View Object Detection Network for LiDAR Point Cloud</li><li>Cooperative Transportation Robot System Using Risk-Sensitive Stochastic Control</li><li>Diverse Critical Interaction Generation for Planning and Planner Evaluation</li><li>Interpretable Goal Recognition in the Presence of Occluded Factors for Autonomous Vehicles</li><li>Semi-Cooperative Control for Autonomous Emergency Vehicles</li><li>RV-FuseNet: Range View Based Fusion of Time-Series LiDAR Data for Joint 3D Object Detection and Motion Forecasting</li><li>A Simple and Efficient Multi-Task Network for 3D Object Detection and Road Understanding</li><li>DeepSIL: A Software-In-The-Loop Framework for Evaluating Motion Planning Schemes Using Multiple Trajectory Prediction Networks</li><li>Joint Intention and Trajectory Prediction Based on Transformer<h2 id="Intention-Recognition"><a href="#Intention-Recognition" class="headerlink" title="Intention Recognition"></a>Intention Recognition</h2></li><li>An Efficient Understandability Objective for Dynamic Optimal Control</li><li>A Multimodal and Hybrid Framework for Human Navigational Intent Inference</li><li>Multi-Modal Scene-Compliant User Intention Estimation in Navigation</li><li>Simultaneous Prediction of Pedestrian Trajectory and Actions Based on Context Information Iterative Reasoning</li><li>Safety-Oriented Pedestrian Occupancy Forecasting</li><li>GRIT: Fast, Interpretable, and Verifiable Goal Recognition with Learned Decision Trees for Autonomous Driving</li><li>CovarianceNet: Conditional Generative Model for Correct Covariance Prediction in Human Motion Prediction<h2 id="Learning-from-Demonstration"><a href="#Learning-from-Demonstration" class="headerlink" title="Learning from Demonstration"></a>Learning from Demonstration</h2></li><li>Learning Forceful Manipulation Skills from Multi-Modal Human Demonstrations</li><li>ILoSA: Interactive Learning of Stiffness and Attractors</li><li>A Marginal Log-Likelihood Approach for the Estimation of Discount Factors of Multiple Experts in Inverse Reinforcement Learning</li><li>Towards Coordinated Robot Motions: End-To-End Learning of Motion Policies on Transform Trees</li><li>Learning to Optimize Control Policies and Evaluate Reproduction Performance from Human Demonstrations</li><li>Learning from Successful and Failed Demonstrations Via Optimization</li><li>A Novel Curved Gaussian Mixture Model and Its Application in Motion Skill Encoding<h2 id="Learning-from-Experience"><a href="#Learning-from-Experience" class="headerlink" title="Learning from Experience"></a>Learning from Experience</h2></li><li>In-Air Knotting of Rope Using Dual-Arm Robot Based on Deep Learning</li><li>Automated Generation of Robotic Planning Domains from Observations</li><li>Behavior Self-Organization Supports Task Inference for Continual Robot Learning</li><li>CRIL: Continual Robot Imitation Learning Via Generative and Prediction Model</li><li>Adaptive Robotic Tool-Tip Control Learning Considering Online Changes in Grasping State</li><li>Ontology-Assisted Generalisation of Robot Action Execution Knowledge</li><li>Self-Body Image Acquisition and Posture Generation with Redundancy Using Musculoskeletal Humanoid Shoulder Complex for Object Manipulation<h2 id="Legged-Robots"><a href="#Legged-Robots" class="headerlink" title="Legged Robots"></a>Legged Robots</h2></li><li>Legged Robot State Estimation with Dynamic Contact Event Information</li><li>Tachyon: Design and Control of High Payload, Robust, and Dynamic Quadruped Robot with Series-Parallel Elastic Actuators</li><li>Modeling and Trajectory Optimization for Standing Long Jumping of a Quadruped with a Preloaded Elastic Prismatic Spine</li><li>The Usage of Kinematic Singularities to Produce Periodic High-Powered Locomotion</li><li>Quadrupedal Template Model for the Parametric Stability Analysis of Trotting Gaits</li><li>Coupling-Dependent Convergence Behavior of Phase Oscillators with Tegotae-Control</li><li>Towards Autonomous Area Inspection with a Bio-Inspired Underwater Legged Robot</li><li>Development of Rotating Workspace Ground Contact Force Observer for Legged Robot</li><li>Instantaneous Capture Input for Balancing the Variable Height Inverted Pendulum</li><li>Design of a Large-Scale Electrically-Actuated Quadruped Robot and Locomotion Control for the Narrow Passage</li><li>Force-Feedback Based Whole-Body Stabilizer for Position-Controlled Humanoid Robots</li><li>Adaptive Force-Based Control for Legged Robots</li><li>Quadruped Robot Hopping on Two Legs</li><li>Trotting and Pacing Locomotion of a Position-Controlled Quadruped Robot</li><li>A Hierarchical Framework for Quadruped Locomotion Based on Reinforcement Learning</li><li>Linear Policies Are Sufficient to Enable Low-Cost Quadrupedal Robots to Traverse Rough Terrain</li><li>Verifying Safe Transitions between Dynamic Motion Primitives on Legged Robots</li><li>Rapid Stability Margin Estimation for Contact-Rich Locomotion</li><li>GPU-Accelerated Rapid Planar Region Extraction for Dynamic Behaviors on Legged Robots</li><li>Animal Gaits on Quadrupedal Robots Using Motion Matching and Model-Based Control</li><li>Run Like a Dog: Learning Based Whole-Body Control Framework for Quadruped Gait Style Transfer<h2 id="Localization"><a href="#Localization" class="headerlink" title="Localization"></a>Localization</h2></li><li>Coarse-To-Fine Semantic Localization with HD Map for Autonomous Driving in Structural Scenes</li><li>High Accuracy Three-Dimensional Self-Localization Using Visual Markers and Inertia Measurement Unit</li><li>Online Spatio-Temporal Calibration of Tightly-Coupled Ultrawideband-Aided Inertial Localization</li><li>Heading Estimation Using Ultra-Wideband Received Signal Strength and Gaussian Processes</li><li>DPLVO: Direct Point-Line Monocular Visual Odometry</li><li>SemSegMap - 3D Segment-Based Semantic Localization</li><li>Recalling Direct 2D-3D Matches for Large-Scale Visual Localization</li><li>Finding Robust 2D-To-3D Correspondence with LSTM Score Estimation for Camera Localization</li><li>Deep Unsupervised Learning Based Visual Odometry with Multi-Scale Matching and Latent Feature Constraint</li><li>EventVLAD : Visual Place Recognition with Reconstructed Edges from Event Cameras</li><li>Localization with Directional Coordinates</li><li>A Hierarchical Dual Model of Environment and Place-Specific Utility for Visual Place Recognition</li><li>Monte-Carlo Localization in Underground Parking Lots Using Parking Slot Numbers</li><li>Real-Time Geo-Localization Using Satellite Imagery and Topography for Unmanned Aerial Vehicles</li><li>Cross-Layer Configuration Optimization for Localization on Resource-Constrained Devices</li><li>BSP-MonoLoc: Basic Semantic Primitives Based Monocular Localization on Roads</li><li>Ground Encoding: Learned Factor Graph-Based Models for Localizing Ground Penetrating Radar</li><li>CLMM-Net: Robust Cascaded LiDAR Map Matching Based onMulti-Level Intensity Map</li><li>DLL: Direct LIDAR Localization. a Map-Based Localization Approach for Aerial Robots</li><li>Real-Time Multi-Adaptive-Resolution-Surfel 6D LiDAR Odometry Using Continuous-Time Trajectory Optimization</li><li>Efficient Localisation Using Images and OpenStreetMaps</li><li>Direct Near-Infrared-Depth Visual SLAM with Active Lighting</li><li>A Computationally Efficient Moving Horizon Estimator for Ultra-Wideband Localization on Small Quadrotors<h2 id="Machine-Learning-for-Robot-Control"><a href="#Machine-Learning-for-Robot-Control" class="headerlink" title="Machine Learning for Robot Control"></a>Machine Learning for Robot Control</h2></li><li>Learning to Play Pursuit-Evasion with Visibility Constraints</li><li>Online Learning of Unknown Dynamics for Model-Based Controllers in Legged Locomotion</li><li>Learning-Based Robust Motion Planning with Guaranteed Stability: A Contraction Theory Approach</li><li>InsertionNet - a Scalable Solution for Insertion</li><li>Object Picking Using a Two-Fingered Gripper Measuring the Deformation and Slip Detection Based on a 3-Axis Tactile Sensing</li><li>Learning to Control an Unstable System with One Minute of Data: Leveraging Gaussian Process Differentiation in Predictive Control</li><li>OHPL: One-Shot Hand-Eye Policy Learner</li><li>NaturalNets: Simplified Biological Neural Networks for Learning Complex Tasks</li><li>Talk the Talk and Walk the Walk: Dialogue-Driven Navigation in Unknown Indoor Environments</li><li>ORCHID: Optimisation of Robotic Control and Hardware in Design Using Reinforcement Learning</li><li>Many-Joint Robot Arm Control with Recurrent Spiking Neural Networks</li><li>Bootstrapping Motor Skill Learning with Motion Planning</li><li>Towards Safe Navigation through Crowded Dynamic Environments</li><li>Self-Balancing Online Dataset for Incremental Driving Intelligence</li><li>Coarse-To-Fine for Sim-To-Real: Sub-Millimetre Precision across Wide Task Spaces</li><li>Hannes Prosthesis Control Based on Regression Machine Learning Algorithms</li><li>Learning-Based Contact Status Recognition for Peg-In-Hole Assembly</li><li>Binary Neural Network in Robotic Manipulation: Flexible Object Manipulation for Humanoid Robot Using Partially Binarized Auto-Encoder on FPGA</li><li>STFP: Simultaneous Traffic Scene Forecasting and Planning for Autonomous Driving</li><li>Learning Contact-Rich Skills Using Residual Admittance Policy</li><li>ObserveNet Control: A Vision-Dynamics Learning Approach to Predictive Control in Autonomous Vehicles<h2 id="Manipulation-Planning"><a href="#Manipulation-Planning" class="headerlink" title="Manipulation Planning"></a>Manipulation Planning</h2></li><li>TrajectoTree: Trajectory Optimization Meets Tree Search for Planning Multi-Contact Dexterous Manipulation</li><li>Geometry-Based Two-Contact Inverse Kinematic Solution for Whole Arm Manipulation</li><li>Can Robots Refill a Supermarket Shelf?: Motion Planning and Grasp Control (I)</li><li>Efficient Task Planning for Mobile Manipulation: A Virtual Kinematic Chain Perspective</li><li>Efficient Picking by Considering Simultaneous Two-Object Grasping</li><li>Search-Based Path Planning for a High Dimensional Manipulator in Cluttered Environments Using Optimization-Based Primitives</li><li>NMPC-MP: Real-Time Nonlinear Model Predictive Control for Safe Motion Planning in Manipulator Teleoperation</li><li>Planning Robotic Manipulation with Tight Environment Constraints</li><li>Motion and Force Planning for Manipulating Heavy Objects by Pivoting</li><li>Coordinated Motion Generation and Object Placement: A Reactive Planning and Landing Approach</li><li>Dynamic Pre-Grasp Planning When Tracing a Moving Object through a Multi-Agent Perspective</li><li>Learning to Hit: A Statistical Dynamical System Based Approach</li><li>Dynamic Grasping with Reachability and Motion Awareness</li><li>Learning Initial Trajectory Using Sequence-To-Sequence Approach to Warm Start an Optimization-Based Motion Planner</li><li>Understanding and Segmenting Human Demonstrations into Reusable Compliant Primitives<h2 id="Manufacturing-Automation"><a href="#Manufacturing-Automation" class="headerlink" title="Manufacturing Automation"></a>Manufacturing Automation</h2></li><li>Textile Taxonomy and Classification Using Pulling and Twisting</li><li>Learning of Parameters in Behavior Trees for Movement Skills</li><li>On Step-And-Scan Trajectories Used in Wafer Scanners in Semiconductor Manufacturing</li><li>Energy-Efficient Mobile Robot Control Via Run-Time Monitoring of Environmental Complexity and Computing Workload</li><li>Adaptive Optimization of Autonomous Vehicle Computational Resources for Performance and Energy Improvement</li><li>Design of a New Robot End-Effector Based on Compliant Constant-Force Mechanism</li><li>A New Method for Generating Work Piece Surface Representations for Robotic Machining<h2 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h2></li><li>What’s Best for My Mesh? Convex or Non-Convex Regularisation for Mesh Optimisation</li><li>Local to Global Plane Regularity Aggregation for Dense Surfel Mapping</li><li>Smooth Mesh Estimation from Depth Data Using Non-Smooth Convex Optimization</li><li>DeepRelativeFusion: Dense Monocular SLAM Using Single-Image Relative Depth Prediction</li><li>Automatic Construction of Lane-Level HD Maps for Urban Scenes</li><li>CLINS: Continuous-Time Trajectory Estimation for LiDAR Inertial System</li><li>An Efficient and Continuous Representation for Occupancy Mapping with Random Mapping</li><li>Moving Object Segmentation in 3D LiDAR Data: A Learning-Based Approach Exploiting Sequential Data</li><li>R2LIVE: A Robust, Real-Time, LiDAR-Inertial-Visual Tightly-Coupled State Estimator and Mapping</li><li>Endo-Depth-And-Motion: Reconstruction and Tracking in Endoscopic Videos Using Depth Networks and Photometric Constraints</li><li>CRMI: Confidence-Rich Mutual Information for Information-Theoretic Mapping</li><li>3D Shape Reconstruction of Small Bodies from Sparse Features</li><li>Adaptive Hyperparameter Tuning for Black-Box LiDAR Odometry</li><li>CatChatter: Acoustic Perception for Mobile Robots<h2 id="Marine-Robotics"><a href="#Marine-Robotics" class="headerlink" title="Marine Robotics"></a>Marine Robotics</h2></li><li>An Open-Source, Fiducial-Based, Underwater Stereo Visual-Inertial Localization Method with Refraction Correction</li><li>Cooperative ASV/AUV System Exploiting Active Acoustic Localization</li><li>Coordinated Path Planning for Surface Acoustic Beacons for Supporting Underwater Localization</li><li>Shipborne Sea-Ice Field Mapping Using a LiDAR</li><li>3D Ensemble-Based Online Oceanic Flow Field Estimation for Underwater Glider Path Planning</li><li>Leveraging Metadata in Representation Learning with Georeferenced Seafloor Imagery</li><li>Online Kinematic and Dynamic Parameter Estimation for Autonomous Surface and Underwater Vehicles</li><li>Towards Robust Visual Diver Detection Onboard Autonomous Underwater Robots: Assessing the Effect of Models and Data</li><li>Predicting the Future Motion of Divers for Enhanced Underwater Human-Robot Collaboration</li><li>Efficient LiDAR-Based In-Water Obstacle Detection and Segmentation by Autonomous Surface Vehicles in Aquatic Environments</li><li>Robust Data Association for Multi-Object Detection in Maritime Environments Using Camera and Radar Measurements</li><li>ShorelineNet: An Efficient Deep Learning Approach for Shoreline Semantic Segmentation for Unmanned Surface Vehicles</li><li>AquaVis: A Perception-Aware Autonomous Navigation Framework for Underwater Vehicles</li><li>From Aerobatics to Hydrobatics: Agile Trajectory Planning and Tracking for Micro Underwater Robots</li><li>A Predictive Control Framework for Stabilizing a Manipulator-Assisted UAV Landing Platform on a Disturbed USV</li><li>Invariant Extended Kalman Filtering for Underwater Navigation</li><li>Long-Term Autonomy for AUVs Operating under Uncertainties in Dynamic Marine Environments</li><li>Embedded Stochastic Field Exploration with Micro Diving Agents Using Bayesian Optimization-Guided Tree-Search and GMRFs</li><li>Stochastic Guidance of Buoyancy Controlled Vehicles under Ice Shelves Using Ocean Currents</li><li>Thrust Direction Control of an Underactuated Oscillating Swimming Robot<h2 id="Mechanism-Design"><a href="#Mechanism-Design" class="headerlink" title="Mechanism Design"></a>Mechanism Design</h2></li><li>Control-Aware Design Optimization for Bio-Inspired Quadruped Robots</li><li>Singularity-Aware Design Optimization for Multi-Degree-Of-Freedom Spatial Linkages</li><li>Embedding a Nonlinear Strict Oscillatory Mode into a Segmented Leg</li><li>A Novel Design of Mobile Robotic System for Opening and Transitioning through a Watertight Ship Door</li><li>Designing Rotary Linkages for Polar Motions</li><li>Modular Two-Degree-Of-Freedom Transformable Wheels Capable of Overcoming Obstacle</li><li>Dynamic Analysis of an Inverted Pendulum Robot with Transformable Wheels for Overcoming Steps</li><li>BogieBot: A Climbing Robot in Cluttered Confined Space of Bogies with Ferrous Metal Surfaces</li><li>Design and Analysis of FCSTAR, a Hybrid Flying and Climbing Sprawl Tuned Robot</li><li>Design and Analysis of a Robotic Out-Pipe Grinding System with Friction Actuating</li><li>Modular Pipe Climber III with Three-Output Open Differential</li><li>Modeling and Analysis of Tensegrity Robot for Passive Dynamic Walking</li><li>A Highly Maneuverable Hybrid Energy-Efficient Rolling/Flying System</li><li>HanGrawler 2: Super-High-Speed and Large-Payload Ceiling Mobile Robot Using Crawler</li><li>Mechanical Design and Evaluation of a Selectively-Actuated MRI-Compatible Continuum Neurosurgical Robot<h2 id="Medical-Robots-and-Systems"><a href="#Medical-Robots-and-Systems" class="headerlink" title="Medical Robots and Systems"></a>Medical Robots and Systems</h2></li><li>Modeling a Symmetrically-Notched Continuum Neurosurgical Robot with Non-Constant Curvature and Superelastic Property</li><li>Dynamic-Based RCM Torque Controller for Robotic-Assisted Minimally Invasive Surgery</li><li>Multiobjective Trajectory Tracking of a Flexible Tool During Robotic Percutaneous Nephrolithotomy</li><li>Image-Guided Control of an Endoscopic Robot for OCT Path Scanning</li><li>A Novel Wax Based Piezo Actuator for Autonomous Deep Anterior Lamellar Keratoplasty (Piezo-DALK)</li><li>W-ROMA: A Wearable Robotic Device for Assistive Navigation and Object Manipulation</li><li>Capturing Skill State in Curriculum Learning for Human Skill Acquisition</li><li>Deformation-Aware Robotic 3D Ultrasound</li><li>Feasibility of Remote Landmark Identification for Cricothyrotomy Using Robotic Palpation</li><li>Force Feedback on Hand Rest Function in Master Manipulator for Robotic Surgery</li><li>SurRoL: An Open-Source Reinforcement Learning Centered and dVRK Compatible Platform for Surgical Robot Learning</li><li>Analytical Tip Force Estimation on Tendon-Driven Catheters through Inverse Solution of Cosserat Rod Model</li><li>Towards Safe in Situ Needle Manipulation for Robot Assisted Lumbar Injection in Interventional MRI</li><li>Design, Actuation, and Control of an MRI-Powered Untethered Robot for Wireless Capsule Endoscopy</li><li>A Robotic Healthcare Assistant for COVID-19 Emergency (I)</li><li>Digital Innovation Hubs in Health-Care Robotics Fighting COVID-19: Novel Support for Patients and Health-Care Workers across Europe (I)</li><li>Medical Robots for Infectious Diseases: Lessons and Challenges from the COVID-19 Pandemic (I)</li><li>A Tapered Soft Robotic Oropharyngeal Swab for Throat Testing (I)</li><li>A Dual Doctor-Patient Twin Paradigm for Transparent Remote Examination, Diagnosis, and Rehabilitation</li><li>Robust Event Detection Based on Spatio-Temporal Latent Action Unit Using Skeletal Information</li><li>Towards a Manipulator System for Disposal of Waste from Patients Undergoing Chemotherapy</li><li>A Static Model for a Stiffness-Adjustable Snake-Like Robot<h2 id="Micro-Nano-Robots"><a href="#Micro-Nano-Robots" class="headerlink" title="Micro/Nano Robots"></a>Micro/Nano Robots</h2></li><li>Precise Control of Magnetized Macrophage Cell Robot for Targeted Drug Delivery</li><li>Development of a Vision-Based Robotic Manipulation System for Transferring of Oocytes</li><li>Hybrid Magnetic Force and Torque Actuation of Miniature Helical Robots Using Mobile Coils to Accelerate Blood Clot Removal</li><li>Adaptive Tracking Controller for an Alginate Artificial Cell</li><li>Automatic Cell Rotation Based on Real-Time Detection and Tracking</li><li>Autonomous Object Harvesting Using Synchronized Optoelectronic Microrobots</li><li>Keeping It Simple: Bio-Inspired Threshold-Based Strain Sensing for Micro-Aerial Vehicles</li><li>Simultaneous Actuation and Localization of Magnetic Robots Using Mobile Coils and Eye-In-Hand Hall-Effect Sensors</li><li>Enhancing Swimming and Pumping Performance of Helical Swimmers at Low Reynolds Numbers</li><li>Modeling of Bilayer Hydrogel Springs for Microrobots with Adaptive Locomotion</li><li>Low Voltage Control of Micro-Ionic Thrusters Using the Electrostatic Induced Potential of the Collector</li><li>Open-Loop Magnetic Actuation of Helical Robots Using Position-Constrained Rotating Dipole Field</li><li>Analysis of the Effect of Clearance in Spherical Joints on the Rotation Accuracy of Parallel Type Micro-Robotic Systems</li><li>A Portable Remote Optoelectronic Tweezer System for Microobjects Manipulation<h2 id="Mobile-and-Bimanual-Manipulation"><a href="#Mobile-and-Bimanual-Manipulation" class="headerlink" title="Mobile and Bimanual Manipulation"></a>Mobile and Bimanual Manipulation</h2></li><li>Mobile Manipulation Hackathon: Moving into Real World Applications (I)</li><li>Optimal Order Pick-And-Place of Objects in Cluttered Scene by a Mobile Manipulator</li><li>Simultaneous Scene Reconstruction and Whole-Body Motion Planning for Safe Operation in Dynamic Environments</li><li>Effect of Assembly Design on a Walking Multi-Arm Robotics for In-Space Assembly</li><li>A Multi-Target Trajectory Planning of a 6-DoF Free-Floating Space Robot Via Reinforcement Learning</li><li>Disentangling Dense Multi-Cable Knots</li><li>Design and Evaluation of a Hair Combing System Using a General-Purpose Robotic Arm<h2 id="Model-Learning-for-Control"><a href="#Model-Learning-for-Control" class="headerlink" title="Model Learning for Control"></a>Model Learning for Control</h2></li><li>GloCAL: Glocalized Curriculum-Aided Learning of Multiple Tasks with Application to Robotic Grasping</li><li>Multi-Scale Aggregation with Self-Attention Network for Modeling Electrical Motor Dynamics</li><li>A Robust Data-Driven Approach for Dynamics Model Identification in Trajectory Planning</li><li>Guiding Robot Model Construction with Prior Features</li><li>A Novel Quotient Space Approach to Model-Based Fault Detection and Isolation: Theory and Preliminary Simulation Evaluation</li><li>Particle MPC for Uncertain and Learning-Based Control</li><li>DMotion: Robotic Visuomotor Control with Unsupervised Forward Model Learned from Videos<h2 id="Modeling-Control-and-Learning-for-Soft-Robots"><a href="#Modeling-Control-and-Learning-for-Soft-Robots" class="headerlink" title="Modeling, Control, and Learning for Soft Robots"></a>Modeling, Control, and Learning for Soft Robots</h2></li><li>Soft Robot Configuration Estimation and Control Using Simultaneous Localization and Mapping</li><li>A Parameter Identification Method for Static Cosserat Rod Models: Application to Soft Material Actuators with Exteroceptive Sensors</li><li>Analytical Modeling of a Soft Pneu-Net Actuator Based on Finite Strain Beam Theory</li><li>Soft-CCD Algorithm for Inverse Kinematics of Soft Continuum Manipulators</li><li>Shape-Centric Modeling for Soft Robot Inchworm Locomotion</li><li>SoPrA: Fabrication &amp; Dynamical Modeling of a Scalable Soft Continuum Robotic Arm with Integrated Proprioceptive Sensing</li><li>Dynamic Modelling and Visco-Elastic Parameter Identification of a Fibre-Reinforced Soft Fluidic Elastomer Manipulator</li><li>Sim2Sim Evaluation of a Novel Data-Efficient Differentiable Physics Engine for Tensegrity Robots</li><li>Soft Manipulator Fault Detection and Identification Using ANC-Based LSTM</li><li>Position Control and Variable-Height Trajectory Tracking of a Soft Pneumatic Legged Robot</li><li>Task Driven Skill Learning in a Soft-Robotic Arm</li><li>Design and Control of Pneumatic Systems for Soft Robotics: A Simulation Approach</li><li>Constant Fluidic Mass Control for Soft Actuators Using Artificial Neural Network Algorithm</li><li>Koopman-Based Control of a Soft Continuum Manipulator under Variable Loading Conditions</li><li>Closed-Loop Position Control of a Self-Sensing 3-DoF Origami Module with Pneumatic Actuators</li><li>Discrete Cosserat Approach for Closed-Chain Soft Robots: Application to the Fin-Ray® Finger (I)</li><li>Manipulating a Whip in 3D Via Dynamic Primitives</li><li>A Hybrid Dual Jacobian Approach for Autonomous Control of Concentric Tube Robots in Unknown Constrained Environments</li><li>Dynamics Computation of a Hybrid Multi-Link Humanoid Robot Integrating Rigid and Soft Bodies</li><li>A Control and Drive System for Pneumatic Soft Robots: PneuSoRD</li><li>Flow Path Optimization for Soft Pneumatic Actuators: Towards Optimal Performance and Portability<h2 id="Motion-Control"><a href="#Motion-Control" class="headerlink" title="Motion Control"></a>Motion Control</h2></li><li>Exponential Stability of Trajectory Tracking Control in the Orientation Space Utilizing Unit Quaternions</li><li>Control of Spherical Robots on Uneven Terrains</li><li>Area Defense and Surveillance on Rectangular Regions Using Control Barrier Functions</li><li>Robust Feedback Motion Primitives for Exploration of Unknown Terrains</li><li>On Energy-Preserving Motion in Twisted String Actuators</li><li>Learning-Based Balance Control of Wheel-Legged Robots</li><li>Source Seeking Control of Unicycle Robots with 3D-Printed Flexible Piezoresistive Sensors (I)<h2 id="Motion-and-Path-Planning"><a href="#Motion-and-Path-Planning" class="headerlink" title="Motion and Path Planning"></a>Motion and Path Planning</h2></li><li>B-Spline Path Planner for Safe Navigation of Mobile Robots</li><li>Closed-Loop Fast Marching Tree (CL-FMT*) with Application to Helicopter Landing Trajectory Planning</li><li>Informed Autonomous Exploration of Subterranean Environments</li><li>UV-C Mobile Robots with Optimized Path Planning Can Improve Surface Disinfection against SARS-CoV-2 (I)</li><li>Exploring Learning for Intercepting Projectiles with a Robot-Held Stick</li><li>Disruption-Limited Planning for Robot Navigation in Dynamic Environments</li><li>Spatial Constraint Generation for Motion Planning in Dynamic Environments</li><li>Trajectory Optimization for Rendezvous Planning Using Quadratic Bezier Curves</li><li>Unsupervised Path Regression Networks</li><li>Path-Constrained Optimal Trajectory Planning for Robot Manipulators with Obstacle Avoidance</li><li>CR-LSTM: Collision-Prior Guided Social Refinement for Pedestrian Trajectory Prediction</li><li>Robust and Recursively Feasible Real-Time Trajectory Planning in Unknown Environments</li><li>PILOT: Efficient Planning by Imitation Learning and Optimisation for Safe Autonomous Driving</li><li>Exploring Imitation Learning for Autonomous Driving with Feedback Synthesizer and Differentiable Rasterization</li><li>Interpretable Run-Time Prediction and Planning in Co-Robotic Environments</li><li>HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization</li><li>Designing Human-Robot Coexistence Space</li><li>APPLE: Adaptive Planner Parameter Learning from Evaluative Feedback</li><li>Generation of Human-Like Arm Motions Using Sampling-Based Motion Planning</li><li>PlannerFlows: Learning Motion Samplers with Normalising Flows</li><li>Safe and Fast Path Planner for Minimally Invasive Surgery</li><li>DT*: Temporal Logic Path Planning in a Dynamic Environment</li><li>Mobile Recharger Path Planning and Recharge Scheduling in a Multi-Robot Environment</li><li>Geometric Motion Planning for a System on the Cylindrical Surface</li><li>Section Patterns: Efficiently Solving Narrow Passage Problems in Multilevel Motion Planning (I)</li><li>PG-RRT: A Gaussian Mixture Model Driven, Kinematically Constrained Bi-Directional RRT for Robot Path Planning</li><li>Accelerating Kinodynamic RRT* through Dimensionality Reduction</li><li>Risk-Averse RRT* Planning with Nonlinear Steering and Tracking Controllers for Nonlinear Robotic Systems under Uncertainty</li><li>Learning When to Quit: Meta-Reasoning for Motion Planning</li><li>Joint Sampling and Trajectory Optimization Over Graphs for Online Motion Planning</li><li>Path Planning for Robotic Manipulators in Dynamic Environments Using Distance Information</li><li>Variable-Speed Traveling Salesman Problem for Vehicles with Curvature Constrained Trajectories</li><li>Risk-Aware Submodular Optimization for Stochastic Travelling Salesperson Problem</li><li>Fast Generation of Obstacle-Avoiding Motion Primitives for Quadrotors</li><li>Roadmap for Visibility-Based Target Tracking: Iterative Construction and Motion Strategy</li><li>Discrete Optimization of Adaptive State Lattices for Iterative Motion Planning on Unmanned Ground Vehicles</li><li>Learning Continuous Cost-To-Go Functions for Non-Holonomic Systems</li><li>Robust Sample-Based Output-Feedback Path Planning</li><li>Combined Stochastic-Deterministic Predictive Control Using Local-Minima Free Navigation</li><li>Safe Navigation in Human Occupied Environments Using Sampling and Control Barrier Functions</li><li>Constrained Iterative LQG for Real-Time Chance-Constrained Gaussian Belief Space Planning</li><li>Robotic Jigsaws: Path Planning for Non-Holonomic Cutting Robots</li><li>A Meta-Learning-Based Trajectory Tracking Framework for UAVs under Degraded Conditions</li><li>Orientation-Aware Planning for Parallel Task Execution of Omni-Directional Mobile Robot</li><li>Informed Sampling Exploration Path Planner for 3D Reconstruction of Large Scenes</li><li>Class-Ordered LPA: An Incremental-Search Algorithm for Weighted Colored Graphs</li><li>Rough Terrain Navigation for Legged Robots Using Reachability Planning and Template Learning</li><li>Using Experience to Improve Constrained Planning on Foliations for Multi-Modal Problems</li><li>A Sampling-Based Motion Planning Framework for Complex Motor Actions</li><li>Capacitated Vehicle Routing with Target Geometric Constraints</li><li>Sparsification for Fast Optimal Multi-Robot Path Planning in Lazy Compilation Schemes</li><li>A Novel Recursive Smooth Trajectory Generation Method for Unmanned Vehicles (I)</li><li>Search-Based Planning with Learned Behaviors for Navigation among Pedestrians</li><li>A Fast Algorithm for Stochastic Orienteering with Chance Constraints</li><li>Kohonen Self-Organizing Map Based Route Planning: A Revisit</li><li>FloMo: Tractable Motion Prediction with Normalizing Flows</li><li>Cognitive Navigation for Indoor Environment Using Floorplan</li><li>Improving Kinodynamic Planners for Vehicular Navigation with Learned Goal-Reaching Controllers</li><li>Polygon-Based Random Tree Search Algorithm with Variable Polygon Size</li><li>A Holistic Motion Planning and Control Solution to Challenge a Professional Racecar Driver</li><li>Risk Conditioned Neural Motion Planning</li><li>Real-Time Volumetric-Semantic Exploration and Mapping: An Uncertainty-Aware Approach</li><li>Multitask and Transfer Learning of Geometric Robot Motion<h2 id="Multi-Robot-SLAM"><a href="#Multi-Robot-SLAM" class="headerlink" title="Multi-Robot SLAM"></a>Multi-Robot SLAM</h2></li><li>MR-iSAM2: Incremental Smoothing and Mapping with Multi-Root Bayes Tree for Multi-Robot SLAM</li><li>A Collaborative Visual SLAM Framework for Service Robots</li><li>Distributed Certifiably Correct Pose-Graph Optimization (I)</li><li>ORBBuf: A Robust Buffering Method for Remote Visual SLAM</li><li>Distributed Visual-Inertial Cooperative Localization</li><li>Coxgraph: Multi-Robot Collaborative, Globally Consistent, Online Dense Reconstruction System</li><li>Super Odometry: IMU-Centric LiDAR-Visual-Inertial Estimator for Challenging Environments<h2 id="Multi-Robot-Systems"><a href="#Multi-Robot-Systems" class="headerlink" title="Multi-Robot Systems"></a>Multi-Robot Systems</h2></li><li>Distributed Event and Self-Triggered Coverage Control with Speed Constrained Unicycle Robots</li><li>Combined Routing and Scheduling of Heterogeneous Transport and Service Agents</li><li>Encirclement Guaranteed Cooperative Pursuit with Robust Model Predictive Control</li><li>On Provably Safe and Live Multi-Robot Coordination with Online Goal Posting (I)</li><li>Path Optimization for Cooperative Mapping Using Multiple Robots with Limited Sensing Capabilities</li><li>An Interleaved Approach to Trait-Based Task Allocation and Scheduling</li><li>Multi-Robot Task Assignment for Aerial Tracking with Viewpoint Constraints</li><li>Downing a Rogue Drone with a Team of Aerial Radio Signal Jammers</li><li>Multi-Agent Reinforcement Learning for Visibility-Based Persistent Monitoring</li><li>Cooperative Multi-Robot Object Transportation System Based on Hierarchical Quadratic Programming</li><li>Autonomous Aerial Filming with Distributed Lighting by a Team of Unmanned Aerial Vehicles</li><li>Planning for Aerial Robot Teams for Wide-Area Biometric and Phenotypic Data Collection</li><li>Desperate Times Call for Desperate Measures: Towards Risk-Adaptive Task Allocation</li><li>Source Seeking by Dynamic Source Location Estimation</li><li>Market-Based Multi-Robot Coordination with HTN Planning</li><li>Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs Using Deep Reinforcement Learning</li><li>Learning to Play Soccer from Scratch: Sample-Efficient Emergent Coordination through Curriculum-Learning and Competition</li><li>Dual Quaternion Cluster-Space Formation Control</li><li>Impact of Heterogeneity and Risk Aversion on Task Allocation in Multi-Agent Teams</li><li>Hiding Leader’s Identity in Leader-Follower Navigation through Multi-Agent Reinforcement Learning</li><li>Moving Forward in Formation: A Decentralized Hierarchical Learning Approach to Multi-Agent Moving Together</li><li>Scalable Reinforcement Learning Policies for Multi-Agent Control</li><li>Refuel Scheduling for Multirobot Charging-On-Demand</li><li>Event-Triggered Control for Weight-Unbalanced Directed Robot Networks</li><li>Impedance-Based Collision Reaction Strategy Via Internal Stress Loading in Cooperative Manipulation</li><li>Detection and Inference of Randomness-Based Behavior for Resilient Multi-Vehicle Coordinated Operations</li><li>Meta Preference Learning for Fast User Adaptation in Human-Supervisory Multi-Robot Deployments</li><li>Relative Localization of Mobile Robots with Multiple Ultra-WideBand Ranging Measurements</li><li>Optimization-Based Robot Team Exploration Considering Attrition and Communication Constraints</li><li>Distributed Sampling-Based Planning for Non-Myopic Active Information Gathering<h2 id="Object-Detection-Segmentation-and-Categorization"><a href="#Object-Detection-Segmentation-and-Categorization" class="headerlink" title="Object Detection, Segmentation and Categorization"></a>Object Detection, Segmentation and Categorization</h2></li><li>Camera Parameters Aware Motion Segmentation Network with Compensated Optical Flow</li><li>APEX: Unsupervised, Object-Centric Scene Segmentation and Tracking for Robot Manipulation</li><li>PLUMENet: Efficient 3D Object Detection from Stereo Images</li><li>Part-Aware Data Augmentation for 3D Object Detection in Point Cloud</li><li>MS-UDA: Multi-Spectral Unsupervised Domain Adaptation for Thermal Image Semantic Segmentation</li><li>MapFusion: A General Framework for 3D Object Detection with HDMaps</li><li>SpikeMS: Deep Spiking Neural Network for Motion Segmentation</li><li>Active Perception for Ambiguous Objects Classification</li><li>Event-Based Motion Segmentation by Cascaded Two-Level Multi-Model Fitting</li><li>FIDNet: LiDAR Point Cloud Semantic Segmentation with Fully Interpolation Decoding</li><li>Look before You Act: Boosting Pseudo-LiDAR with Online Semantic Embedding</li><li>FEANet: Feature-Enhanced Attention Network for RGB-Thermal Real-Time Semantic Segmentation</li><li>ODIP: Towards Automatic Adaptation for Object Detection by Interactive Perception</li><li>Vessel Classification Using a Regression Neural Network Approach<h2 id="Optimization-and-Optimal-Control"><a href="#Optimization-and-Optimal-Control" class="headerlink" title="Optimization and Optimal Control"></a>Optimization and Optimal Control</h2></li><li>Offset-Free Model Predictive Control: A Ball Catching Application with a Spherical Soft Robotic Arm</li><li>Embedded Hardware Appropriate Fast 3D Trajectory Optimization for Fixed Wing Aerial Vehicles by Leveraging Hidden Convex Structures</li><li>Probabilistic Iterative LQR for Short Time Horizon MPC</li><li>Efficient and Reactive Planning for High Speed Robot Air Hockey</li><li>Closed-Loop Robotic Cooking of Scrambled Eggs with a Salinity-Based ‘Taste’ Sensor</li><li>Car Racing Line Optimization with Genetic Algorithm Using Approximate Homeomorphism</li><li>Human Motion Imitation Using Optimal Control with Time-Varying Weights</li><li>Learning Environment Constraints in Collaborative Robotics: A Decentralized Leader-Follower Approach</li><li>Decentralized Trajectory Optimization for Multi-Agent Ergodic Exploration</li><li>Accelerating Second-Order Differential Dynamic Programming for Rigid-Body Systems</li><li>Rapid Convex Optimization of Centroidal Dynamics Using Block Coordinate Descent</li><li>Real-Time Hamilton-Jacobi Reachability Analysis of Autonomous System with an FPGA</li><li>Pairwise Preferences-Based Optimization of a Path-Based Velocity Planner in Robotic Sealing Tasks</li><li>Memory Clustering Using Persistent Homology for Multimodality and Discontinuity-Sensitive Learning of Optimal Control Warm-Starts (I)<h2 id="Parallel-Robots"><a href="#Parallel-Robots" class="headerlink" title="Parallel Robots"></a>Parallel Robots</h2></li><li>Static Workspace Optimization of Aerial Cable Towed Robots with Land-Fixed Winches (I)</li><li>A Reaction-Based Stabilizer for Nonmodel-Based Vibration Control of Cable-Driven Parallel Robots (I)</li><li>Wrench Feasibility and Workspace Expansion of Planar Cable-Driven Parallel Robots by a Novel Passive Counterbalancing Mechanism (I)</li><li>Development of a New 2-DOF Wrist Mechanism Using Reverse Motion Transmission</li><li>A Novel 2-SUR 6-DOF Parallel Manipulator Actuated by Spherical Motion Generators</li><li>A Novel Model-Based Robust Super-Twisting Sliding Mode Control of PKMs: Design and Real-Time Experiments</li><li>Moving-Platform Pose Estimation for Cable-Driven Parallel Robots<h2 id="Path-Planning-for-Multiple-Mobile-Robots-or-Agents"><a href="#Path-Planning-for-Multiple-Mobile-Robots-or-Agents" class="headerlink" title="Path Planning for Multiple Mobile Robots or Agents"></a>Path Planning for Multiple Mobile Robots or Agents</h2></li><li>Iterative Refinement for Real-Time Multi-Robot Path Planning</li><li>Subdimensional Expansion for Multi-Objective Multi-Agent Path Finding</li><li>Parallel Hierarchical Composition Conflict-Based Search for Optimal Multi-Agent Pathfinding</li><li>Loosely Synchronized Search for Multi-Agent Path Finding with Asynchronous Actions</li><li>On Connected Deployment of Delay-Critical FANETs</li><li>Team Orienteering Coverage Planning with Uncertain Reward</li><li>Rapid Recovery from Robot Failures in Multi-Robot Visibility-Based Pursuit-Evasion</li><li>PlanSys2: A Planning System Framework for ROS2<h2 id="Perception-for-Grasping-and-Manipulation"><a href="#Perception-for-Grasping-and-Manipulation" class="headerlink" title="Perception for Grasping and Manipulation"></a>Perception for Grasping and Manipulation</h2></li><li>Sim-To-Real Transfer for Robotic Manipulation with Tactile Sensory</li><li>Visual-Tactile Fusion for 3D Objects Reconstruction from a Single Depth View and a Single Gripper Touch for Robotics Tasks</li><li>Policy Learning for Visually Conditioned Tactile Manipulation</li><li>Hybrid ICP</li><li>Improving Grasp Stability with Rotation Measurement from Tactile Sensing</li><li>Multi-View Fusion for Multi-Level Robotic Scene Understanding</li><li>Fast Reactive Grasping with In-Finger Vision and In-Hand FPGA-Accelerated CNNs<h2 id="Perception-Action-Coupling"><a href="#Perception-Action-Coupling" class="headerlink" title="Perception-Action Coupling"></a>Perception-Action Coupling</h2></li><li>Explaining the Decisions of Deep Policy Networks for Robotic Manipulations</li><li>An Adversarial Objective for Scalable Exploration</li><li>Leading or Following? Dyadic Robot Imitative Interaction Using the Active Inference Framework</li><li>Robotic Occlusion Reasoning for Efficient Object Existence Prediction</li><li>Multimodal VAE Active Inference Controller</li><li>Large-Area Conformable Sensor for Proximity, Light Touch, and Pressure-Based Gesture Recognition</li><li>Tactile Slip Detection in the Wild Leveraging Distributed Sensing of Both Normal and Shear Forces</li><li>NudgeSeg: Zero-Shot Object Segmentation by Repeated Physical Interaction<h2 id="Physical-Human-Robot-Interaction"><a href="#Physical-Human-Robot-Interaction" class="headerlink" title="Physical Human-Robot Interaction"></a>Physical Human-Robot Interaction</h2></li><li>Contact Anticipation for Physical Human-Robot Interaction with Robotic Manipulators Using Onboard Proximity Sensors</li><li>Biomechanics Aware Collaborative Robot System for Delivery of Safe Physical Therapy in Shoulder Rehabilitation</li><li>A Computational Multicriteria Optimization Approach to Controller Design for Physical Human-Robot Interaction (I)</li><li>Task Geometry Aware Assistance for Kinesthetic Teaching of Redundant Robots</li><li>A Framework for Dyadic Physical Interaction Studies During Ankle Motor Tasks</li><li>A Conceptual Approach of Passive Human-Intention-Orientated Variable Admittance Control Using Power Envelope</li><li>Inferring Goals with Gaze During Teleoperated Manipulation<h2 id="Planning-Scheduling-and-Coordination"><a href="#Planning-Scheduling-and-Coordination" class="headerlink" title="Planning, Scheduling and Coordination"></a>Planning, Scheduling and Coordination</h2></li><li>Multi-Robot Task Planning under Individual and Collaborative Temporal Logic Specifications</li><li>Reduced State Value Iteration for Multi-Drone Persistent Surveillance with Charging Constraints</li><li>Multi-Robot Scheduling for Environmental Monitoring As a Team Orienteering Problem</li><li>An Augmented MDP Approach for Solving Stochastic Security Games</li><li>A Resolution Adaptive Algorithm for the Stochastic Orienteering Problem with Chance Constraints</li><li>Force-Based Formation Control of Omnidirectional Ground Vehicles</li><li>Hybrid Path Planning for UAV Traffic Management</li><li>Optimizing Requests for Support in Context-Restricted Autonomy<h2 id="Prosthetics-and-Exoskeletons"><a href="#Prosthetics-and-Exoskeletons" class="headerlink" title="Prosthetics and Exoskeletons"></a>Prosthetics and Exoskeletons</h2></li><li>A Soft Robotic Hip Exosuit (SR-HExo) to Assist Hip Flexion and Extension During Human Locomotion</li><li>Using Footsteps to Estimate Changes in the Desired Gait Speed of an Exoskeleton User</li><li>Virtual Energy Regulator: A Time-Independent Solution for Control of Lower Limb Exoskeletons</li><li>Online Learning of the Dynamical Internal Model of Transfemoral Prosthesis for Enhancing Compliance</li><li>Muscle Synergies Enable Accurate Joint Moment Prediction Using Few Electromyography Sensors</li><li>F-VESPA: A Kinematic-Based Algorithm for Real-Time Heel-Strike Detection During Walking</li><li>Temporal Dilation of Deep LSTM for Agile Decoding of sEMG: Application in Prediction of Upperlimb Motor Intention in NeuroRobotics</li><li>An Anthropomorphic Prosthetic Hand with an Active, Selectively Lockable Differential Mechanism: Towards Affordable Dexterity</li><li>A Powered Prosthetic Ankle Designed for Task Variability - a Concept Validation</li><li>Self-Contained 2-DOF Ankle-Foot Prosthesis with Low-Inertia Extremity for Agile Walking on Uneven Terrain</li><li>Hybrid Volitional Control As a Framework for Lower-Limb Prosthetic Control: A Simulation Study</li><li>Sensorimotor-Inspired Tactile Feedback and Control Improve Consistency of Prosthesis Manipulation in the Absence of Direct Vision</li><li>Phase-Variable Control of a Powered Knee-Ankle Prosthesis Over Continuously Varying Speeds and Inclines</li><li>User Controlled Interface for Tuning Robotic Knee Prosthesis</li><li>Design and Implementation of a Stumble Recovery Controller for a Knee Exoskeleton<h2 id="RGB-D-Perception"><a href="#RGB-D-Perception" class="headerlink" title="RGB-D Perception"></a>RGB-D Perception</h2></li><li>Spatial Imagination with Semantic Cognition for Mobile Robots</li><li>Decoder Modulation for Indoor Depth Completion</li><li>Adversarial Attacks on Camera-LiDAR Models for 3D Car Detection</li><li>Robust and Accurate RGB-D Reconstruction with Line Feature Constraints</li><li>Object-Augmented RGB-D SLAM for Wide-Disparity Relocalisation</li><li>Plane Segmentation Using Depth-Dependent Flood Fill</li><li>Robust Pose Estimation Based on Normalized Information Distance</li><li>RoboSLAM: Dense RGB-D SLAM for Humanoid Robots<h2 id="Range-Sensing"><a href="#Range-Sensing" class="headerlink" title="Range Sensing"></a>Range Sensing</h2></li><li>Joint Depth and Normal Estimation from Real-World Time-Of-Flight Raw Data</li><li>On the Descriptive Power of LiDAR Intensity Images for Segment-Based Loop Closing in 3-D SLAM</li><li>Learning State-Dependent Sensor Measurement Models with Limited Sensor Measurements</li><li>Self-Calibrated Dense 3D Sensor Using Multiple Cross Line Lasers Based on Light Sectioning Method and Visual Odometry</li><li>Patchwork: Concentric Zone-Based Region-Wise Ground Segmentation with Ground Likelihood Estimation Using a 3D LiDAR Sensor</li><li>MILIOM: Tightly Coupled Multi-Input Lidar-Inertia Odometry and Mapping</li><li>Obstacle Avoidance Onboard MAVs Using a FMCW Radar<h2 id="Reactive-and-Sensor-Based-Planning"><a href="#Reactive-and-Sensor-Based-Planning" class="headerlink" title="Reactive and Sensor-Based Planning"></a>Reactive and Sensor-Based Planning</h2></li><li>Autonomous Runtime Composition of Sensor-Based Skills Using Concurrent Task Planning</li><li>Multi-Resolution POMDP Planning for Multi-Object Search in 3D</li><li>Deformation Recovery Control and Post-Impact Trajectory Replanning for Collision-Resilient Mobile Robots</li><li>Towards Autonomous Parking Using Vision-Only Sensors</li><li>Mechanical Search on Shelves Using Lateral Access X-RAY</li><li>XAI-N: Sensor-Based Robot Navigation Using Expert Policies and Decision Trees</li><li>Reactive Control for Bipedal Running Over Random Discrete Terrain under Uncertainty<h2 id="Recognition"><a href="#Recognition" class="headerlink" title="Recognition"></a>Recognition</h2></li><li>Object-To-Scene: Learning to Transfer Object Knowledge to Indoor Scene Recognition</li><li>MV-FractalDB: Formula-Driven Supervised Learning for Multi-View Image Recognition</li><li>CORAL: Colored Structural Representation for Bi-Modal Place Recognition</li><li>SSC: Semantic Scan Context for Large-Scale Place Recognition</li><li>Fully-Online Always-Adaptation of Transfer Functions and Its Application to Sound Source Localization and Separation</li><li>Enabling Robots to Distinguish between Aggressive and Joking Attitudes</li><li>Alternating Drive-And-Glide Flight Navigation of a Kinteplane for Sound Source Position Estimation<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2></li><li>A Sim-To-Real Pipeline for Deep Reinforcement Learning for Autonomous Robot Navigation in Cluttered Rough Terrain</li><li>Inclined Quadrotor Landing Using Deep Reinforcement Learning</li><li>Self-Supervised Online Reward Shaping in Sparse-Reward Environments</li><li>CLAMGen: Closed-Loop Arm Motion Generation Via Multi-View Vision-Based RL</li><li>Residual Feedback Learning for Contact-Rich Manipulation Tasks with Uncertainty</li><li>DEALIO: Data-Efficient Adversarial Learning for Imitation from Observation</li><li>Learning to Design and Construct Bridge without Blueprint</li><li>Sample-Efficient Reinforcement Learning Representation Learning with Curiosity Contrastive Forward Dynamics Model</li><li>An Efficient Image-To-Image Translation HourGlass-Based Architecture for Object Pushing Policy Learning</li><li>A Joint Imitation-Reinforcement Learning Framework for Reduced Baseline Regret</li><li>Passing through Narrow Gaps with Deep Reinforcement Learning</li><li>HARL-A: Hardware Agnostic Reinforcement Learning through Adversarial Selection</li><li>Motion Planning for Autonomous Vehicles in the Presence of Uncertainty Using Reinforcement Learning</li><li>Safe Continuous Control with Constrained Model-Based Policy Optimization</li><li>Terrain-Aware Risk-Assessment-Network-Aided Deep Reinforcement Learning for Quadrupedal Locomotion in Tough Terrain</li><li>Hierarchical Terrain-Aware Control for Quadrupedal Locomotion by Combining Deep Reinforcement Learning and Optimal Control</li><li>Model-Based Constrained Reinforcement Learning Using Generalized Control Barrier Function</li><li>Learning Human Rewards by Inferring Their Latent Intelligence Levels in Multi-Agent Games: A Theory-Of-Mind Approach with Application to Driving Data</li><li>Meta-Learning for Fast Adaptive Locomotion with Uncertainties in Environments and Robot Dynamics</li><li>Monolithic vs. Hybrid Controller for Multi-Objective Sim-To-Real Learning</li><li>Centralizing State-Values in Dueling Networks for Multi-Robot Reinforcement Learning Mapless Navigation</li><li>Benchmarking Safe Deep Reinforcement Learning in Aquatic Navigation</li><li>Multi-Agent Collaborative Learning with Relational Graph Reasoning in Adversarial Environments</li><li>Semantic Tracklets: An Object-Centric Representation for Visual Multi-Agent Reinforcement Learning</li><li>Bayesian Residual Policy Optimization: Scalable Bayesian Reinforcement Learning with Clairvoyant Experts</li><li>Memory-Based Deep Reinforcement Learning for POMDPs</li><li>PNS: Population-Guided Novelty Search for Reinforcement Learning in Hard Exploration Environments</li><li>MAMBPO: Sample-Efficient Multi-Robot Reinforcement Learning Using Learned World Models</li><li>Q-Learning with Long-Term Action-Space Shaping to Model Complex Behavior for Autonomous Lane Changes<h2 id="Representation-Learning"><a href="#Representation-Learning" class="headerlink" title="Representation Learning"></a>Representation Learning</h2></li><li>COCOI: Contact-Aware Online Context Inference for Generalizable Non-Planar Pushing</li><li>DeepKoCo: Efficient Latent Planning with a Task-Relevant Koopman Representation</li><li>Low Dimensional State Representation Learning with Robotics Priors in Continuous Action Spaces</li><li>Acceleration of Actor-Critic Deep Reinforcement Learning for Visual Grasping by State Representation Learning Based on a Preprocessed Input Image</li><li>SSTN: Self-Supervised Domain Adaptation Thermal Object Detection for Autonomous Driving</li><li>Self-Supervised Disentangled Representation Learning for Third-Person Imitation Learning</li><li>Learning to Drop Points for LiDAR Scan Synthesis<h2 id="Robot-Safety"><a href="#Robot-Safety" class="headerlink" title="Robot Safety"></a>Robot Safety</h2></li><li>On Compliance and Safety with Torque-Control for Robots with High Reduction Gears and No Joint-Torque Feedback</li><li>A Kelvin Wake Avoidance Scheme for Autonomous Sailing Robots Based on Orientation-Restricted Dubins Path</li><li>A Predictive Safety Filter for Learning-Based Racing Control</li><li>Measurement-Robust Control Barrier Functions: Certainty in Safety with Uncertainty in State</li><li>Group Multi-Object Tracking for Dynamic Risk Map and Safe Path Planning</li><li>Reactive and Safe Road User Simulations Using Neural Barrier Certificates</li><li>Rm-Code: Proprioceptive Real-Time Recursive Multi-Contact Detection, Isolation and Identification</li><li>R-SNN: An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversarial Attacks through Noise Filters for Dynamic Vision Sensors<h2 id="Robotic-Systems-and-Benchmarking"><a href="#Robotic-Systems-and-Benchmarking" class="headerlink" title="Robotic Systems and Benchmarking"></a>Robotic Systems and Benchmarking</h2></li><li>Identifying Performance Regression Conditions for Testing &amp; Evaluation of Autonomous Systems</li><li>JCopter: Reliable UAV Software through Managed Languages</li><li>Towards a Reference Framework for Tactile Robot Performance and Safety Benchmarking</li><li>On Assessing the Usefulness of Proxy Domains for Developing and Evaluating Embodied Agents</li><li>Towards Efficient Learning-Based Model Predictive Control Via Feedback Linearization and Gaussian Process Regression</li><li>HOPPY: An Open-Source Kit for Education with Dynamic Legged Robots</li><li>A Methodology for Approaching the Integration of Complex Robotics Systems Illustrated through a Bi-Manual Manipulation Case-Study (I)</li><li>Robust SLAM Systems: Are We There Yet?</li><li>Evaluating the Impact of Semantic Segmentation and Pose Estimation on Dense Semantic SLAM</li><li>Overlap Displacement Error: Are Your SLAM Poses Map-Consistent?</li><li>Error Diagnosis of Deep Monocular Depth Estimation Models</li><li>New Metrics for Industrial Depth Sensors Evaluation for Precise Robotic Applications</li><li>I3SA: The Increased Step Size Stability Assessment Benchmark and Its Application to the Humanoid Robot REEM-C</li><li>Interpretable Trade-Offs between Robot Task Accuracy and Compute Efficiency<h2 id="Robotics-and-Automation-in-Agriculture-and-Forestry"><a href="#Robotics-and-Automation-in-Agriculture-and-Forestry" class="headerlink" title="Robotics and Automation in Agriculture and Forestry"></a>Robotics and Automation in Agriculture and Forestry</h2></li><li>Few-Leaf Learning: Weed Segmentation in Grasslands</li><li>Toward Robotic Weed Control: Detection of Nutsedge Weed in Bermudagrass Turf Using Inaccurate and Insufficient Training Data</li><li>A Low-Cost Robot with Autonomous Recharge and Navigation for Weed Control in Fields with Narrow Row Spacing</li><li>Viewpoint Planning for Fruit Size and Position Estimation</li><li>Robotic Lime Picking by Considering Leaves As Permeable Obstacles</li><li>Towards Intelligent Fruit Picking with In-Hand Sensing</li><li>A Robust Illumination-Invariant Camera System for Agricultural Applications</li><li>Depth Ranging Performance Evaluation and Improvement for RGB-D Cameras on Field-Based High-Throughput Phenotyping Robots<h2 id="Robotics-and-Automation-in-Agriculture-Forestry-and-Construction"><a href="#Robotics-and-Automation-in-Agriculture-Forestry-and-Construction" class="headerlink" title="Robotics and Automation in Agriculture, Forestry and Construction"></a>Robotics and Automation in Agriculture, Forestry and Construction</h2></li><li>Reinforcement Learning Control of a Forestry Crane Manipulator</li><li>Hybrid Data-Driven Modelling for Inverse Control of Hydraulic Excavators</li><li>Real-Time Motion Planning of a Hydraulic Excavator Using Trajectory Optimization and Model Predictive Control</li><li>Task-Consistent Path Planning for Mobile 3D Printing</li><li>A Learning Approach to Robot-Agnostic Force-Guided High Precision Assembly</li><li>Image-Based Joint State Estimation Pipeline for Sensorless Manipulators</li><li>Navigate-And-Seek: A Robotics Framework for People Localization in Agricultural Environments<h2 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a>SLAM</h2></li><li>A General Framework for Lifelong Localization and Mapping in Changing Environment</li><li>Geometry-Based Graph Pruning for Lifelong SLAM</li><li>Consistent SLAM Using Local Optimization with Virtual Prior Topologies</li><li>Line Flow Based Simultaneous Localization and Mapping (I)</li><li>Probabilistic Appearance-Invariant Topometric Localization with New Place Awareness</li><li>Efficient Multimodal Belief Propagation for Robust SLAM Using Clustering Based Reparameterization</li><li>Robust Initialization of Multi-Camera SLAM with Limited View Overlaps and Inaccurate Extrinsic Calibration</li><li>Visual Place Recognition Using LiDAR Intensity Information</li><li>F-LOAM: Fast LiDAR Odometry and Mapping</li><li>LiDAR-Based Object-Level SLAM for Autonomous Vehicles</li><li>LiDAR SLAM with Plane Adjustment for Indoor Environment</li><li>Low-Drift Odometry, Mapping and Ground Segmentation Using a Backpack LiDAR System</li><li>RF-LIO: Removal-First Tightly-Coupled Lidar Inertial Odometry in High Dynamic Environments</li><li>What’s in My LiDAR Odometry Toolbox?</li><li>Accurate Visual-Inertial SLAM by Manhattan Frame Re-Identification</li><li>SymbioLCD: Ensemble-Based Loop Closure Detection Using CNN-Extracted Objects and Visual Bag-Of-Words</li><li>Consensus-Informed Optimization Over Mixtures for Ambiguity-Aware Object SLAM</li><li>GR-Fusion: Multi-Sensor Fusion SLAM for Ground Robots with High Robustness and Low Drift</li><li>Multi-Layer VI-GNSS Global Positioning Framework with Numerical Solution Aided MAP Initialization</li><li>Angular Super-Resolution Radar SLAM</li><li>CFEAR Radarodometry - Conservative Filtering for Efficient and Accurate Radar Odometry</li><li>Stereo Plane SLAM Based on Intersecting Lines</li><li>Hierarchical Segment-Based Optimization for SLAM</li><li>CodeMapping: Real-Time Dense Mapping for Sparse SLAM Using Compact Scene Representations</li><li>Topology Aware Object-Level Semantic Mapping towards More Robust Loop Closure</li><li>Random Fourier Features Based SLAM</li><li>Robust Rank Deficient SLAM</li><li>Keypoint Matching for Point Cloud Registration Using Multiplex Dynamic Graph Attention Networks</li><li>Robust Multi-Camera SLAM with Manhattan Constraint Toward Automated Valet Parking</li><li>DSVP: Dual-Stage Viewpoint Planner for Rapid Exploration by Dynamic Expansion</li><li>PoseFusion2: Simultaneous Background Reconstruction and Human Shape Recovery in Real-Time</li><li>A Multi-Hypothesis Approach to Pose Ambiguity in Object-Based SLAM</li><li>Underwater Visual Acoustic SLAM with Extrinsic Calibration</li><li>Some Research Questions for SLAM in Deformable Environments</li><li>An Analytical Solution to the IMU Initialization Problem for Visual-Inertial Systems<h2 id="Semantic-Scene-Understanding"><a href="#Semantic-Scene-Understanding" class="headerlink" title="Semantic Scene Understanding"></a>Semantic Scene Understanding</h2></li><li>Up-To-Down Network: Fusing Multi-Scale Context for 3D Semantic Scene Completion</li><li>Memory-Based Semantic Segmentation for Off-Road Unstructured Natural Environments</li><li>A Deep Learning-Based Indoor Scene Classification Approach Enhanced with Inter-Object Distance Semantic Features</li><li>BORM: Bayesian Object Relation Model for Indoor Scene Recognition</li><li>CORSAIR: Convolutional Object Retrieval and Symmetry-AIded Registration</li><li>Real-Time Monocular Human Depth Estimation and Segmentation on Embedded Systems</li><li>Multi-Scale Feature Aggregation by Cross-Scale Pixel-To-Region Relation Operation for Semantic Segmentation</li><li>TUPPer-Map: Temporal and Unified Panoptic Perception for 3D Metric-Semantic Mapping</li><li>Local Memory Attention for Fast Video Semantic Segmentation</li><li>LiDAR-Based Drivable Region Detection for Autonomous Driving</li><li>CP-Loss: Connectivity-Preserving Loss for Road Curb Detection in Autonomous Driving with Aerial Images</li><li>Semantic Image Alignment for Vehicle Localization</li><li>ISSAFE: Improving Semantic Segmentation in Accidents by Fusing Event-Based Data</li><li>SNE-RoadSeg+: Rethinking Depth-Normal Translation and Deep Supervision for Freespace Detection<h2 id="Sensor-Fusion"><a href="#Sensor-Fusion" class="headerlink" title="Sensor Fusion"></a>Sensor Fusion</h2></li><li>Lvio-Fusion: A Self-Adaptive Multi-Sensor Fusion SLAM Framework Using Actor-Critic Method</li><li>Reactive Visual Odometry Scheduling Based on Noise Analysis Using an Adaptive Extended Kalman Filter</li><li>Multi-Sensor Fusion Incorporating Adaptive Transformation for Reconfigurable Pavement Sweeping Robot</li><li>Modular Multi-Sensor Fusion: A Collaborative State Estimation Perspective</li><li>GEM: Glare or Gloom, I Can Still See You — End-To-End Multi-Modal Object Detection</li><li>Continuous-Time Radar-Inertial Odometry for Automotive Radars</li><li>Radar Visual Inertial Odometry and Radar Thermal Inertial Odometry: Robust Navigation Even in Challenging Visual Conditions</li><li>Accurate Depth Estimation from a Hybrid Event-RGB Stereo Setup</li><li>FINO-Net: A Deep Multimodal Sensor Fusion Framework for Manipulation Failure Detection</li><li>3D-FFS: Faster 3D Object Detection with Focused Frustum Search in Sensor Fusion Based Networks</li><li>Reinforcement Learning Compensated Extended Kalman Filter for Attitude Estimation</li><li>Radar Ghost Target Detection Via Multimodal Transformers</li><li>AcousticFusion: Fusing Sound Source Localization to Visual SLAM in Dynamic Environments</li><li>Data-Fusion for Robust Off-Road Perception Considering Data Quality of Uncertain Sensors<h2 id="Service-Art-and-Entertainment-Robotics"><a href="#Service-Art-and-Entertainment-Robotics" class="headerlink" title="Service, Art and Entertainment Robotics"></a>Service, Art and Entertainment Robotics</h2></li><li>Imagination-Enabled Robot Perception</li><li>AutoPhoto: Aesthetic Photo Capture Using Reinforcement Learning</li><li>Motion Strategy Using Opponent Player’s Serial Learning for Air-Hockey Robots</li><li>Learning Robotic Contact Juggling</li><li>Towards a User Adaptive Assistive Robot: Learning from Demonstration Using Navigation Functions</li><li>Cross-Modal Analysis of Human Detection for Robotics: An Industrial Case Study</li><li>Consolidating Kinematic Models to Promote Coordinated Mobile Manipulations<h2 id="Shared-Autonomy-for-Physical-Human-Robot-Interaction"><a href="#Shared-Autonomy-for-Physical-Human-Robot-Interaction" class="headerlink" title="Shared Autonomy for Physical Human-Robot Interaction"></a>Shared Autonomy for Physical Human-Robot Interaction</h2></li><li>Shared Control Based on a Brain-Computer Interface for Human-Multirobot Cooperation</li><li>Reconfigurable Constraint-Based Reactive Framework for Assistive Robotics with Adaptable Levels of Autonomy</li><li>Toward Vision-Based High Sampling Interaction Force Estimation with Master Position and Orientation for Teleoperation</li><li>Informing Real-Time Corrections in Corrective Shared Autonomy through Expert Demonstrations</li><li>Autonomy in Physical Human-Robot Interaction: A Brief Survey</li><li>A Shared Control Method for Collaborative Human-Robot Plug Task</li><li>Robotics for Occupational Therapy: Learning Upper-Limb Exercises from Demonstrations</li><li>Intelligent Locomotion Planning with Enhanced Postural Stability for Lower-Limb Exoskeletons</li><li>Human-In-The-Loop Stability Analysis of Haptic Rendering with Time Delay by Tracking the Roots of the Characteristic Quasi-Polynomial — the Effect of Arm Impedance</li><li>Deep Neural Skill Assessment and Transfer: Application to Robotic Surgery Training</li><li>Towards Safe Human-Quadrotor Interaction: Mixed-Initiative Control Via Real-Time NMPC<h2 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a>Simulation</h2></li><li>Learning to Fly—a Gym Environment with PyBullet Physics for Reinforcement Learning of Multi-Agent Quadcopter Control</li><li>IGibson 1.0: A Simulation Environment for Interactive Tasks in Large Realistic Scenes</li><li>An Approach to Deploy Interactive Robotic Simulators on the Web for HRI Experiments: Results in Social Robot Navigation</li><li>Co-Design of Embodied Intelligence: A Structured Approach</li><li>Muscle-Reflex Model of Human Locomotion Entrains to Mechanical Perturbations</li><li>Daß: Distributable and Scalable Simulation of Robotic Applications</li><li>Mobile 3D Printing Robot Simulation with Viscoelastic Fluids<h2 id="Social-Human-Robot-Interaction"><a href="#Social-Human-Robot-Interaction" class="headerlink" title="Social Human-Robot Interaction"></a>Social Human-Robot Interaction</h2></li><li>Advocating Attitudinal Change through Android Robot’s Intention-Based Expressive Behaviors: Towards WHO COVID-19 Guidelines Adherence</li><li>Text-Based Robot Emotion and Human-Like Emotional Transition</li><li>Personalization of Human-Robot Gestural Communication through Voice Interaction Grounding</li><li>“Pretending to Be Okay in a Sad Voice”: Social Robot’s Usage of Verbal and Nonverbal Cue Combination and Its Effect on Human Empathy and Behavior Inducement</li><li>Pain Expression-Based Visual Feedback Method for Care Training Assistant Robot with Musculoskeletal Symptoms</li><li>A Unified Bi-Directional Model for Natural and Artificial Trust in Human-Robot Collaboration</li><li>Expectations vs. Reality: Unreliability and Transparency in a Treasure Hunt Game with ICub</li><li>Collaborative Storytelling with Social Robots</li><li>An Integrated Approach to Context-Sensitive Moral Cognition in Robot Cognitive Architectures</li><li>Translating Natural Language Instructions to Computer Programs for Robot Manipulation</li><li>Design of Taking a Walk with a Robot That Receives Care from a Person and Indirectly Mediates Communication with Strangers</li><li>Human-Robot Greeting: Tracking Human Greeting Mental States and Acting Accordingly</li><li>A Robot That Encourages Self-Disclosure to Reduce Anger Mood</li><li>Persuasion Strategies for Social Robot to Keep Humans Accepting Daily Different Recommendations</li><li>ROS for Human-Robot Interaction</li><li>Mobile Robot Yielding Cues for Human-Robot Spatial Interaction</li><li>Semantic-Based Explainable AI: Leveraging Semantic Scene Graphs and Pairwise Ranking to Explain Robot Failures</li><li>The Effects of Conversational Contexts and Forms of Non-Lexical Backchannel on User’s Perception of the Robot</li><li>Using an Android Robot to Improve Social Connectedness by Sharing Recent Experiences of Group Members in Human-Robot Conversations</li><li>Exploring Consequential Robot Sound: Should We Make Robots Quiet and Kawaii-Et?</li><li>Drones in Wonderland — Disentangling Collocated Interaction Using Radical Form<h2 id="Soft-Robot-Applications"><a href="#Soft-Robot-Applications" class="headerlink" title="Soft Robot Applications"></a>Soft Robot Applications</h2></li><li>Laser Endoscopic Manipulator Using Spring-Reinforced Multi-DoF Soft Actuator</li><li>Inverse Dynamics Model-Based Shape Control of Soft Continuum Finger Robot Using Parametric Curve</li><li>Soft Robotic Oscillators with Strain-Based Coordination</li><li>SoMo: Fast and Accurate Simulations of Continuum Robots in Complex Environments</li><li>Toward State-Unsaturation Guaranteed Fault Detection Method in Visual Servoing of Soft Robot Manipulators</li><li>Fuzzy-Depth Objects Grasping Based on FSG Algorithm and Soft Robotic Hand</li><li>Deformable Elasto-Plastic Object Shaping Using an Elastic Hand and Model-Based Reinforcement Learning<h2 id="Soft-Robot-Materials-and-Design"><a href="#Soft-Robot-Materials-and-Design" class="headerlink" title="Soft Robot Materials and Design"></a>Soft Robot Materials and Design</h2></li><li>Two-Sheet Type Rotary-Driven Thin Bending Mechanism Realizing High Stiffness</li><li>Turning an Articulated 3-PPSR Manipulator into a Parallel Continuum Robot</li><li>Origami-Inspired Robot That Swims Via Jet Propulsion</li><li>Multifunctional Robotic Glove with Active-Passive Training Modes for Hand Rehabilitation and Assistance</li><li>S-Climbot: A Soft Robot with Novel Grippers and Rigid-Compliantly Constrained Body for Climbing on Various Poles</li><li>Soft Retraction Device and Internal Camera Mount for Everting Vine Robots</li><li>Partial Formation of Hydroxyapatite on Poly (Vinyl Alcohol) Hydrogel for Intensive Motions of Biomimetic Soft Robots</li><li>Development of a Permanent Magnet Elastomer (PME) Infused Soft Robot Skin for Tactile Sensing</li><li>Wide-Bandwidth Soft Vibrotactile Interface Using Electrohydraulic Actuator for Haptic Steering Wheel Application</li><li>Design and Feasibility Analysis of a Foldable Robot Arm for Drones Using a Twisted String Actuator: FRAD-TSA</li><li>Analytical Design of a Pneumatic Elastomer Robot with Deterministically Adjusted Stiffness</li><li>Design and Validation of a New Family of Bio-Inspired 3D-Printable Structurally-Programmable Soft Robots</li><li>Shape Recognition of a Tensegrity with Soft Sensor Threads and Artificial Muscles Using a Recurrent Neural Network</li><li>Origami Logic Gates for Printable Robots</li><li>SPHR: A Soft Pneumatic Hybrid Robot with Extreme Shape Changing and Lifting Abilities<h2 id="Soft-Sensors-and-Actuators"><a href="#Soft-Sensors-and-Actuators" class="headerlink" title="Soft Sensors and Actuators"></a>Soft Sensors and Actuators</h2></li><li>EPM–MRE: Electropermanent Magnet–Magnetorheological Elastomer for Soft Actuation System and Its Application to Robotic Grasping</li><li>Double Helical Soft Pneumatic Actuator Capable of Generating Complex 3D Torsional Motions</li><li>Bistable Valves for Magnetorheological Fluid-Based Soft Robotic Actuation Systems</li><li>Wireless Powered Dielectric Elastomer Actuator</li><li>Reducing the Influence of the Contact Area on a Soft Capacitive Force Sensor</li><li>Dynamic Hand Gesture Recognition Using a Stretchable Multi-Layer Capacitive Array, Proximity Sensing, and a SVM Classifier</li><li>Estimating the Shape of Soft Pneumatic Actuators Using Active Vibroacoustic Sensing<h2 id="Software-and-Hardware"><a href="#Software-and-Hardware" class="headerlink" title="Software and Hardware"></a>Software and Hardware</h2></li><li>Smart Pointers and Shared Memory Synchronisation for Efficient Inter-Process Communication in ROS on an Autonomous Vehicle</li><li>Human-Aware Navigation Planner for Diverse Human-Robot Interaction Contexts</li><li>CompROS: A Composable ROS2 Based Architecture for Real-Time Embedded Robotic Development</li><li>Arena-Rosnav: Towards Deployment of Deep-Reinforcement-Learning-BasedObstacle Avoidance into Conventional Autonomous NavigationSystems</li><li>Efficient Computation of Map-Scale Continuous Mutual Information on Chip in Real Time</li><li>Data-Driven Energy Estimation of Individual Instructions in User-Defined Robot Programs for Collaborative Robots</li><li>DQ Robotics: A Library for Robot Modeling and Control (I)</li><li>Grasping Robot Integration and Prototyping: The GRIP Software Framework (I)<h2 id="Space-Robotics-and-Automation"><a href="#Space-Robotics-and-Automation" class="headerlink" title="Space Robotics and Automation"></a>Space Robotics and Automation</h2></li><li>Towards Robust Monocular Visual Odometry for Flying Robots on Planetary Missions</li><li>Stereo Perception in the Dark Using Uncalibrated Line Laser</li><li>Enhancing Lunar Reconnaissance Orbiter Images Via Multi-Frame Super Resolution for Future Robotic Space Missions</li><li>Multi-Modal Loop Closing in Unstructured Planetary Environments with Visually Enriched Submaps</li><li>Online Information-Aware Motion Planning with Inertial Parameter Learning for Robotic Free-Flyers</li><li>Surface Sliding Behavior Analysis of Space Probes in Simulated Extraterrestrial Environments</li><li>A Compliant Partitioned Shared Control Strategy for an Orbital Robot</li><li>Compliant Floating-Base Control of Space Robots<h2 id="Surgical-Robotics"><a href="#Surgical-Robotics" class="headerlink" title="Surgical Robotics"></a>Surgical Robotics</h2></li><li>Autonomous Bi-Manual Surgical Suturing Based on Skills Learned from Demonstration</li><li>Safe Reinforcement Learning Using Formal Verification for Tissue Retraction in Autonomous Robotic-Assisted Surgery</li><li>Fall Detection for Robotic Endoscope Holders in Minimally Invasive Surgery</li><li>Pre-Operative Offline Optimization of Insertion Point Location for Safe and Accurate Surgical Task Execution</li><li>Globally Optimal Fetoscopic Mosaicking Based on Pose Graph Optimisation with Affine Constraints</li><li>Fusion of Biplane Fluoroscopy with Fiber Bragg Grating for 3D Catheter Shape Reconstruction</li><li>Position-Based Dynamics Simulator of Brain Deformations for Path Planning and Intra-Operative Control in Keyhole Neurosurgery<h2 id="Swarm-Robotics"><a href="#Swarm-Robotics" class="headerlink" title="Swarm Robotics"></a>Swarm Robotics</h2></li><li>A Decentralized Cluster Formation Containment Framework for Multirobot Systems (I)</li><li>Sniffy Bug: A Fully Autonomous Swarm of Gas-Seeking Nano Quadcopters in Cluttered Environments</li><li>Personalized Human-Swarm Interaction through Hand Motion</li><li>Towards a Passive Self-Assembling Macroscale Multi-Robot System</li><li>Decentralized Localization in Homogeneous Swarms Considering Real-World Non-Idealities</li><li>Cooperative Object Transportation Using Gibbs Random Fields</li><li>Extension of Flocking Models to Environments with Obstacles and Degraded Communications</li><li>MicROS.BT: An Event-Driven Behavior Tree Framework for Swarm Robots<h2 id="Task-and-Motion-Planning"><a href="#Task-and-Motion-Planning" class="headerlink" title="Task and Motion Planning"></a>Task and Motion Planning</h2></li><li>Prioritized Indoor Exploration with a Dynamic Deadline</li><li>Assembly Planning by Recognizing a Graphical Instruction Manual</li><li>Optimal Planning Over Long and Infinite Horizons for Achieving Independent Partially-Observable Tasks That Evolve Over Time</li><li>Probabilistic Inference in Planning for Partially Observable Long Horizon Problems</li><li>Intelligent Execution through Plan Analysis</li><li>A General Task and Motion Planning Framework for Multiple Manipulators</li><li>Spatial Action Maps Augmented with Visit Frequency Maps for Exploration Tasks</li><li>Learning Symbolic Operators for Task and Motion Planning<h2 id="Telerobotics-and-Teleoperation"><a href="#Telerobotics-and-Teleoperation" class="headerlink" title="Telerobotics and Teleoperation"></a>Telerobotics and Teleoperation</h2></li><li>Miniature Tangible Cube: Concept and Design of Target-Object-Oriented User Interface for Dual-Arm Telemanipulation</li><li>Cursor-Based Robot Tele-Manipulation through 2D-To-SE2 Interfaces</li><li>Mobile Teleoperation: Feasibility of Wireless Wearable Sensing of the Operator’s Arm Motion</li><li>Drawing Elon Musk: A Robot Avatar for Remote Manipulation</li><li>Analysis of User Preferences for Robot Motions in Immersive Telepresence</li><li>A Reconfigurable Interface for Ergonomic and Dynamic Tele-Locomanipulation</li><li>Safety-Oriented Teleoperation Framework for Contact-Rich Tasks in Hazardous Workspaces</li><li>QoE-Driven Delay-Adaptive Control Scheme Switching for Time-Delayed Bilateral Teleoperation with Haptic Data Reduction</li><li>Passivity-Based Control for Haptic Teleoperation of a Legged Manipulator in Presence of Time-Delays</li><li>SnakeRaven: Teleoperation of a 3D Printed Snake-Like Manipulator Integrated to the RAVEN II Surgical Robot</li><li>Position Synchronization through the Energy-Reflection Based Time Domain Passivity Approach in Position-Position Architectures</li><li>Learning to Guide Human Attention on Mobile Telepresence Robots with 360 Vision</li><li>Learning to Arbitrate Human and Robot Control Using Disagreement between Sub-Policies</li><li>NimbRo Avatar: Interactive Immersive Telepresence with Force-Feedback Telemanipulation<h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h2></li><li>Delay Aware Universal Notice Network : Real World Multi-Robot Transfer Learning</li><li>Domain Curiosity: Learning Efficient Data Collection Strategies for Domain Adaptation</li><li>Knowledge Transfer across Imaging Modalities Via Simultaneous Learning of Adaptive Autoencoders for High-Fidelity Mobile Robot Vision</li><li>Bayesian Meta-Learning for Few-Shot Policy Adaptation across Robotic Platforms</li><li>Shaping Progressive Net of Reinforcement Learning for Policy Transfer with Human Evaluative Feedback</li><li>A Conformal Mapping-Based Framework for Robot-To-Robot and Sim-To-Real Transfer Learning</li><li>On Explainability and Sensor-Adaptability of a Robot Tactile Texture Representation Using a Two-Stage Recurrent Networks<h2 id="Underactuated-amp-Redundant-Robots"><a href="#Underactuated-amp-Redundant-Robots" class="headerlink" title="Underactuated &amp; Redundant Robots"></a>Underactuated &amp; Redundant Robots</h2></li><li>Streamlined Tuning Procedure for Stable PID Control of Flexible-Base Manipulators</li><li>RRT-Based Path Planning for Follow-The-Leader Motion of Hyper-Redundant Manipulators</li><li>Anisotropic Disturbance Rejection for Kinematically Redundant Systems with Applications on an UVMS</li><li>Tension Control Method Utilizing Antagonistic Tension to Enlarge the Workspace of Coupled Tendon-Driven Articulated Manipulator</li><li>Momentum Based Whole-Body Optimal Planning for a Single-Spherical-Wheeled Balancing Mobile Manipulator</li><li>Design Optimization of Musculoskeletal Humanoids with Maximization of Redundancy to Compensate for Muscle Rupture</li><li>Supervised Autonomy for Remote Teleoperation of Hybrid Wheel-Legged Mobile Manipulator Robots</li><li>Fuzzy PID Controller Based on Yaw Angle Prediction of a Spherical Robot<h2 id="Vision-Based-Navigation"><a href="#Vision-Based-Navigation" class="headerlink" title="Vision-Based Navigation"></a>Vision-Based Navigation</h2></li><li>Motion Field Consensus with Locality Preservation: A Geometric Confirmation Strategy for Loop Closure Detection</li><li>Re-Attention Is All You Need: Memory-Efficient Scene Text Detection Via Re-Attention on Uncertain Regions</li><li>Trajectory-Constrained Deep Latent Visual Attention for Improved Local Planning in Presence of Heterogeneous Terrain</li><li>Towards Generalization in Target-Driven Visual Navigation by Using Deep Reinforcement Learning (I)</li><li>Learning Navigation Skills for Legged Robots with Learned Robot Embeddings</li><li>NavTuner: Learning a Scene-Sensitive Family of Navigation Policies</li><li>Fast and Robust Bio-Inspired Teach and Repeat Navigation</li><li>POMP++: Pomcp-Based Active Visual Search in Unknown Indoor Environments</li><li>DT-Loc: Monocular Visual Localization on HD Vector Map Using Distance Transforms of 2D Semantic Detections</li><li>Probabilistic Visual Navigation with Bidirectional Image Prediction</li><li>FAITH: Fast Iterative Half-Plane Focus of Expansion Estimation Using Optic Flow</li><li>Mapless Humanoid Navigation Using Learned Latent Dynamics</li><li>Success Weighted by Completion Time: A Dynamics-Aware Evaluation Criteria for Embodied Navigation</li><li>A Bio-Inspired Multi-Sensor System for Robust Orientation and Position Estimation</li><li>Monocular Teach-And-Repeat Navigation Using a Deep Steering Network with Scale Estimation</li><li>Self-Supervised Scale Recovery for Monocular Depth and Egomotion Estimation</li><li>Assembly Action Understanding from Fine-Grained Hand Motions, a Multi-Camera and Deep Learning Approach</li><li>Robust and Long-Term Monocular Teach-And-Repeat Navigationusing a Single-Experience Map</li><li>Self Attention Guided Depth Completion Using RGB and SparseLiDAR Point Clouds</li><li>Laser-Based Side-By-Side Following for Human-Following Robots</li><li>Deep Leg Tracking by Detection and Gait Analysis in 2D Range Data for Intelligent Robotic Assistants<h2 id="Visual-Learning"><a href="#Visual-Learning" class="headerlink" title="Visual Learning"></a>Visual Learning</h2></li><li>ADD: A Fine-Grained Dynamic Inference Architecture for Semantic Image Segmentation</li><li>COINet: Adaptive Segmentation with Co-Interactive Network for Autonomous Driving</li><li>Category-Level 6D Object Pose Estimation Via Cascaded Relation and Recurrent Reconstruction Networks</li><li>Scanline Resolution-Invariant Depth Completion Using a Single Image and Sparse LiDAR Point Cloud</li><li>Unknown Object Segmentation from Stereo Images</li><li>Object Learning for 6D Pose Estimation and Grasping from RGB-D Videos of In-Hand Manipulation</li><li>Online Monitoring of Object Detection Performance During Deployment</li><li>OPEn: An Open-Ended Physics Environment for Learning without a Task</li><li>Fast and Unsupervised 3D-CNN Based Non-Local Feature Learning for Direct Volume Rendering of 3D Medical Images</li><li>Self-Supervised Optical Flow with Spiking Neural Networks and Event Based Cameras</li><li>DA4Event: Towards Bridging the Sim-To-Real Gap for Event Cameras Using Domain Adaptation</li><li>Accurate Grid Keypoint Learning for Efficient Video Prediction</li><li>Improving Monocular Depth Estimation by Semantic Pre-Training</li><li>3D Segmentation Learning from Sparse Annotations and Hierarchical Descriptors</li><li>TemporalFusion: Temporal Motion Reasoning with Multi-Frame Fusion for 6D Object Pose Estimation<h2 id="Visual-Servoing"><a href="#Visual-Servoing" class="headerlink" title="Visual Servoing"></a>Visual Servoing</h2></li><li>Mind Control of a Service Robot with Visual Servoing</li><li>Sampling-Based MPC for Constrained Vision Based Control</li><li>A Real-Time State Dependent Region Estimator for Autonomous Endoscope Navigation (I)</li><li>Image-Based Visual Servoing of Rotorcrafts to Planar Visual Targets of Arbitrary Orientation</li><li>Robot-Assisted Breast Ultrasound Scanning Using Geometrical Analysis of the Seroma and Image Segmentation</li><li>Multi-Scale Laplacian-Based FMM for Shape Control</li><li>RTVS: A Lightweight Differentiable MPC Framework for Real-Time Visual Servoing<h2 id="Visual-Tracking"><a href="#Visual-Tracking" class="headerlink" title="Visual Tracking"></a>Visual Tracking</h2></li><li>Joint Multi-Object Detection and Tracking with Camera-LiDAR Fusion for Autonomous Driving</li><li>Powerline Tracking with Event Cameras</li><li>Improvement of Optical Flow Estimation by Using the Hampel Filter for Low-End Embedded Systems</li><li>Real-Time Outdoor Illumination Estimation for Camera Tracking in Indoor Environments</li><li>CRACT: Cascaded Regression-Align-Classification for Robust Tracking</li><li>Dynamic Event Camera Calibration</li><li>PointSiamRCNN: Target-Aware Voxel-Based Siamese Tracker for Point Clouds</li><li>Improving Object Permanence Using Agent Actions and Reasoning</li><li>Multi-Variable State Prediction: HMM Based Approach for Real-Time Trajectory Prediction</li><li>Towards Robust Human Trajectory Prediction in Raw Videos</li><li>BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models</li><li>Model-Free Vehicle Tracking and State Estimation in Point Cloud Sequences</li><li>Score Refinement for Confidence-Based 3D Multi-Object Tracking</li><li>A High-Accuracy Fiducial Marker with Parallel Lenticular Angle Gauges<h2 id="Visual-Inertial-SLAM"><a href="#Visual-Inertial-SLAM" class="headerlink" title="Visual-Inertial SLAM"></a>Visual-Inertial SLAM</h2></li><li>Stereo Visual Inertial Odometry for Robots with Limited Computational Resources</li><li>Feature-Aided Bundle Adjustment Learning Framework for Self-Supervised Monocular Visual Odometry</li><li>Accurate Visual-Inertial SLAM by Feature Re-Identification</li><li>PLF-VINS: Real-Time Monocular Visual-Inertial SLAM with Point-Line Fusion and Parallel-Line Fusion</li><li>Sampson Distance: A New Approach to Improving Visual-Inertial Odometry’s Accuracy</li><li>A Comparison of Modern General-Purpose Visual SLAM Approaches</li><li>RP-VIO: Robust Plane-Based Visual-Inertial Odometry for Dynamic Environments</li><li>A Visual Inertial Odometry Framework for 3D Points, Lines and Planes<h2 id="Wearable-Robotics"><a href="#Wearable-Robotics" class="headerlink" title="Wearable Robotics"></a>Wearable Robotics</h2></li><li>Wearable Tactile Sensor Suit for Natural Body Dynamics Extraction: Case Study on Posture Prediction Based on Physical Reservoir Computing</li><li>Method for the Determination of Relative Joint Axes for Wearable Inertial Sensor Applications</li><li>Evaluation of Lumbar Burdens for Endoskeleton-Type Assist Suit Based on Musculoskeletal Model and Its Improvement of the Utility</li><li>Exo-Muscle: A Semi-Rigid Assistive Device for the Knee</li><li>Estimating the Center of Mass of Human-Exoskeleton Systems with Physically Coupled Serial Chain</li><li>A Soft Assistive Device for Elbow Effort-Compensation</li><li>Gaussian Process Regression for COP Trajectory Estimation in Healthy and Pathological Gait Using Instrumented Insoles</li><li>Learning Fingertip Force to Grasp Deformable Objects for Soft Wearable Robotic Glove with TSM<h2 id="Wheeled-Robots"><a href="#Wheeled-Robots" class="headerlink" title="Wheeled Robots"></a>Wheeled Robots</h2></li><li>Development of an Agile Omnidirectional Mobile Robot with Gravity Compensated Wheel-Leg Mechanisms for Human Environment</li><li>Continuous Robust Trajectory Tracking Control for Autonomous Ground Vehicles Considering Lateral and Longitudinal Kinematics and Dynamics Via Recursive Backstepping</li><li>Sub-Optimal and Robust Path Tracking: A Geometric Approach</li><li>Whole-Body MPC and Online Gait Sequence Generation for Wheeled-Legged Robots</li><li>Design and Analysis of a Bi-Directional Transformable Wheel Robot Trimode</li><li>Environmentally Adaptive Control Including Variance Minimization Using Stochastic Predictive Network with Parametric Bias: Application to Mobile Robots</li><li>Traversability-Based Trajectory Planning with Quasi-Dynamic Vehicle Model in Loose Soil</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> IROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICRA2020文章目录</title>
      <link href="/2022/01/03/icra2020-paper-list/"/>
      <url>/2022/01/03/icra2020-paper-list/</url>
      
        <content type="html"><![CDATA[<h1 id="ICRA2020-paper-list"><a href="#ICRA2020-paper-list" class="headerlink" title="ICRA2020-paper-list"></a>ICRA2020-paper-list</h1><p>Welcome to ICRA 2020, the 2020 IEEE International Conference on Robotics and Automation.</p><p>ICRA is the largest robotics meeting in the world and is the flagship conference of the IEEE Robotics &amp; Automation Society. It is thus our honor and pleasure to welcome you to this edition, although the current exceptional circumstances did not allow us to organize it with the glimpse and splendor that our wonderful robotics community deserves.</p><p>ICRA 2020 received 3,512 submissions, a new record, from 64 countries and 14,665 authors. Overall, 3,446 papers were reviewed. The 10 most popular keywords, in descending order, were: Deep Learning in Robotics and Automation, Motion and Path Planning, Localization, Learning and Adaptive Systems, Autonomous Vehicle Navigation, Multi-Robot Systems, SLAM, Object Detection, Segmentation and Categorization, and Visual-Based Navigation. </p><p>This list is edited by <a href="https://github.com/PaoPaoRobot">PaopaoRobot, 泡泡机器人</a> , the Chinese academic nonprofit organization. Welcome to follow our github and our WeChat Public Platform Account ( <a href="https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&amp;mid=100000102&amp;idx=1&amp;sn=0a8a831a4f2c18443dbf436ef5d5ff8c&amp;chksm=6c10bf625b6736748c9612879e166e510f1fe301b72ed5c5d7ecdd0f40726c5d757e975f37af&amp;mpshare=1&amp;scene=1&amp;srcid=0530KxSLjUE9I38yLgfO2nVm&amp;pass_ticket=0aB5tcjeTfmcl9u0eSVzN4Ag4tkpM2RjRFH8DG9vylE%3D#rd">paopaorobot_slam</a> ). Of course, you could contact with <a href="https://github.com/yvonshong">Yvon Shong</a>.</p><p>You could use <a href="index.md">index.md</a> to look up the index of some paper.</p><h1 id="Categories"><a href="#Categories" class="headerlink" title="Categories"></a>Categories</h1><ul><li>Awards I: Service Robots; Medical Robotics</li><li>Awards II: Robot Mechanisms and Design; Automation</li><li>Awards III: Human-Robot Interaction (HRI); Multi-Robot Systems</li><li>Awards IV: Unmanned Aerial Vehicles; Robot Vision</li><li>Awards V: Robot Manipulation; Cognitive Robotics</li><li>Awards VI: Best Student Paper Award; Best Conference Paper Award</li><li>SLAM  </li><li>Deep Learning in Robotics and Automation</li><li>Motion and Path Planning </li><li>Aerial Systems: Mechanics and Control </li><li>Autonomous Driving </li><li>Localization </li><li>Learning from Demonstration- Medical Robots and Systems </li><li>Legged Robots- Multi-Robot Systems </li><li>Modeling, Control, and Learning for Soft Robots</li><li>Manipulation</li><li>Sensor Fusion </li><li>Compliance and Impedance Control</li><li>Visual Learning</li><li>Soft Sensors and Actuators</li><li>Wearable Robots</li><li>Cognitive Human-Robot Interaction</li><li>Robotics in Agriculture and Forestry</li><li>Calibration and Identification </li><li>Industrial Robots</li><li>Biomimetics</li><li>Robust/Adaptive Control of Robotic Systems </li><li>Space Robotics and Automation</li><li>Perception for Grasping and Manipulation</li><li>Humanoid Robots</li><li>Force Control </li><li>Semantic Scene Understanding</li><li>Social Human-Robot Interaction </li><li>Biologically-Inspired Robots- Robotics in Agriculture, Construction and Mining </li><li>Kinematics </li><li>Robot Safety</li><li>Swarms </li><li>Simulation and Animation</li><li>Reinforcement Learning for Robotics </li><li>Manipulation Planning </li><li>Contact Modeling</li><li>Robotics in Hazardous Fields </li><li>Dynamics</li><li>Product Design, Development and Prototyping</li><li>Cellular and Modular Robots</li><li>Performance Evaluation and Benchmarking</li><li>Aerial Systems: Applications</li><li>Learning and Adaptive Systems</li><li>Surgical Robotics: Laparascopy I</li><li>Surgical Robotics: Laparoscopy II</li><li>Surgical Robotics: Steerable Catheters/Needles</li><li>Path Planning for Multiple Mobile Robots or Agents </li><li>Optimization and Optimal Control</li><li>Grasping</li><li>Omnidirectional Vision </li><li>Force and Tactile Sensing- Visual-Based Navigation</li><li>Soft Robot Applications</li><li>Prosthetics and Exoskeletons </li><li>Human-Centered Robotics </li><li>Mechanism Design</li><li>Marine Robotics</li><li>Compliant Joint/Mechanism</li><li>Search and Rescue Robots </li><li>Human Detection and Tracking </li><li>Omnidirectional Vision and Audition</li><li>Hydraulic/Pneumatic Actuators</li><li>Service Robots </li><li>Robot Perception </li><li>Distributed Robot Systems</li><li>Range Sensing</li><li>Transfer Learning</li><li>Flexible Robots</li><li>Field and Space Robots</li><li>Recognition</li><li>Aerial Systems: Multi-Robots</li><li>Biological Cell Manipulation</li><li>Cooperating Robots </li><li>RGB-D Perception</li><li>Task Planning</li><li>Brain-Machine Interfaces </li><li>Tendon/Wire Mechanism</li><li>Agricultural Automation</li><li>Underactuated Robots</li><li>Applications- Robust and Sensor-Based Control</li><li>Object Detection, Segmentation and Categorization- Aerial Systems: Perception and Autonomy</li><li>Autonomous Vehicle Navigation</li><li>Mapping- Computer Vision for Other Robotic Applications</li><li>Humanoid and Bipedal Locomotion</li><li>Motion Control</li><li>Dexterous Manipulation</li><li>Computer Vision for Automation and Manufacturing</li><li>Visual Servoing</li><li>Soft Robot Materials and Design- Rehabilitation Robotics </li><li>Physical Human-Robot Interaction- Telerobotics and Teleoperation</li><li>Collision Avoidance</li><li>Micro/Nano Robots</li><li>AI-Based Methods</li><li>Climbing Robots </li><li>Failure Detection and Recovery</li><li>Learning to Predict</li><li>Learning for Motion Planning- Motion Control of Manipulators- Computer Vision for Medical Robots</li><li>Grippers and Other End-Effectors</li><li>Formal Methods in Robotics and Automation </li><li>Parallel Robots</li><li>Mechanism and Verification</li><li>Model Learning for Control </li><li>Mobile Manipulation</li><li>Computer Vision for Transportation</li><li>Haptics and Haptic Interfaces</li><li>Visual Tracking</li><li>Planning, Scheduling and Coordination</li><li>Reactive and Sensor-Based Planning</li></ul><h2 id="Awards-I-Service-Robots-Medical-Robotics"><a href="#Awards-I-Service-Robots-Medical-Robotics" class="headerlink" title="Awards I: Service Robots; Medical Robotics"></a>Awards I: Service Robots; Medical Robotics</h2><ul><li>Online Trajectory Planning through Combined Trajectory Optimization and Function Approximation: Application to the Exoskeleton Atalante</li><li>Human-Centric Active Perception for Autonomous Observation</li><li>Active Reward Learning for Co-Robotic Vision Based Exploration in Bandwidth Limited Environments</li><li>Fault Tolerant Control in Shape-Changing Internal Robots</li><li>Swing-Assist for Enhancing Stair Ambulation in a Primarily-Passive Knee Prosthesis</li><li>A Multilayer-Multimodal Fusion Architecture for Pattern Recognition of Natural Manipulations in Percutaneous Coronary Interventions</li></ul><h2 id="Awards-II-Robot-Mechanisms-and-Design-Automation"><a href="#Awards-II-Robot-Mechanisms-and-Design-Automation" class="headerlink" title="Awards II: Robot Mechanisms and Design; Automation"></a>Awards II: Robot Mechanisms and Design; Automation</h2><ul><li>Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation</li><li>Swing-Assist for Enhancing Stair Ambulation in a Primarily-Passive Knee Prosthesis</li><li>Asynchronous and Decoupled Control of the Position and the Stiffness of a Spatial RCM Tensegrity Mechanism for Needle Manipulation</li><li>Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly</li><li>Deep Visual Heuristics: Learning Feasibility of Mixed-Integer Programs for Manipulation Planning</li><li>Securing Industrial Operators with Collaborative Robots: Simulation and Experimental Validation for a Carpentry Task</li></ul><h2 id="Awards-III-Human-Robot-Interaction-HRI-Multi-Robot-Systems"><a href="#Awards-III-Human-Robot-Interaction-HRI-Multi-Robot-Systems" class="headerlink" title="Awards III: Human-Robot Interaction (HRI); Multi-Robot Systems"></a>Awards III: Human-Robot Interaction (HRI); Multi-Robot Systems</h2><ul><li>Preference-Based Learning for Exoskeleton Gait Optimization</li><li>Perception-Action Coupling in Usage of Telepresence Cameras</li><li>Human Interface for Teleoperated Object Manipulation with a Soft Growing Robot</li><li>Efficient Large-Scale Multi-Drone Delivery Using Transit Networks</li><li>Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee Using Relative Bernstein Polynomial</li><li>Scalable Target-Tracking for Autonomous Vehicle Fleets</li></ul><h2 id="Awards-IV-Unmanned-Aerial-Vehicles-Robot-Vision"><a href="#Awards-IV-Unmanned-Aerial-Vehicles-Robot-Vision" class="headerlink" title="Awards IV: Unmanned Aerial Vehicles; Robot Vision"></a>Awards IV: Unmanned Aerial Vehicles; Robot Vision</h2><ul><li>Design and Autonomous Stabilization of a Ballistically Launched Multirotor</li><li>A Morphable Aerial-Aquatic Quadrotor with Coupled Symmetric Thrust Vectoring</li><li>Nonlinear Vector-Projection Control for Agile Fixed-Wing Unmanned Aerial Vehicles</li><li>OmniSLAM: Omnidirectional Localization and Dense Mapping for Wide-Baseline Multi-Camera Systems</li><li>Metrically-Scaled Monocular SLAM Using Learned Scale Factors</li><li>Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection</li></ul><h2 id="Awards-V-Robot-Manipulation-Cognitive-Robotics"><a href="#Awards-V-Robot-Manipulation-Cognitive-Robotics" class="headerlink" title="Awards V: Robot Manipulation; Cognitive Robotics"></a>Awards V: Robot Manipulation; Cognitive Robotics</h2><ul><li>6-DOF Grasping for Target-Driven Object Manipulation in Clutter</li><li>Tactile Dexterity: Manipulation Primitives with Tactile Feedback</li><li>Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation</li><li>Semantic Linking Maps for Active Visual Object Search</li><li>Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video</li><li>Transient Behavior and Predictability in Manipulating Complex Objects</li></ul><h2 id="Awards-VI-Best-Student-Paper-Award-Best-Conference-Paper-Award"><a href="#Awards-VI-Best-Student-Paper-Award-Best-Conference-Paper-Award" class="headerlink" title="Awards VI: Best Student Paper Award; Best Conference Paper Award"></a>Awards VI: Best Student Paper Award; Best Conference Paper Award</h2><ul><li>Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation</li><li>An ERT-Based Robotic Skin with Sparsely Distributed Electrodes: Structure, Fabrication, and DNN-Based Signal Processing</li><li>6-DOF Grasping for Target-Driven Object Manipulation in Clutter</li><li>Preference-Based Learning for Exoskeleton Gait Optimization</li><li>Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation</li><li>Prediction of Human Full-Body Movements with Motion Optimization and Recurrent Neural Networks</li></ul><h2 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a>SLAM</h2><ul><li>Real-Time Graph-Based SLAM with Occupancy Normal Distributions Transforms</li><li>Spatio-Temporal Non-Rigid Registration of 3D Point Clouds of Plants</li><li>Uncertainty-Based Adaptive Sensor Fusion for Visual-Inertial Odometry under Various Motion Characteristics</li><li>Loam_livox: A Fast, Robust, High-Precision LiDAR Odometry and Mapping Package for LiDARs of Small FoV</li><li>Active SLAM Using 3D Submap Saliency for Underwater Volumetric Exploration</li><li>Are We Ready for Service Robots? the OpenLORIS-Scene Datasets for Lifelong SLAM</li><li>Intensity Scan Context: Coding Intensity and Geometry Relations for Loop Closure Detection</li><li>TextSLAM: Visual SLAM with Planar Text Features</li><li>FlowNorm: A Learning-Based Method for Increasing Convergence Range of Direct Alignment</li><li>Redesigning SLAM for Arbitrary Multi-Camera Systems</li><li>Dynamic SLAM: The Need for Speed</li><li>GradSLAM: Dense SLAM Meets Automatic Differentiation</li><li>Long-Term Place Recognition through Worst-Case Graph Matching to Integrate Landmark Appearances and Spatial Relationships</li><li>Linear RGB-D SLAM for Atlanta World</li><li>Stereo Visual Inertial Odometry with Online Baseline Calibration</li><li>Lidar-Monocular Visual Odometry Using Point and Line Features</li><li>Probabilistic Data Association Via Mixture Models for Robust Semantic SLAM</li><li>Closed-Loop Benchmarking of Stereo Visual-Inertial SLAM Systems: Understanding the Impact of Drift and Latency on Tracking Accuracy</li><li>Metrically-Scaled Monocular SLAM Using Learned Scale Factors</li><li>Inertial-Only Optimization for Visual-Inertial Initialization</li><li>Hierarchical Quadtree Feature Optical Flow Tracking Based Sparse Pose-Graph Visual-Inertial SLAM</li><li>Keypoint Description by Descriptor Fusion Using Autoencoders</li><li>Towards Noise Resilient SLAM</li><li>LAMP: Large-Scale Autonomous Mapping and Positioning for Exploration of Perceptually-Degraded Subterranean Environments</li><li>Modeling Semi-Static Scenes with Persistence Filtering in Visual SLAM</li><li>Broadcast Your Weaknesses: Cooperative Active Pose-Graph SLAM for Multiple Robots</li><li>FlowFusion: Dynamic Dense RGB-D SLAM Based on Optical Flow</li><li><p>Efficient Algorithms for Maximum Consensus Robust Fitting (I)</p></li><li><p>MulRan: Multimodal Range Dataset for Urban Place Recognition</p></li><li>GPO: Global Plane Optimization for Fast and Accurate Monocular SLAM Initialization</li><li>Large-Scale Volumetric Scene Reconstruction Using LiDAR</li><li>Topological Mapping for Manhattan-Like Repetitive Environments</li><li>Structure-Aware COP-SLAM</li><li>Robust RGB-D Camera Tracking Using Optimal Key-Frame Selection</li><li>Voxgraph: Globally Consistent, Volumetric Mapping Using Signed Distance Function Submaps</li><li>DeepFactors: Real-Time Probabilistic Dense Monocular SLAM</li><li>DOOR-SLAM: Distributed, Online, and Outlier Resilient SLAM for Robotic Teams</li><li>Windowed Bundle Adjustment Framework for Unsupervised Learning of Monocular Depth Estimation with U-Net Extension and Clip Loss</li><li><p>StructVIO : Visual-Inertial Odometry with Structural Regularity of Man-Made Environments (I)</p></li><li><p>Flow-Motion and Depth Network for Monocular Stereo and Beyond</p></li><li>Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure</li><li>Hybrid Camera Pose Estimation with Online Partitioning for SLAM</li><li>Analysis of Minima for Geodesic and Chordal Cost for a Minimal 2D Pose-Graph SLAM Problem</li><li>Voxel Map for Visual SLAM</li></ul><h2 id="Deep-Learning-in-Robotics-and-Automation"><a href="#Deep-Learning-in-Robotics-and-Automation" class="headerlink" title="Deep Learning in Robotics and Automation"></a>Deep Learning in Robotics and Automation</h2><ul><li>Learning 3D-Aware Egocentric Spatial-Temporal Interaction Via Graph Convolutional Networks</li><li>C-3PO: Cyclic-Three-Phase Optimization for Human-Robot Motion Retargeting Based on Reinforcement Learning</li><li>AP-MTL: Attention Pruned Multi-Task Learning Model for Real-Time Instrument Detection and Segmentation in Robot-Assisted Surgery</li><li>Automatic Gesture Recognition in Robot-Assisted Surgery with Reinforcement Learning and Tree Search</li><li>Towards Privacy-Preserving Ego-Motion Estimation Using an Extremely Low-Resolution Camera</li><li>ACNN: A Full Resolution DCNN for Medical Image Segmentation</li><li>RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, &amp; New Methods</li><li>Segmenting 2K-Videos at 36.5 FPS with 24.3 GFLOPs: Accurate and Lightweight Realtime Semantic Segmentation Network</li><li>Temporally Consistent Horizon Lines</li><li>Full-Scale Continuous Synthetic Sonar Data Generation with Markov Conditional Generative Adversarial Networks</li><li>Real-Time Soft Body 3D Proprioception Via Deep Vision-Based Sensing</li><li>A General Framework for Uncertainty Estimation in Deep Learning</li><li>Learning Local Behavioral Sequences to Better Infer Non-Local Properties in Real Multi-Robot Systems</li><li>Unsupervised Geometry-Aware Deep LiDAR Odometry</li><li>SA-Net: Robust State-Action Recognition for Learning from Observations</li><li>A Generative Approach for Socially Compliant Navigation</li><li>Scalable Multi-Task Imitation Learning with Autonomous Improvement</li><li>Motion2Vec: Semi-Supervised Representation Learning from Surgical Videos</li><li>PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points</li><li>Learning Error Models for Graph SLAM</li><li>SMArT: Training Shallow Memory-Aware Transformers for Robotic Explainability</li><li>A 3D-Deep-Learning-Based Augmented Reality Calibration Method for Robotic Environments Using Depth Sensor Data</li><li>Adversarial Feature Training for Generalizable Robotic Visuomotor Control</li><li>Efficient Bimanual Manipulation Using Learned Task Schemas</li><li>BayesOD: A Bayesian Approach for Uncertainty Estimation in Deep Object Detectors</li><li>Learning Object Placements for Relational Instructions by Hallucinating Scene Representations</li><li>FADNet: A Fast and Accurate Network for Disparity Estimation</li><li>Training Adversarial Agents to Exploit Weaknesses in Deep Control Policies</li><li>TRASS: Time Reversal As Self-Supervision</li><li>Federated Imitation Learning: A Novel Framework for Cloud Robotic Systems with Heterogeneous Sensor Data</li><li>Uncertainty Quantification with Statistical Guarantees in End-To-End Autonomous Driving Control</li><li>Autonomously Navigating a Surgical Tool Inside the Eye by Learning from Demonstration</li><li>Learn-To-Recover: Retrofitting UAVs with Reinforcement Learning-Assisted Flight Control under Cyber-Physical Attacks</li><li>Model-Based Reinforcement Learning for Physical Systems without Velocity and Acceleration Measurements</li><li>Towards the Probabilistic Fusion of Learned Priors into Standard Pipelines for 3D Reconstruction</li><li>Learning Natural Locomotion Behaviors for Humanoid Robots Using Human Bias</li><li>Aggressive Online Control of a Quadrotor Via Deep Network Representations of Optimality Principles</li><li>Visual Object Search by Learning Spatial Context</li><li>Salient View Selection for Visual Recognition of Industrial Components</li><li>Low to High Dimensional Modality Reconstruction Using Aggregated Fields of View</li><li>Learning Fast Adaptation with Meta Strategy Optimization</li><li>Deep Neural Network Approach in Robot Tool Dynamics Identification for Bilateral Teleoperation</li><li>Learning Matchable Image Transformations for Long-Term Metric Visual Localization</li><li>OriNet: Robust 3-D Orientation Estimation with a Single Particular IMU</li><li>Learning Densities in Feature Space for Reliable Segmentation of Indoor Scenes</li><li>A Multimodal Target-Source Classifier with Attention Branches to Understand Ambiguous Instructions for Fetching Daily Objects</li><li>On-Board Deep-Learning-Based Unmanned Aerial Vehicle Fault Cause Detection and Identification</li><li>Learning One-Shot Imitation from Humans without Humans</li><li>Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video</li><li>Event-Based Angular Velocity Regression with Spiking Networks</li><li><p>Visual Odometry Revisited: What Should Be Learnt?</p></li><li><p>3D Scene Geometry-Aware Constraint for Camera Localization with Deep Learning</p></li><li>ACDER: Augmented Curiosity-Driven Experience Replay</li><li>TrueRMA: Learning Fast and Smooth Robot Trajectories with Recursive Midpoint Adaptations in Cartesian Space</li></ul><h2 id="Motion-and-Path-Planning"><a href="#Motion-and-Path-Planning" class="headerlink" title="Motion and Path Planning"></a>Motion and Path Planning</h2><ul><li>Hyperproperties for Robotics: Planning Via HyperLTL</li><li>Abstractions for Computing All Robotic Sensors That Suffice to Solve a Planning Problem</li><li>T* : A Heuristic Search Based Path Planning Algorithm for Temporal Logic Specifications</li><li>Global/local Motion Planning Based on Dynamic Trajectory Reconfiguration and Dynamical Systems for Autonomous Surgical Robots</li><li>Deep Imitative Reinforcement Learning for Temporal Logic Robot Motion Planning with Noisy Semantic Observations</li><li>Minimal 3D Dubins Path with Bounded Curvature and Pitch Angle</li><li>Adaptively Informed Trees (AIT*): Fast Asymptotically Optimal Path Planning through Adaptive Heuristics</li><li>Informing Multi-Modal Planning with Synergistic Discrete Leads</li><li>Hierarchical Coverage Path Planning in Complex 3D Environments</li><li>Perception-Aware Time Optimal Path Parameterization for Quadrotors</li><li>Generating Visibility-Aware Trajectories for Cooperative and Proactive Motion Planning</li><li>An Obstacle-Interaction Planning Method for Navigation of Actuated Vine Robots</li><li>A New Path Planning Architecture to Consider Motion Uncertainty in Natural Environment</li><li><p>Revisiting the Asymptotic Optimality of RRT*</p></li><li><p>Sample Complexity of Probabilistic Roadmaps Via Epsilon Nets</p></li><li>Reinforcement Learning Based Manipulation Skill Transferring for Robot-Assisted Minimally Invasive Surgery</li><li>Safe Mission Planning under Dynamical Uncertainties</li><li>An Iterative Quadratic Method for General-Sum Differential Games with Feedback Linearizable Dynamics</li><li>Real-Time UAV Path Planning for Autonomous Urban Scene Reconstruction</li><li>A Fast Marching Gradient Sampling Strategy for Motion Planning Using an Informed Certificate Set</li></ul><ul><li>Privacy-Aware UAV Flights through Self-Configuring Motion Planning</li><li>Improved C-Space Exploration and Path Planning for Robotic Manipulators Using Distance Information</li><li>Tuning-Free Contact-Implicit Trajectory Optimization</li><li><p>PPCPP: A Predator�Prey-Based Approach to Adaptive Coverage Path Planning (I)</p></li><li><p>Advanced BIT<em> (ABIT</em>): Sampling-Based Planning with Advanced Graph-Search Techniques</p></li><li>Voxel-Based General Voronoi Diagram for Complex Data with Application on Motion Planning</li><li>Dynamic Movement Primitives for Moving Goals with Temporal Scaling Adaptation</li><li>Navigating Discrete Difference Equation Governed WMR by Virtual Linear Leader Guided HMPC</li><li>Dispertio: Optimal Sampling for Safe Deterministic Sampling-Based Motion Planning</li><li>Aggregation and Localization of Simple Robots in Curved Environments</li><li>Interpretable Run-Time Monitoring and Replanning for Safe Autonomous Systems Operations</li><li>An Efficient Sampling-Based Method for Online Informative Path Planning in Unknown Environments</li><li>Koopman Operator Method for Chance-Constrained Motion Primitive Planning</li><li>Robust Humanoid Contact Planning with Learned Zero and One-Step Capturability Prediction</li><li>Differential Flatness Based Path Planning with Direct Collocation on Hybrid Modes for a Quadrotor with a Cable-Suspended Payload</li><li>A Real-Time Approach for Chance-Constrained Motion Planning with Dynamic Obstacles</li><li>Learning When to Trust a Dynamics Model for Planning in Reduced State Spaces</li><li>MIST: A Single-Query Path Planning Approach Using Memory and Information-Sharing Trees</li><li>Fast Planning Over Roadmaps Via Selective Densification</li><li>Refined Analysis of Asymptotically-Optimal Kinodynamic Planning in the State-Cost Space</li><li>Polygon-Based Random Tree Search Planning for Variable Geometry Truss Robot</li><li>An Iterative Dynamic Programming Approach to the Multipoint Markov-Dubins Problem</li><li>GOMP: Grasp-Optimized Motion Planning for Bin Picking</li><li>Motion Planning and Task Allocation for a Jumping Rover Team</li><li>Active 3D Modeling Via Online Multi-View Stereo</li><li>Reoriented Short-Cuts (RSC): An Adjustment Method for Locally Optimal Path Short-Cutting in High DoF Configuration Spaces</li><li>Learning Resilient Behaviors for Navigation under Uncertainty Environments</li><li>Motion Planning Explorer: Visualizing Local Minima Using a Local-Minima Tree</li><li>Fog Robotics Algorithms for Distributed Motion Planning Using Lambda Serverless Computing</li><li>Exploration of 3D Terrains Using Potential Fields with Elevation-Based Local Distortions</li><li>R3T: Rapidly-Exploring Random Reachable Set Tree for Optimal Kinodynamic Planning of Nonlinear Hybrid Systems</li><li>DeepSemanticHPPC: Hypothesis-Based Planning Over Uncertain Semantic Point Clouds</li><li>Balancing Actuation and Computing Energy in Motion Planning</li><li>Posterior Sampling for Anytime Motion Planning on Graphs with Expensive-To-Evaluate Edges</li></ul><h2 id="Aerial-Systems-Mechanics-and-Control"><a href="#Aerial-Systems-Mechanics-and-Control" class="headerlink" title="Aerial Systems: Mechanics and Control"></a>Aerial Systems: Mechanics and Control</h2><ul><li>Model Reference Adaptive Control of Multirotor for Missions with Dynamic Change of Payloads During Flight</li><li>Adaptive Air Density Estimation for Precise Tracking Control and Accurate External Wrench Observation for Flying Robots</li><li>The Tiercel: A Novel Autonomous Micro Aerial Vehicle That Can Map the Environment by Flying into Obstacles</li><li>Full-Pose Manipulation Control of a Cable-Suspended Load with Multiple UAVs under Uncertainties</li><li>Learning Pugachev’s Cobra Maneuver for Tail-Sitter UAVs Using Acceleration Model</li></ul><ul><li>Adaptive Control of Variable-Pitch Propellers: Pursuing Minimum-Effort Operation</li><li>Design and Control of a Variable Aerial Cable Towed System</li><li>Novel Model-Based Control Mixing Strategy for a Coaxial Push-Pull Multirotor</li><li>Robust Quadcopter Control with Artificial Vector Fields</li><li>Global Identification of the Propeller Gains and Dynamic Parameters of Quadrotors from Flight Data</li><li>Gemini: A Compact yet Efficient Bi-Copter UAV for Indoor Applications</li><li>Direct Force Feedback Control and Online Multi-Task Optimization for Aerial Manipulators</li><li>Nonlinear Vector-Projection Control for Agile Fixed-Wing Unmanned Aerial Vehicles</li><li>Adaptive Nonlinear Control of Fixed-Wing VTOL with Airflow Vector Sensing</li><li>The Reconfigurable Aerial Robotic Chain: Modeling and Control</li><li>Direct Acceleration Feedback Control of Quadrotor Aerial Vehicles</li><li>Trajectory Tracking Nonlinear Model Predictive Control for an Overactuated MAV</li><li>Optimal Oscillation Damping Control of Cable-Suspended Aerial Manipulator with a Single IMU Sensor</li><li>Upset Recovery Control for Quadrotors Subjected to a Complete Rotor Failure from Large Initial Disturbances</li><li>Identification and Evaluation of a Force Model for Multirotor UAVs</li><li>Preliminary Study of an Aerial Manipulator with Elastic Suspension</li><li>Towards Low-Latency High-Bandwidth Control of Quadrotors Using Event Cameras</li><li>Perception-Constrained and Motor-Level Nonlinear MPC for Both Underactuated and Tilted-Propeller UAVs</li><li>Coordinate-Free Dynamics and Differential Flatness of a Class of 6DOF Aerial Manipulators</li></ul><h2 id="Autonomous-Driving"><a href="#Autonomous-Driving" class="headerlink" title="Autonomous Driving"></a>Autonomous Driving</h2><ul><li>Goal Directed Occupancy Prediction for Lane Following Actors</li><li>Intent-Aware Pedestrian Prediction for Adaptive Crowd Navigation</li><li>Brno Urban Dataset - the New Data for Self-Driving Agents and Mapping Tasks</li><li>Efficient Uncertainty-Aware Decision-Making for Automated Driving Using Guided Branching</li><li>Imitative Reinforcement Learning Fusing Vision and Pure Pursuit for Self-Driving</li><li>Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving</li><li>A*3D Dataset: Towards Autonomous Driving in Challenging Environments</li><li>SegVoxelNet: Exploring Semantic Context and Depth-Aware Features for 3D Vehicle Detection from Point Cloud</li><li>Fine-Grained Driving Behavior Prediction Via Context-Aware Multi-Task Inverse Reinforcement Learning</li></ul><ul><li>How to Keep HD Maps for Automated Driving up to Date</li><li>Binary DAD-Net: Binarized Driveable Area Detection Network for Autonomous Driving</li><li>Learning Robust Control Policies for End-To-End Autonomous Driving from Data-Driven Simulation</li><li>FG-GMM-Based Interactive Behavior Estimation for Autonomous Driving Vehicles in Ramp Merging Control</li><li>Cooperative Perception and Localization for Cooperative Driving</li><li>Learning to Drive Off Road on Smooth Terrain in Unstructured Environments Using an On-Board Camera and Sparse Aerial Images</li><li>RoadTrack: Realtime Tracking of Road Agents in Dense and Heterogeneous Environments</li><li>Cooperative Control of Heterogeneous Connected Vehicle Platoons: An Adaptive Leader-Following Approach</li><li>Semantic Segmentation with Unsupervised Domain Adaptation under Varying Weather Conditions for Autonomous Vehicles</li><li>Deep Merging: Vehicle Merging Controller Based on Deep Reinforcement Learning with Embedding Network</li><li>Radar As a Teacher: Weakly Supervised Vehicle Detection Using Radar Labels</li><li>Robust Lane Detection with Binary Integer Optimization</li><li>A Synchronization Approach for Achieving Cooperative Adaptive Cruise Control Based Non-Stop Intersection Passing</li><li>Self-Supervised Linear Motion Deblurring</li><li>Urban Driving with Conditional Imitation Learning</li><li>Simulation-Based Reinforcement Learning for Real-World Autonomous Driving</li><li>Driving Style Encoder: Situational Reward Adaptation for General-Purpose Planning in Automated Driving</li><li>Analysis and Prediction of Pedestrian Crosswalk Behavior During Automated Vehicle Interactions</li><li>The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset</li><li>Multi-Modal Experts Network for Autonomous Driving</li><li>Spatiotemporal Relationship Reasoning for Pedestrian Intent Prediction</li><li>TunerCar: A Superoptimization Toolchain for Autonomous Racing</li><li>Risk Assessment and Planning with Bidirectional Reachability for Autonomous Driving</li><li>MapLite: Autonomous Intersection Navigation without a Detailed Prior Map</li><li>Game Theoretic Decision Making Based on Real Sensor Data for Autonomous Vehicles’ Maneuvers in High Traffic</li><li>Driving in Dense Traffic with Model-Free Reinforcement Learning</li><li>Enhancing Game-Theoretic Autonomous Car Racing Using Control Barrier Functions</li><li>CMTS: An Conditional Multiple Trajectory Synthesizer for Generating Safety-Critical Driving Scenarios</li><li>LiDAR Inertial Odometry Aided Robust LiDAR Localization System in Changing City Scenes</li><li>Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning in Autonomous Driving</li><li>Interacting Vehicle Trajectory Prediction with Convolutional Recurrent Neural Networks</li><li>Navigation Command Matching for Vision-Based Autonomous Driving</li><li>GraphRQI: Classifying Driver Behaviors Using Graph Spectrums</li></ul><h2 id="Localization"><a href="#Localization" class="headerlink" title="Localization"></a>Localization</h2><ul><li>ROI-Cloud: A Key Region Extraction Method for LiDAR Odometry and Localization</li><li>To Learn or Not to Learn: Visual Localization from Essential Matrices</li><li>Hierarchical Multi-Process Fusion for Visual Place Recognition</li><li>Camera Tracking in Lighting Adaptable Maps of Indoor Environments</li><li>Fast, Compact and Highly Scalable Visual Place Recognition through Sequence-Based Matching of Overloaded Representations</li><li>Vision-Based Multi-MAV Localization with Anonymous Relative Measurements Using Coupled Probabilistic Data Association Filter</li><li>UrbanLoco: A Full Sensor Suite Dataset for Mapping and Localization in Urban Scenes</li><li>Map As the Hidden Sensor: Fast Odometry-Based Global Localization</li><li>Joint Human Pose Estimation and Stereo 3D Localization</li><li>Self-Supervised Deep Pose Corrections for Robust Visual Odometry</li><li>Ultra-High-Accuracy Visual Marker for Indoor Precise Positioning</li><li>Accurate Position Tracking with a Single UWB Anchor</li><li>Association-Free Multilateration Based on Times of Arrival</li><li>Adversarial Feature Disentanglement for Place Recognition across Changing Appearance</li><li>A Fast and Accurate Solution for Pose Estimation from 3D Correspondences</li><li>Ground Texture Based Localization Using Compact Binary Descriptors</li><li>Reliable Data Association for Feature-Based Vehicle Localization Using Geometric Hashing Methods</li><li>Vehicle Localization Based on Visual Lane Marking and Topological Map Matching</li><li>RISE: A Novel Indoor Visual Place Recogniser</li><li>Beyond Photometric Consistency: Gradient-Based Dissimilarity for Improving Visual Odometry and Stereo Matching</li><li>ICS: Incremental Constrained Smoothing for State Estimation</li><li>Drone-Aided Localization in LoRa IoT Networks</li><li>A Fast and Practical Method of Indoor Localization for Resource-Constrained Devices with Limited Sensing</li><li>GN-Net: The Gauss-Newton Loss for Multi-Weather Relocalization</li><li><p>A Data-Driven Motion Prior for Continuous-Time Trajectory Estimation on SE(3)</p></li><li><p>Estimation with Fast Feature Selection in Robot Visual Navigation</p></li></ul><ul><li>A Tightly Coupled VLC-Inertial Localization System by EKF</li><li>Localization of Inspection Device Along Belt Conveyors with Multiple Branches Using Deep Neural Networks</li><li>Localising PMDs through CNN Based Perception of Urban Streets</li><li>The Complex-Step Derivative Approximation on Matrix Lie Groups</li><li>Hybrid Localization Using Model and Learning-Based Methods: Fusion of Monte Carlo and E2E Localizations Via Importance Sampling</li><li>Measurement Scheduling for Cooperative Localization in Resource-Constrained Conditions</li><li>Quantifying Robot Localization Safety: A New Integrity Monitoring Method for Fixed-Lag Smoothing</li><li>Visual Localization with Google Earth Images for Robust Global Pose Estimation of UAVs</li><li>Relax and Recover: Guaranteed Range-Only Continuous Localization</li><li>SPRINT: Subgraph Place Recognition for Intelligent Transportation</li><li>OneShot Global Localization: Instant LiDAR-Visual Pose Estimation</li><li>Relocalization on Submaps: Multi-Session Mapping for Planetary Rovers Equipped with Stereo Cameras</li><li>DeepTIO: A Deep Thermal-Inertial Odometry with Visual Hallucination</li><li>RSL-Net: Localising in Satellite Images from a Radar on the Ground</li><li>Kidnapped Radar: Topological Radar Localisation Using Rotationally-Invariant Metric Learning</li><li>Global Visual Localization in LiDAR-Maps through Shared 2D-3D Embedding Space</li><li>Unsupervised Learning Methods for Visual Place Recognition in Discretely and Continuously Changing Environments</li><li>LOL: Lidar-Only Odometry and Localization in 3D Point Cloud Maps</li><li>Localising Faster: Efficient and Precise Lidar-Based Robot Localisation in Large-Scale Environments</li><li>Set-Membership State Estimation by Solving Data Association</li></ul><h2 id="Learning-from-Demonstration"><a href="#Learning-from-Demonstration" class="headerlink" title="Learning from Demonstration"></a>Learning from Demonstration</h2><ul><li>Benchmark for Skill Learning from Demonstration: Impact of User Experience, Task Complexity, and Start Configuration on Performance</li><li>MPC-Net: A First Principles Guided Policy Search</li><li>Robot Programming without Coding</li><li>Learning Robust Task Priorities and Gains for Control of Redundant Robots</li><li><p>Planning with Uncertain Specifications (PUnS)</p></li><li><p>Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic Walking</p></li><li>Adaptive Curriculum Generation from Demonstrations for Sim-To-Real Visuomotor Control</li><li>Accept Synthetic Objects As Real: End-To-End Training of Attentive Deep Visuomotor Policies for Manipulation in Clutter</li><li>A Probabilistic Framework for Imitating Human Race Driver Behavior</li><li>Learning of Exception Strategies in Assembly Tasks</li><li>A Framework for Learning from Demonstration with Minimal Human Effort</li><li>Learning Constraints from Locally-Optimal Demonstrations under Cost Function Uncertainty</li><li>Gershgorin Loss Stabilizes the Recurrent Neural Network Compartment of an End-To-End Robot Learning Scheme</li><li>Mini-Batched Online Incremental Learning through Supervisory Teleoperation with Kinesthetic Coupling</li><li>Recurrent Neural Network Control of a Hybrid Dynamical Transfemoral Prosthesis with EdgeDRNN Accelerator</li><li>Cross-Context Visual Imitation Learning from Demonstrations</li><li>Improving Generalisation in Learning Assistance by Demonstration for Smart Wheelchairs</li><li>Analyzing the Suitability of Cost Functions for Explaining and Imitating Human Driving Behavior Based on Inverse Reinforcement Learning</li><li>A Linearly Constrained Nonparametric Framework for Imitation Learning</li><li>An Energy-Based Approach to Ensure the Stability of Learned Dynamical Systems</li><li>IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data</li><li>Geometry-Aware Dynamic Movement Primitives</li><li>Learning a Pile Loading Controller from Demonstrations</li><li>Learning Navigation Costs from Demonstration in Partially Observable Environments</li></ul><h2 id="Medical-Robots-and-Systems"><a href="#Medical-Robots-and-Systems" class="headerlink" title="Medical Robots and Systems"></a>Medical Robots and Systems</h2><ul><li>Design of a Percutaneous MRI-Guided Needle Robot with Soft Fluid-Driven Actuator</li><li><p>SCADE: Simultaneous Sensor Calibration and Deformation Estimation of FBG-Equipped Unmodeled Continuum Manipulators (I)</p></li><li><p>Novel Optimization-Based Design and Surgical Evaluation of a Treaded Robotic Capsule Colonoscope (I)</p></li><li><p>Generative Localisation with Uncertainty Estimation through Video-CT Data for Bronchoscopic Biopsy</p></li><li>Internet of Things (IoT)-Based Collaborative Control of a Redundant Manipulator for Teleoperated Minimally Invasive Surgeries</li><li>Design and Prototyping of a Bio-Inspired Kinematic Sensing Suit for the Shoulder Joint: Precursor to a Multi-DoF Shoulder Exosuit</li><li>LaryngoTORS: A Novel Cable-Driven Parallel Robotic System for Transoral Laser Phonosurgery</li><li>Online Disturbance Estimation for Improving Kinematic Accuracy in Continuum Manipulators</li><li>Permanent Magnet-Based Localization for Growing Robots in Medical Applications</li><li>An Ergonomic Shared Workspace Analysis Framework for the Optimal Placement of a Compact Master Control Console</li><li>Virtual Fixture Assistance for Suturing in Robot-Aided Pediatric Endoscopic Surgery</li><li>Design, Modeling, and Control of a Compact SMA-Actuated MR-Conditional Steerable Neurosurgical Robot</li><li>Constrained-Space Optimization and Reinforcement Learning for Complex Tasks</li><li>Automatic Design of Compliant Surgical Forceps with Adaptive Grasping Functions</li><li>A Parametric Grasping Methodology for Multi-Manual Interactions in Real-Time Dynamic Simulations</li><li>PCA-Based Visual Servoing Using Optical Coherence Tomography</li><li>A Tele-Operated Microsurgical Forceps-Driver with a Variable Stiffness Haptic Feedback Master Device</li><li>Hysteresis Compensator with Learning-Based Hybrid Joint Angle Estimation for Flexible Surgery Robots</li><li>Towards FBG-Based Shape Sensing for Micro-Scale and Meso-Scale Continuum Robots with Large Deflection</li><li>Agile 3D-Navigation of a Helical Magnetic Swimmer</li><li>Two Shank-Mounted IMUs-Based Gait Analysis and Classification for Neurological Disease Patients</li><li>An Open-Source Framework for Rapid Development of Interactive Soft-Body Simulations for Real-Time Training</li><li>Towards 5-DoF Control of an Untethered Magnetic Millirobot Via MRI Gradient Coils</li><li>The ARMM System - Autonomous Steering of Magnetically-Actuated Catheters: Towards Endovascular Applications</li><li>Automatic Normal Positioning of Robotic Ultrasound Probe Based Only on Confidence Map Optimization and Force Measurement</li><li>A Semi-Autonomous Stereotactic Brain Biopsy Robot with Enhanced Safety</li><li>Magnetically Steered Robotic Insertion of Cochlear-Implant Electrode Arrays: System Integration and First-In-Cadaver Results</li><li>Magnetic Sensor Based Topographic Localization for Automatic Dislocation of Ingested Button Battery</li><li>A Fully Actuated Body-Mounted Robotic Assistant for MRI-Guided Low Back Pain Injection</li><li>Fault Tolerant Control in Shape-Changing Internal Robots</li><li>Evaluation of Increasing Camera Baseline on Depth Perception in Surgical Robotics</li><li>Toward Autonomous Robotic Micro-Suturing Using Optical Coherence Tomography Calibration and Path Planning</li><li>Improved Multiple Objects Tracking Based Autonomous Simultaneous Magnetic Actuation &amp; Localization for WCE</li><li>Towards Bimanual Vein Cannulation: Preliminary Study of a Bimanual Robotic System with a Dual Force Constraints Controller</li><li>Evaluation of a Combined Grip of Pinch and Power Grips in Manipulating a Master Manipulator</li><li>Contact Stability Analysis of Magnetically-Actuated Robotic Catheter under Surface Motion</li><li>Fast and Accurate Intracorporeal Targeting through an Anatomical Orifice Exhibiting Unknown Behavior</li><li>Robotic Swarm Control for Precise and On-Demand Embolization</li><li>Bilateral Teleoperation Control of a Redundant Manipulator with an RCM Kinematic Constraint</li></ul><h2 id="Legged-Robots"><a href="#Legged-Robots" class="headerlink" title="Legged Robots"></a>Legged Robots</h2><ul><li>An Open Torque-Controlled Modular Robot Architecture for Legged Locomotion Research</li><li>Passive Quadrupedal Gait Synchronization for Extra Robotic Legs Using a Dynamically Coupled Double Rimless Wheel Model</li><li>Optimal Fast Entrainment Waveform for Indirectly Controlled Limit Cycle Walker against External Disturbances</li><li>GaitMesh: Controller-Aware Navigation Meshes for Long-Range Legged Locomotion Planning in Multi-Layered Environments</li><li>Mechanical Shock Propagation Reduction in Robot Legs</li><li>Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot Locomotion</li><li>MPC-Based Controller with Terrain Insight for Dynamic Legged Locomotion</li><li>An Adaptive Supervisory Control Approach to Dynamic Locomotion under Parametric Uncertainty</li><li>Joint Space Position/Torque Hybrid Control of the Quadruped Robot for Locomotion and Push Reaction</li><li>Improved Performance on Moving-Mass Hopping Robots with Parallel Elasticity</li><li>Vision Aided Dynamic Exploration of Unstructured Terrain with a Small-Scale Quadruped Robot</li><li>Reactive Support Polygon Adaptation for the Hybrid Legged-Wheeled CENTAURO Robot</li><li>Reliable Trajectories for Dynamic Quadrupeds Using Analytical Costs and Learned Initializations</li><li>On the Hardware Feasibility of Nonlinear Trajectory Optimization for Legged Locomotion Based on a Simplified Dynamics</li><li>Agile Legged-Wheeled Reconfigurable Navigation Planner Applied on the CENTAURO Robot</li><li>Bounded Haptic Teleoperation of a Quadruped Robot’s Foot Posture for Sensing and Manipulation</li><li>Pinbot: A Walking Robot with Locking Pin Arrays for Passive Adaptability to Rough Terrains</li><li>Planning for the Unexpected: Explicitly Optimizing Motions for Ground Uncertainty in Running</li><li>On the Efficient Control of Series-Parallel Compliant Articulated Robots</li><li>Preintegrated Velocity Bias Estimation to Overcome Contact Nonlinearities in Legged Robot Odometry</li><li>Optimized Foothold Planning and Posture Searching for Energy-Efficient Quadruped Locomotion Over Challenging Terrains</li><li>Extracting Legged Locomotion Heuristics with Regularized Predictive Control</li><li>Learning Generalizable Locomotion Skills with Hierarchical Reinforcement Learning</li><li>SoRX: A Soft Pneumatic Hexapedal Robot to Traverse Rough, Steep, and Unstable Terrain</li><li>Probe-Before-Step Walking Strategy for Multi-Legged Robots on Terrain with Risk of Collapse</li><li>An Augmented Kinematic Model for the Cartesian Control of the Hybrid Wheeled-Legged Quadrupedal Robot CENTAURO</li><li>Precision Robotic Leaping and Landing Using Stance-Phase Balance</li><li><p>STANCE: Locomotion Adaptation Over Soft Terrain (I)</p></li><li><p>Rolling in the Deep - Hybrid Locomotion for Wheeled-Legged Robots Using Online Trajectory Optimization</p></li><li>Optimal Landing Strategy for Two-Mass Hopping Leg with Natural Dynamics</li><li>From Bipedal Walking to Quadrupedal Locomotion: Full-Body Dynamics Decomposition for Rapid Gait Generation</li><li>Posture Control for a Low-Cost Commercially-Available Hexapod Robot</li><li>DeepGait: Planning and Control of Quadrupedal Gaits Using Deep Reinforcement Learning</li><li>The Soft-Landing Problem: Minimizing Energy Loss by a Legged Robot Impacting Yielding Terrain</li><li>A Computational Framework for Designing Skilled Legged-Wheeled Robots</li></ul><h2 id="Multi-Robot-Systems"><a href="#Multi-Robot-Systems" class="headerlink" title="Multi-Robot Systems"></a>Multi-Robot Systems</h2><ul><li>Optimal Perimeter Guarding with Heterogeneous Robot Teams: Complexity Analysis and Effective Algorithms</li><li>Spatial Scheduling of Informative Meetings for Multi-Agent Persistent Coverage</li><li>Simultaneous Policy and Discrete Communication Learning for Multi-Agent Cooperation</li><li>Cooperative Team Strategies for Multi-Player Perimeter-Defense Games</li><li><p>Multirobot Symmetric Formations for Gradient and Hessian Estimation with Application to Source Seeking (I)</p></li><li><p>Multi-Robot Path Deconfliction through Prioritization by Path Prospects</p></li><li>Cooperative Aerial-Ground Multi-Robot System for Automated Construction Tasks</li><li>A Connectivity-Prediction Algorithm and Its Application in Active Cooperative Localization for Multi-Robot Systems</li><li>Multi-Agent Formation Control Based on Distributed Estimation with Prescribed Performance</li><li>Optimization-Based Distributed Flocking Control for Multiple Rigid Bodies</li><li>Behavior Mixing with Minimum Global and Subgroup Connectivity Maintenance for Large-Scale Multi-Robot Systems</li><li>CAPRICORN: Communication Aware Place Recognition Using Interpretable Constellations of Objects in Robot Networks</li><li>Online Planning for Quadrotor Teams in 3-D Workspaces Via Reachability Analysis on Invariant Geometric Trees</li><li>Decentralized Visual-Inertial-UWB Fusion for Relative State Estimation of Aerial Swarm</li><li>Synthesis of a Time-Varying Communication Network by Robot Teams with Information Propagation Guarantees</li><li>DC-CAPT: Concurrent Assignment and Planning of Trajectories for Dubins Cars</li><li>An Adversarial Approach to Private Flocking in Mobile Robot Teams</li><li>Subspace Projectors for State-Constrained Multi-Robot Consensus</li><li>Multi-Agent Task Allocation Using Cross-Entropy Temporal Logic Optimization</li><li>Adaptive Task Allocation for Heterogeneous Multi-Robot Teams with Evolving and Unknown Robot Capabilities</li><li>Mobile Wireless Network Infrastructure on Demand</li><li>Monitoring Over the Long Term: Intermittent Deployment and Sensing Strategies for Multi-Robot Teams</li><li>Multi-Robot Coordination for Estimation and Coverage of Unknown Spatial Fields</li><li>Dense R-Robust Formations on Lattices</li></ul><ul><li>Optimizing Topologies for Probabilistically Secure Multi-Robot Systems</li><li>Efficient Communication in Large Multi-Robot Networks</li><li>CyPhyHouse: A Programming, Simulation, and Deployment Toolchain for Heterogeneous Distributed Coordination</li><li>Chance Constrained Simultaneous Path Planning and Task Assignment for Multiple Robots with Stochastic Path Costs</li><li>Optimal Topology Selection for Stable Coordination of Asymmetrically Interacting Multi-Robot Systems</li><li>Representing Multi-Robot Structure through Multimodal Graph Embedding for the Selection of Robot Teams</li><li><p>MAMS-A<em>: Multi-Agent Multi-Scale A</em></p></li><li><p>Connectivity Maintenance: Global and Optimized Approach through Control Barrier Functions</p></li><li>Controller Synthesis for Infinitesimally Shape-Similar Formations</li><li>A Distributed Source Term Estimation Algorithm for Multi-Robot Systems</li><li>Weighted Buffered Voronoi Cells for Distributed Semi-Cooperative Behavior</li><li>Collaborative Multi-Robot Localization in Natural Terrain</li><li>Multi-Robot Control Using Coverage Over Time-Varying Non-Convex Domains</li><li>Efficient Large-Scale Multi-Drone Delivery Using Transit Networks</li><li>Resilience in Multi-Robot Target Tracking through Reconfiguration</li><li>Teleoperation of Multi-Robot Systems to Relax Topological Constraints</li><li>Eciton Robotica: Design and Algorithms for an Adaptive Self-Assembling Soft Robot Collective</li></ul><h2 id="Modeling-Control-and-Learning-for-Soft-Robots"><a href="#Modeling-Control-and-Learning-for-Soft-Robots" class="headerlink" title="Modeling, Control, and Learning for Soft Robots"></a>Modeling, Control, and Learning for Soft Robots</h2><ul><li>Learning Robotic Assembly Tasks with Lower Dimensional Systems by Leveraging Softness and Environmental Constraints</li><li>Titan: A Parallel Asynchronous Library for Multi-Agent and Soft-Body Robotics Using NVIDIA CUDA</li><li>Motion Planning with Competency-Aware Transition Models for Underactuated Adaptive Hands</li><li>Learning to Walk a Tripod Mobile Robot Using Nonlinear Soft Vibration Actuators with Entropy Adaptive Reinforcement Learning</li><li>Time Generalization of Trajectories Learned on Articulated Soft Robots</li><li>A Probabilistic Model-Based Online Learning Optimal Control Algorithm for Soft Pneumatic Actuators</li><li>Rigid-Soft Interactive Learning for Robust Grasping</li><li>Model and Data Based Approaches to the Control of Tensegrity Robots</li><li>Stiffness Imaging with a Continuum Appendage: Real-Time Shape and Tip Force Estimation from Base Load Readings</li><li>Sim-To-Real Transfer Learning Approach for Tracking Multi-DOF Ankle Motions Using Soft Strain Sensors</li><li>Model-Based Pose Control of Inflatable Eversion Robot with Variable Stiffness</li><li>Learning to Control Reconfigurable Staged Soft Arms</li><li>Open-Loop Position Control in Collaborative, Modular Variable-Stiffness-Link (VSL) Robots</li><li>Control of a Silicone Soft Tripod Robot Via Uncertainty Compensation</li><li>Control Oriented Modeling of Soft Robots: The Polynomial Curvature Case</li><li>Modeling and Analysis of SMA Actuator Embedded in Stretchable Coolant Vascular Pursuing Artificial Muscles</li><li>Distributed Proprioception of 3D Configuration in Soft, Sensorized Robots Via Deep Learning</li><li>Stable Tool-Use with Flexible Musculoskeletal Hands by Learning the Predictive Model of Sensor State Transition</li><li>Learning to Transfer Dynamic Models of Underactuated Soft Robotic Hands</li><li>Periodic Movement Learning in a Soft-Robotic Arm</li><li>An Input Observer-Based Stiffness Estimation Approach for Flexible Robot Joints</li><li>Fast Model-Based Contact Patch and Pose Estimation for Highly Deformable Dense-Geometry Tactile Sensors</li><li>Mechanism and Model of a Soft Robot for Head Stabilization in Cancer Radiation Therapy</li></ul><h2 id="Manipulation"><a href="#Manipulation" class="headerlink" title="Manipulation"></a>Manipulation</h2><ul><li>Grasping Unknown Objects by Coupling Deep Reinforcement Learning, Generative Adversarial Networks, and Visual Servoing</li><li>Incorporating Motion Planning Feasibility Considerations During Task-Agent Assignment to Perform Complex Tasks Using Mobile-Manipulators</li><li>Learning to Scaffold the Development of Robotic Manipulation Skills</li><li>Online Replanning in Belief Space for Partially Observable Task and Motion Problems</li><li>An Automated Dynamic-Balancing-Inspection Scheme for Wheel Machining</li><li>Faster Confined Space Manufacturing Teleoperation through Dynamic Autonomy with Task Dynamics Imitation Learning</li><li>Learning Precise 3D Manipulation from Multiple Uncalibrated Cameras</li><li>Surfing on an Uncertain Edge: Precision Cutting of Soft Tissue Using Torque-Based Medium Classification</li><li>Dynamic Cloth Manipulation with Deep Reinforcement Learning</li><li>Learning to Combine Primitive Skills: A Step towards Versatile Robotic Manipulation</li><li>Learning to Assemble: Estimating 6D Poses for Robotic Object-Object Manipulation</li><li>Learning Affordance Space in Physical World for Vision-Based Robotic Object Manipulation</li></ul><h2 id="Sensor-Fusion"><a href="#Sensor-Fusion" class="headerlink" title="Sensor Fusion"></a>Sensor Fusion</h2><ul><li>LiStereo: Generate Dense Depth Maps from LIDAR and Stereo Imagery</li><li>Monocular Visual-Inertial Odometry in Low-Textured Environments with Smooth Gradients: A Fully Dense Direct Filtering Approach</li><li>Gated Recurrent Fusion to Learn Driving Behaviour from Temporal Multimodal Data</li><li>Cooperative Visual-Inertial Odometry: Analysis of Singularities, Degeneracies and Minimal Cases</li><li>A Lightweight and Accurate Localization Algorithm Using Multiple Inertial Measurement Units</li><li><p>Accelerating the Estimation of Metabolic Cost Using Signal Derivatives: Implications for Optimization and Evaluation of Wearable Robots (I)</p></li><li><p>Deep Depth Fusion for Black, Transparent, Reﬂective and Texture-Less Objects</p></li><li>LiDAR-Enhanced Structure-From-Motion</li><li>Low Latency and Low-Level Sensor Fusion for Automotive Use-Cases</li><li>Spatiotemporal Camera-LiDAR Calibration: A Targetless and Structureless Approach</li><li>Robot-Assisted and Wearable Sensor-Mediated Autonomous Gait Analysis</li><li>Gaussian Process Preintegration for Inertial-Aided State Estimation</li><li><p>A Code for Unscented Kalman Filtering on Manifolds (UKF-M)</p></li><li><p>Efficient and Precise Sensor Fusion for Non-Linear Systems with Out-Of-Sequence Measurements by Example of Mobile Robotics</p></li><li>UNO: Uncertainty-Aware Noisy-Or Multimodal Fusion for Unanticipated Input Degradation</li><li>Intermittent GPS-Aided VIO: Online Initialization and Calibration</li><li>A Mathematical Framework for IMU Error Propagation with Applications to Preintegration</li><li>Radar-Inertial Ego-Velocity Estimation for Visually DegradedEnvironments</li><li>Observability Analysis of Flight State Estimation for UAVs and Experimental Validation</li><li>OpenVINS: A Research Platform for Visual-Inertial Estimation</li><li>Decentralized Collaborative State Estimation for Aided Inertial Navigation</li><li>Analytic Combined IMU Integration (ACI^2) for Visual Inertial Navigation</li><li>Second-Order Kinematics for Floating-Base Robots Using the Redundant Acceleration Feedback of an Artificial Sensory Skin</li><li>Clock-Based Time Synchronization for an Event-Based Camera Dataset Acquisition Platform</li></ul><h2 id="Compliance-and-Impedance-Control"><a href="#Compliance-and-Impedance-Control" class="headerlink" title="Compliance and Impedance Control"></a>Compliance and Impedance Control</h2><ul><li><p>Hierarchical Impedance-Based Tracking Control of Kinematically Redundant Robots (I)</p></li><li><p>Position-Based Impedance Control of a 2-DOF Compliant Manipulator for a Facade Cleaning Operation</p></li><li>Robust, Locally Guided Peg-In-Hole with Impedance-Controlled Robots</li><li><p>Model-Free Friction Observers for Flexible Joint Robots with Torque Measurements (I)</p></li><li><p>Necessary and Sufficient Conditions for the Passivity of Impedance Rendering with Velocity-Sourced Series Elastic Actuation (I)</p></li><li><p>Design of Spatial Admittance for Force-Guided Assembly of Polyhedral Parts in Single Point Frictional Contact</p></li><li>Model Predictive Impedance Control</li><li>Kinematic Modeling and Compliance Modulation of Redundant Manipulators under Bracing Constraints</li><li>Successive Stiffness Increment and Time Domain Passivity Approach for Stable High Bandwidth Control of Series Elastic Actuator</li><li>Arm-Hand Motion-Force Coordination for Physical Interactions with Non-Flat Surfaces Using Dynamical Systems: Toward Compliant Robotic Massage</li><li>A Control Scheme with a Novel DMP-Robot Coupling Achieving Compliance and Tracking Accuracy under Unknown Task Dynamics and Model Uncertainties</li><li>A Bio-Signal Enhanced Adaptive Impedance Controller for Lower Limb Exoskeleton</li></ul><h2 id="Visual-Learning"><a href="#Visual-Learning" class="headerlink" title="Visual Learning"></a>Visual Learning</h2><ul><li>Vid2Param: Modelling of Dynamics Parameters from Video</li><li>Safe Robot Navigation Via Multi-Modal Anomaly Detection</li><li>MAVRIC: Morphology-Agnostic Visual Robotic Control</li><li>MFuseNet: Robust Depth Estimation with Learned Multiscopic Fusion</li><li>Deceiving Image-To-Image Translation Networks for Autonomous Driving with Adversarial Perturbations</li><li>Self-Supervised Learning of State Estimation for Manipulating Deformable Linear Objects</li><li>Self-Supervised Correspondence in Visuomotor Policy Learning</li><li>Differentiable Mapping Networks: Learning Structured Map Representations for Sparse Visual Localization</li><li>Attentive Task-Net: Self Supervised Task-Attention Network for Imitation Learning Using Video Demonstration</li><li>OpenLORIS-Object: A Robotic Vision Dataset and Benchmark for Lifelong Deep Learning</li><li>Unsupervised Depth Completion from Visual Inertial Odometry</li><li>Geometric Pretraining for Monocular Depth Estimation</li></ul><h2 id="Soft-Sensors-and-Actuators"><a href="#Soft-Sensors-and-Actuators" class="headerlink" title="Soft Sensors and Actuators"></a>Soft Sensors and Actuators</h2><ul><li>Active Acoustic Contact Sensing for Soft Pneumatic Actuators</li><li>PneuAct-II: Hybrid Manufactured Electromagnetically Stealth Pneumatic Stepper Actuator</li><li>A Bidirectional 3D-Printed Soft Pneumatic Actuator and Graphite-Based Flex Sensor for Versatile Grasping</li><li>A Proprioceptive Bellows (PB) Actuator with Position Feedback and Force Estimation</li><li>Automatic Design of Soft Dielectric Elastomer Actuators with Optimal Spatial Electric Fields (I)</li><li><p>Stochastic Control for Orientation and Transportation of Microscopic Objects Using Multiple Optically Driven Robotic Fingertips (I)</p></li><li><p>Soft Fingertips with Adaptive Sensing and Active Deformation for Robust Grasping of Delicate Objects</p></li><li>Sensorization of a Continuum Body Gripper for High Force and Delicate Object Grasping</li><li>Eye-In-Hand Visual Servoing Enhanced with Sparse Strain Measurement for Soft Continuum Robots</li><li>A Soft Gripper with Retractable Nails for Advanced Grasping and Manipulation</li><li>A Sensorized Hybrid Gripper to Evaluate a Grasping Quality Based on a Largest Minimum Wrench</li><li>A Soft Pressure Sensor Skin for Hand and Wrist Orthoses</li><li>Characterisation of Self-Locking High-Contraction Electro-Ribbon Actuators</li><li>Helically Wrapped Supercoiled Polymer (HW-SCP) Artificial Muscles: Design, Characterization, and Modeling</li><li>A Variable Stiffness Soft Continuum Robot Based on Pre-Charged Air, Particle Jamming, and Origami</li><li>A Pneumatic/Cable-Driven Hybrid Linear Actuator with Combined Structure of Origami Chambers and Deployable Mechanism</li><li>Simple, Low-Hysteresis, Foldable, Fabric Pneumatic Artificial Muscle</li><li><p>Flat Inflatable Artificial Muscles with Large Stroke and Adjustable Force-Length Relations (I)</p></li><li><p>Joint Rotation Angle Sensing of Flexible Endoscopic Surgical Robots</p></li><li>Soft, Round, High Resolution Tactile Fingertip Sensors for Dexterous Robotic Manipulation</li><li>Creating a Soft Tactile Skin Employing Fluorescence Based Optical Sensing</li><li>FootTile: A Rugged Foot Sensor for Force and Center of Pressure Sensing in Soft Terrain</li><li>A Vision-Based Soft Somatosensory Approach for Distributed Pressure and Temperature Sensing</li><li>A Stretchable Capacitive Sensory Skin for Exploring Cluttered Environments</li></ul><h2 id="Wearable-Robots"><a href="#Wearable-Robots" class="headerlink" title="Wearable Robots"></a>Wearable Robots</h2><ul><li>SwarmRail: A Novel Overhead Robot System for Indoor Transport and Mobile Manipulation</li><li>Fast Local Planning and Mapping in Unknown Off-Road Terrain</li><li>Multifunctional 3-DOF Wearable Supernumerary Robotic Arm Based on Magnetorheological Clutches</li><li>Leveraging the Human Operator in the Design and Control of Supernumerary Robotic Limbs</li><li>Revisiting Scaling Laws for Robotic Mobility in Granular Media</li><li>Learning a Control Policy for Fall Prevention on an Assistive Walking Device</li><li>Assistive Force of a Belt-Type Hip Assist Suit for Lifting the Swing Leg During Walking</li><li>Soft Pneumatic System for Interface Pressure Regulation and Automated Hands-Free Donning in Robotic Prostheses</li><li>Automated Detection of Soleus Concentric Contraction in Variable Gait Conditions for Improved Exosuit Control</li><li>Soft Sensing Shirt for Shoulder Kinematics Estimation</li><li>Characterizing Torso Stiffness in Female Adolescents with and without Scoliosis</li></ul><h2 id="Cognitive-Human-Robot-Interaction"><a href="#Cognitive-Human-Robot-Interaction" class="headerlink" title="Cognitive Human-Robot Interaction"></a>Cognitive Human-Robot Interaction</h2><ul><li>Scaled Autonomy: Enabling Human Operators to Control Robot Fleets</li><li>An Actor-Critic Approach for Legible Robot Motion Planner</li><li>May I Draw Your Attention? Initial Lessons from the Large-Scale Generative Mark Maker</li><li>Intuitive 3D Control of a Quadrotor in User Proximity with Pointing Gestures</li><li>Joint Inference of States, Robot Knowledge, and Human (False-)Beliefs</li><li>Visual-Audio Cognitive Architecture for Autonomous Learning of Face Localisation by a Humanoid Robot</li><li>Motion Reasoning for Goal-Based Imitation Learning</li><li>Flexible Online Adaptation of Learning Strategy Using EEG-Based Reinforcement Signals in Real-World Robotic Applications</li><li>Object-Oriented Semantic Graph Based Natural Question Generation</li><li>Towards Safe Human-Robot Collaboration Using Deep Reinforcement Learning</li><li>Deep Compositional Robotic Planners That Follow Natural Language Commands</li><li>Learning User Preferences from Corrections on State Lattices</li></ul><h2 id="Robotics-in-Agriculture-and-Forestry"><a href="#Robotics-in-Agriculture-and-Forestry" class="headerlink" title="Robotics in Agriculture and Forestry"></a>Robotics in Agriculture and Forestry</h2><ul><li>Visual Servoing-Based Navigation for Monitoring Row-Crop Fields</li><li>Optimal Routing Schedules for Robots Operating in Aisle-Structures</li><li>Time Optimal Motion Planning with ZMP Stability Constraint for Timber Manipulation</li><li>Plucking Motions for Tea Harvesting Robots Using Probabilistic Movement Primitives</li><li>SLOAM: Semantic Lidar Odometry and Mapping for Forest Inventory</li><li>Push and Drag: An Active Obstacle Separation Method for Fruit Harvesting Robots</li></ul><h2 id="Calibration-and-Identification"><a href="#Calibration-and-Identification" class="headerlink" title="Calibration and Identification"></a>Calibration and Identification</h2><ul><li>Unified Intrinsic and Extrinsic Camera and LiDAR Calibration under Uncertainties</li><li>AC/DCC : Accurate Calibration of Dynamic Camera Clusters for Visual SLAM</li><li>Analytic Plane Covariances Construction for Precise Planarity-Based Extrinsic Calibration of Camera and LiDAR</li><li>A Stable Adaptive Observer for Hard-Iron and Soft-Iron Bias Calibration and Compensation for Two-Axis Magnetometers: Theory and Experimental Evaluation</li><li>Extrinsic Calibration of an Eye-In-Hand 2D LiDAR Sensor in Unstructured Environments Using ICP</li><li><p>Geometric Robot Dynamic Identification: A Convex Programming Approach (I)</p></li><li><p>A Novel Calibration Method between a Camera and a 3D LiDAR with Infrared Images</p></li><li>Online Camera-LiDAR Calibration with Sensor Semantic Information</li><li>Precise 3D Calibration of Wafer Handling Robot by Visual Detection and Tracking of Elliptic-Shape Wafers</li><li>Globally Optimal Relative Pose Estimation for Camera on a Selfie Stick</li><li>Online Calibration of Exterior Orientations of a Vehicle-Mounted Surround-View Camera System</li><li>Learning Camera Miscalibration Detection</li></ul><h2 id="Industrial-Robots"><a href="#Industrial-Robots" class="headerlink" title="Industrial Robots"></a>Industrial Robots</h2><ul><li>An End-Effector Wrist Module for the Kinematically Redundant Manipulation of Arm-Type Robots</li><li>Robust Path Following of the Tractor-Trailers System in GPS-Denied Environments</li><li>Online Trajectory Planning for an Industrial Tractor Towing Multiple Full Trailers</li><li>Towards Efficient Human Robot Collaboration with Robust Plan Recognition and Trajectory Prediction</li><li>Collaborative Human-Robot Framework for Delicate Sanding of Complex Shape Surface</li><li>External Force Estimation for Industrial Robots with Flexible Joints</li><li>Robotic General Parts Feeder: Bin-Picking, Regrasping, and Kitting</li><li>Planning, Learning and Reasoning Framework for Robot Truck Unloading</li><li>Evaluation of Perception Latencies in a Human-Robot Collaborative Environment</li><li>Assembly of Randomly Placed Parts Realized by Using Only One Robot Arm with a General Parallel-Jaw Gripper</li><li>Drive-Based Vibration Damping Control for Robot Machining</li><li>Toward Fast and Optimal Robotic Pick-And-Place on a Moving Conveyor</li></ul><h2 id="Biomimetics"><a href="#Biomimetics" class="headerlink" title="Biomimetics"></a>Biomimetics</h2><ul><li>A Bio-Inspired Transportation Network for Scalable Swarm Foraging</li><li>Stance Control Inspired by Cerebellum Stabilizes Reflex-Based Locomotion on HyQ Robot</li><li>Error Estimation and Correction in a Spiking Neural Network for Map Formation in Neuromorphic Hardware</li><li>A Hybrid Compact Neural Architecture for Visual Place Recognition</li><li>Musculoskeletal AutoEncoder: A Unified Online Acquisition Method of Intersensory Networks for State Estimation, Control, and Simulation of Musculoskeletal Humanoids</li><li>Snake-Inspired Kirigami Skin for Lateral Undulation of a Soft Snake Robot</li><li>Bio-Inspired Distance Estimation Using the Self-Induced Acoustic Signature of a Motor-Propeller System</li><li>A Bio-Inspired 3-DOF Light-Weight Manipulator with Tensegrity X-Joints</li><li>The Lobster-Inspired Antagonistic Actuation Mechanism towards a Bending Module</li><li>Emulating Duration and Curvature of Coral Snake Anti-Predator Thrashing Behaviors Using a Soft-Robotic Platform</li><li>Directional Mechanical Impedance of the Human Ankle During Standing with Active Muscles</li><li>Insect�Computer Hybrid Robot Achieves a Walking Gait Rarely Seen in Nature by Replacing the Anisotropic Natural Leg Spines with Isotropic Artificial Leg Spines (I)</li></ul><h2 id="Robust-Adaptive-Control-of-Robotic-Systems"><a href="#Robust-Adaptive-Control-of-Robotic-Systems" class="headerlink" title="Robust/Adaptive Control of Robotic Systems"></a>Robust/Adaptive Control of Robotic Systems</h2><ul><li>Adaptive Visual Shock Absorber with Visual-Based Maxwell Model Using Magnetic Gear</li><li>Slip-Based Nonlinear Recursive Backstepping Path Following Controller for Autonomous Ground Vehicles</li><li>Fast and Safe Path-Following Control Using a State-Dependent Directional Metric</li><li>Backlash-Compensated Active Disturbance Rejection Control of Nonlinear Multi-Input Series Elastic Actuators</li><li>On Generalized Homogenization of Linear Quadrotor Controller</li><li>Coordinated Optical Tweezing and Manipulation of Multiple Microscopic Objects with Stochastic Perturbations</li><li>Contact Surface Estimation Via Hapic Perception</li><li>Local Policy Optimization for Trajectory-Centric Reinforcement Learning</li><li>Automatic Snake Gait Generation Using Model Predictive Control</li><li>Safe and Fast Tracking on a Robot Manipulator: Robust MPC and Neural Network Control</li><li>3D Path-Following Using MRAC on a Millimeter-Scale Spiral-Type Magnetic Robot</li><li>Adaptive Model-Based Myoelectric Control for a Soft Wearable Arm Exosuit (I)</li></ul><h2 id="Space-Robotics-and-Automation"><a href="#Space-Robotics-and-Automation" class="headerlink" title="Space Robotics and Automation"></a>Space Robotics and Automation</h2><ul><li>Planetary Rover Exploration Combining Remote and in Situ Measurements for Active Spectroscopic Mapping</li><li>Magnetic Docking Mechanism for Free-Flying Space Robots with Spherical Surfaces</li><li>Barefoot Rover: A Sensor-Embedded Rover Wheel Demonstrating In-Situ Engineering and Science Extractions Using Machine Learning</li><li>Deep Learning for Spacecraft Pose Estimation from Photorealistic Rendering</li><li>Concurrent Parameter Identification and Control for Free-Floating Robotic Systems During On-Orbit Servicing</li><li>A Dual Quaternion-Based Discrete Variational Approach for Accurate and Online Inertial Parameter Estimation in Free-Flying Robots</li></ul><h2 id="Perception-for-Grasping-and-Manipulation"><a href="#Perception-for-Grasping-and-Manipulation" class="headerlink" title="Perception for Grasping and Manipulation"></a>Perception for Grasping and Manipulation</h2><ul><li>Transferable Task Execution from Pixels through Deep Planning Domain Learning</li><li>Depth by Poking: Learning to Estimate Depth from Self-Supervised Grasping</li><li>Online Learning of Object Representations by Appearance Space Feature Alignment</li><li>Visual Prediction of Priors for Articulated Object Interaction</li><li>MT-DSSD: Deconvolutional Single Shot Detector Using Multi Task Learning for Object Detection, Segmentation, and Grasping Detection</li><li>Using Synthetic Data and Deep Networks to Recognize Primitive Shapes for Object Grasping</li><li>Real-Time, Highly Accurate Robotic Grasp Detection Using Fully Convolutional Neural Network with Rotation Ensemble Module</li><li>Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly</li><li>Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data</li><li>Efficient Two Step Optimization for Large Embedded Deformation Graph Based SLAM</li><li>Camera-To-Robot Pose Estimation from a Single Image</li><li>DIGIT: A Novel Design for a Low-Cost Compact High-Resolution Tactile Sensor with Application to In-Hand Manipulation</li><li>LyRN (Lyapunov Reaching Network): A Real-Time Closed Loop Approach from Monocular Vision</li><li>Object Finding in Cluttered Scenes Using Interactive Perception</li><li>Multi-Modal Perception and Transfer Learning for Grasping Transparent and Specular Objects</li><li>CCAN: Constraint Co-Attention Network for Instance Grasping</li><li>RLBench: The Robot Learning Benchmark &amp; Learning Environment</li><li>Learning Task-Oriented Grasping from Human Activity Datasets</li><li>Inferring the Material Properties of Granular Media for Robotic Tasks</li><li>KETO: Learning Keypoint Representations for Tool Manipulation</li><li>Learning to See before Learning to Act: Visual Pre-Training for Manipulation</li><li>Learning Continuous 3D Reconstructions for Geometrically Aware Grasping</li><li>Contact-Based In-Hand Pose Estimation Using Particle Filtering</li><li>A Single Multi-Task Deep Neural Network with Post-Processing for Object Detection with Reasoning and Robotic Grasp Detection</li><li>In-Hand Object Pose Tracking Via Contact Feedback and GPU-Accelerated Robotic Simulation</li><li>Robust, Occlusion-Aware Pose Estimation for Objects Grasped by Adaptive Hands</li><li>Robust 6D Object Pose Estimation by Learning RGB-D Features</li><li>Split Deep Q-Learning for Robust Object Singulation</li><li>6-DOF Grasping for Target-Driven Object Manipulation in Clutter</li><li>Single Shot 6D Object Pose Estimation</li></ul><h2 id="Humanoid-Robots"><a href="#Humanoid-Robots" class="headerlink" title="Humanoid Robots"></a>Humanoid Robots</h2><ul><li>HRP-4 Walks on Soft Feet</li><li>A Study on Sparse Hierarchical Inverse Kinematics Algorithms for Humanoid Robots</li><li>Inferring the Geometric Nullspace of Robot Skills from Human Demonstrations</li><li>A Dynamical System Approach for Adaptive Grasping, Navigation and Co-Manipulation with Humanoid Robots</li><li>Humanoid Robots in Aircraft Manufacturing (I)</li></ul><ul><li><p>A Multi-Mode Teleoperation Framework for Humanoid Loco-Manipulation (I)</p></li><li><p>Balance of Humanoid Robots in a Mix of Fixed and Sliding Multi-Contact Scenarios</p></li><li>Fast Whole-Body Motion Control of Humanoid Robots with Inertia Constraints</li><li>SL1M: Sparse L1-Norm Minimization for Contact Planning on Uneven Terrain</li><li>Finding Locomanipulation Plans Quickly in the Locomotion Constrained Manifold</li><li>Force-Based Control of Bipedal Balancing on Dynamic Terrain with the “Tallahassee Cassie” Robotic Platform</li><li>Simultaneous Control Framework for Humanoid Tracking Human Movement with Interacting Wearable Assistive Device</li></ul><h2 id="Force-Control"><a href="#Force-Control" class="headerlink" title="Force Control"></a>Force Control</h2><ul><li>Dynamic Control of a Rigid Pneumatic Gripper</li><li>A Control Framework Definition to Overcome Position/Interaction Dynamics Uncertainties in Force-Controlled Tasks</li><li>Identification of Compliant Contact Parameters and Admittance Force Modulation on a Non-Stationary Compliant Surface</li><li>Convex Controller Synthesis for Robot Contact</li><li>Force Adaptation in Contact Tasks with Dynamical Systems</li><li>Sensitivity Ellipsoids for Force Control of Magnetic Robots with Localization Uncertainty (I)</li></ul><h2 id="Semantic-Scene-Understanding"><a href="#Semantic-Scene-Understanding" class="headerlink" title="Semantic Scene Understanding"></a>Semantic Scene Understanding</h2><ul><li>Highly Parallelizable Plane Extraction for Organized Point Clouds Using Spherical Convex Hulls</li><li>Boosting Real-Time Driving Scene Parsing with Shared Semantics</li><li>CNN-Based Lidar Point Cloud De-Noising in Adverse Weather</li><li>View-Invariant Loop Closure with Oriented Semantic Landmarks</li><li>Semantic Foreground Inpainting from Weak Supervision</li><li>Fast Panoptic Segmentation Network</li><li>Weakly Supervised Silhouette-Based Semantic Scene Change Detection</li><li>3DCFS: Fast and Robust Joint 3D Semantic-Instance Segmentation Via Coupled Feature Selection</li><li>Who2com: Collaborative Perception Via Learnable Handshake Communication</li><li>Comparing View-Based and Map-Based Semantic Labelling in Real-Time SLAM</li><li>Generative Modeling of Environments with Scene Grammars and Variational Inference</li><li>SHOP-VRB: A Visual Reasoning Benchmark for Object Perception</li></ul><h2 id="Social-Human-Robot-Interaction"><a href="#Social-Human-Robot-Interaction" class="headerlink" title="Social Human-Robot Interaction"></a>Social Human-Robot Interaction</h2><ul><li>Simultaneous Learning from Human Pose and Object Cues for Real-Time Activity Recognition</li><li>Demonstration of Hospital Receptionist Robot with Extended Hybrid Code Network</li><li>Can I Trust You? a User Study of Robot Mediation of a Support Group</li><li>Group Split and Merge Prediction with 3D Convolutional Networks</li><li>TH�R: Human-Robot Navigation Data Collection and Accurate Motion Trajectories Dataset</li><li><p>Socially Assistive Infant-Robot Interaction: Using Robots to Encourage Infant Leg-Motion (I)</p></li><li><p>Real-Time Continuous Hand Motion Myoelectric Decoding by Automated Data Labeling</p></li><li>Towards Proactive Navigation: A Pedestrian-Vehicle Cooperation Based Behavioral Model</li><li>Studying Navigation As a Form of Interaction: A Design Approach for Social Robot Navigation Methods</li><li>Robot Plan Model Generation and Execution with Natural Language Interface</li><li>Mapless Navigation among Dynamics with Social-Safety-Awareness: A Reinforcement Learning Approach from 2D Laser Scans</li><li>People’s Adaptive Side-By-Side Model Evolved to Accompany Groups of People by Social Robots</li></ul><h2 id="Biologically-Inspired-Robots"><a href="#Biologically-Inspired-Robots" class="headerlink" title="Biologically-Inspired Robots"></a>Biologically-Inspired Robots</h2><ul><li>Coronal Plane Spine Twisting Composes Shape to Adjust the Energy Landscape for Grounded Reorientation</li><li><p>Significance of the Compliance of the Joints on the Dynamic Slip Resistance of a Bioinspired Hoof (I)</p></li><li><p>Motion Design for a Snake Robot Negotiating Complicated Pipe Structures of a Constant Diameter</p></li><li>A Neuro-Inspired Computational Model for a Visually Guided Robotic Lamprey Using Frame and Event Based Cameras</li><li>Untethered Flight of an At-Scale Dual-Motor Hummingbird Robot with Bio-Inspired Decoupled Wings</li><li>Model-Based Feedback Control of Live Zebrafish Behavior Via Interaction with a Robotic Replica (I)</li><li>Steering Control of Magnetic Helical Swimmers in Swirling Flows Due to Confinement</li><li>Sim2real Gap Is Non-Monotonic with Robot Complexity for Morphology-In-The-Loop Flapping Wing Design</li><li>A Linearized Model for an Ornithopter in Gliding Flight: Experiments and Simulations</li><li>Towards Biomimicry of a Bat-Style Perching Maneuver on Structures: The Manipulation of Inertial Dynamics</li><li>Bioinspired Object Motion Filters As the Basis of Obstacle Negotiation in Micro Aerial Systems</li><li>Design and Architecture of ARCSnake: Archimedes’ Screw-Propelled Serpentine Robot</li></ul><h2 id="Robotics-in-Agriculture-Construction-and-Mining"><a href="#Robotics-in-Agriculture-Construction-and-Mining" class="headerlink" title="Robotics in Agriculture, Construction and Mining"></a>Robotics in Agriculture, Construction and Mining</h2><ul><li>GPR-Based Subsurface Object Detection and Reconstruction Using Random Motion and DepthNet</li><li>A Data-Driven Approach to Prediction and Optimal Bucket-Filling Control for Autonomous Excavators</li></ul><ul><li>Real-Time Stereo Visual Servoing for Rose Pruning with Robotic Arm</li><li>Canopy-Based Monte Carlo Localization in Orchards Using Top-View Imagery</li><li>In-Field Grape Cluster Size Assessment for Vine Yield Estimation Using a Mobile Robot and a Consumer Level RGB-D Camera</li><li>Autonomous Excavation of Rocks Using a Gaussian Process Model and Unscented Kalman Filter</li></ul><h2 id="Kinematics"><a href="#Kinematics" class="headerlink" title="Kinematics"></a>Kinematics</h2><ul><li>Slip-Limiting Controller for Redundant Line-Suspended Robots: Application to LineRanger</li><li>Interval Search Genetic Algorithm Based on Trajectory to Solve Inverse Kinematics of Redundant Manipulators and Its Application</li><li>Analytical Expressions of Serial Manipulator Jacobians and Their High-Order Derivatives Based on Lie Theory</li><li>Inverse Kinematics for Serial Kinematic Chains Via Sum of Squares Optimization</li><li>Multi-Task Closed-Loop Inverse Kinematics Stability through Semidefinite Programming</li><li>Stable-By-Design Kinematic Control Based on Optimization (I)</li></ul><h2 id="Robot-Safety"><a href="#Robot-Safety" class="headerlink" title="Robot Safety"></a>Robot Safety</h2><ul><li>Securing Industrial Operators with Collaborative Robots: Simulation and Experimental Validation for a Carpentry Task</li><li>Learning Shape-Based Representation for Visual Localization in Extremely Changing Conditions</li><li>Trajectory Planning with Safety Guaranty for a Multirotor Based on the Forward and Backward Reachability Analysis</li><li>A Hamilton-Jacobi Reachability-Based Framework for Predicting and Analyzing Human Motion for Safe Planning</li><li>Enhancing Privacy in Robotics Via Judicious Sensor Selection</li><li>Robust Model Predictive Shielding for Safe Reinforcement Learning with Stochastic Dynamics</li></ul><h2 id="Swarms"><a href="#Swarms" class="headerlink" title="Swarms"></a>Swarms</h2><ul><li>Segregation of Heterogeneous Swarms of Robots in Curves</li><li>A Fast, Accurate, and Scalable Probabilistic Sample-Based Approach for Counting Swarm Size</li><li>Bayes Bots: Collective Bayesian Decision-Making in Decentralized Robot Swarms</li><li>Supervisory Control of Robot Swarms Using Public Events</li><li><p>Planetary Exploration with Robot Teams (I)</p></li><li><p>Statistics-Based Automated Control for a Swarm of Paramagnetic Nanoparticles in 2D Space (I)</p></li></ul><h2 id="Simulation-and-Animation"><a href="#Simulation-and-Animation" class="headerlink" title="Simulation and Animation"></a>Simulation and Animation</h2><ul><li>Automatic Tool for Gazebo World Construction: From a Grayscale Image to a 3D Solid Model</li><li>A ROS Gazebo Plugin to Simulate ARVA Sensors</li><li>Is That a Chair? Imagining Affordances Using Simulations of an Articulated Human Body</li><li>Toward Sim-To-Real Directional Semantic Grasping</li><li>Learning to Collaborate from Simulation for Robot-Assisted Dressing</li><li>Realtime Simulation of Thin-Shell Deformable Materials Using CNN-Based Mesh Embedding</li></ul><h2 id="Reinforcement-Learning-for-Robotics"><a href="#Reinforcement-Learning-for-Robotics" class="headerlink" title="Reinforcement Learning for Robotics"></a>Reinforcement Learning for Robotics</h2><ul><li>Dynamic Actor-Advisor Programming for Scalable Safe Reinforcement Learning</li><li>Discrete Deep Reinforcement Learning for Mapless Navigation</li><li>Learning Multi-Robot Decentralized Macro-Action-Based Policies Via a Centralized Q-Net</li><li>Robust Model-Free Reinforcement Learning with Multi-Objective Bayesian Optimization</li><li>Motor Synergy Development in High-Performing Deep Reinforcement Learning Algorithms</li><li><p>Barrier-Certified Adaptive Reinforcement Learning with Applications to Brushbot Navigation (I)</p></li><li><p>On Simple Reactive Neural Networks for Behaviour-Based Reinforcement Learning</p></li><li>Predicting Optimal Value Functions by Interpolating Reward Functions in Scalarized Multi-Objective Reinforcement Learning</li><li>Integrated Moment-Based LGMD and Deep Reinforcement Learning for UAV Obstacle Avoidance</li><li>Interactive Reinforcement Learning with Inaccurate Feedback</li><li>Guided Uncertainty-Aware Policy Optimization: Combining Model-Free and Model-Based Strategies for Sample-Efficient Learning</li><li>High-Speed Autonomous Drifting with Deep Reinforcement Learning</li></ul><h2 id="Manipulation-Planning"><a href="#Manipulation-Planning" class="headerlink" title="Manipulation Planning"></a>Manipulation Planning</h2><ul><li>Non-Prehensile Manipulation in Clutter with Human-In-The-Loop</li><li>PuzzleFlex: Kinematic Motion of Chains with Loose Joints</li><li>Accurate Vision-Based Manipulation through Contact Reasoning</li><li>A Probabilistic Framework for Constrained Manipulations and Task and Motion Planning under Uncertainty</li><li>Planning with Selective Physics-Based Simulation for Manipulation among Movable Objects</li><li>Hybrid Differential Dynamic Programming for Planar Manipulation Primitives</li><li>Human-Like Planning for Reaching in Cluttered Environments</li><li>Where to Relocate?: Object Rearrangement Inside Cluttered and Confined Environments for Robotic Manipulation</li><li>Autonomous Modification of Unstructured Environments with Found Material</li><li>Tethered Tool Manipulation Planning with Cable Maneuvering</li><li>Optimization-Based Posture Generation for Whole-Body Contact Motion by Contact Point Search on the Body Surface</li><li>Real-Time Conflict Resolution of Task-Constrained Manipulator Motion in Unforeseen Dynamic Environments (I)</li></ul><h2 id="Contact-Modeling"><a href="#Contact-Modeling" class="headerlink" title="Contact Modeling"></a>Contact Modeling</h2><ul><li>Interaction Stability Analysis from the Input-Output Viewpoints</li></ul><ul><li>Improving the Contact Instant Detection of Sensing Antennae Using a Super-Twisting Algorithm</li><li>6DFC: Efficiently Planning Soft Non-Planar Area Contact Grasps Using 6D Friction Cones</li><li>Long-Horizon Prediction and Uncertainty Propagation with Residual Point Contact Learners</li></ul><ul><li>Versatile Trajectory Optimization Using a LCP Wheel Model for Dynamic Vehicle Maneuvers</li><li>A Transition-Aware Method for the Simulation of Compliant Contact with Regularized Friction</li></ul><h2 id="Robotics-in-Hazardous-Fields"><a href="#Robotics-in-Hazardous-Fields" class="headerlink" title="Robotics in Hazardous Fields"></a>Robotics in Hazardous Fields</h2><ul><li>Single Actuator Peristaltic Robot for Subsurface Exploration and Device Emplacement</li><li>Improving Visual Feature Extraction in Glacial Environments</li><li><p>Unmanned Aerial Vehicle Based Hazardous Materials Response: Information-Theoretic Hazardous Source Search and Reconstruction (I)</p></li><li><p>Planning Maximum-Manipulability Cutting Paths</p></li><li>Robot Risk-Awareness by Formal Risk Reasoning and Planning</li><li>Experimental Evaluation and Characterization of Radioactive Source Effects on Robot Visual Localization and Mapping</li></ul><h2 id="Dynamics"><a href="#Dynamics" class="headerlink" title="Dynamics"></a>Dynamics</h2><ul><li>Dynamic Modeling of Robotic Manipulators for Accuracy Evaluation</li><li>A Real-Robot Dataset for Assessing Transferability of Learned Dynamics Models</li><li>MagNet: Discovering Multi-Agent Interaction Dynamics Using Neural Network</li><li>Modulation of Robot Orientation State Via Leg-Obstacle Contact Positions</li><li><p>Beyond Basins of Attraction: Quantifying Robustness of Natural Dynamics (I)</p></li><li><p>Stable Parking Control of a Robot Astronaut in a Space Station Based on Human Dynamics (I)</p></li></ul><h2 id="Product-Design-Development-and-Prototyping"><a href="#Product-Design-Development-and-Prototyping" class="headerlink" title="Product Design, Development and Prototyping"></a>Product Design, Development and Prototyping</h2><ul><li>Development of a Robotic System for Automated Decaking of 3D-Printed Parts</li><li>A Novel Solar Tracker Driven by Waves: From Idea to Implementation</li><li>Design and Implementation of Hydraulic-Cable Driven Manipulator for Disaster Response Operation</li><li>Designs for an Expressive Mechatronic Chordophone</li><li>Multi Directional Piezoelectric Plate Energy Harvesters Designed by Topology Optimization Algorithm</li><li>OmBURo: A Novel Unicycle Robot with Active Omnidirectional Wheel</li></ul><h2 id="Cellular-and-Modular-Robots"><a href="#Cellular-and-Modular-Robots" class="headerlink" title="Cellular and Modular Robots"></a>Cellular and Modular Robots</h2><ul><li>Self-Reconfiguration in Response to Faults in Modular Aerial Systems</li><li>Recognition and Reconfiguration of Lattice-Based Cellular Structures by Simple Robots</li><li>A Fast Configuration Space Algorithm for Variable Topology Truss Modular Robots</li><li>ModQuad-DoF: A Novel Yaw Actuation for Modular Quadrotors</li><li>An Actuation Fault Tolerance Approach to Reconfiguration Planning of Modular Self-Folding Robots</li><li>Parallel Permutation for Linear Full-Resolution Reconfiguration of Heterogeneous Sliding-Only Cubic Modular Robots</li></ul><h2 id="Performance-Evaluation-and-Benchmarking"><a href="#Performance-Evaluation-and-Benchmarking" class="headerlink" title="Performance Evaluation and Benchmarking"></a>Performance Evaluation and Benchmarking</h2><ul><li>Determining and Improving the Localization Accuracy of AprilTag Detection</li><li>Change of Optimal Values: A Pre-Calculated Metric</li><li>A Flexible Method for Performance Evaluation of Robot Localization</li><li>Quantifying Good Seamanship for Autonomous Surface Vessel Performance Evaluation</li><li>Action-Conditioned Benchmarking of Robotic Video Prediction Models: A Comparative Study</li><li>Performance Indicators for Wheeled Robots Traversing Obstacles</li></ul><h2 id="Aerial-Systems-Applications"><a href="#Aerial-Systems-Applications" class="headerlink" title="Aerial Systems: Applications"></a>Aerial Systems: Applications</h2><ul><li>A Morphable Aerial-Aquatic Quadrotor with Coupled Symmetric Thrust Vectoring</li><li>An Autonomous Intercept Drone with Image-Based Visual Servo</li><li>Real-Time Optimal Trajectory Generation and Control of a Multi-Rotor with a Suspended Load for Obstacle Avoidance</li><li>Wildfire Fighting by Unmanned Aerial System Exploiting Its Time-Varying Mass</li><li>On the Human Control of a Multiple Quadcopters with a Cable-Suspended Payload System</li><li>Dronument: System for Reliable Deployment of Micro Aerial Vehicles in Dark Areas of Large Historical Monuments</li><li>Robust Real-Time UAV Replanning Using Guided Gradient-Based Optimization and Topological Paths</li><li>Learning-Based Path Planning for Autonomous Exploration of Subterranean Environments</li><li>Visual-Inertial Telepresence for Aerial Manipulation</li><li>Distributed Rotor-Based Vibration Suppression for Flexible Object Transport and Manipulation</li><li>Aerial Manipulation Using Model Predictive Control for Opening a Hinged Door</li><li>Integrated Motion Planner for Real-Time Aerial Videography with a Drone in a Dense Environment</li><li>Stable Control in Climbing and Descending Flight under Upper Walls Using Ceiling Effect Model Based on Aerodynamics</li><li>Motion Primitives-Based Path Planning for Fast and Agile Exploration Using Aerial Robots</li><li>Unsupervised Anomaly Detection for Self-Flying Delivery Drones</li></ul><ul><li>Keyfilter-Aware Real-Time UAV Object Tracking</li><li>Aerial Regrasping: Pivoting with Transformable Multilink Aerial Robot</li><li>Grounding Language to Landmarks in Arbitrary Outdoor Environments</li></ul><h2 id="Learning-and-Adaptive-Systems"><a href="#Learning-and-Adaptive-Systems" class="headerlink" title="Learning and Adaptive Systems"></a>Learning and Adaptive Systems</h2><ul><li>MANGA: Method Agnostic Neural-Policy Generalization and Adaptation</li><li>Fast Adaptation of Deep Reinforcement Learning-Based Navigation Skills to Human Preference</li><li>Model-Based Generalization under Parameter Uncertainty Using Path Integral Control</li><li>Memory of Motion for Warm-Starting Trajectory Optimization</li><li>Safety Augmented Value Estimation from Demonstrations (SAVED): Safe Deep Model-Based RL for Sparse Cost Robotic Tasks</li><li>Variational Inference with Mixture Model Approximation for Applications in Robotics</li><li>Preference-Based Learning for Exoskeleton Gait Optimization</li><li>Adaptive Neural Trajectory Tracking Control for Flexible-Joint Robots with Online Learning</li><li>BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking</li><li>Adaptive Unknown Object Rearrangement Using Low-Cost Tabletop Robot</li><li>Unsupervised Learning and Exploration of Reachable Outcome Space</li><li>Context-Aware Cost Shaping to Reduce the Impact of Model Error in Safe, Receding Horizon Control</li><li>Context-Aware Task Execution Using Apprenticeship Learning</li><li>Hierarchical Interest-Driven Associative Goal Babbling for Efficient Bootstrapping of Sensorimotor Skills</li><li>Robot-Supervised Learning for Object Segmentation</li><li>Gradient and Log-Based Active Learning for Semantic Segmentation of Crop and Weed for Agricultural Robots</li><li>Learning How to Walk: Warm-Starting Optimal Control Solver with Memory of Motion</li><li>Feedback Linearization for Unknown Systems Via Reinforcement Learning</li><li>Long-Term Robot Navigation in Indoor Environments Estimating Patterns in Traversability Changes</li><li>Sample-And-Computation-Efficient Probabilistic Model Predictive Control with Random Features</li><li>Sample-Efficient Robot Motion Learning Using Gaussian Process Latent Variable Models</li><li>Iterative Learning Based Feedforward Control for Transition of a Biplane-Quadrotor Tailsitter UAS</li><li>Reinforcement Learning for Adaptive Illumination with X-Rays</li><li>Efficient Updates for Data Association with Mixtures of Gaussian Processes</li></ul><h2 id="Surgical-Robotics-Laparascopy-I"><a href="#Surgical-Robotics-Laparascopy-I" class="headerlink" title="Surgical Robotics: Laparascopy I"></a>Surgical Robotics: Laparascopy I</h2><ul><li>Hand-Eye Calibration of Surgical Instrument for Robotic Surgery Using Interactive Manipulation</li><li>Real-Time Data Driven Precision Estimator for RAVEN-II Surgical Robot End Effector Position</li><li>Vision-Based Dynamic Virtual Fixtures for Tools Collision Avoidance in Robotic Surgery</li><li>An Experimental Comparison towards Autonomous Camera Navigation to Optimize Training in Robot Assisted Surgery</li><li>Temporal Segmentation of Surgical Sub-Tasks through Deep Learning with Multiple Data Sources</li><li>Controlling Assistive Robots with Learned Latent Actions</li></ul><h2 id="Surgical-Robotics-Laparoscopy-II"><a href="#Surgical-Robotics-Laparoscopy-II" class="headerlink" title="Surgical Robotics: Laparoscopy II"></a>Surgical Robotics: Laparoscopy II</h2><ul><li>SuPer: A Surgical Perception Framework for Endoscopic Tissue Manipulation with Surgical Robotics</li><li>Multi-Task Recurrent Neural Network for Surgical Gesture Recognition and Progress Prediction</li><li>Neural Network Based Inverse Dynamics Identification and External Force Estimation on the Da Vinci Research Kit</li><li>Visual Servo of a 6-DOF Robotic Stereo Flexible Endoscope Based on Da Vinci Research Kit (dVRK) System</li><li>Reflective-AR Display: An Interaction Methodology for Virtual-To-Real Alignment in Medical Robotics</li></ul><h2 id="Surgical-Robotics-Steerable-Catheters-Needles"><a href="#Surgical-Robotics-Steerable-Catheters-Needles" class="headerlink" title="Surgical Robotics: Steerable Catheters/Needles"></a>Surgical Robotics: Steerable Catheters/Needles</h2><ul><li>Aortic 3D Deformation Reconstruction Using 2D X-Ray Fluoroscopy and 3D Pre-Operative Data for Endovascular Interventions</li><li>Design and Kinematic Modeling of a Novel Steerable Needle for Image-Guided Insertion</li><li>Robotic Needle Insertion in Moving Soft Tissues Using Constraint-Based Inverse Finite Element Simulation</li><li>Collaborative Robot-Assisted Endovascular Catheterization withGenerative Adversarial Imitation Learning</li><li>A Novel Sensing Method to Detect Tissue Boundaries During Robotic Needle Insertion Based on Laser Doppler Flowmetry</li><li>GA3C Reinforcement Learning for Surgical Steerable Catheter Path Planning</li></ul><h2 id="Path-Planning-for-Multiple-Mobile-Robots-or-Agents"><a href="#Path-Planning-for-Multiple-Mobile-Robots-or-Agents" class="headerlink" title="Path Planning for Multiple Mobile Robots or Agents"></a>Path Planning for Multiple Mobile Robots or Agents</h2><ul><li>Online Trajectory Generation with Distributed Model Predictive Control for Multi-Robot Motion Planning</li><li>One-Shot Multi-Path Planning for Robotic Applications Using Fully Convolutional Networks</li><li>Walk, Stop, Count, and Swap: Decentralized Multi-Agent Path Finding with Theoretical Guarantees</li><li>Efficient Iterative Linear-Quadratic Approximations for Nonlinear Multi-Player General-Sum Differential Games</li><li>Online Motion Planning for Deforming Maneuvering and Manipulation by Multilinked Aerial Robot Based on Differential Kinematics</li><li>DDM: Fast Near-Optimal Multi-Robot Path Planning Using Diversified-Path and Optimal Sub-Problem Solution Database Heuristics</li><li>UBAT: On Jointly Optimizing UAV Trajectories and Placement of Battery Swap Stations</li><li>Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee Using Relative Bernstein Polynomial</li><li>Optimal Sequential Task Assignment and Path Finding for Multi-Agent Robotic Assembly Planning</li><li>Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning</li><li>Adaptive Directional Path Planner for Real-Time, Energy-Efficient, Robust Navigation of Mobile Robots</li><li>Distributed State Estimation Using Intermittently Connected Robot Networks (I)</li></ul><h2 id="Optimization-and-Optimal-Control"><a href="#Optimization-and-Optimal-Control" class="headerlink" title="Optimization and Optimal Control"></a>Optimization and Optimal Control</h2><ul><li>Whole-Body Motion Tracking for a Quadruped-On-Wheel Robot Via a Compact-Form Controller with Improved Prioritized Optimization</li><li>Optimal Control of an Energy-Recycling Actuator for Mobile Robotics Applications</li><li>Real-Time Nonlinear Model Predictive Control of Robots Using a Graphics Processing Unit</li><li>An NMPC Approach Using Convex Inner Approximations for Online Motion Planning with Guaranteed Collision Avoidance</li><li>Multi-Contact Heavy Object Pushing with a Centaur-Type Humanoid Robot: Planning and Control for a Real Demonstrator</li><li>Hierarchical Stochastic Optimization with Application to Parameter Tuning for Electronically Controlled Transmissions</li><li>Targeted Drug Delivery: Algorithmic Methods for Collecting a Swarm of Particles with Uniform, External Forces</li><li>Virtual Point Control Strategy with Power Optimization for Trajectory Planning of Autonomous Mobile Robots</li><li>Enhancing Bilevel Optimization for UAV Time-Optimal Trajectoryusing a Duality Gap Approach</li><li>Constrained Sampling-Based Trajectory Optimization Using StochasticApproximation</li><li>Learning Control Policies from Optimal Trajectories</li><li>Crocoddyl: An Efficient and Versatile Framework for Multi-Contact Optimal Control</li><li>Path-Following Model Predictive Control of Ballbots</li><li>Underactuated Waypoint Trajectory Optimization for Light Painting Photography</li><li>Whole-Body Walking Generation Using Contact Parametrization: A Non-Linear Trajectory Optimization Approach</li><li>Controlling Fast Height Variation of an Actively Articulated Wheeled Humanoid Robot Using Center of Mass Trajectory</li><li>Contact-Aware Controller Design for Complementarity Systems</li><li>Trajectory Optimization of Robots with Regenerative Drive Systems: Numerical and Experimental Results (I)</li><li>Exploiting Sparsity in Robot Trajectory Optimization with Direct Collocation and Geometric Algorithms</li><li>Bi-Convex Approximation of Non-Holonomic Trajectory Optimization</li><li>Fast, Versatile, and Open-Loop Stable Running Behaviors with Proprioceptive-Only Sensing Using Model-Based Optimization</li><li>Wasserstein Distributionally Robust Motion Planning and Control with Safety Constraints Using Conditional Value-At-Risk</li><li>One Robot for Many Tasks: Versatile Co-Design through Stochastic Programming</li><li>Inverse Optimal Control for Multiphase Cost Functions (I)</li></ul><h2 id="Grasping"><a href="#Grasping" class="headerlink" title="Grasping"></a>Grasping</h2><ul><li>Action Image Representation: Learning Deep Grasping Policies with Zero Real World Data</li><li>High Accuracy and Efficiency Grasp Pose Detection Scheme with Dense Predictions</li><li>Transferable Active Grasping and Real Embodied Dataset</li><li>PointNet++ Grasping: Learning an End-To-End Spatial Grasp Generation Algorithm from Sparse Point Clouds</li><li>UniGrasp: Learning a Unified Model to Grasp with Multifingered Robotic Hands</li><li>Grasp for Stacking Via Deep Reinforcement Learning</li><li>CAGE: Context-Aware Grasping Engine</li><li>Time Optimal Motion Planning and Admittance Control for Cooperative Grasping</li><li>Jamming-Free Immobilizing Grasps Using Dual-Friction Robotic Fingertips</li><li>Force-Guided High-Precision Grasping Control of Fragile and Deformable Objects Using sEMG-Based Force Prediction</li><li>Grasp It Like a Pro: Grasp of Unknown Objects with Robotic Hands Based on Skilled Human Expertise</li><li>Learning to Generate 6-DoF Grasp Poses with Reachability Awareness</li><li>Enhancing Grasp Pose Computation in Gripper Workspace Spheres</li><li>Minimal Work: A Grasp Quality Metric for Deformable Hollow Objects</li><li>Hierarchical 6-DoF Grasping with Approaching Direction Selection</li><li>Geometric Characterization of Two-Finger Basket Grasps of 2-D Objects: Contact Space Formulation</li><li>A Multi-Level Optimization Framework for Simultaneous Grasping and Motion Planning</li><li>Grasping Fragile Objects Using a Stress-Minimization Metric</li><li>Grasp Control for Enhancing Dexterity of Parallel Grippers</li><li>Theoretical Derivation and Realization of Adaptive Grasping Based on Rotational Incipient Slip Detection</li><li>Grasp State Assessment of Deformable Objects Using Visual-Tactile Fusion Perception</li><li>Beyond Top-Grasps through Scene Completion</li><li>Dex-Net AR: Distributed Deep Grasp Planning Using a Commodity Cellphone and Augmented Reality App</li></ul><h2 id="Omnidirectional-Vision"><a href="#Omnidirectional-Vision" class="headerlink" title="Omnidirectional Vision"></a>Omnidirectional Vision</h2><ul><li>OmniSLAM: Omnidirectional Localization and Dense Mapping for Wide-Baseline Multi-Camera Systems</li><li>What’s in My Room? Object Recognition on Indoor Panoramic Images</li><li>FisheyeDistanceNet: Self-Supervised Scale-Aware Distance Estimation Using Monocular Fisheye Camera for Autonomous Driving</li><li>360SD-Net: 360° Stereo Depth Estimation with Learnable Cost Volume</li><li>Omnidirectional Depth Extension Networks</li></ul><ul><li>3D Orientation Estimation and Vanishing Point Extraction from Single Panoramas Using Convolutional Neural Network</li></ul><h2 id="Force-and-Tactile-Sensing"><a href="#Force-and-Tactile-Sensing" class="headerlink" title="Force and Tactile Sensing"></a>Force and Tactile Sensing</h2><ul><li>Low-Cost GelSight with UV Markings: Feature Extraction of Objects Using AlexNet and Optical Flow without 3D Image Reconstruction</li><li>Evaluation of Non-Collocated Force Feedback Driven by Signal-Independent Noise</li><li>Vibration-Based Multi-Axis Force Sensing: Design, Characterization, and Modeling</li><li>Tactile Sensing Based on Fingertip Suction Flow for Submerged Dexterous Manipulation</li><li>Discrete Bimanual Manipulation for Wrench Balancing</li><li>Shear, Torsion and Pressure Tactile Sensor Via Plastic Optofiber Guided Imaging</li><li>Dynamically Reconfigurable Tactile Sensor for Robotic Manipulation</li><li>NeuroTac: A Neuromorphic Optical Tactile Sensor Applied to Texture Recognition</li><li>Reducing Uncertainty in Pose Estimation under Complex Contacts Via Force Forecast</li><li>Comparison of Constrained and Unconstrained Human Grasp Forces Using Fingernail Imaging and Visual Servoing</li><li>An ERT-Based Robotic Skin with Sparsely Distributed Electrodes: Structure, Fabrication, and DNN-Based Signal Processing</li><li>FBG-Based Triaxial Force Sensor Integrated with an Eccentrically Configured Imaging Probe for Endoluminal Optical Biopsy</li><li>Calibrating a Soft ERT-Based Tactile Sensor with a Multiphysics Model and Sim-To-Real Transfer Learning</li><li>Sim-To-Real Transfer for Optical Tactile Sensing</li><li>Semi-Empirical Simulation of Learned Force Response Models for Heterogeneous Elastic Objects</li><li>Low-Cost Fiducial-Based 6-Axis Force-Torque Sensor</li><li>Curvature Sensing with a Spherical Tactile Sensor Based on the Color-Interference of a Marker Array</li><li>Center-Of-Mass-Based Robust Grasp Planning for Unknown Objects Using Tactile-Visual Sensors</li><li>OmniTact: A Multi-Directional High-Resolution Touch Sensor</li><li>Highly Sensitive Bio-Inspired Sensor for Fine Surface Exploration and Characterization</li><li>Implementing Tactile and Proximity Sensing for Crack Detection</li><li>Novel Proximity Sensor for Realizing Tactile Sense in Suction Cups</li></ul><h2 id="Visual-Based-Navigation"><a href="#Visual-Based-Navigation" class="headerlink" title="Visual-Based Navigation"></a>Visual-Based Navigation</h2><ul><li>Exploring Performance Bounds of Visual Place Recognition Using Extended Precision</li><li>Deep Reinforcement Learning for Instruction Following Visual Navigation in 3D Maze-Like Environments</li><li>Aggressive Perception-Aware Navigation Using Deep Optical Flow Dynamics and PixelMPC</li><li>Visual-Inertial Mapping with Non-Linear Factor Recovery</li><li>Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in Cluttered Environments</li><li>Highly Robust Visual Place Recognition through Spatial Matching of CNN Features</li><li>Robust and Efficient Estimation of Absolute Camera Pose for Monocular Visual Odometry</li><li>Robust Vision-Based Obstacle Avoidance for Micro Aerial Vehicles in Dynamic Environments</li><li>Proximity Estimation Using Vision Features Computed on Sensor</li><li>Efficient Globally-Optimal Correspondence-Less Visual Odometry for Planar Ground Vehicles</li><li>EgoTEB: Egocentric, Perception Space Navigation Using Timed-Elastic-Bands</li><li>Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection</li><li>Reliable Frame-To-Frame Motion Estimation for Vehicle-Mounted Surround-View Camera Systems</li><li>Enabling Topological Planning with Monocular Vision</li><li>DeepMEL: Compiling Visual Multi-Experience Localization into a Deep Neural Network</li><li>SnapNav: Learning Mapless Visual Navigationwith Sparse Directional Guidance and Visual Reference</li><li>Kimera: An Open-Source Library for Real-Time Metric-Semantic Localization and Mapping</li><li>CityLearn: Diverse Real-World Environments for Sample-Efficient Navigation Policy Learning</li><li>Constrained Filtering-Based Fusion of Images, Events, and Inertial Measurements for Pose Estimation</li><li>Schmidt-EKF-Based Visual-Inertial Moving Object Tracking</li><li>Learning View and Target Invariant Visual Servoing for Navigation</li><li>Tightly-Coupled Single-Anchor Ultra-Wideband-Aided Monocular Visual Odometry System</li><li>Scaling Local Control to Large-Scale Topological Navigation</li><li>Zero-Shot Imitation Learning from Demonstrations for Legged Robot Visual Navigation</li></ul><h2 id="Soft-Robot-Applications"><a href="#Soft-Robot-Applications" class="headerlink" title="Soft Robot Applications"></a>Soft Robot Applications</h2><ul><li>High Resolution Soft Tactile Interface for Physical Human-Robot Interaction</li><li>Learning-Based Fingertip Force Estimation for Soft Wearable Hand Robot with Tendon-Sheath Mechanism</li><li>Autonomous and Reversible Adhesion Using Elastomeric Suction Cups for In-Vivo Medical Treatments</li><li>Design of an Inflatable Wrinkle Actuator with Fast Inflation/Deflation Responses for Wearable Suits</li><li>Design and Validation of a Soft Ankle-Foot Orthosis Exosuit for Inversion and Eversion Support</li><li>Vine Robots: Design, Teleoperation, and Deployment for Navigation and Exploration (I)</li></ul><ul><li>Pressure-Driven Manipulator with Variable Stiffness Structure</li><li>3D Electromagnetic Reconfiguration Enabled by Soft Continuum Robots</li><li>VaLeNS: Design of a Novel Variable Length Nested Soft Arm</li><li>A Programmably Compliant Origami Mechanism for Dynamically Dexterous Robots</li><li>Human Interface for Teleoperated Object Manipulation with a Soft Growing Robot</li></ul><h2 id="Prosthetics-and-Exoskeletons"><a href="#Prosthetics-and-Exoskeletons" class="headerlink" title="Prosthetics and Exoskeletons"></a>Prosthetics and Exoskeletons</h2><ul><li>A Closed-Loop and Ergonomic Control for Prosthetic Wrist Rotation</li><li>Comparison of Online Algorithms for the Tracking of Multiple Magnetic Targets in a Myokinetic Control Interface</li><li>SIMPA: Soft-Grasp Infant Myoelectric Prosthetic Arm</li><li>Backdrivable and Fully-Portable Pneumatic Back Support Exoskeleton for Lifting Assistance</li><li>Clinical Readiness of a Myoelectric Postural Control Algorithm for Persons with Transradial Amputation (I)</li><li><p>Force Control of SEA-Based Exoskeletons for Multimode Human-Robot Interactions (I)</p></li><li><p>Velocity Field Based Active-Assistive Control for Upper Limb Rehabilitation Exoskeleton Robot</p></li><li>Design, Development and Control of a Tendon-Actuated Exoskeleton for Wrist Rehabilitation and Training</li><li>Impedance Control of a Transfemoral Prosthesis Using Continuously Varying Ankle Impedances and Multiple Equilibria</li><li>Towards Variable Assistance for Lower Body Exoskeletons</li><li>Offline Assistance Optimization of a Soft Exosuit for Augmenting Ankle Power of Stroke Survivors During Walking</li><li>Gait Patterns Generation Based on Basis Functions Interpolation for the TWIN Lower-Limb Exoskeleton</li><li>Modulating Hip Stiffness with a Robotic Exoskeleton Immediately Changes Gait</li><li>Swing-Assist for Enhancing Stair Ambulation in a Primarily-Passive Knee Prosthesis</li><li>Proof-Of-Concept of a Pneumatic Ankle Foot Orthosis Powered by a Custom Compressor for Drop Foot Correction</li><li>Knowledge-Guided Reinforcement Learning Control for Robotic Lower Limb Prosthesis</li><li>Development of a Twisted String Actuator-Based Exoskeleton for Hip Joint Assistance in Lifting Tasks</li><li>A Novel Portable Lower Limb Exoskeleton for Gravity Compensation During Walking</li></ul><h2 id="Human-Centered-Robotics"><a href="#Human-Centered-Robotics" class="headerlink" title="Human-Centered Robotics"></a>Human-Centered Robotics</h2><ul><li>Human-Centric Active Perception for Autonomous Observation</li><li>Prediction of Human Full-Body Movements with Motion Optimization and Recurrent Neural Networks</li><li>Predicting and Optimizing Ergonomics in Physical Human-Robot Cooperation Tasks</li><li>Active Reward Learning for Co-Robotic Vision Based Exploration in Bandwidth Limited Environments</li><li>Characterizing User Responses to Failures in Aerial Autonomous Systems</li><li>VariPath: A Database for Modelling the Variance of Human Pathways in Manual and HRC Processes with Heavy-Duty Robots</li><li>Congestion-Aware Evacuation Routing Using Augmented Reality Devices</li><li>Human-Robot Interaction for Robotic Manipulator Programming in Mixed Reality</li><li>Heart Rate Sensing with a Robot Mounted mmWave Radar</li><li>VibeRo: Vibrotactile Stiffness Perception Interface for Virtual Reality</li><li>Detachable Body: The Impact of Binocular Disparity and Vibrotactile Feedback in Co-Presence Tasks</li><li>Prediction of Gait Cycle Percentage Using Instrumented Shoes with Artificial Neural Networks</li><li>Perception-Action Coupling in Usage of Telepresence Cameras</li><li>A Technical Framework for Human-Like Motion Generation with Autonomous Anthropomorphic Redundant Manipulators</li><li>Real-Time Adaptive Assembly Scheduling in Human-Multi-Robot Collaboration According to Human Capability</li><li>Microscope-Guided Autonomous Clear Corneal Incision</li><li>A Haptic Interface for the Teleoperation of Extensible Continuum Manipulators</li><li>From Crowd Simulation to Robot Navigation in Crowds</li></ul><ul><li>Are We There Yet? Comparing Remote Learning Technologies in the University Classroom</li><li>Bilateral Haptic Collaboration for Human-Robot Cooperative Tasks</li><li>A Surgeon-Robot Shared Control for Ergonomic Pedicle Screw Fixation</li><li>Improving Robotic Cooking Using Batch Bayesian Optimization</li><li>Adaptive Motion Planning for a Collaborative Robot Based on Prediction Uncertainty to Enhance Human Safety and Work Efficiency (I)</li></ul><h2 id="Mechanism-Design"><a href="#Mechanism-Design" class="headerlink" title="Mechanism Design"></a>Mechanism Design</h2><ul><li>Quadrupedal Locomotion on Uneven Terrain with Sensorized Feet</li><li>Exploiting Singular Configurations for Controllable, Low-Power, Friction Enhancement on Unmanned Ground Vehicles</li><li>Flow Compensation for Hydraulic Direct-Drive System with a Single-Rod Cylinder Applied to Biped Humanoid Robot</li><li>Development of Visible Manipulator with Multi-Gear Array Mechanism for Laparoscopic Surgery</li><li>Mechanically Programmed Miniature Origami Grippers</li><li>Design of a Novel Multiple-DOF Extendable Arm with Rigid Components Inspired by a Deployable Origami Structure</li><li>A Compact and Low-Cost Robotic Manipulator Driven by Supercoiled Polymer Actuators</li><li>A Wall-Mounted Robot Arm Equipped with a 4-DOF Yaw-Pitch-Yaw-Pitch Counterbalance Mechanism</li><li>Internally-Balanced Magnetic Mechanisms Using a Magnetic Spring for Producing a Large Amplified Clamping Force</li><li>A Continuum Manipulator with Closed-Form Inverse Kinematics and Independently Tunable Stiffness</li><li>Shape-Morphing Wheel Mechanism for Step Climbing in High Speed Locomotion</li><li>Design and Compensation Control of a Flexible Instrument for Endoscopic Surgery</li><li>Steerable Burrowing Robot: Design, Modeling and Experiments</li><li>High Force Density Gripping with UV Activation and Sacrificial Adhesion</li><li>Stiffness Optimization of a Cable Driven Parallel Robot for Additive Manufacturing</li><li>CAMI - Analysis, Design and Realization of a Force-Compliant Variable Cam System</li><li>Using Manipulation to Enable Adaptive Ground Mobility</li><li>SNIAE-SSE Deformation Mechanism Enabled Scalable Multicopter: Design, Modeling and Flight Performance Validation</li></ul><h2 id="Marine-Robotics"><a href="#Marine-Robotics" class="headerlink" title="Marine Robotics"></a>Marine Robotics</h2><ul><li>Distance and Steering Heuristics for Streamline-Based Flow Field Planning</li><li>Enhancing Coral Reef Monitoring Utilizing a Deep Semi-Supervised Learning Approach</li><li>DOB-Net: Actively Rejecting Unknown Excessive Time-Varying Disturbances</li><li>Demonstration of Autonomous Nested Search for Local Maxima Using an Unmanned Underwater Vehicle</li><li>Towards Distortion Based Underwater Domed Viewport Camera Calibration</li><li>A Flapped Paddle-Fin for Improving Underwater Propulsive Efficiency of Oscillatory Actuation</li><li>Bio-Inspired Tensegrity Fish Robot</li><li>A Hybrid Underwater Manipulator System with Intuitive Muscle-Level sEMG Mapping Control</li><li>Single-Hydrophone Low-Cost Underwater Vehicle Swarming</li></ul><ul><li>2D Estimation of Velocity Relative to Water and Tidal Currents Based on Differential Pressure for Autonomous Underwater Vehicles</li><li>Multi-Sensor Mapping for Low Contrast, Quasi-Dynamic, Large Objects</li><li>Gaussian-Dirichlet Random Fields for Inference Over High Dimensional Categorical Observations</li><li>Cooperative Autonomy and Data Fusion for Underwater Surveillance with Networked AUVs</li><li>Bidirectional Resonant Propulsion and Localization for AUVs</li><li>Hierarchical Planning in Time-Dependent Flow Fields for Marine Robots</li><li>Navigation in the Presence of Obstacles for an Agile Autonomous Underwater Vehicle</li><li>Underwater Image Super-Resolution Using Deep Residual Multipliers</li><li>Nonlinear Synchronization Control for Short-Range Mobile Sensors Drifting in Geophysical Flows</li></ul><h2 id="Compliant-Joint-Mechanism"><a href="#Compliant-Joint-Mechanism" class="headerlink" title="Compliant Joint/Mechanism"></a>Compliant Joint/Mechanism</h2><ul><li>Energy-Based Safety in Series Elastic Actuation</li><li>Safe High Impedance Control of a Series-Elastic Actuator with a Disturbance Observer</li><li>Variable Stiffness Springs for Energy Storage Applications</li><li>Parallel-Motion Thick Origami Structure for Robotic Design</li><li>Gyroscopic Tensegrity Robots</li></ul><h2 id="Search-and-Rescue-Robots"><a href="#Search-and-Rescue-Robots" class="headerlink" title="Search and Rescue Robots"></a>Search and Rescue Robots</h2><ul><li>Real-Time Simulation of Non-Deformable Continuous Tracks with Explicit Consideration of Friction and Grouser Geometry</li><li>Test Your SLAM! the SubT-Tunnel Dataset and Metric for Mapping</li><li>Uncertainty Measured Markov Decision Process in Dynamic Environments</li><li>A Minimally Actuated Reconfigurable Continuous Track Robot</li><li>Cooperative Mapping and Target Search Over an Unknown Occupancy Graph Using Mutual Information</li><li>Flexible Disaster Response of Tomorrow - Final Presentation and Evaluation of the CENTAURO System (I)</li></ul><h2 id="Human-Detection-and-Tracking"><a href="#Human-Detection-and-Tracking" class="headerlink" title="Human Detection and Tracking"></a>Human Detection and Tracking</h2><ul><li>Natural Scene Facial Expression Recognitionwith Dimension Reduction Network</li><li>Hand Pose Estimation for Hand-Object Interaction Cases Using Augmented Autoencoder</li><li>Accurate Detection and 3D Localization of Humans Using a Novel YOLO-Based RGB-D Fusion Approach and Synthetic Training Data</li><li>Pedestrian Planar LiDAR Pose (PPLP) Network for Oriented Pedestrian Detection Based on Planar LiDAR and Monocular Images</li><li>Wide-Range Load Sensor Using Vacuum Sealed Quartz Crystal Resonator for Simultaneous Biosignals Measurement on Bed</li></ul><ul><li>Joint Pedestrian Detection and Risk-Level Prediction with Motion-Representation-By-Detection</li></ul><h2 id="Omnidirectional-Vision-and-Audition"><a href="#Omnidirectional-Vision-and-Audition" class="headerlink" title="Omnidirectional Vision and Audition"></a>Omnidirectional Vision and Audition</h2><ul><li>Robust Sound Source Localization Considering Similarity of Back-Propagation Signals</li><li>BatVision: Learning to See 3D Spatial Layout with Two Ears</li><li>Self-Supervised Learning for Alignment of Objects and Sound</li><li>Variational Fisheye Stereo</li><li>The OmniScape Dataset</li><li>Corners for Layout: End-To-End Layout Recovery from 360 Images</li></ul><h2 id="Hydraulic-Pneumatic-Actuators"><a href="#Hydraulic-Pneumatic-Actuators" class="headerlink" title="Hydraulic/Pneumatic Actuators"></a>Hydraulic/Pneumatic Actuators</h2><ul><li><p>How Far Are Pneumatic Artificial Muscles from Biological Muscles?</p></li><li><p>Optically Sensorized Elastomer Air Chamber for Proprioceptive Sensing of Soft Pneumatic Actuator</p></li><li>A Compact McKibben Muscle Based Bending Actuator for Close-To-Body Application in Assistive Wearable Robots</li><li>Proposal and Prototyping of Self-Excited Pneumatic Actuator Using Automatic-Flow-Path-Switching-Mechanism</li><li>Development of Backdrivable Servovalve with Feedback Spring for Enhanced Electro-Hydraulic Torque Actuator</li><li>Passivity-Based Robust Compliance Control of Electro-Hydraulic Robot Manipulators with Joint Angle Limit</li></ul><h2 id="Service-Robots"><a href="#Service-Robots" class="headerlink" title="Service Robots"></a>Service Robots</h2><ul><li>Shared Control Templates for Assistive Robotics</li><li>Enabling Robots to Understand Incomplete Natural Language Instructions Using Commonsense Reasoning</li><li>A Holistic Approach in Designing Tabletop Robot’s Expressivity</li><li>DirtNet: Visual Dirt Detection for Autonomous Cleaning Robots</li><li>Semantic Linking Maps for Active Visual Object Search</li><li>ALTER-EGO: A Mobile Robot with Functionally Anthropomorphic Upper Body Designed for Physical Interaction (I)</li></ul><h2 id="Robot-Perception"><a href="#Robot-Perception" class="headerlink" title="Robot Perception"></a>Robot Perception</h2><ul><li>Active Depth Estimation: Stability Analysis and Its Applications</li><li>VALID: A Comprehensive Virtual Aerial Image Dataset</li><li>Multiple Sound Source Position Estimation by Drone Audition Based on Data Association between Sound Source Localization and Identification</li><li>Augmented LiDAR Simulator for Autonomous Driving</li><li>Purely Image-Based Pose Stabilization of Nonholonomic Mobile Robots with a Truly Uncalibrated Overhead Camera (I)</li></ul><h2 id="Distributed-Robot-Systems"><a href="#Distributed-Robot-Systems" class="headerlink" title="Distributed Robot Systems"></a>Distributed Robot Systems</h2><ul><li>Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning</li><li>Multirobot Patrolling against Adaptive Opponents with Limited Information</li><li>Distributed Optimization of Nonlinear, Non-Gaussian, Communication-Aware Information Using Particle Methods</li><li>Experimental Comparison of Decentralized Task Allocation Algorithms under Imperfect Communication</li><li>Parallel Self-Assembly with SMORES-EP, a Modular Robot</li><li>Scalable Cooperative Transport of Cable-Suspended Loads with UAVs Using Distributed Trajectory Optimization</li></ul><h2 id="Range-Sensing"><a href="#Range-Sensing" class="headerlink" title="Range Sensing"></a>Range Sensing</h2><ul><li>Super-Pixel Sampler: A Data-Driven Approach for Depth Sampling and Reconstruction</li><li>Physics-Based Simulation of Continuous-Wave LIDAR for Localization, Calibration and Tracking</li><li>A Spatial-Temporal Multiplexing Method for Dense 3D Surface Reconstruction of Moving Objects</li><li>Modeling of Architectural Components for Large-Scale Indoor Spaces from Point Cloud Measurement</li><li>PhaRaO: Direct Radar Odometry Using Phase Correlation</li><li>DeepTemporalSeg: Temporally Consistent Semantic Segmentation of 3D LiDAR Scans</li></ul><h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h2><ul><li>Self-Supervised Sim-To-Real Adaptation for Visual Robotic Manipulation</li><li>Meta Reinforcement Learning for Sim-To-Real Domain Adaptation</li><li>Variational Auto-Regularized Alignment for Sim-To-Real Control</li><li>Experience Selection Using Dynamics Similarity for Efficient Multi-Source Transfer Learning between Robots</li><li>DeepRacer: Autonomous Racing Platform for Experimentation with Sim2Real Reinforcement Learning</li><li>Cross-Domain Motion Transfer Via Safety-Aware Shared Latent Space Modeling</li></ul><h2 id="Flexible-Robots"><a href="#Flexible-Robots" class="headerlink" title="Flexible Robots"></a>Flexible Robots</h2><ul><li>Investigation of a Multistable Tensegrity Robot Applied As Tilting Locomotion System</li><li>A Novel Articulated Soft Robot Capable of Variable Stiffness through Bistable Structure</li><li>Modeling and Experiments on the Swallowing and Disgorging Characteristics of an Underwater Continuum Manipulator</li><li>Salamanderbot: A Soft-Rigid Composite Continuum Mobile Robotto Traverse Complex Environments</li><li>Flexure Hinge-Based Biomimetic Thumb with a Rolling-Surface Metacarpal Joint</li><li>Stretchable Kirigami Components for Composite Meso-Scale Robots</li></ul><h2 id="Field-and-Space-Robots"><a href="#Field-and-Space-Robots" class="headerlink" title="Field and Space Robots"></a>Field and Space Robots</h2><ul><li>Ibex: A Reconfigurable Ground Vehicle with Adaptive Terrain Navigation Capability</li><li>Day and Night Collaborative Dynamic Mapping in Unstructured Environment Based on Multimodal Sensors</li><li>Generating Locomotion with Effective Wheel Radius Manipulation</li><li>Where to Map? Iterative Mars Helicopter-Rover Path Planning for Long-Range Autonomous Exploration</li><li>A GNC Architecture for Planetary Rovers with Autonomous Navigation</li><li>Mine Tunnel Exploration Using Multiple Quadrupedal Robots</li></ul><h2 id="Recognition"><a href="#Recognition" class="headerlink" title="Recognition"></a>Recognition</h2><ul><li>Learning Face Recognition Unsupervisedly by Disentanglement and Self-Augmentation</li><li>PARC: A Plan and Activity Recognition Component for Assistive Robots</li><li>Image-Based Place Recognition on Bucolic Environment across Seasons from Semantic Edge Description</li><li>A Multilayer-Multimodal Fusion Architecture for Pattern Recognition of Natural Manipulations in Percutaneous Coronary Interventions</li><li>Action Description from 2D Human Postures in Care Facilities</li><li>CoHOG: A Light-Weight, Compute-Efficient and Training-Free Visual Place Recognition Technique for Changing Environments</li></ul><h2 id="Aerial-Systems-Multi-Robots"><a href="#Aerial-Systems-Multi-Robots" class="headerlink" title="Aerial Systems: Multi-Robots"></a>Aerial Systems: Multi-Robots</h2><ul><li>Distributed Consensus Control of Multiple UAVs in a Constrained Environment</li><li>Neural-Swarm: Decentralized Close-Proximity Multirotor Control Using Learned Interactions</li><li>Line Coverage with Multiple Robots</li><li>Visual Coverage Maintenance for Quadcopters Using Nonsmooth Barrier Functions</li><li>Autonomous Reflectance Transformation Imaging by a Team of Unmanned Aerial Vehicles</li><li>Localization of Ionizing Radiation Sources by Cooperating Micro Aerial Vehicles with Pixel Detectors in Real-Time</li></ul><h2 id="Biological-Cell-Manipulation"><a href="#Biological-Cell-Manipulation" class="headerlink" title="Biological Cell Manipulation"></a>Biological Cell Manipulation</h2><ul><li>Design and Control of a Piezo Drill for Robotic Piezo-Driven Cell Penetration</li><li>Model-Based Robotic Cell Aspiration: Tackling Nonlinear Dynamics and Varying Cell Sizes</li><li>Automated High-Productivity Microinjection System for Adherent Cells</li><li>High Fidelity Force Feedback Facilitates Manual Injection in Biological Samples</li><li>Dynamic Response of Swimming Paramecium Induced by Local Stimulation Using a Threadlike-Microtool</li><li>Injection of a Fluorescent Microsensor into a Specific Cell by Laser Manipulation and Heating with Multiple Wavelengths of Light</li></ul><h2 id="Cooperating-Robots"><a href="#Cooperating-Robots" class="headerlink" title="Cooperating Robots"></a>Cooperating Robots</h2><ul><li>Correspondence Identification in Collaborative Robot Perception through Maximin Hypergraph Matching</li><li>Scalable Target-Tracking for Autonomous Vehicle Fleets</li><li>A Dynamic Weighted Area Assignment Based on a Particle Filter for Active Cooperative Perception</li><li>Flying Batteries: In-Flight Battery Switching to Increase Multirotor Flight Time</li><li><p>Sensor Assignment Algorithms to Improve Observability While Tracking Targets (I)</p></li><li><p>Coordinated Bayesian-Based Bioinspired Plume Source Term Estimation and Source Seeking for Mobile Robots (I)</p></li></ul><h2 id="RGB-D-Perception"><a href="#RGB-D-Perception" class="headerlink" title="RGB-D Perception"></a>RGB-D Perception</h2><ul><li>ClearGrasp: 3D Shape Estimation of Transparent Objects for Manipulation</li><li>6D Object Pose Regression Via Supervised Learning on Point Clouds</li><li>YCB-M: A Multi-Camera RGB-D Dataset for Object Recognition and 6DoF Pose Estimation</li><li>Depth Based Semantic Scene Completion with Position Importance Aware Loss</li><li>Self-Supervised 6D Object Pose Estimation for Robot Manipulation</li><li>Panoptic 3D Mapping and Object Pose Estimation Using Adaptively Weighted Semantic Information</li></ul><h2 id="Task-Planning"><a href="#Task-Planning" class="headerlink" title="Task Planning"></a>Task Planning</h2><ul><li>Online Trajectory Planning through Combined Trajectory Optimization and Function Approximation: Application to the Exoskeleton Atalante</li><li>Act, Perceive, and Plan in Belief Space for Robot Localization</li><li>Decentralized Task Allocation in Multi-Agent Systems Using a Decentralized Genetic Algorithm</li><li>Fast and Resilient Manipulation Planning for Target Retrieval in Clutter</li><li>Multi-Robot Task and Motion Planning with Subtask Dependencies</li><li>Untethered Soft Millirobot with Magnetic Actuation</li></ul><h2 id="Brain-Machine-Interfaces"><a href="#Brain-Machine-Interfaces" class="headerlink" title="Brain-Machine Interfaces"></a>Brain-Machine Interfaces</h2><ul><li>Accelerated Robot Learning Via Human Brain Signals</li><li>Muscle and Brain Activations in Cylindrical Rotary Controller Manipulation with Index Finger and Thumb</li><li>Real-Time Robot Reach-To-Grasp Movements Control Via EOG and EMG Signals Decoding</li><li>Simultaneous Estimations of Joint Angle and Torque in Interactions with Environments Using EMG</li><li>High-Density Electromyography Based Control of Robotic Devices: On the Execution of Dexterous Manipulation Tasks</li><li>The Role of the Control Framework for Continuous Teleoperation of a Brain�Machine Interface-Driven Mobile Robot (I)</li></ul><h2 id="Tendon-Wire-Mechanism"><a href="#Tendon-Wire-Mechanism" class="headerlink" title="Tendon/Wire Mechanism"></a>Tendon/Wire Mechanism</h2><ul><li>Asynchronous and Decoupled Control of the Position and the Stiffness of a Spatial RCM Tensegrity Mechanism for Needle Manipulation</li><li>Redundancy Resolution Integrated Model Predictive Control of CDPRs: Concept, Implementation and Experiments</li><li>Mechanics for Tendon Actuated Multisection Continuum Arms</li><li>Trajectory Optimization for a Six-DOF Cable-Suspended Parallel Robot with Dynamic Motions Beyond the Static Workspace</li><li>Design of Tensegrity-Based Manipulators: Comparison of Two Approaches to Respect a Remote Center of Motion Constraint</li><li>Accurate Dynamic Modeling of Twisted String Actuators Accounting for String Compliance and Friction</li></ul><h2 id="Agricultural-Automation"><a href="#Agricultural-Automation" class="headerlink" title="Agricultural Automation"></a>Agricultural Automation</h2><ul><li>An Intelligent Spraying System with Deep Learning-Based Semantic Segmentation of Fruit Trees in Orchards</li><li>An Efficient Planning and Control Framework for Pruning Fruit Trees</li><li>Context Dependant Iterative Parameter Optimisation for Robust Robot Navigation</li><li>Combining Domain Adaptation and Spatial Consistency for Unseen Fruits Counting: A Quasi-Unsupervised Approach</li><li>A Navigation Architecture for Ackermann Vehicles in Precision Farming</li><li>MinneApple: A Benchmark Dataset for Apple Detection and Segmentation</li></ul><h2 id="Underactuated-Robots"><a href="#Underactuated-Robots" class="headerlink" title="Underactuated Robots"></a>Underactuated Robots</h2><ul><li>Extending Riemmanian Motion Policies to a Class of Underactuated Wheeled-Inverted-Pendulum Robots</li><li>Augmenting Self-Stability: Height Control of a Bernoulli Ball Via Bang-Bang Control</li><li>Singularity-Free Inverse Dynamics for Underactuated Systems with a Rotating Mass</li><li>Coordinated Particle Relocation Using Finite Static Friction with Boundary Walls</li><li>Robust Capture of Unknown Objects with a Highly Under-Actuated Gripper</li><li>TWISTER Hand: Underactuated Robotic Gripper Inspired by Origami Twisted Tower (I)</li></ul><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><ul><li>Robust Autonomous Navigation of Unmanned Aerial Vehicles (UAVs) for Warehouses’ Inventory Applications</li><li>SUMMIT: A Simulator for Urban Driving in Massive Mixed Traffic</li><li>A Model-Based Reinforcement Learning and Correction Framework for Process Control of Robotic Wire Arc Additive Manufacturing</li><li>Toward Optimal FDM Toolpath Planning with Monte Carlo Tree Search</li><li>Optimizing Performance in Automation through Modular Robots</li><li>Towards Practical Multi-Object Manipulation Using Relational Reinforcement Learning</li><li>SwarmMesh: A Distributed Data Structure for Cooperative Multi-Robot Applications</li></ul><h2 id="Robust-and-Sensor-Based-Control"><a href="#Robust-and-Sensor-Based-Control" class="headerlink" title="Robust and Sensor-Based Control"></a>Robust and Sensor-Based Control</h2><ul><li>Avalanche Victim Search Via Robust Observers</li><li>Reactive Control and Metric-Topological Planning for Exploration</li><li>Information Theoretic Active Exploration in Signed Distance Fields</li><li>Adaptive Integral Inverse Kinematics Control for Lightweight Compliant Manipulators</li><li>Bayesian Learning-Based Adaptive Control for Safety Critical Systems</li><li>A Novel Adaptive Controller for Robot Manipulators Based on Active Inference</li></ul><h2 id="Object-Detection-Segmentation-and-Categorization"><a href="#Object-Detection-Segmentation-and-Categorization" class="headerlink" title="Object Detection, Segmentation and Categorization"></a>Object Detection, Segmentation and Categorization</h2><ul><li>Stillleben: Realistic Scene Synthesis for Deep Learning in Robotics</li><li>From Planes to Corners: Multi-Purpose Primitive Detection in Unorganized 3D Point Clouds</li><li>Addressing the Sim2Real Gap in Robotic 3D Object Classification</li><li>A Generative Approach towards Improved Robotic Detection of Marine Litter</li><li>Learning to Optimally Segment Point Clouds</li><li>CNN Based Road User Detection Using the 3D Radar Cube</li><li></li><li>PST900: RGB-Thermal Calibration, Dataset and Segmentation Network</li><li>Instance Segmentation of LiDAR Point Clouds</li><li>Generation of Object Candidates through Simply Looking Around</li><li>Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds</li><li>A Water-Obstacle Separation and Refinement Network for Unmanned Surface Vehicles</li><li>Dynamic Anchor Selection for Improving Object Localization</li><li>3D Object Detection and Tracking Based on Streaming Data</li><li>Object-Centric Stereo Matching for 3D Object Detection</li><li>The Relative Confusion Matrix, a Tool to Assess Classifiablility in Large Scale Picking Applications</li><li>Pose-Guided Auto-Encoder and Feature-Based Refinement for 6-DoF Object Pose Regression</li><li>PrimiTect: Fast Continuous Hough Voting for Primitive Detection</li><li>FarSee-Net: Real-Time Semantic Segmentation by Efficient Multi-Scale Context Aggregation and Feature Space Super-Resolution</li></ul><h2 id="Aerial-Systems-Perception-and-Autonomy"><a href="#Aerial-Systems-Perception-and-Autonomy" class="headerlink" title="Aerial Systems: Perception and Autonomy"></a>Aerial Systems: Perception and Autonomy</h2><ul><li>Pose-Estimate-Based Target Tracking for Human-Guided Remote Sensor Mounting with a UAV</li><li>Aerial Single-View Depth Completion with Image-Guided Uncertainty Estimation</li><li>EVDodgeNet: Deep Dynamic Obstacle Dodging with Event Cameras</li><li>Direct Visual-Inertial Ego-Motion Estimation Via Iterated Extended Kalman Filter</li><li>A Robust UAV System for Operations in a Constrained Environment</li><li>On Training Datasets for Machine Learning-Based Visual Relative Localization of Micro-Scale UAVs</li><li>Fast Frontier-Based Information-Driven Autonomous Exploration with an MAV</li><li>Dynamic Landing of an Autonomous Quadrotor on a Moving Platform in Turbulent Wind Conditions</li><li>Cross-Drone Binocular Coordination for Ground Moving Target Tracking in Occlusion-Rich Scenarios</li><li>Direct NMPC for Post-Stall Motion Planning with Fixed-Wing UAVs</li><li>IMU-Based Inertia Estimation for a Quadrotor Using Newton-Euler Dynamics</li><li>A Flight Envelope Determination and Protection System for Fixed-Wing UAVs</li><li>AU-AIR: A Multi-Modal Unmanned Aerial Vehicle Dataset for Low Altitude Traffic Surveillance</li><li>Design and Autonomous Stabilization of a Ballistically Launched Multirotor</li><li>Asynchronous Event-Based Clustering and Tracking for Intrusion Monitoring in UAS</li><li>SHIFT: Selective Heading Image for Translation, an Onboard Monocular Optical Flow Estimator for Fast Constantly Rotating UAVs</li><li>Flydar: Magnetometer-Based High Angular Rate Estimation During Gyro Saturation for SLAM</li><li>Nonlinear MPC with Motor Failure Identification and Recovery for Safe and Aggressive Multicopter Flight</li></ul><h2 id="Autonomous-Vehicle-Navigation"><a href="#Autonomous-Vehicle-Navigation" class="headerlink" title="Autonomous Vehicle Navigation"></a>Autonomous Vehicle Navigation</h2><ul><li>Autonomous Navigation in Inclement Weather Based on a Localizing Ground Penetrating Radar</li><li>Robot Navigation in Crowds by Graph Convolutional Networks with Attention Learned from Human Gaze</li><li>Wall Deadlock Evasion Control Based on Rotation Radius Adjustment</li><li>Socially-Aware Reactive Obstacle Avoidance Strategy Based on Limit Cycle</li><li>Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting</li><li>Temporal Information Integration for Video Semantic Segmentation</li><li>Map-Predictive Motion Planning in Unknown Environments</li><li>Using Multiple Short Hops for Multicopter Navigation with Only Inertial Sensors</li><li>An Efficient and Continuous Approach to Information-Theoretic Exploration</li><li>A Feature-Based Underwater Path Planning Approach Using Multiple Perspective Prior Maps</li><li>Automatic LiDAR-Camera Calibration of Extrinsic Parameters Using a Spherical Target</li></ul><h2 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h2><ul><li>A Unified Framework for Piecewise Semantic Reconstruction in Dynamic Scenes Via Exploiting Superpixel Relations</li><li>Keyframe-Based Dense Mapping with the Graph of View-Dependent Local Maps</li><li>Informative Path Planning for Active Mapping under Localization Uncertainty</li><li>Ensemble of Sparse Gaussian Process Experts for Implicit Surface Mapping with Streaming Data</li><li>Robust Method for Removing Dynamic Objects from Point Clouds</li><li>Skeleton-Based Conditionally Independent Gaussian Process Implicit Surfaces for Fusion in Sparse to Dense 3D Reconstruction</li><li>Motion Estimation in Occupancy Grid Maps in Stationary Settings Using Recurrent Neural Networks</li><li><p>A Divide and Conquer Method for 3D Registration of Inhomogeneous, Partially Overlapping Scans with Fourier Mellin SOFT (FMS)</p></li><li><p>Estimating Motion Uncertainty with Bayesian ICP</p></li><li>Actively Mapping Industrial Structures with Information Gain-Based Planning on a Quadruped Robot</li><li>Efficient Covisibility-Based Image Matching for Large-Scale SfM</li><li>Probabilistic TSDF Fusion Using Bayesian Deep Learning for Dense 3D Reconstruction with a Single RGB Camera</li><li>A Volumetric Albedo Framework for 3D Imaging Sonar Reconstruction</li><li>Map Management Approach for SLAM in Large-Scale Indoor and Outdoor Areas</li><li>A Hierarchical Framework for Collaborative Probabilistic Semantic Mapping</li><li>Autonomous Navigation in Unknown Environments Using Sparse Kernel-Based Occupancy Mapping</li><li>Hybrid Topological and 3D Dense Mapping through Autonomous Exploration for Large Indoor Environments</li><li>Resolving Marker Pose Ambiguity by Robust Rotation Averaging with Clique Constraints</li></ul><h2 id="Computer-Vision-for-Other-Robotic-Applications"><a href="#Computer-Vision-for-Other-Robotic-Applications" class="headerlink" title="Computer Vision for Other Robotic Applications"></a>Computer Vision for Other Robotic Applications</h2><ul><li>Real-Time Semantic Stereo Matching</li><li>Multi-Task Learning for Single Image Depth Estimation and Segmentation Based on Unsupervised Network</li><li>Learning Transformable and Plannable Se(3) Features for Scene Imitation of a Mobile Service Robot</li><li>Multimodal Multispectral Imaging System for Small UAVs</li><li>Unseen Salient Object Discovery for Monocular Robot Vision</li><li>CorsNet: 3D Point Cloud Registration by Deep Neural Network</li><li>Anticipating the Start of User Interaction for Service Robot in the Wild</li><li>Spin Detection in Robotic Table Tennis</li><li>Look, Listen, and Act: Towards Audio-Visual Embodied Navigation</li><li>Autonomous Tool Construction with Gated Graph Neural Network</li><li>Training-Set Distillation for Real-Time UAV Object Tracking</li><li>CNN-Based Simultaneous Dehazing and Depth Estimation</li><li>IF-Net: An Illumination-Invariant Feature Network</li><li>Deep-Learning Assisted High-Resolution Binocular Stereo Depth Reconstruction</li><li>Least-Squares Optimal Relative Planar Motion for Vehicle-Mounted Cameras</li><li>Relative Planar Motion for Vehicle-Mounted Cameras from a Single Affine Correspondence</li><li>Moving Object Detection for Visual Odometry in a Dynamic Environment Based on Occlusion Accumulation</li><li>A Low-Rank Matrix Approximation Approach to Multiway Matching with Applications in Multi-Sensory Data Association</li></ul><h2 id="Humanoid-and-Bipedal-Locomotion"><a href="#Humanoid-and-Bipedal-Locomotion" class="headerlink" title="Humanoid and Bipedal Locomotion"></a>Humanoid and Bipedal Locomotion</h2><ul><li>LQR-Assisted Whole-Body Control of a Wheeled Bipedal Robot with Kinematic Loops</li><li>Leveraging the Template and Anchor Framework for Safe, Online Robotic Gait Design</li><li>Unified Push Recovery Fundamentals: Inspiration from Human Study</li><li>Nonholonomic Virtual Constraint Design for Variable-Incline Bipedal Robotic Walking</li><li><p>MPC for Humanoid Gait Generation: Stability and Feasibility (I)</p></li><li><p>A Robust Walking Controller Based on Online Optimization of Ankle, Hip, and Stepping Strategies (I)</p></li></ul><ul><li>Passive Dynamic Balancing and Walking in Actuated Environments</li><li>Biped Stabilization by Linear Feedback of the Variable-Height Inverted Pendulum Model</li><li>Stability Criteria of Balanced and Steppable Unbalanced States for Full-Body Systems with Implications in Robotic and Human Gait</li><li>Material Handling by Humanoid Robot While Pushing Carts Using a Walking Pattern Based on Capture Point</li><li>Interconnection and Damping Assignment Passivity-Based Control for Gait Generation in Underactuated Compass-Like Robots</li><li>Safety-Critical Control of a Cassie Bipedal Robot Riding Hovershoes for Vision-Based Obstacle Avoidance</li><li>A Methodology for the Incorporation of Arbitrarily-Shaped Feet in Passive Bipedal Walking Dynamics</li><li>Experimental Analysis of Structural Vibration Problems of a Biped Walking Robot</li><li>Dynamic Coupling As an Indicator of Gait Robustness for Underactuated Biped Robots</li><li>ZMP Constraint Restriction for Robust Gait Generation in Humanoids</li><li>Hybrid Zero Dynamics Inspired Feedback Control Policy Design for 3D Bipedal Locomotion Using Reinforcement Learning</li><li>Optimal Reduced-Order Modeling of Bipedal Locomotion</li></ul><h2 id="Motion-Control"><a href="#Motion-Control" class="headerlink" title="Motion Control"></a>Motion Control</h2><ul><li>Anti-Jackknife Control of Tractor-Trailer Vehicles Via Intrinsically Stable MPC</li><li>On Sensing-Aware Model Predictive Path-Following Control for a Reversing General 2-Trailer with a Car-Like Tractor</li><li>Offline Practising and Runtime Training Framework for Autonomous Motion Control of Snake Robots</li><li>Control of a Differentially Driven Nonholonomic Robot Subject to a Restricted Wheels Rotation</li><li>Inferring Task-Space Central Pattern Generator Parameters for Closed-Loop Control of Underactuated Robots</li><li>Magnetically Actuated Simple Millirobots for Complex Navigation and Modular Assembly</li></ul><h2 id="Dexterous-Manipulation"><a href="#Dexterous-Manipulation" class="headerlink" title="Dexterous Manipulation"></a>Dexterous Manipulation</h2><ul><li>MagicHand: Context-Aware Dexterous Grasping Using an Anthropomorphic Robotic Hand</li><li>Strategy for Roller Chain Assembly with Parallel Jaw Gripper</li><li>Distal Hyperextension Is Handy: High Range of Motion in Cluttered Environments</li><li>Learning Pre-Grasp Manipulation for Objects in Un-Graspable Poses</li><li>Object-Level Impedance Control for Dexterous In-Hand Manipulation</li><li>Picking Thin Objects by Tilt-And-Pivot Manipulation and Its Application to Bin Picking</li><li>In-Hand Manipulation of Objects with Unknown Shapes</li><li>Learning Hierarchical Control for Robust In-Hand Manipulation</li><li>Tactile Dexterity: Manipulation Primitives with Tactile Feedback</li><li>Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation</li><li>High-Resolution Optical Fiber Shape Sensing of Continuum Robots: A Comparative Study</li><li>Local Trajectory Stabilization for Dexterous Manipulation Via Piecewise Affine Approximations</li></ul><h2 id="Computer-Vision-for-Automation-and-Manufacturing"><a href="#Computer-Vision-for-Automation-and-Manufacturing" class="headerlink" title="Computer Vision for Automation and Manufacturing"></a>Computer Vision for Automation and Manufacturing</h2><ul><li>Monocular Direct Sparse Localization in a Prior 3D Surfel Map</li><li>LINS: A Lidar-Inertial State Estimator for Robust and Efficient Navigation</li><li>Automated Eye-In-Hand Robot-3D Scanner Calibration for Low Stitching Errors</li><li>Monocular Visual Odometry Using Learned Repeatability and Description</li><li>Interaction Graphs for Object Importance Estimation in On-Road Driving Videos</li><li>A Robotics Inspection System for Detecting Defects on Semi-Specular Painted Automotive Surfaces</li></ul><h2 id="Visual-Servoing"><a href="#Visual-Servoing" class="headerlink" title="Visual Servoing"></a>Visual Servoing</h2><ul><li>Active Deformation through Visual Servoing of Soft Objects</li><li>Visual Geometric Skill Inference by Watching Human Demonstration</li><li>Direct Visual Servoing in the Frequency Domain</li><li>DFVS: Deep Flow Guided Scene Agnostic Image Based Visual Servoing</li><li>Photometric Path Planning for Vision-Based Navigation</li><li>A Memory of Motion for Visual Predictive Control Tasks</li></ul><h2 id="Soft-Robot-Materials-and-Design"><a href="#Soft-Robot-Materials-and-Design" class="headerlink" title="Soft Robot Materials and Design"></a>Soft Robot Materials and Design</h2><ul><li>Designing Ferromagnetic Soft Robots (FerroSoRo) with Level-Set-Based Multiphysics Topology Optimization</li><li>Exoskeleton-Covered Soft Finger with Vision-Based Proprioception and Tactile Sensing</li><li>Tuning the Energy Landscape of Soft Robots for Fast and Strong Motion</li><li>REBOund: Untethered Origami Jumping Robot with Controllable Jump Height</li><li>Concentric Precurved Bellows: New Bending Actuators for Soft Robots</li><li>Design of Deployable Soft Robots through Plastic Deformation of Kirigami Structures</li><li>Self-Excited Vibration Valve That Induces Traveling Waves in Pneumatic Soft Mobile Robots</li><li>A 1mm-Thick Miniatured Mobile Soft Robot with Mechanosensation and Multimodal Locomotion</li><li>Anisotropic Soft Robots Based on 3D Printed Meso-Structured Materials: Design, Modeling by Homogenization and Simulation</li><li>3D-Printed Electroactive Hydraulic Valves for Use in Soft Robotic Applications</li><li>Design and Workspace Characterisation of Malleable Robots</li><li>A Tri-Stable Soft Robotic Finger Capable of Pinch and Wrap Grasps</li><li>A Dexterous Tip-Extending Robot with Variable-Length Shape-Locking</li><li>Compliant Electromagnetic Actuator Architecture for Soft Robotics</li><li>Dynamically Reconfigurable Discrete Distributed Stiffness for Inflated Beam Robots</li><li>Retraction of Soft Growing Robots without Buckling</li></ul><h2 id="Rehabilitation-Robotics"><a href="#Rehabilitation-Robotics" class="headerlink" title="Rehabilitation Robotics"></a>Rehabilitation Robotics</h2><ul><li>Motion Intensity Extraction Scheme for Simultaneous Recognition of Wrist/Hand Motions</li><li>Simultaneous Online Motion Discrimination and Evaluation of Whole-Body Exercise by Synergy Probes for Home Rehabilitation</li><li>IART: Learning from Demonstration for Assisted Robotic Therapy Using LSTM</li><li>Validation of a Forward Kinematics Based Controller for a Mobile Tethered Pelvic Assist Device to Augment Pelvic Forces During Walking</li><li>Temporal Muscle Synergy Features Estimate Effects of Short-Term Rehabilitation in Sit-To-Stand of Post-Stroke Patients</li><li>Model Learning for Control of a Paralyzed Human Arm with Functional Electrical Stimulation</li><li>Patient-Specific, Voice-Controlled, Robotic FLEXotendon Glove-II System for Spinal Cord Injury</li><li>Integration of Self-Sealing Suction Cups on the FLEXotendon Glove-II Robotic Exoskeleton System</li><li>A Novel End-Effector Robot System Enabling to Monitor Upper-Extremity Posture During Robot-Aided Reaching Movements</li><li>Optimal Design of a Novel 3-DOF Orientational Parallel Mechanism for Pelvic Assistance on a Wheelchair: An Approach Based on Kinematic Geometry and Screw Theory</li><li><p>Using Human Ratings for Feedback Control: A Supervised Learning Approach with Application to Rehabilitation Robotics (I)</p></li><li><p>Compliant Humanoids Moving Toward Rehabilitation Applications: Transparent Integration of Real-Time Control, Whole-Body Motion Generation, and Virtual Reality (I)</p></li><li><p>Data-Driven Reinforcement Learning for Walking Assistance Control of a Lower Limb Exoskeleton with Hemiplegic Patients</p></li><li>On the Effects of Visual Anticipation of Floor Compliance Changes on Human Gait: Towards Model-Based Robot-Assisted Rehabilitation</li><li>A Visual Positioning System for Indoor Blind Navigation</li><li>An Outsole-Embedded Optoelectronic Sensor to Measure Shear Ground Reaction Forces During Locomotion</li><li>Bump�em: An Open-Source, Bump-Emulation System for Studying Human Balance and Gait</li><li>A Hybrid, Soft Exoskeleton Glove Equipped with a Telescopic Extra Thumb and Abduction Capabilities</li></ul><h2 id="Physical-Human-Robot-Interaction"><a href="#Physical-Human-Robot-Interaction" class="headerlink" title="Physical Human-Robot Interaction"></a>Physical Human-Robot Interaction</h2><ul><li>Transient Behavior and Predictability in Manipulating Complex Objects</li><li>A Variable-Fractional Order Admittance Controller for PHRI</li><li>Assistive Gym: A Physics Simulation Framework for Assistive Robotics</li><li>Learning Whole-Body Human-Robot Haptic Interaction in Social Contexts</li><li>Human Preferences in Using Damping to Manage Singularities During Physical Human-Robot Collaboration</li><li>MOCA-MAN: A MObile and Reconfigurable Collaborative Robot Assistant for Conjoined huMAN-Robot Actions</li><li>Variable Damping Control of a Robotic Arm to Improve Trade-Off between Agility and Stability and Reduce User Effort</li><li>Robustness in Human Manipulation of Dynamically Complex Objects through Control Contraction Metrics</li><li>Cooperative Human-Robot Grasping with Extended Contact Patches</li><li><p>The InSight Crutches: Analyzing the Role of Arm Support During Robot-Assisted Leg Movements (I)</p></li><li><p>Cognitive and Motor Compliance in Intentional Human-Robot Interaction</p></li><li>Controlling an Upper-Limb Exoskeleton by EMG Signal While Carrying Unknown Load</li><li>Learning Grasping Points for Garment Manipulation in Robot-Assisted Dressing</li><li>TACTO-Selector: Enhanced Hierarchical Fusion of PBVS with Reactive Skin Control for Physical Human-Robot Interaction</li><li>Towards an Intelligent Collaborative Robotic System for Mixed Case Palletizing</li><li>Treadmill Based Three Tether Parallel Robot for Evaluating Auditory Warnings While Running</li><li>Evaluation of Human-Robot Object Co-Manipulation under Robot Impedance Control</li></ul><h2 id="Telerobotics-and-Teleoperation"><a href="#Telerobotics-and-Teleoperation" class="headerlink" title="Telerobotics and Teleoperation"></a>Telerobotics and Teleoperation</h2><ul><li><p>Adaptive </p></li><li><p>Tactile Telerobots for Dull, Dirty, Dangerous, and Inaccessible Tasks</p></li><li>A Teleoperation Framework for Mobile Robots Based on Shared Control</li><li>A Novel Orientability Index and the Kinematic Design of the RemoT-ARM: A Haptic Master with Large and Dexterous Workspace</li><li>Enhancing the Transparency by Onomatopoeia for Passivity-Based Time-Delayed Teleoperation</li><li>RAVEN-S: Design and Simulation of a Robot for Teleoperated Microgravity Rodent Dissection under Time Delay</li></ul><ul><li>Closing the Force Loop to Enhance Transparency in Time-Delayed Teleoperation</li><li>Evaluation of an Exoskeleton-Based Bimanual Teleoperation Architecture with Independently Passivated Slave Devices</li><li>Hand-Worn Haptic Interface for Drone Teleoperation</li><li>Toward Human-Like Teleoperated Robot Motion: Performance and Perception of a Choreography-Inspired Method in Static and Dynamic Tasks for Rapid Pose Selection of Articulated Robots</li><li>Helping Robots Learn: A Human-Robot Master-Apprentice Model Using Demonstrations Via Virtual Reality Teleoperation</li><li>A Framework for Interactive Virtual Fixture Generation for Shared Teleoperation in Unstructured Environments</li><li>Whole-Body Bilateral Teleoperation of a Redundant Aerial Manipulator</li><li>Shared Autonomous Interface for Reducing Physical Effort in Robot Teleoperation Via Human Motion Mapping</li><li>DexPilot: Vision-Based Teleoperation of Dexterous Robotic Hand-Arm System</li><li>Distributed Winner-Take-All Teleoperation of a Multi-Robot System</li><li>Enhanced Teleoperation Using Autocomplete</li></ul><h2 id="Collision-Avoidance"><a href="#Collision-Avoidance" class="headerlink" title="Collision Avoidance"></a>Collision Avoidance</h2><ul><li>Collision-Free Navigation of Human-Centered Robots Via Markov Games</li><li>DenseCAvoid: Real-Time Navigation in Dense Crowds Using Anticipatory Behaviors</li><li>DEEPCRASHTEST: Turning Dashcam Videos into Virtual Crash Tests for Automated Driving Systems</li><li>Observer-Extended Direct Method for Collision Monitoring in Robot Manipulators Using Proprioception and IMU Sensing</li><li>DCAD: Decentralized Collision Avoidance with Dynamics Constraints for Agile Quadrotor Swarms</li><li>Forward Kinematics Kernel for Improved Proxy Collision Checking</li><li>Local Obstacle-Skirting Path Planning for a Fast Bi-Steerable Rover Using B�ziers Curves</li><li>Collision Avoidance with Proximity Servoing for Redundant Serial Robot Manipulators</li><li>Predicting Obstacle Footprints from 2D Occupancy Maps by Learning from Physical Interactions</li><li>Path Planning in Dynamic Environments Using Generative RNNs and Monte Carlo Tree Search</li><li>Safety-Critical Rapid Aerial Exploration of Unknown Environments</li><li>Reactive Navigation under Non-Parametric Uncertainty through Hilbert Space Embedding of Probabilistic Velocity Obstacles</li><li>Contact-Based Bounding Volume Hierarchy for Assembly Tasks</li><li>Construction of Bounding Volume Hierarchies for Triangle Meshes with Mixed Face Sizes</li><li>Strategy for Automated Dense Parking: How to Navigate in Narrow Lanes</li><li>Multimodal Trajectory Predictions for Urban Environments Using Geometric Relationship between a Vehicle and Lanes</li><li>Online Optimal Motion Generation with Guaranteed Safety in Shared Workspace</li><li>Episodic Koopman Learning of Nonlinear Robot Dynamics with Applications to Fast Multirotor Landing</li></ul><h2 id="Micro-Nano-Robots"><a href="#Micro-Nano-Robots" class="headerlink" title="Micro/Nano Robots"></a>Micro/Nano Robots</h2><ul><li>Reconfigurable Magnetic Microswarm for Thrombolysis under Ultrasound Imaging</li><li>Improving Optical Micromanipulation with Force-Feedback Bilateral Coupling</li><li>Maneuver at Micro Scale: Steering by Actuation Frequency Control in Micro Bristle Robots</li><li>Scaling down an Insect-Size Microrobot, HAMR-VI into HAMR-Jr</li><li>Model Predictive Control with Obstacle Avoidance for Inertia Actuated AFM Probes Inside a Scanning Electron Microscope</li><li>Double-Modal Locomotion and Application of Soft Cruciform Thin-Film Microrobot</li><li>Robotic Control of a Magnetic Swarm for On-Demand Intracellular Measurement</li><li>Acoustofluidic Tweezers for the 3D Manipulation of Microparticles</li><li>Task Space Motion Control for AFM-Based Nanorobot Using Optimal and Ultralimit Archimedean Spiral Local Scan</li><li>Kinematic Model of a Magnetic-Microrobot Swarm in a Rotating Magnetic Dipole Field</li><li>Magnetic Milli-Robot Swarm Platform: A Safety Barrier Certificate Enabled, Low-Cost Test Bed</li><li>A Device for Rapid, Automated Trimming of Insect-Sized Flying Robots</li><li>Eye-In-Hand 3D Visual Servoing of Helical Swimmers Using Parallel Mobile Coils</li><li>A Mobile Paramagnetic Nanoparticle Swarm with Automatic Shape Deformation Control</li><li>Magnetic Miniature Swimmers with Multiple Flagella</li><li>Design and Control of a Large-Range Nil-Stiffness Electro-Magnetic Active Force Sensor</li><li>Modeling Electromagnetic Navigation Systems for Medical Applications Using Random Forests and Artificial Neural Networks</li><li>Automated Tracking System with Head and Tail Recognition for Time-Lapse Observation of Free-Moving C. Elegans</li></ul><h2 id="AI-Based-Methods"><a href="#AI-Based-Methods" class="headerlink" title="AI-Based Methods"></a>AI-Based Methods</h2><ul><li>Towards Adaptive Benthic Habitat Mapping</li><li>Multispectral Domain Invariant Image for Retrieval-Based Place Recognition</li><li>Probabilistic Effect Prediction through Semantic Augmentation and Physical Simulation</li><li>Anytime Integrated Task and Motion Policies for Stochastic Environments</li><li>Context-Aware Human Activity Recognition</li><li>Interactive Natural Language-Based Person Search</li></ul><h2 id="Climbing-Robots"><a href="#Climbing-Robots" class="headerlink" title="Climbing Robots"></a>Climbing Robots</h2><ul><li>CCRobot-III: A Split-Type Wire-Driven Cable Climbing Robot for Cable-Stayed Bridge Inspection</li><li>Omnidirectional Tractable Three Module Robot</li><li>A Practical Climbing Robot for Steel Bridge Inspection</li><li>Development of a Wheeled Wall-Climbing Robot with a Shape-Adaptive Magnetic Adhesion Mechanism</li><li>Towards More Possibilities: Motion Planning and Control for Hybrid Locomotion of Wheeled-Legged Robots</li><li>Navigation for Legged Mobility: Dynamic Climbing (I)</li></ul><h2 id="Failure-Detection-and-Recovery"><a href="#Failure-Detection-and-Recovery" class="headerlink" title="Failure Detection and Recovery"></a>Failure Detection and Recovery</h2><ul><li>Algebraic Fault Detection and Identification for Rigid Robots</li><li>Fault Tolerance Analysis of a Hexarotor with Reconfigurable Tilted Rotors</li><li>Detecting Execution Anomalies As an Oracle for Autonomy Software Robustness</li><li>When Your Robot Breaks: Active Learning During Plant Failure</li><li>An Integrated Dynamic Fall Protection and Recovery System for Two-Wheeled Humanoids</li><li>Reliability Validation of Learning Enabled Vehicle Tracking</li></ul><h2 id="Learning-to-Predict"><a href="#Learning-to-Predict" class="headerlink" title="Learning to Predict"></a>Learning to Predict</h2><ul><li>Spatiotemporal Representation Learning with GAN Trained LSTM-LSTM Networks</li><li>Belief Regulated Dual Propagation Nets for Learning Action Effects on Groups of Articulated Objects</li><li>Deep Kinematic Models for Kinematically Feasible Vehicle Trajectory Predictions</li><li>Human Driver Behavior Prediction Based on UrbanFlow</li><li>Environment Prediction from Sparse Samples for Robotic Information Gathering</li><li>Predicting Pushing Action Effects on Spatial Object Relations by Learning Internal Prediction Models</li><li>Under the Radar: Learning to Predict Robust Keypoints for Odometry Estimation and Metric Localisation in Radar</li><li>SpAGNN: Spatially-Aware Graph Neural Networks for Relational Behavior Forecasting from Sensor Data</li><li>Any Motion Detector: Learning Class-Agnostic Scene Dynamics from a Sequence of LiDAR Point Clouds</li><li>Real Time Trajectory Prediction Using Deep Conditional Generative Models</li><li>Ambiguity in Sequential Data: Predicting Uncertain Futures with Recurrent Models</li><li>Where and When: Event-Based Spatiotemporal Trajectory Prediction from the iCub’s Point-Of-View</li></ul><h2 id="Learning-for-Motion-Planning"><a href="#Learning-for-Motion-Planning" class="headerlink" title="Learning for Motion Planning"></a>Learning for Motion Planning</h2><ul><li>Learning of Key Pose Evaluation for Efficient Multi-Contact Motion Planner</li><li>Differentiable Gaussian Process Motion Planning</li><li>Learn and Link: Learning Critical Regions for Efficient Planning</li><li>What the Constant Velocity Model Can Teach Us about Pedestrian Motion Prediction</li><li>Path Planning with Local Motion Estimations</li><li>Scene Compliant Trajectory Forecast with Agent-Centric Spatio-Temporal Grids</li><li>A Data-Driven Planning Framework for Robotic Texture Painting on 3D Surfaces</li><li>Learned Critical Probabilistic Roadmaps for Robotic Motion Planning</li><li>Learning Heuristic A*: Efficient Graph Search Using Neural Network</li><li>3D-CNN Based Heuristic Guided Task-Space Planner for Faster Motion Planning</li><li>Learned Sampling Distributions for Efficient Planning in Hybrid Geometric and Object-Level Representations</li><li>Deep Visual Heuristics: Learning Feasibility of Mixed-Integer Programs for Manipulation Planning</li><li></li></ul><h2 id="Motion-Control-of-Manipulators"><a href="#Motion-Control-of-Manipulators" class="headerlink" title="Motion Control of Manipulators"></a>Motion Control of Manipulators</h2><ul><li>Segmentation and Averaging of sEMG Muscle Activations Prior to Synergy Extraction</li><li>Energy-Optimal Cooperative Manipulation Via Provable Internal-Force Regulation</li><li>Robot Telekinesis: Application of a Unimanual and Bimanual Object Manipulation Technique to Robot Control</li><li>A Set-Theoretic Approach to Multi-Task Execution and Prioritization</li><li>Task Space Control of Articulated Robot Near Kinematic Singularity: Forward Dynamics Approach</li><li>Variable Impedance Control in Cartesian Latent Space While Avoiding Obstacles in Null Space</li><li></li></ul><h2 id="Computer-Vision-for-Medical-Robots"><a href="#Computer-Vision-for-Medical-Robots" class="headerlink" title="Computer Vision for Medical Robots"></a>Computer Vision for Medical Robots</h2><ul><li>Attention-Guided Lightweight Network for Real-Time Segmentation of Robotic Surgical Instruments</li><li>Automated Robotic Breast Ultrasound Acquisition Using Ultrasound Feedback</li><li>Robust and Accurate 3D Curve to Surface Registration with Tangent and Normal Vectors</li><li>Single Shot Pose Estimation of Surgical Robot Instruments’ Shafts from Monocular Endoscopic Images</li><li>End-To-End Real-Time Catheter Segmentation with Optical Flow-Guided Warping During Endovascular Intervention</li><li>Pathological Airway Segmentation with Cascaded Neural Networks for Bronchoscopic Navigation</li></ul><h2 id="Grippers-and-Other-End-Effectors"><a href="#Grippers-and-Other-End-Effectors" class="headerlink" title="Grippers and Other End-Effectors"></a>Grippers and Other End-Effectors</h2><ul><li>A Novel Underactuated End-Effector for Planar Sequential Grasping of Multiple Objects</li><li>Design and Analysis of a Synergy-Inspired Three-Fingered Hand</li><li>Multiplexed Manipulation: Versatile Multimodal Grasping Via a Hybrid Soft Gripper</li><li>Modeling, Optimization, and Experimentation of the ParaGripper for In-Hand Manipulation without Parasitic Rotation</li><li>Underactuated Gecko Adhesive Gripper for Simple and Versatile Grasp</li><li>Examining the Frictional Behavior of Primitive Contact Geometries for Use As Robotic Finger Pads</li><li>Design of 3D-Printed Assembly Mechanisms Based on Special Wooden Joinery Techniques and Its Application to a Robotic Hand</li><li>Parallel Gripper with Displacement-Magnification Mechanism and Extendable Finger Mechanism</li><li>Sheet-Based Gripper Featuring Passive Pull-In Functionality for Bin Picking and for Picking up Thin Flexible Objects</li><li>An Origami-Inspired Variable Friction Surface for Increasing the Dexterity of Robotic Grippers</li><li>A Shape Memory Polymer Adhesive Gripper for Pick-And-Place Applications</li><li>A High-Payload Proprioceptive Hybrid Robotic Gripper with Soft Origamic Actuators</li></ul><h2 id="Formal-Methods-in-Robotics-and-Automation"><a href="#Formal-Methods-in-Robotics-and-Automation" class="headerlink" title="Formal Methods in Robotics and Automation"></a>Formal Methods in Robotics and Automation</h2><ul><li>Reality As a Simulation of Reality: Robot Illusions, Fundamental Limits, and a Physical Demonstration</li><li>Finding Missing Skills for High-Level Behaviors</li><li>Near-Optimal Reactive Synthesis Incorporating RuntimeInformation</li><li>Control Synthesis from Linear Temporal Logic Specifications Using Model-Free Reinforcement Learning</li><li>A Framework for Formal Verification of Behavior Trees with Linear Temporal Logic</li><li>Safety Assessment of Collaborative Robotics through Automated Formal Verification (I)</li></ul><h2 id="Parallel-Robots"><a href="#Parallel-Robots" class="headerlink" title="Parallel Robots"></a>Parallel Robots</h2><ul><li>R-Min: A Fast Collaborative Underactuated Parallel Robot for Pick-And-Place Operations</li><li>High-Flexibility Locomotion and Whole-Torso Control for a Wheel-Legged Robot on Challenging Terrain</li><li>Prince’s Tears, a Large Cable-Driven Parallel Robot for an Artistic Exhibition</li><li>Singularity Analysis and Reconfiguration Mode of the 3-CRS Parallel Manipulator</li><li>Trajectory Optimization for a Class of Robots Belonging to Constrained Collaborative Mobile Agents (CCMA) Family</li><li>Multiaxis Reaction System (MARS) for Vibration Control of Planar Cable-Driven Parallel Robots (I)</li></ul><h2 id="Mechanism-and-Verification"><a href="#Mechanism-and-Verification" class="headerlink" title="Mechanism and Verification"></a>Mechanism and Verification</h2><ul><li>Reconfiguration Solution of a Variable Topology Truss: Design and Experiment</li><li>Development of Body Rotational Wheeled Robot and Its Verification of Effectiveness</li><li>Error Bounds for PD-Controlled Mechanical Systems under Bounded Disturbances Using Interval Arithmetic</li><li><p>Hardware-In-The-Loop Iterative Optimal Feedback Control without Model-Based Future Prediction (I)</p></li><li><p>Analysis and Synthesis of Underactuated Compliant Mechanisms Based on Transmission Properties of Motion and Force (I)</p></li></ul><ul><li>Radar Sensors in Collaborative Robotics: Fast Simulation and Experimental Validation</li></ul><h2 id="Model-Learning-for-Control"><a href="#Model-Learning-for-Control" class="headerlink" title="Model Learning for Control"></a>Model Learning for Control</h2><ul><li>Sparse, Online, Locally Adaptive Regression Using Gaussian Processes for Bayesian Robot Model Learning and Control</li><li>DISCO: Double Likelihood-Free Inference Stochastic Control</li><li>Discovering Interpretable Dynamics by Sparsity Promotion on Energy and the Lagrangian</li><li>Online Simultaneous Semi-Parametric Dynamics Model Learning</li><li>Sufficiently Accurate Model Learning</li><li>Active Learning of Dynamics for Data-Driven Control Using Koopman Operators (I)</li></ul><h2 id="Mobile-Manipulation"><a href="#Mobile-Manipulation" class="headerlink" title="Mobile Manipulation"></a>Mobile Manipulation</h2><ul><li>Towards Plan Transformations for Real-World Mobile Fetch and Place</li><li>Planning an Efficient and Robust Base Sequence for a Mobile Manipulator Performing Multiple Pick-And-Place Tasks</li><li>Towards Mobile Multi-Task Manipulation in a Confined and Integrated Environment with Irregular Objects</li><li>Linear Time-Varying MPC for Nonprehensile Object Manipulation with a Nonholonomic Mobile Robot</li><li>A Mobile Manipulation System for One-Shot Teaching of Complex Tasks in Homes</li></ul><h2 id="Computer-Vision-for-Transportation"><a href="#Computer-Vision-for-Transportation" class="headerlink" title="Computer Vision for Transportation"></a>Computer Vision for Transportation</h2><ul><li>2D to 3D Line-Based Registration with Unknown Associations Via Mixed-Integer Programming</li><li>An Efficient Solution to the Relative Pose Estimation with a Common Direction</li><li>Task-Aware Novelty Detection for Visual-Based Deep Learning in Autonomous Systems</li><li>DirectShape: Direct Photometric Alignment of Shape Priors for Visual Vehicle Pose and Shape Estimation</li><li>RoadText-1K: Text Detection &amp; Recognition Dataset for Driving Videos</li><li>End-To-End Learning for Inter-Vehicle Distance and Relative Velocity Estimation in ADAS with a Monocular Camera</li></ul><h2 id="Haptics-and-Haptic-Interfaces"><a href="#Haptics-and-Haptic-Interfaces" class="headerlink" title="Haptics and Haptic Interfaces"></a>Haptics and Haptic Interfaces</h2><ul><li>Learning an Action-Conditional Model for Haptic Texture Generation</li><li>Just Noticeable Differences for Joint Torque Feedback During Static Poses</li><li>Design of a Parallel Haptic Device with Gravity Compensation by Using Its System Weight</li><li>Enhanced Haptic Sensations Using a Novel Electrostatic Vibration Actuator with Frequency Beating Phenomenon</li><li>Electromagnetic Haptic Feedback System for Use with a Graphical Display Using Flat Coils and Sensor Array</li><li>An Instrumented Master Tool Manipulator (MTM) for Force Feedback in the Da Vinci Surgical Robot</li></ul><h2 id="Visual-Tracking"><a href="#Visual-Tracking" class="headerlink" title="Visual Tracking"></a>Visual Tracking</h2><ul><li>Multi-Person Pose Tracking Using Sequential Monte Carlo with Probabilistic Neural Pose Predictor</li><li>4D Generic Video Object Proposals</li><li>Simultaneous Tracking and Elasticity Parameter Estimation of Deformable Objects</li><li>AVOT: Audio-Visual Object Tracking of Multiple Objects for Robotics</li><li>Efficient Pig Counting in Crowds with Keypoints Tracking and Spatial-Aware Temporal Response Filtering</li><li>6-PACK: Category-Level 6D Pose Tracker with Anchor-Based Keypoints</li><li>Multimodal Tracking Framework for Visual Odometry in Challenging Illumination Conditions</li><li>Real-Time Multi-Diver Tracking and Re-Identification for Underwater Human-Robot Collaboration</li><li>Autonomous Tissue Scanning under Free-Form Motion for Intraoperative Tissue Characterisation</li><li>High Speed Three Dimensional Tracking of Swimming Cell by Synchronous Modulation between TeCE Camera and TAG Lens</li><li>Track to Reconstruct and Reconstruct to Track</li><li>PointTrackNet: An End-To-End Network for 3-D Object Detection and Tracking from Point Clouds</li></ul><h2 id="Planning-Scheduling-and-Coordination"><a href="#Planning-Scheduling-and-Coordination" class="headerlink" title="Planning, Scheduling and Coordination"></a>Planning, Scheduling and Coordination</h2><ul><li>An Online Scheduling Algorithm for Human-Robot Collaborative Kitting</li><li>A Model-Free Approach to Meta-Level Control of Anytime Algorithms</li><li>Simultaneous Task Allocation and Motion Scheduling for Complex Tasks Executed by Multiple Robots</li><li>Efficient Planning for High-Speed MAV Flight in Unknown Environments Using Online Sparse Topological Graphs</li><li>Evaluating Adaptation Performance of Hierarchical Deep Reinforcement Learning</li><li>An Approximation Algorithm for a Task Allocation, Sequencing and Scheduling Problem Involving a Human-Robot Team</li></ul><h2 id="Reactive-and-Sensor-Based-Planning"><a href="#Reactive-and-Sensor-Based-Planning" class="headerlink" title="Reactive and Sensor-Based Planning"></a>Reactive and Sensor-Based Planning</h2><ul><li>Iterator-Based Temporal Logic Task Planning</li><li>Reactive Temporal Logic Planning for Multiple Robots in Unknown Environments</li><li>Higher Order Function Networks for View Planning and Multi-View Reconstruction</li><li>Residual Reactive Navigation: Combining Classical and Learned Navigation Strategies for Deployment in Unknown Environments</li><li>Online Grasp Plan Refinement for Reducing Defects During Robotic Layup of Composite Prepreg Sheets</li><li>Object-Centric Task and Motion Planning in Dynamic Environments</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> ICRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICRA2021文章目录</title>
      <link href="/2022/01/03/icra2021-paper-list/"/>
      <url>/2022/01/03/icra2021-paper-list/</url>
      
        <content type="html"><![CDATA[<h1 id="ICRA2021-paper-list"><a href="#ICRA2021-paper-list" class="headerlink" title="ICRA2021-paper-list"></a>ICRA2021-paper-list</h1><p>The 2021 International Conference on Robotics and Automation (ICRA 2021) has taken place from May 30 to June 5, 2021 at the brand new magnificent Xi’an International Convention and Exhibition Center in Xi’an China.</p><p>The ICRA 2021 conference promises to be a great event with excellent technical and social programs. Paper manuscripts reporting original research results on all aspects of robotics and automation are welcome. Proposals for tutorials and workshops, and organized sessions, on new topics or innovative applications are invited. Video clips iIIustrating new and exciting results are invited for video sessions. Exhibits from both industries and research laboratories are welcome. Please visit the official conference website for detailed instructions for paper, proposal, video, and exhibit submissions and for competition information. The IEEE ICRA 2021 will be held in a hybrid format, including both on-site and cloud meetings.</p><p>This list is edited by <a href="https://github.com/PaoPaoRobot">PaopaoRobot, 泡泡机器人</a> , the Chinese academic nonprofit organization. Welcome to follow our github and our WeChat Public Platform Account ( <a href="https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&amp;mid=100000102&amp;idx=1&amp;sn=0a8a831a4f2c18443dbf436ef5d5ff8c&amp;chksm=6c10bf625b6736748c9612879e166e510f1fe301b72ed5c5d7ecdd0f40726c5d757e975f37af&amp;mpshare=1&amp;scene=1&amp;srcid=0530KxSLjUE9I38yLgfO2nVm&amp;pass_ticket=0aB5tcjeTfmcl9u0eSVzN4Ag4tkpM2RjRFH8DG9vylE%3D#rd">paopaorobot_slam</a> ). Of course, you could contact with <a href="https://github.com/yvonshong">@Yvon Shong</a>.</p><div class="table-container"><table><thead><tr><th>title</th><th>index</th></tr></thead><tbody><tr><td><strong>Session</strong> TuHT24 : Active Perception in Robotics</td><td></td></tr><tr><td>Active Bayesian Multi-Class Mapping from Range and Semantic Segmentation Observations</td><td>1</td></tr><tr><td>Attention-Based Probabilistic Planning with Active Perception</td><td>8</td></tr><tr><td>Search-Based Planning for Active Sensing in Goal-Directed Coverage Tasks</td><td>15</td></tr><tr><td>Bearing-Only Active Sensing under Merged Measurements</td><td>22</td></tr><tr><td><strong>Session</strong> TuIT24 : Adaptive Robotic Systems</td><td></td></tr><tr><td>Robust Adaptive Synchronization of Interconnected Heterogeneous Quadrotors Transporting a Cable-Suspended Load</td><td>31</td></tr><tr><td>Adaptive Failure Search Using Critical States from Domain Experts</td><td>38</td></tr><tr><td>Policy Transfer Via Kinematic Domain Randomization and Adaptation</td><td>45</td></tr><tr><td>Uniform Complete Observability of Mass and Rotational Inertial Parameters in Adaptive Identification of Rigid-Body Plant Dynamics</td><td>52</td></tr><tr><td><strong>Session</strong> TuDT24 : Aerial Robotics</td><td></td></tr><tr><td>A Tethered Quadrotor UAV-Buoy System for Marine Locomotion</td><td>59</td></tr><tr><td>Power Line Inspection Tasks with Multi-Aerial Robot Systems Via Signal Temporal Logic  Specifications</td><td>66</td></tr><tr><td>Distributed Formation Estimation Via Pairwise Distance Measurements</td><td>74</td></tr><tr><td>Distributed Variable-Baseline Stereo SLAM from Two UAVs</td><td>82</td></tr><tr><td><strong>Session</strong> TuET24 : Aerial Robotics: Control I</td><td></td></tr><tr><td>Fast Sampling-Based Next-Best-View Exploration Algorithm for a MAV</td><td>89</td></tr><tr><td>Neuromorphic Control for Optic-Flow-Based Landing of MAVs Using the Loihi Processor</td><td>96</td></tr><tr><td>Event-Driven Vision and Control for UAVs on a Neuromorphic Chip</td><td>103</td></tr><tr><td>Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots</td><td>110</td></tr><tr><td><strong>Session</strong> TuDT23 : Aerial Robotics: Control II</td><td></td></tr><tr><td>Adaptive Stiffness Estimation Impedance Control for Achieving Sustained Contact in Aerial Manipulation</td><td>117</td></tr><tr><td>Model Predictive Control for Dynamic Quadrotor Bearing Formations</td><td>124</td></tr><tr><td>Direct Force and Pose NMPC with Multiple Interaction Modes for Aerial Push-And-Slide Operations</td><td>131</td></tr><tr><td>Motor and Perception Constrained NMPC for Torque-Controlled Generic Aerial Vehicles</td><td>138</td></tr><tr><td><strong>Session</strong> WeAT18 : Aerial Robotics: Control III</td><td></td></tr><tr><td>Conquering Textureless with RF-Referenced Monocular Vision for MAV State Estimation</td><td>146</td></tr><tr><td>Control of an Aerial Manipulator Using a Quadrotor with a Replaceable Robotic Arm</td><td>153</td></tr><tr><td>Self-Triggered Based Coordinate Control with Low Communication for Tethered Multi-UAV  Collaborative Transportation</td><td>160</td></tr><tr><td>Flying with Damaged Wings: The Effect on Flight Capacity and Bio-Inspired Coping Strategies of a  Flapping Wing Robot</td><td>168</td></tr><tr><td><strong>Session</strong> TuIT23 : Aerial Robotics: Design and Mechanism I</td><td></td></tr><tr><td>Collision-Free Vector Field Guidance and MPC for a Fixed-Wing UAV</td><td>176</td></tr><tr><td>Toward Impact-resilient Quadrotor Design, Collision Characterization and Recovery Control to  Sustain Flight after Collisions</td><td>183</td></tr><tr><td>H-ModQuad: Modular Multi-Rotors with 4, 5, and 6 Controllable DOF</td><td>190</td></tr><tr><td><strong>Session</strong> TuKT23 : Aerial Robotics: Design and Mechanism II</td><td></td></tr><tr><td>The Catenary Robot: Design and Control of a Cable Propelled by Two Quadrotors</td><td>197</td></tr><tr><td>Aerial Multi-Camera Robotic Jib Crane</td><td>203</td></tr><tr><td>Design, Sensing, and Control of a Novel UAV Platform for Aerial Drilling and Screwing</td><td>209</td></tr><tr><td>Freyja: A Full Multirotor System for Agile &amp; Precise Outdoor Flights</td><td>217</td></tr><tr><td><strong>Session</strong> TuFT24 : Aerial Robotics: Detection</td><td></td></tr><tr><td>Context-Dependent Anomaly Detection for Low Altitude Traffic Surveillance</td><td>224</td></tr><tr><td>GridNet: Image-Agnostic Conditional Anomaly Detection for Indoor Surveillance</td><td>231</td></tr><tr><td>Autonomous Flying into Buildings in a Firefighting Scenario</td><td>239</td></tr><tr><td>LoLa-SLAM: Low-latency LiDAR SLAM using Continuous Scan Slicing</td><td>246</td></tr><tr><td><strong>Session</strong> TuJT23 : Aerial Robotics: Learning and Adaptive Systems</td><td></td></tr><tr><td>Learning-Based Bias Correction for Time Difference of Arrival Ultra-Wideband Localization of  Resource-Constrained Mobile Robots</td><td>254</td></tr><tr><td>CVaR-Based Flight Energy Risk Assessment for Multirotor UAVs Using a Deep Energy Model</td><td>262</td></tr><tr><td>Hypergame-Based Adaptive Behavior Path Planning for Combined Exploration and Visual Search</td><td>269</td></tr><tr><td>Morphologically Adapatative Quad-Rotor Towards Acquiring High-Performance Flight: A  Comparative Study and Validation</td><td>276</td></tr><tr><td><strong>Session</strong> TuBT24 : Aerial Robotics: Mechanics and Control I</td><td></td></tr><tr><td>Fixed-root Aerial Manipulator: Design, Modeling, and Control of Multilink Aerial Arm to Adhere Foot  Module to Ceilings using Rotor Thrust</td><td>283</td></tr><tr><td>Aerial Manipulator Pushing a Movable Structure Using a DOB-Based Robust Controller</td><td>290</td></tr><tr><td>Data-Driven MPC for Quadrotors</td><td>298</td></tr><tr><td>Singularity-Free Aerial Deformation by Two-Dimensional Multilinked Aerial Robot with 1-DoF  Vectorable Propeller</td><td>306</td></tr><tr><td><strong>Session</strong> TuCT24 : Aerial Robotics: Mechanics and Control II</td><td></td></tr><tr><td>Underwater Stability of a Morphable Aerial-Aquatic Quadrotor with Variable Thruster Angles</td><td>314</td></tr><tr><td>Development of Flapping Robot with Self-Takeoff from The Ground Capability</td><td>321</td></tr><tr><td>Fast-Tracker: A Robust Aerial System for Tracking Agile Target in Cluttered Environments</td><td>328</td></tr><tr><td>Teach-Repeat-Replan: A Complete and Robust System for Aggressive Flight in Complex  Environments</td><td>335</td></tr><tr><td><strong>Session</strong> TuGT24 : Aerial Robotics: Optimization</td><td></td></tr><tr><td>Practical and Accurate Generation of Energy-Optimal Trajectories for a Planar Quadrotor</td><td>355</td></tr><tr><td>Optimization-Based Trajectory Planning for Tethered Aerial Robots</td><td>362</td></tr><tr><td>A Novel Robust Hexarotor Capable of Static Hovering in Presence of Propeller Failure</td><td>369</td></tr><tr><td>Optimal Tuning of the Lateral-Dynamics Parameters for Aerial Vehicles with Bounded Lateral  Force</td><td>377</td></tr><tr><td><strong>Session</strong> TuAT24 : Aerial Robotics: Planning and Control</td><td></td></tr><tr><td>Estimation and Adaption of Indoor Ego Airflow Disturbance with Application to Quadrotor Trajectory  Planning</td><td>384</td></tr><tr><td>Real-Time Active Detection of Targets and Path Planning Using UAVs</td><td>391</td></tr><tr><td>EVA-Planner: Environmental Adaptive Quadrotor Planning</td><td>398</td></tr><tr><td>EGO-Planner: An ESDF-Free Gradient-Based Local Planner for Quadrotors</td><td>405</td></tr><tr><td><strong>Session</strong> TuHT23 : Aerial Robotics: Sensing and Control I</td><td></td></tr><tr><td>MorphEyes: Variable Baseline Stereo for Quadrotor Navigation</td><td>413</td></tr><tr><td>A Drive-Through Recharging Strategy for a Quadrotor</td><td>420</td></tr><tr><td>Continuous-time State &amp; Dynamics Estimation Using a Pseudo-Spectral Parameterization</td><td>426</td></tr><tr><td>Use of a MEMS Differential Pressure Sensor to Detect Ground, Ceiling, and Walls on Small  Quadrotors</td><td>433</td></tr><tr><td><strong>Session</strong> TuIT21 : Aerial Robotics: Sensing and Control II</td><td></td></tr><tr><td>UAV Localization Using Autoencoded Satellite Images</td><td>441</td></tr><tr><td>Cooperative Transportation of Cable Suspended Payloads with MAVs Using Monocular Vision and  Inertial Sensing</td><td>449</td></tr><tr><td>Tracking and Relative Localization of Drone Swarms with a Vision-Based Headset</td><td>458</td></tr><tr><td>SelfDeco: Self-Supervised Monocular Depth Completion in Challenging Indoor Environments</td><td>467</td></tr><tr><td><strong>Session</strong> TuHT21 : Aerial Robotics: Space Robotics and Automation</td><td></td></tr><tr><td>An Anytime Algorithm for Chance Constrained Stochastic Shortest Path Problems and Its  Application to Aircraft Routing</td><td>475</td></tr><tr><td>An Intention Guided Hierarchical Framework for Trajectory-Based Teleoperation of Mobile Robots</td><td>482</td></tr><tr><td>Distance Estimation Using Self-Induced Noise of an Aerial Vehicle</td><td>489</td></tr><tr><td><strong>Session</strong> WeBT18 : Aerial Robotics: Tracking</td><td></td></tr><tr><td>ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking</td><td>496</td></tr><tr><td>Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label</td><td>503</td></tr><tr><td>Siamese Anchor Proposal Network for High-Speed Aerial Tracking</td><td>510</td></tr><tr><td>Computationally Efficient Trajectory Planning for High Speed Obstacle Avoidance of a Quadrotor  with Active Sensing</td><td>517</td></tr><tr><td><strong>Session</strong> TuET22 : Aerial Systems: Mechanics and Control</td><td></td></tr><tr><td>Novel Omnidirectional Aerial Manipulator with Elastic Suspension: Dynamic Control and  Experimental Performance Assessment</td><td>525</td></tr><tr><td>Improving Dynamics of an Aerial Manipulator with Elastic Suspension Using Nonlinear Model  Predictive Control</td><td>533</td></tr><tr><td>Design of the High-Payload Flapping Wing Robot E-Flap</td><td>540</td></tr><tr><td>Fernández, Francisco Javier; Sanchez-Laulhe, Ernesto; Grau, Pedro; Perez Capote, Martin;</td><td></td></tr><tr><td>Acosta, Jose Angel; Ollero, Anibal Pneumatic-Mechanical Systems in UAVs: Autonomous Power Line Sensor Unit Deployment</td><td>548</td></tr><tr><td><strong>Session</strong> TuDT22 : Aerial Systems: Multi-Robots</td><td></td></tr><tr><td>A Multi-UAV System for Detection and Elimination of Multiple Targets</td><td>555</td></tr><tr><td>Optic Flow-Based Reactive Collision Prevention for MAV Using Fictitious Obstacle Hypothesis</td><td>562</td></tr><tr><td>Autonomous Aerial Swarming in GNSS-denied Environments with High Obstacle Density</td><td>570</td></tr><tr><td>Forceful Aerial Manipulation Based on an Aerial Robotic Chain: Hybrid Modeling and Control</td><td>577</td></tr><tr><td><strong>Session</strong> TuET23 : Aerial Systems: Perception and Autonomy</td><td></td></tr><tr><td>Combined System Identification and State Estimation for a Quadrotor UAV</td><td>585</td></tr><tr><td>Geometry-Aware Compensation Scheme for Morphing Drones</td><td>592</td></tr><tr><td>Autonomous Quadrotor Flight despite Rotor Failure with Onboard Vision Sensors: Frames vs.  Events</td><td>599</td></tr><tr><td>SplatPlanner: Efficient Autonomous Exploration Via Permutohedral Frontier Filtering</td><td>608</td></tr><tr><td><strong>Session</strong> TuAT22 : Applications of Micro and Nano Robotics I</td><td></td></tr><tr><td>Parallel Actuation of Nanorod Swarm and Nanoparticle Swarm to Different Targets</td><td>616</td></tr><tr><td>Robotic Micromanipulation for Active Pin Alignment in Electronic Soldering Industry</td><td>623</td></tr><tr><td>In-Situ Bonding of Multilayer Microfluidic Devices Assisted by a Fully-Automated Aligning System</td><td>629</td></tr><tr><td>Robotic Handling of Micro-Objects Using Stochastic Optically-Actuated End-Effector</td><td>635</td></tr><tr><td><strong>Session</strong> TuBT22 : Applications of Micro and Nano Robotics II</td><td></td></tr><tr><td>Design of Soft Sensor for Feedback Control of Bio-Actuator Powered by Skeletal Muscle</td><td>643</td></tr><tr><td>Molecular Transport of a Magnetic Nanoparticle Swarm towards Thrombolytic Therapy</td><td>649</td></tr><tr><td>Efficient Single Cell Mechanical Measurement by Integrating a Cell Arraying Microfluidic Device  with Magnetic Tweezer</td><td>657</td></tr><tr><td>A Portable Acoustofluidic Device for Multifunctional Cell Manipulation and Reconstruction</td><td>664</td></tr><tr><td><strong>Session</strong> TuBT23 : Applications of Robotic Exploration</td><td></td></tr><tr><td>Design and Soft-Landing Control of a Six-Legged Mobile Repetitive Lander for Lunar Exploration</td><td>670</td></tr><tr><td>LEAF: Latent Exploration Along the Frontier</td><td>677</td></tr><tr><td>LAFFNet: A Lightweight Adaptive Feature Fusion Network for Underwater Image Enhancement</td><td>685</td></tr><tr><td>Ultrasound Doppler Imaging and Navigation of Collective Magnetic Cell Microrobots in Blood</td><td>693</td></tr><tr><td><strong>Session</strong> TuFT23 : Automation and Industrial Robotics</td><td></td></tr><tr><td>Automated Generation of Robot Trajectories for Assembly Processes Requiring Only Sparse  Manual Input</td><td>700</td></tr><tr><td>Benchmarking Real-Time Capabilities of ROS 2 and OROCOS for Robotics Applications</td><td>708</td></tr><tr><td>The KIT Gripper: A Multi-Functional Gripper for Disassembly Tasks</td><td>715</td></tr><tr><td>In-Process Workpiece Geometry Estimation for Robotic Arc Welding Based on Supervised  Learning for Multi-Sensor Inputs</td><td>722</td></tr><tr><td><strong>Session</strong> TuAT0 : Automation Award Session</td><td></td></tr><tr><td>A General-Purpose Anomalous Scenario Synthesizer for Rotary Equipment</td><td>729</td></tr><tr><td><strong>Session</strong> WeAT17 : Automation I</td><td></td></tr><tr><td>Viko: An Adaptive Gecko Gripper with Vision-Based Tactile Sensor</td><td>736</td></tr><tr><td>POIS: Policy-Oriented Instance Segmentation for Ambidextrous Robot Picking</td><td>743</td></tr><tr><td>Learning-Based Predictive Path Following Control for Nonlinear Systems under Uncertain  Disturbances</td><td>750</td></tr><tr><td>Thrust Enhancement of Wave-Driven Unmanned Surface Vehicle by Using Asymmetric Foil</td><td>758</td></tr><tr><td><strong>Session</strong> WeBT17 : Automation II</td><td></td></tr><tr><td>Proactive Action Visual Residual Reinforcement Learning for Contact-Rich Tasks Using a Torque-Controlled Robot</td><td>765</td></tr><tr><td>ParametricNet: 6DoF Pose Estimation Network for Parametric Shapes in Stacked Scenarios</td><td>772</td></tr><tr><td>Optimal Online Dispatch for High-Capacity Shared Autonomous Mobility-On-Demand Systems</td><td>779</td></tr><tr><td>An Improved Magnetic Spot Navigation for Replacing the Barcode Navigation in Automated Guided  Vehicles</td><td>786</td></tr><tr><td><strong>Session</strong> TuJT22 : Automation: Machine Learning I</td><td></td></tr><tr><td>Model-Based Reinforcement Learning with Provable Safety Guarantees Via Control Barrier Functions</td><td>792</td></tr><tr><td>Continual Model-Based Reinforcement Learning with Hypernetworks</td><td>799</td></tr><tr><td>Reinforcement Learning Based Temporal Logic Control with Maximum Probabilistic Satisfaction</td><td>806</td></tr><tr><td>Solving Markov Decision Processes with Partial State Abstractions</td><td>813</td></tr><tr><td><strong>Session</strong> TuKT22 : Automation: Machine Learning II</td><td></td></tr><tr><td>Exploiting Object Similarity for Robotic Visual Recognition</td><td>820</td></tr><tr><td>Team Assignment for Heterogeneous Multi-Robot Sensor Coverage through Graph  Representation Learning</td><td>838</td></tr><tr><td>GPR-Based Model Reconstruction System for Underground Utilities Using GPRNet</td><td>845</td></tr><tr><td>Replay Overshooting: Learning Stochastic Latent Dynamics with the Extended Kalman Filter</td><td>852</td></tr><tr><td><strong>Session</strong> TuKT24 : Automation: Manufacturing</td><td></td></tr><tr><td>Optimizing Part Placement for Improving Accuracy of Robot-Based Additive Manufacturing</td><td>859</td></tr><tr><td>Automated Mosquito Salivary Gland Extractor for PfSPZ-Based Malaria Vaccine Production</td><td>866</td></tr><tr><td>Safe Tumbling of Heavy Objects Using a Two-Cable Crane</td><td>873</td></tr><tr><td><strong>Session</strong> TuJT24 : Automation: Performance Metrics</td><td></td></tr><tr><td>Beelines: Motion Prediction Metrics for Self-Driving Safety and Comfort</td><td>881</td></tr><tr><td>NeilFrom Manual Operation to Collaborative Robot Assembly: An Integrated Model of Productivity and  Ergonomic Performance</td><td>888</td></tr><tr><td>Performance Metrics Calculation for Assembly Systems with Exponential Reliability Machines</td><td>896</td></tr><tr><td>Learning Seed Placements and Automation Policies for Polyculture Farming with Companion  Plants</td><td>902</td></tr><tr><td>Mark; Chui, Jackson; Shao, Yuqiao; Huang, Huang; Kotani, Atsunobu; Sharma, Satvik;</td><td></td></tr><tr><td>Parikh, Rishi; Luo, Michael; Mukherjee, Sandeep; Carpin, Stefano; Viers, Joshua;</td><td></td></tr><tr><td>Vougioukas, Stavros; Goldberg, Ken</td><td></td></tr><tr><td><strong>Session</strong> TuIT22 : Automation: Sensors and Grasping</td><td></td></tr><tr><td>Detect, Reject, Correct: Crossmodal Compensation of Corrupted Sensors</td><td>909</td></tr><tr><td>Advanced Sensing Development to Support Robot Accuracy Assessment and Improvement</td><td>917</td></tr><tr><td>Robotic Grasping of Fully-Occluded Objects Using RF Perception</td><td>923</td></tr><tr><td>A Simulation-Based Grasp Planner for Enabling Robotic Grasping During Composite Sheet Layup</td><td>930</td></tr><tr><td><strong>Session</strong> TuCT23 : Autonomous Driving</td><td></td></tr><tr><td>IDE-Net: Interactive Driving Event and Pattern Extraction from Human Data</td><td>938</td></tr><tr><td>HD Map Update for Autonomous Driving With Crowdsourced Data</td><td>946</td></tr><tr><td>Distributed Dynamic Map Fusion Via Federated Learning for Intelligent Networked Vehicles</td><td>953</td></tr><tr><td>Ground-Aware Monocular 3D Object Detection for Autonomous Driving</td><td>960</td></tr><tr><td>Session TuCT22 : Autonomous ManipulationPrecise Multi-Modal In-Hand Pose Estimation Using Low-Precision Sensors for Robotic Assembly</td><td>968</td></tr><tr><td>Assembly Sequences Based on Multiple Criteria Against Products with Deformable Parts</td><td>975</td></tr><tr><td>A Versatile End-Effector for Pick-And-Release of Fabric Parts</td><td>982</td></tr><tr><td>A Soft Robotic Hand Based on Bellows Actuators for Dishwashing Automation</td><td>990</td></tr><tr><td><strong>Session</strong> TuDT21 : Autonomous Navigation I</td><td></td></tr><tr><td>Shared Autonomy for Teleoperated Driving: A Real-Time Interactive Path Planning Approach</td><td>999</td></tr><tr><td>Comfortable and Safe Decelerations for a Self-Driving Transit Bus</td><td>1005</td></tr><tr><td>A Unified Approach for Autonomous Volumetric Exploration of Large Scale Environments under  Severe Odometry Drift</td><td>1012</td></tr><tr><td>Urban Driving Games with Lexicographic Preferences and Socially Efficient Nash Equilibria</td><td>1020</td></tr><tr><td><strong>Session</strong> TuGT22 : Autonomous Navigation II</td><td></td></tr><tr><td>Amortized Q-Learning with Model-Based Action Proposals for Autonomous Driving on Highways</td><td>1028</td></tr><tr><td>Decision Making for Autonomous Driving Via Augmented Adversarial Inverse Reinforcement  Learning</td><td>1036</td></tr><tr><td>Interpretable Goal-based Prediction and Planning for Autonomous Driving</td><td>1043</td></tr><tr><td>Encoding Human Driving Styles in Motion Planning for Autonomous Vehicles</td><td>1050</td></tr><tr><td><strong>Session</strong> TuFT22 : Autonomous Navigation III</td><td></td></tr><tr><td>Mesh Manifold Based Riemannian Motion Planning for Omnidirectional Micro Aerial Vehicles</td><td>1057</td></tr><tr><td>What Data Do We Need for Training an AV Motion Planner?</td><td>1066</td></tr><tr><td>Learn to Path: Using Neural Networks to Predict Dubins Path Characteristics for Aerial Vehicles in  Wind</td><td>1073</td></tr><tr><td>Where to Go Next: Learning a Subgoal Recommendation Policy for Navigation among Pedestrians</td><td>1080</td></tr><tr><td><strong>Session</strong> TuJT21 : Autonomous Vehicle Navigation I</td><td></td></tr><tr><td>Deep Reinforcement Learning for Mapless Navigation of a Hybrid Aerial Underwater Vehicle with  Medium Transition</td><td>1088</td></tr><tr><td>NF-iSAM: Incremental Smoothing and Mapping via Normalizing Flows</td><td>1095</td></tr><tr><td>UPSLAM: Union of Panoramas SLAM</td><td>1103</td></tr><tr><td>RELLIS-3D Dataset: Data, Benchmarks and Analysis</td><td>1110</td></tr><tr><td><strong>Session</strong> TuKT21 : Autonomous Vehicle Navigation II</td><td></td></tr><tr><td>Fast Path Computation Using Lattices in the Sensor-Space for Forest Navigation</td><td>1117</td></tr><tr><td>Learning Barrier Functions with Memory for Robust Safe Navigation</td><td>1124</td></tr><tr><td>Hierarchical Object Map Estimation for Efficient and Robust Navigation</td><td>1132</td></tr><tr><td>Robot Navigation in Constrained Pedestrian Environments Using Reinforcement Learning</td><td>1140</td></tr><tr><td><strong>Session</strong> TuAT4 : Best Paper Award Session</td><td></td></tr><tr><td>An Artin Braid Group Representation of Knitting Machine State with Applications to Validation and  Optimization of Fabrication Plans</td><td>1147</td></tr><tr><td><strong>Session</strong> TuDT4 : Best Student Paper Award Session</td><td></td></tr><tr><td>Unsupervised Learning of Lidar Features for Use in a Probabilistic Trajectory Estimator</td><td>1154</td></tr><tr><td><strong>Session</strong> TuAT21 : Biologically-Inspired Robots</td><td></td></tr><tr><td>Multiphysics Simulation of Magnetically Actuated Robotic Origami Worms</td><td>1162</td></tr><tr><td>Spherical Magnetic Joint for Inverted Locomotion of Multi-Legged Robot</td><td>1170</td></tr><tr><td>An Open-Source Mechanical Design of ALARIS Hand: A 6-DOF Anthropomorphic Robotic Hand</td><td>1177</td></tr><tr><td>Biomimetic Operational Space Control for Musculoskeletal Humanoid Optimizing across Muscle  Activation and Joint Nullspace</td><td>1184</td></tr><tr><td><strong>Session</strong> TuBT21 : Biomedical Robotics I</td><td></td></tr><tr><td>Orientation Control of an Electromagnetically Actuated Soft-Tethered Colonoscope Based on 2OR  Pseudo-Rigid-Body Model</td><td>1191</td></tr><tr><td>An Integrated High-Dexterity Cooperative Robotic Assistant for Intraocular Micromanipulation</td><td>1198</td></tr><tr><td>A Sigmoid-Colon-Straightening Soft Actuator With Peristaltic Motion for Colonoscopy Insertion  Assistance: Easycolon</td><td>1205</td></tr><tr><td>A Miniature Manipulator with Variable Stiffness towards Minimally Invasive Transluminal  Endoscopic Surgery</td><td>1213</td></tr><tr><td><strong>Session</strong> WeBT15 : Biomedical Robotics II</td><td></td></tr><tr><td>A Magnetic Continuum Robot with Multi-Mode Control Using Opposite-Magnetized Magnets</td><td>1221</td></tr><tr><td>Magnetically-Connected Modular Reconfigurable Mini-Robotic System with Bilateral Isokinematic  Mapping and Fast On-Site Assembly towards Minimally Invasive Procedures</td><td>1229</td></tr><tr><td>Reinforcement Learning Control of a Novel Magnetic Actuated Flexible-Joint Robotic Camera  System for Single Incision Laparoscopic Surgery</td><td>1236</td></tr><tr><td>Muscular Stimulation Based Biological Actuator from Locust’s Hindleg</td><td>1242</td></tr><tr><td><strong>Session</strong> WeCT6 : Biomedical Robotics III</td><td></td></tr><tr><td>Three-Dimensional Positioning of the Micropipette for Intracytoplasmic Sperm Injection</td><td>1249</td></tr><tr><td>Robotic Cardinal Vein Microinjection of Zebrafish Larvae Based on 3D Positioning</td><td>1256</td></tr><tr><td>Modeling and Simulation of Running Expansion with Trunk and Pelvic Rotation Assist Suit</td><td>1263</td></tr><tr><td>A Bipolar Myoelectric Sensor-Enabled Human-Machine Interface Based on Spinal Module  Activations</td><td>1269</td></tr><tr><td><strong>Session</strong> TuHT0 : Cognitive Robotics Award Session</td><td></td></tr><tr><td>Learning Task Space Actions for Bipedal Locomotion</td><td>1276</td></tr><tr><td>Learning Sampling Distributions Using Local 3D Workspace Decompositions for Motion Planning  in High Dimensions</td><td>1283</td></tr><tr><td>Auto-Tuned Sim-To-Real Transfer</td><td>1290</td></tr><tr><td><strong>Session</strong> TuET21 : Computer Vision for Automation</td><td></td></tr><tr><td>A Metric Space Perspective on Self-Supervised Policy Adaptation</td><td>1297</td></tr><tr><td>Efficient Recovery of Multi-Camera Motion from Two Affine Correspondences</td><td>1305</td></tr><tr><td>Dynamic-Aware Autonomous Exploration in Populated Environments</td><td>1312</td></tr><tr><td>Goal-Conditioned End-To-End Visuomotor Control for Versatile Skill Primitives</td><td>1319</td></tr><tr><td><strong>Session</strong> TuFT21 : Computer Vision in Medical Robotics</td><td></td></tr><tr><td>Towards Standardized Acquisition with a Dual-Probe Ultrasound Robot for Fetal Imaging</td><td>1326</td></tr><tr><td>Matthew, Jackeline; Noh, Yohan; Eltiraifi, Olla; Singh, Anisha; Singh, Davinder; Rhode,</td><td></td></tr><tr><td>Kawal</td><td></td></tr><tr><td>A Kinematic Bottleneck Approach for Pose Regression of Flexible Surgical Instruments Directly  from Images</td><td>1333</td></tr><tr><td>Robotic instrument segmentation with image-to-image translation</td><td>1341</td></tr><tr><td>Surgical Gesture Recognition Based on Bidirectional Multi-Layer Independently RNN with  Explainable Spatial Feature Extraction</td><td>1350</td></tr><tr><td><strong>Session</strong> TuGT21 : Contact and Collision Control</td><td></td></tr><tr><td>Safe Impacts with Soft Contacts Based on Learned Deformations</td><td>1357</td></tr><tr><td>A State-Dependent Damping Method to Reduce Collision Force and Its Variability</td><td>1364</td></tr><tr><td>Contact Forces Preintegration for Estimation in Legged Robotics Using Factor Graphs</td><td>1372</td></tr><tr><td>Overload Clutch Design for Collision Tolerant High–Speed Industrial Robots</td><td>1379</td></tr><tr><td><strong>Session</strong> TuHT19 : Continuum Robotics I</td><td></td></tr><tr><td>Learning-Based Inverse Kinematics from Shape As Input for Concentric Tube Continuum Robots</td><td>1387</td></tr><tr><td>Effect of External and Internal Loads on Tension Loss of Tendon-Driven Continuum Manipulators</td><td>1394</td></tr><tr><td>Using Euler Curves to Model Continuum Robots</td><td>1402</td></tr><tr><td>Optimal Design of Continuum Robots with Reachability Constraints</td><td>1409</td></tr><tr><td><strong>Session</strong> TuIT19 : Continuum Robotics II</td><td></td></tr><tr><td>Design Considerations for a Steerable Needle Robot to Maximize Reachable Lung Volume</td><td>1418</td></tr><tr><td>Margaret; Granna, Josephine; Kuntz, Alan; Akulian, Jason; Webster III, Robert James;</td><td></td></tr><tr><td>Alterovitz, Ron</td><td></td></tr><tr><td>An Active Steering Hand-Held Robotic System for Minimally Invasive Orthopaedic Surgery Using a  Continuum Manipulator</td><td>1426</td></tr><tr><td>Design of a Reconfigurable Parallel Continuum Robot with Tendon-Actuated Kinematic Chains</td><td>1434</td></tr><tr><td>Design and Control of a Hand-Held Concentric Tube Robot for Minimally Invasive Surgery</td><td>1442</td></tr><tr><td><strong>Session</strong> TuGT19 : Continuum Robotics III</td><td></td></tr><tr><td>Deep Reinforcement Learning for Concentric Tube Robot Control with a Goal-Based Curriculum</td><td>1459</td></tr><tr><td>Optimized 3D Path Planner for Steerable Catheters with Deductive Reasoning</td><td>1466</td></tr><tr><td>Robotic Electrospinning Actuated by Non-Circular Joint Continuum Manipulator for Endoluminal  Therapy</td><td>1473</td></tr><tr><td>Autonomous Steering of Concentric Tube Robots Via Nonlinear Model Predictive Control</td><td>1480</td></tr><tr><td><strong>Session</strong> TuDT19 : Control and Optimization I</td><td></td></tr><tr><td>Online Informative Path Planning for Active Information Gathering of a 3D Surface</td><td>1488</td></tr><tr><td>EKF-based real-time self-attitude estimation with camera DNN learning landscape regularities</td><td>1495</td></tr><tr><td>Advancing Mixture Models for Least Squares Optimization</td><td>1503</td></tr><tr><td>Online Extrinsic Calibration Based on Per-Sensor Ego-Motion Using Dual Quaternions</td><td>1512</td></tr><tr><td><strong>Session</strong> TuAT23 : Control and Optimization II</td><td></td></tr><tr><td>A Class of Optimal Switching Mixed Data Injection Attack in Cyber-Physical Systems</td><td>1520</td></tr><tr><td>Observation Space Matters: Benchmark and Optimization Algorithm</td><td>1527</td></tr><tr><td>Interleaving Fast and Slow Decision Making</td><td>1535</td></tr><tr><td>Multi-output Infinite Horizon Gaussian Processes</td><td>1542</td></tr><tr><td><strong>Session</strong> TuCT21 : Control Applications</td><td></td></tr><tr><td>Faithful Euclidean Distance Field from Log-Gaussian Process Implicit Surfaces</td><td>1550</td></tr><tr><td>Force Control of a Hydraulic Actuator with a Neural Network Inverse Model</td><td>1558</td></tr><tr><td>An Encoder-Free Joint Velocity Estimation Method for Serial Manipulators Using Inertial Sensors</td><td>1566</td></tr><tr><td>D-ACC: Dynamic Adaptive Cruise Control for Highways with Ramps Based on Deep Q-Learning</td><td>1572</td></tr><tr><td>Session TuET19 : Control for Multi-Robot SystemsA Finite-Gain Stable Multi-Agent Robot Control Framework with Adaptive Authority Allocation</td><td>1579</td></tr><tr><td>Decentralized Connectivity Maintenance with Time Delays Using Control Barrier Functions</td><td>1586</td></tr><tr><td>Haptic-Enabled Decentralized Control of a Heterogeneous Human-Robot Team for Search and  Rescue in Partially-Known Environments</td><td>1593</td></tr><tr><td>Multi-Robot Implicit Control of Herds</td><td>1601</td></tr><tr><td><strong>Session</strong> TuFT19 : Control of Manipulation I</td><td></td></tr><tr><td>Real-Time Friction Estimation for Grip Force Control</td><td>1608</td></tr><tr><td>Uncertainty-Aware Deep Learning for Robot Touch: Application to Bayesian Tactile Servo Control</td><td>1615</td></tr><tr><td>Towards Integrated Tactile Sensorimotor Control in Anthropomorphic Soft Robotic Hands</td><td>1622</td></tr><tr><td>Simultaneous Tactile Exploration and Grasp Refinement for Unknown Objects</td><td>1629</td></tr><tr><td><strong>Session</strong> TuFT20 : Control of Manipulation II</td><td></td></tr><tr><td>An Efficient Approach to Closed-Loop Shape Control of Deformable Objects Using Finite Element  Models</td><td>1637</td></tr><tr><td>Learning Stable Normalizing-Flow Control for Robotic Manipulation</td><td>1644</td></tr><tr><td>Model Predictive Robot-Environment Interaction Control for Mobile Manipulation Tasks</td><td>1651</td></tr><tr><td>Bilateral Teleoperation with Adaptive Impedance Control for Contact Tasks</td><td>1658</td></tr><tr><td><strong>Session</strong> TuDT20 : Control Theory IMathematical Modeling of a Highly Underactuated Tool for Draping Fiber Plies on Double Curved</td><td></td></tr><tr><td>Molds</td><td>1666</td></tr><tr><td>A General Framework to Increase Safety of Learning Algorithms for Dynamical Systems Based on  Region of Attraction Estimation</td><td>1673</td></tr><tr><td>A Weighted Method for Fast Resolution of Strictly Hierarchical Robot Task Specifications Using  Exact Penalty Functions</td><td>1692</td></tr><tr><td>On-Line Force Capability Evaluation Based on Efficient Polytope Vertex Search</td><td>1700</td></tr><tr><td><strong>Session</strong> TuET20 : Control Theory II</td><td></td></tr><tr><td>Actuating Eigenmanifolds of Conservative Mechanical Systems Via Bounded or Impulsive Control  Actions</td><td>1707</td></tr><tr><td>Robust Frequency-Based Structure Extraction</td><td>1715</td></tr><tr><td>A Hybrid Collision Model for Safety Collision Control</td><td>1722</td></tr><tr><td>Jerk Control of Floating Base Systems with Contact-Stable Parametrised Force Feedback</td><td>1729</td></tr><tr><td><strong>Session</strong> TuGT23 : Control Theory III</td><td></td></tr><tr><td>Spherical Multi-Modal Place Recognition for Heterogeneous Sensor Systems</td><td>1743</td></tr><tr><td>A Multi-Resolution Frontier-Based Planner for Autonomous 3D Exploration</td><td>1751</td></tr><tr><td>A Direct Collocation Method for Optimization of EMG-Driven Wrist Muscle Musculoskeletal Model</td><td>1759</td></tr><tr><td>A Simple Visual-Servoing Task on a Low-Accuracy, Low-Cost Arm</td><td>1766</td></tr><tr><td><strong>Session</strong> TuHT20 : Data-Driven Model Estimation</td><td></td></tr><tr><td>Efficient Dynamics Estimation with Adaptive Model Sets</td><td>1775</td></tr><tr><td>Data-Driven Actuator Selection for Artificial Muscle-Powered Robots</td><td>1783</td></tr><tr><td>EMG-Based Neural Network Model of Human Arm Dynamics in a Haptic Training Simulator of  Sinus Endoscopy</td><td>1790</td></tr><tr><td>Multimodal Dynamics Modeling for Off-Road Autonomous Vehicles</td><td>1796</td></tr><tr><td><strong>Session</strong> TuJT20 : Deep Learning in Robotics and Automation</td><td></td></tr><tr><td>Stabilizing Neural Control Using Self-Learned Almost Lyapunov Critics</td><td>1803</td></tr><tr><td>Regularizing Action Policies for Smooth Control with Reinforcement Learning</td><td>1810</td></tr><tr><td>DeepReach: A Deep Learning Approach to High-Dimensional Reachability</td><td>1817</td></tr><tr><td>Deep Reinforcement Learning for Active Target Tracking</td><td>1825</td></tr><tr><td><strong>Session</strong> TuBT20 : Deep Learning in Robotics I</td><td></td></tr><tr><td>Long-Range Hand Gesture Recognition Via Attention-Based SSD Network</td><td>1832</td></tr><tr><td>Spectral Temporal Graph Neural Network for Trajectory Prediction</td><td>1839</td></tr><tr><td>Dark Reciprocal-Rank: Teacher-To-Student Knowledge Transfer from Self-Localization Model to  Graph-Convolutional Neural Network</td><td>1846</td></tr><tr><td>Efficient SE(3) Reachability Map Generation Via Interplanar Integration of Intra-Planar Convolutions</td><td>1854</td></tr><tr><td><strong>Session</strong> TuCT20 : Deep Learning in Robotics IIFlowDriveNet: An End-To-End Network for Learning Driving Policies from Image Optical Flow and</td><td></td></tr><tr><td>LiDAR Point Flow</td><td>1861</td></tr><tr><td>PocoNet: SLAM-Oriented 3D LiDAR Point Cloud Online Compression Network</td><td>1868</td></tr><tr><td>3D Reconstruction of Deformable Colon Structures Based on Preoperative Model and Deep Neural  Network</td><td>1875</td></tr><tr><td>DenseLiDAR: A Real-Time Pseudo Dense Depth Guided Depth Completion Network</td><td>1882</td></tr><tr><td><strong>Session</strong> TuGT20 : Distributed Robotic Systems</td><td></td></tr><tr><td>Distributed Full-Consensus Control of Multi-Robot Systems with Range and Field-Of-View  Constraints</td><td>1890</td></tr><tr><td>Scalable Recursive Distributed Collaborative State Estimation for Aided Inertial Navigation</td><td>1896</td></tr><tr><td>Distributed Multi-Target Tracking in Camera Networks</td><td>1903</td></tr><tr><td>GenGrid: A Generalised Distributed Experimental Environmental Grid for Swarm Robotics</td><td>1910</td></tr><tr><td><strong>Session</strong> TuIT20 : Dynamic Manipulation</td><td></td></tr><tr><td>Nth Order Analytical Time Derivatives of Inverse Dynamics in Recursive and Closed Forms</td><td>1918</td></tr><tr><td>Robot Dynamics Identification: A Reproducible Comparison with Experiments on the KINOVA  Jaco2</td><td>1925</td></tr><tr><td>Efficient Configuration Exploration in Inverse Dynamics Acquisition of Robotic Manipulators</td><td>1934</td></tr><tr><td>Dynamic Manipulation of Deformable Objects with Implicit Integration</td><td>1942</td></tr><tr><td><strong>Session</strong> TuDT18 : Dynamic Modeling</td><td></td></tr><tr><td>Learning to Propagate Interaction Effects for Modeling Deformable Linear Objects Dynamics</td><td>1950</td></tr><tr><td>Modal Dynamic Modelling and Experimental Validation of a Curved Extensible Continuum  Manipulator</td><td>1958</td></tr><tr><td>A Hybrid Dynamical Modeling Framework for Shape Memory Alloy Wire Actuated Structures</td><td>1966</td></tr><tr><td><strong>Session</strong> TuET18 : Dynamics and Control I</td><td></td></tr><tr><td>Switching Control in Two-Wheeled Self-Balancing Robots</td><td>1974</td></tr><tr><td>Smith-Predictor-Based Torque Control of a Rolling Diaphragm Hydrostatic Transmission</td><td>1981</td></tr><tr><td>A Unified MPC Framework for Whole-Body Dynamic Locomotion and Manipulation</td><td>1989</td></tr><tr><td>Speed Gain in Elastic Joint Robots: An Energy Conversion-Based Approach</td><td>1997</td></tr><tr><td><strong>Session</strong> TuKT20 : Dynamics and Control II</td><td></td></tr><tr><td>No-Frills Dynamic Planning Using Static Planners</td><td>2005</td></tr><tr><td>PCMPC: Perception-Constrained Model Predictive Control for Quadrotors with Suspended Loads  Using a Single Camera and IMU</td><td>2012</td></tr><tr><td>Learning Agile Locomotion Skills with a Mentor</td><td>2019</td></tr><tr><td>Automating Behavior Selection for Affective Telepresence Robot</td><td>2026</td></tr><tr><td><strong>Session</strong> TuJT19 : Dynamics and Control III</td><td></td></tr><tr><td>Transition Motion Planning for Multi-Limbed Vertical Climbing Robots Using Complementarity  Constraints</td><td>2033</td></tr><tr><td>Inverse Dynamics Control of Compliant Hybrid Zero Dynamic Walking</td><td>2040</td></tr><tr><td>Advantages of Bilinear Koopman Realizations for the Modeling and Control of Systems with  Unknown Dynamics</td><td>2048</td></tr><tr><td>The Dynamic Effect of Mechanical Losses of Transmissions on the Equations of Motion of Legged  Robots</td><td>2056</td></tr><tr><td><strong>Session</strong> TuCT19 : Dynamics and Control IV</td><td></td></tr><tr><td>Model Based Evaluation of Human and Lower-Limb Exoskeleton Interaction During Sit to Stand  Motion</td><td>2063</td></tr><tr><td>Efficient Solution Method Based on Inverse Dynamics for Optimal Control Problems of Rigid Body  Systems</td><td>2070</td></tr><tr><td>Compensation for Undefined Behaviors During Robot Task Execution by Switching Controllers  Depending on Embedded Dynamics in RNN</td><td>2077</td></tr><tr><td>Reduction of Ground Impact of a Powered Exoskeleton by Shock Absorption Mechanism on the  Shank</td><td>2085</td></tr><tr><td><strong>Session</strong> TuHT18 : Field Robotics I</td><td></td></tr><tr><td>SLIP Walking over Rough Terrain via H-LIP Stepping and Backstepping-Barrier Function Inspired  Quadratic Program</td><td>2091</td></tr><tr><td>DeepQ Stepper: A Framework for Reactive Dynamic Walking on Uneven Terrain</td><td>2099</td></tr><tr><td>Wetland Soil Strength Tester and Core Sampler Using a Drone</td><td>2106</td></tr><tr><td>Backstepping and Sliding Mode Control for AUVs Aided with Bioinspired Neurodynamics</td><td>2113</td></tr><tr><td><strong>Session</strong> TuFT18 : Field Robotics II</td><td></td></tr><tr><td>Data-Driven Sea State Estimation for Vessels Using Multi-Domain Features from Motion  Responses</td><td>2120</td></tr><tr><td>A Fault Tolerant Control Architecture Based on Fault Trees for an Underwater Robot Executing  Transect Missions</td><td>2127</td></tr><tr><td>How to Train Your Heron</td><td>2134</td></tr><tr><td>Robust Underwater Visual SLAM Fusing Acoustic Sensing</td><td>2140</td></tr><tr><td><strong>Session</strong> TuIT18 : Field Robotics III</td><td></td></tr><tr><td>Place Recognition in Forests with Urquhart Tessellations</td><td>2147</td></tr><tr><td>Detecting and Counting Oysters</td><td>2156</td></tr><tr><td>Autonomous Distributed 3D Radiation Field Estimation for Nuclear Environment Characterization</td><td>2163</td></tr><tr><td>Locomotion and Control of a Friction-Driven Tripedal Robot</td><td>2170</td></tr><tr><td><strong>Session</strong> TuGT18 : Field Robotics IV</td><td></td></tr><tr><td>Predicting the Time Until a Vehicle Changes the Lane Using LSTM-Based Recurrent Neural  Networks</td><td>2177</td></tr><tr><td>Robot-Supervised Learning of Crop Row Segmentation</td><td>2185</td></tr><tr><td>Deep Regression versus Detection for Counting in Robotic Phenotyping</td><td>2192</td></tr><tr><td>Neural Network Controller for Autonomous Pile Loading Revised</td><td>2198</td></tr><tr><td><strong>Session</strong> TuAT19 : Field Robotics V</td><td></td></tr><tr><td>A Peg-In-Hole Task Strategy for Holes in Concrete</td><td>2205</td></tr><tr><td>Semantic Mapping of Construction Site from Multiple Daily Airborne LiDAR Data</td><td>2212</td></tr><tr><td>Ranulfo; Kojima, Shotaro; Suzuki, Taro; Komatsu, Tomohiro; Shibata Yukinori, Shibata;</td><td></td></tr><tr><td>Asano, Kimitaka; Nagatani, Keiji; Miyamoto, Naoto; Suzuki, Takahiro; Harada, Tatsuya;</td><td></td></tr><tr><td>Tadokoro, Satoshi TaskNet: A Neural Task Planner for Autonomous Excavator</td><td>2220</td></tr><tr><td>Steering Induced Roll Quantification During Ship Turning Circle Manoeuvre</td><td>2227</td></tr><tr><td><strong>Session</strong> TuDT17 : Field Robotics VI</td><td></td></tr><tr><td>Mobile Manipulator for Autonomous Localization, Grasping and Precise Placement of Construction  Material in a Semi-Structured Environment</td><td>2233</td></tr><tr><td>Jindal, Kshitij; Zhou, Alex; Thakur, Dinesh; Loianno, Giuseppe; Krajník, Tomáš; Saska,</td><td></td></tr><tr><td>Martin</td><td></td></tr><tr><td>Experimental Validation of Unsteady Wave Induced Loads on a Stationary Remotely Operated  Vehicle</td><td>2242</td></tr><tr><td>ASVLite: A High-Performance Simulator for Autonomous Surface Vehicles</td><td>2249</td></tr><tr><td>Continuous Shortest Path Vector Field Navigation on 3D Triangular Meshes for Mobile Robots</td><td>2256</td></tr><tr><td><strong>Session</strong> TuDT16 : Field Robotics VII</td><td></td></tr><tr><td>Predicting the Post-Impact Velocity of a Robotic Arm Via Rigid Multibody Models: An Experimental  Study</td><td>2264</td></tr><tr><td>Compliant plant exploration for agricultural procedures with a collaborative robot</td><td>2272</td></tr><tr><td>Conv1D Energy-Aware Path Planner for Mobile Robots in Unstructured Environments</td><td>2279</td></tr><tr><td>Resilient Collision-Tolerant Navigation in Confined Environments</td><td>2286</td></tr><tr><td><strong>Session</strong> TuBT19 : Field Robotics VIII</td><td></td></tr><tr><td>A Coach-Based Bayesian Reinforcement Learning Method for Snake Robot Control</td><td>2293</td></tr><tr><td>Estimation of Spatially-Correlated Ocean Currents from Ensemble Forecasts and Online  Measurements</td><td>2301</td></tr><tr><td>Semi-Supervised Gated Recurrent Neural Networks for Robotic Terrain Classification</td><td>2308</td></tr><tr><td>Circus ANYmal: A Quadruped Learning Dexterous Manipulation with Its Limbs</td><td>2316</td></tr><tr><td><strong>Session</strong> TuET16 : Field Robotics: Agricultural Applications</td><td></td></tr><tr><td>PATHoBot: A Robot for Glasshouse Crop Phenotyping and Intervention</td><td>2324</td></tr><tr><td>Using depth information and colour space variations for improving outdoor robustness for instance  segmentation of cabbage</td><td>2331</td></tr><tr><td>Joint Plant Instance Detection and Leaf Count Estimation for In-Field Plant Phenotyping</td><td>2337</td></tr><tr><td>MP-STSP: A Multi-Platform Steiner Traveling Salesman Problem Formulation for Precision  Agriculture in Orchards</td><td>2345</td></tr><tr><td><strong>Session</strong> TuHT16 : Field Robotics: Control</td><td></td></tr><tr><td>Environment Reconfiguration Planning for Autonomous Robotic Manipulation to Overcome Mobility  Constraints</td><td>2352</td></tr><tr><td>On Null Space-Based Inverse Kinematics Techniques for Fleet Management: Toward Time-Varying Task Activation</td><td>2359</td></tr><tr><td>LaND: Learning to Navigate from Disengagements</td><td>2377</td></tr><tr><td>Adaptive Sampling Using POMDPs with Domain-Specific Considerations</td><td>2385</td></tr><tr><td><strong>Session</strong> TuIT16 : Field Robotics: Machine Learning</td><td></td></tr><tr><td>Meta Learning with Paired Forward and Inverse Models for Efficient Receding Horizon Control</td><td>2392</td></tr><tr><td>Reaching Pruning Locations in a Vine Using a Deep Reinforcement Learning Policy</td><td>2400</td></tr><tr><td>A Generative Model-Based Predictive Display for Robotic Teleoperation</td><td>2407</td></tr><tr><td><strong>Session</strong> TuET17 : Field Robotics: Mobile Robots</td><td></td></tr><tr><td>Behavior-Tree-Based Person Search for Symbiotic Autonomous Mobile Robot Tasks</td><td>2414</td></tr><tr><td>Online velocity fluctuation of off-road wheeled mobile robots: A reinforcement learning approach</td><td>2421</td></tr><tr><td>Information-Driven Gas Source Localization Exploiting Gas and Wind Local Measurements for  Autonomous Mobile Robots</td><td>2428</td></tr><tr><td>Integration of a Human-Aware Risk-Based Braking System into an Open-Field Mobile Robot​</td><td>2435</td></tr><tr><td><strong>Session</strong> TuJT18 : Field Robotics: Perception</td><td></td></tr><tr><td>Three-Dimensional Terrain Aware Autonomous Exploration for Subterranean and Confined Spaces</td><td>2443</td></tr><tr><td>Semantically-Aware Strategies for Stereo-Visual Robotic Obstacle Avoidance</td><td>2450</td></tr><tr><td>Sattar, Junaed LiDARNet: A Boundary-Aware Domain Adaptation Model for Point Cloud Semantic Segmentation</td><td>2457</td></tr><tr><td>Real-Time Navigation Using Virtual Magnetic Fields</td><td>2465</td></tr><tr><td><strong>Session</strong> WeBT7 : Field Robots I</td><td></td></tr><tr><td>Design and Experimental Validation of a Robotic System for Reactor Core Detector Removal</td><td>2473</td></tr><tr><td>Accurate and Robust Stereo Direct Visual Odometry for Agricultural Environment</td><td>2480</td></tr><tr><td>A General Approach for the Automation of Hydraulic Excavator Arms Using Reinforcement  Learning</td><td>2487</td></tr><tr><td>Parameter Estimation of an Industrial Car-Like Tractor</td><td>2495</td></tr><tr><td><strong>Session</strong> WeCT7 : Field Robots II</td><td></td></tr><tr><td>Enhancement for Robustness of Koopman Operator-Based Data-Driven Mobile Robotic Systems</td><td>2503</td></tr><tr><td>Collision Risk Assessment and Obstacle Avoidance Control for Autonomous Sailing Robots</td><td>2511</td></tr><tr><td>MSTC*: Multi-Robot Coverage Path Planning under Physical Constraints</td><td>2518</td></tr><tr><td>Impact Mitigation for Dynamic Legged Robots with Steel Wire Transmission Using Nonlinear Active  Compliance Control</td><td>2525</td></tr><tr><td><strong>Session</strong> TuKT19 : Force Control</td><td></td></tr><tr><td>Admittance Control with Uknown Location of Interaction</td><td>2532</td></tr><tr><td>Low-Level Force-Control of MR-Hydrostatic Actuators</td><td>2540</td></tr><tr><td>Zero-Potential-Energy Motions Due to Stiffness in Impedance Control of Robotic Tasks: An  Innovative Theory and Experimental Study</td><td>2548</td></tr><tr><td><strong>Session</strong> TuCT18 : Grasping and Manipulation</td><td></td></tr><tr><td>Adversarial Skill Learning for Robust Manipulation</td><td>2555</td></tr><tr><td>Learning Visual Affordances with Target-Orientated Deep Q-Network to Grasp Objects by  Harnessing Environmental Fixtures</td><td>2562</td></tr><tr><td>Enhancing Robot Perception in Grasping and Dexterous Manipulation through Crowdsourcing and  Gamification</td><td>2569</td></tr><tr><td>Teaching Robotic and Biomechatronic Concepts with a Gripper Design Project and a Grasping and  Manipulation Competition</td><td>2576</td></tr><tr><td><strong>Session</strong> TuFT17 : Grasping I</td><td></td></tr><tr><td>Contact Space Computation of Two-Finger Gravity Based Caging Grasps Security Measure</td><td>2583</td></tr><tr><td>Analysis of Open-Loop Grasping from Piles</td><td>2591</td></tr><tr><td>Human Initiated Grasp Space Exploration Algorithm for an Underactuated Robot Gripper Using  Variational Autoencoder</td><td>2598</td></tr><tr><td>An Underactuated Gripper Based on Car Differentials for Self-Adaptive Grasping with Passive  Disturbance Rejection</td><td>2605</td></tr><tr><td><strong>Session</strong> TuAT20 : Grasping II</td><td></td></tr><tr><td>Dig-Grasping Via Direct Quasistatic Interaction Using Asymmetric Fingers: An Approach to  Effective Bin Picking</td><td>2612</td></tr><tr><td>Uncertainty-Aware Self-Supervised Target-Mass Grasping of Granular Foods</td><td>2620</td></tr><tr><td>SCT-CNN: A Spatio-Channel-Temporal Attention CNN for Grasp Stability Prediction</td><td>2627</td></tr><tr><td>Tactile Velocity Estimation for Controlled In-Grasp Sliding</td><td>2635</td></tr><tr><td><strong>Session</strong> TuKT18 : Hierarchical Motion Planning</td><td></td></tr><tr><td>Q-Tree Search: An Information-Theoretic Approach Toward Hierarchical Abstractions for Agents  with Computational Limitations</td><td>2643</td></tr><tr><td>A Safe Hierarchical Planning Framework for Complex Driving Scenarios Based on Reinforcement  Learning</td><td>2660</td></tr><tr><td>Behavior Planning at Urban Intersections through Hierarchical Reinforcement Learning</td><td>2667</td></tr><tr><td>Collision Avoidance in Tightly-Constrained Environments without Coordination: A Hierarchical  Control Approach</td><td>2674</td></tr><tr><td><strong>Session</strong> TuHT17 : Human-Centered Robotics I</td><td></td></tr><tr><td>Human Arm Stability in Relation to Damping-Defined Mechanical Environments in Physical  Interaction with a Robotic Arm</td><td>2681</td></tr><tr><td>Conditioning Style on Substance: Plans for Narrative Observation</td><td>2687</td></tr><tr><td>Negative Emotion Management Using a Smart Shirt and a Robot Assistant</td><td>2694</td></tr><tr><td>Corrective Shared Autonomy for Addressing Task Variability</td><td>2702</td></tr><tr><td><strong>Session</strong> TuIT17 : Human-Centered Robotics II</td><td></td></tr><tr><td>A Robot Walks into a Bar: Automatic Robot Joke Success Assessment</td><td>2710</td></tr><tr><td>Reverse Psychology in Trust-Aware Human-Robot Interaction</td><td>2717</td></tr><tr><td>Hey Robot, Which Way Are You Going? Nonverbal Motion Legibility Cues for Human-Robot  Interaction</td><td>2725</td></tr><tr><td>Robots Asking for Favors: The Effects of Directness and Familiarity on Persuasive HRI</td><td>2731</td></tr><tr><td><strong>Session</strong> TuJT17 : Human-Centered Robotics III</td><td></td></tr><tr><td>Smile Like You Mean It: Driving Animatronic Robotic Face with Learned Models</td><td>2739</td></tr><tr><td>I Know What You Meant: Learning Human Objectives by (Under)estimating Their Choice Set</td><td>2747</td></tr><tr><td>Analyzing Human Models that Adapt Online</td><td>2754</td></tr><tr><td>When Shall I Be Empathetic? the Utility of Empathetic Parameter Estimation in Multi-Agent  Interactions</td><td>2761</td></tr><tr><td><strong>Session</strong> TuKT17 : Human-In-The-Loop Control</td><td></td></tr><tr><td>End-To-End Grasping Policies for Human-In-The-Loop Robots Via Deep Reinforcement Learning</td><td>2768</td></tr><tr><td>An Investigation of a Balanced Hybrid Active-Passive Actuator for Physical Human-Robot  Interaction</td><td>2775</td></tr><tr><td>Situational Confidence Assistance for Lifelong Shared Autonomy</td><td>2783</td></tr><tr><td>Recognizing Orientation Slip in Human Demonstrations</td><td>2790</td></tr><tr><td><strong>Session</strong> TuKT13 : Humanoid and Bipedal Locomotion I</td><td></td></tr><tr><td>Learning Bipedal Robot Locomotion from Human Movement</td><td>2797</td></tr><tr><td>Preference-Based Learning for User-Guided HZD Gait Generation on Bipedal Walking Robots</td><td>2804</td></tr><tr><td>Reinforcement Learning for Robust Parameterized Locomotion Control of Bipedal Robots</td><td>2811</td></tr><tr><td><strong>Session</strong> TuHT12 : Humanoid and Bipedal Locomotion II</td><td></td></tr><tr><td>Motion Planning and Feedback Control for Bipedal Robots Riding a Snakeboard</td><td>2818</td></tr><tr><td>Global Position Control on Underactuated Bipedal Robots: Step-To-Step Dynamics Approximation  for Step Planning</td><td>2825</td></tr><tr><td>One-Step Ahead Prediction of Angular Momentum about the Contact Point for Control of Bipedal  Locomotion: Validation in a LIP-Inspired Controller</td><td>2832</td></tr><tr><td>Hybrid Sampling/Optimization-Based Planning for Agile Jumping Robots on Challenging Terrains</td><td>2839</td></tr><tr><td><strong>Session</strong> TuIT12 : Humanoid Robots</td><td></td></tr><tr><td>A Comparison Between Joint Space and Task Space Mappings for Dynamic Teleoperation of an  Anthropomorphic Robotic Arm in Reaction Tests</td><td>2846</td></tr><tr><td>Real-Time Self-Collision Avoidance in Joint Space for Humanoid Robots</td><td>2853</td></tr><tr><td>Model Hierarchy Predictive Control of Robotic Systems</td><td>2861</td></tr><tr><td>Impedance Optimization for Uncertain Contact Interactions through Risk Sensitive Optimal Control</td><td>2869</td></tr><tr><td><strong>Session</strong> TuJT12 : Humanoids and Animaloids</td><td></td></tr><tr><td>Learning Human Objectives from Sequences of Physical Corrections</td><td>2877</td></tr><tr><td>SimGAN: Hybrid Simulator Identification for Domain Adaptation Via Adversarial Reinforcement  Learning</td><td>2884</td></tr><tr><td>Look at my new blue force-sensing shoes!</td><td>2891</td></tr><tr><td>Learning Spring Mass Locomotion: Guiding Policies with a Reduced-Order Model</td><td>2897</td></tr><tr><td><strong>Session</strong> TuET13 : Humanoids and Animaloids I</td><td></td></tr><tr><td>DILIGENT-KIO: A Proprioceptive Base Estimator for Humanoid Robots Using Extended Kalman  Filtering on Matrix Lie Groups</td><td>2904</td></tr><tr><td>Modeling of Visco-Elastic Environments for Humanoid Robot Motion Control</td><td>2911</td></tr><tr><td>Feasibility-Driven Step Timing Adaptation for Robust MPC-Based Gait Generation in Humanoids</td><td>2919</td></tr><tr><td>Humanoid Control under Interchangeable Fixed and Sliding Unilateral Contacts</td><td>2927</td></tr><tr><td><strong>Session</strong> TuBT17 : Humanoids and Animaloids III</td><td></td></tr><tr><td>Lywal: A Leg-Wheel Transformable Quadruped Robot with Picking up and Transport Functions</td><td>2935</td></tr><tr><td>Design of a Compact Embedded Hydraulic Power Unit for Bipedal Robots</td><td>2942</td></tr><tr><td>Stair Climbing Capability-Based Dimensional Synthesis for the Multi-Legged Robot</td><td>2950</td></tr><tr><td>Versatile Locomotion by Integrating Ankle, Hip, Stepping, and Height Variation Strategies</td><td>2957</td></tr><tr><td><strong>Session</strong> TuFT13 : Humanoids and Animaloids IV</td><td></td></tr><tr><td>Fast Footstep Planning with Aborting A*</td><td>2964</td></tr><tr><td>Stiffness Modulation in a Humanoid Robotic Leg and Knee</td><td>2971</td></tr><tr><td>Exploiting Visual Servoing and Centroidal Momentum for Whole-Body Motion Control of Humanoid  Robots in Absence of Contacts and Gravity</td><td>2979</td></tr><tr><td>Variable Horizon MPC with Swing Foot Dynamics for Bipedal Walking Control</td><td>2986</td></tr><tr><td><strong>Session</strong> TuCT17 : Humanoids and Animaloids V</td><td></td></tr><tr><td>Robust Landing Stabilization of Humanoid Robot on Uneven Terrain Via Admittance Control and  Heel Strike Motion</td><td>2994</td></tr><tr><td>Toward Autonomous Driving by Musculoskeletal Humanoids: A Study of Developed Hardware and  Learning-Based Software</td><td>3001</td></tr><tr><td>Automatic Grouping of Redundant Sensors and Actuators Using Functional and Spatial Connections: Application to Muscle Grouping for Musculoskeletal Humanoids</td><td>3011</td></tr><tr><td>State Estimation for Hybrid Wheeled-Legged Robots Performing Mobile Manipulation Tasks</td><td>3019</td></tr><tr><td><strong>Session</strong> TuGT13 : Humanoids and Animaloids VI</td><td></td></tr><tr><td>Precise Jump Planning using Centroidal Dynamics based Bilevel Optimization</td><td>3026</td></tr><tr><td>DeepWalk: Omnidirectional Bipedal Gait by Deep Reinforcement Learning</td><td>3033</td></tr><tr><td>ULT-Model: Towards a One-Legged Unified Locomotion Template Model for Forward Hopping with  an Upright Trunk</td><td>3040</td></tr><tr><td>Nonlinear Stiffness Allows Passive Dynamic Hopping for One-Legged Robots with an Upright  Trunk</td><td>3047</td></tr><tr><td><strong>Session</strong> TuAT16 : Humanoids and Animaloids VII</td><td></td></tr><tr><td>Reachability-Based Push Recovery for Humanoid Robots with Variable-Height Inverted Pendulum</td><td>3054</td></tr><tr><td>Meaningful Centroidal Frame Orientation of Multi-body Floating Locomotion Systems</td><td>3061</td></tr><tr><td>Online Object Searching by a Humanoid Robot in an Unknown Environment</td><td>3068</td></tr><tr><td>Origami-inspired New Material Feeding Mechanism for Soft Growing Robots to Keep the Camera  Stay at the Tip by Securing Its Path</td><td>3076</td></tr><tr><td><strong>Session</strong> WeBT3 : Humanoids and Animaloids VIII</td><td></td></tr><tr><td>Vision-Based Path Following of Snake-Like Robots</td><td>3084</td></tr><tr><td>Configuration Transformation of the Wheel-Legged Robot Using Inverse Dynamics Control</td><td>3091</td></tr><tr><td>A Passive Hydraulic Auxiliary System Designed for Increasing Legged Robot Payload and  Efficiency</td><td>3097</td></tr><tr><td>Legged Robot State Estimation in Slippery Environments UsingInvariant Extended Kalman Filter  with Velocity Update</td><td>3104</td></tr><tr><td><strong>Session</strong> TuDT0 : Human-Robot Interaction Award Session</td><td></td></tr><tr><td>Collision Detection, Identification, and Localization on the DLR SARA Robot with Sensing  Redundancy</td><td>3111</td></tr><tr><td>Reactive Human-To-Robot Handovers of Arbitrary Objects</td><td>3118</td></tr><tr><td><strong>Session</strong> TuJT16 : Human-Robot Interaction I</td><td></td></tr><tr><td>Evaluating Guided Policy Search for Human-Robot Handovers</td><td>3125</td></tr><tr><td>Communication Strategy for Efficient Guidance Providing</td><td>3133</td></tr><tr><td>LBGP: Learning Based Goal Planning for Autonomous Following in Front</td><td>3140</td></tr><tr><td><strong>Session</strong> TuFT16 : Human-Robot Interaction II</td><td></td></tr><tr><td>A Reversible Dynamic Movement Primitive Formulation</td><td>3147</td></tr><tr><td>A Safety-Aware Kinodynamic Architecture for Human-Robot Collaboration</td><td>3154</td></tr><tr><td>A Human-Centered Dynamic Scheduling Architecture for Collaborative Application</td><td>3161</td></tr><tr><td>Towards Efficient Human-Robot Cooperation for Socially-Aware Robot Navigation in Human-Populated Environments: The SNAPE Framework</td><td>3169</td></tr><tr><td><strong>Session</strong> WeCT11 : Human-Robot Interaction III</td><td></td></tr><tr><td>Relational Navigation Learning in Continuous Action Space among Crowds</td><td>3175</td></tr><tr><td>Limits of Probabilistic Safety Guarantees When Considering Human Uncertainty</td><td>3182</td></tr><tr><td>Probabilistic Human Motion Prediction Via a Bayesian Neural Network</td><td>3190</td></tr><tr><td>Directed Acyclic Graph Neural Network for Human Motion Prediction</td><td>3197</td></tr><tr><td><strong>Session</strong> TuKT16 : Human-Robot Interaction in Exoskeletons</td><td></td></tr><tr><td>Crawling Support Using Wearable SuperLimbs: Human-Robot Synchronization and Metabolic Cost  Assessment</td><td>3205</td></tr><tr><td>ROIAL: Region of Interest Active Learning for Characterizing Exoskeleton Gait Preference  Landscapes</td><td>3212</td></tr><tr><td>Control of a Transfemoral Prosthesis on Sloped Terrain using Continuous and Nonlinear  Impedance Parameters</td><td>3219</td></tr><tr><td>Model-Dependent Prosthesis Control with Interaction Force Estimation</td><td>3226</td></tr><tr><td><strong>Session</strong> TuAT18 : Human-Robot Interaction IV</td><td></td></tr><tr><td>Comparison of Three Feedback Modalities for Haptics Sensation in Remote Machine  Manipulation</td><td>3233</td></tr><tr><td>Prediction-Error Negativity to Assess Singularity Avoidance Strategies in Physical Human-Robot  Collaboration</td><td>3241</td></tr><tr><td>A Large Area Robotic Skin with Sparsely Embedded Microphones for Human-Robot Tactile  Communication</td><td>3248</td></tr><tr><td>Star Topology Based Interaction for Robust Trajectory Forecasting in Dynamic Scene</td><td>3255</td></tr><tr><td>Session TuIT15 : Human-Robot Interaction IXMaximum Spectral Flatness Control of a Manipulandum for Human Motor System Identification</td><td>3262</td></tr><tr><td>Learning from Demonstration for Real-Time User Goal Prediction and Assistive Shared Control</td><td>3270</td></tr><tr><td>Human-Aware Robot Task Planning Based on a Hierarchical Task Model</td><td>3276</td></tr><tr><td>Exploiting Natural Language for Efficient Risk-Aware Multi-Robot SaR Planning</td><td>3284</td></tr><tr><td><strong>Session</strong> TuHT15 : Human-Robot Interaction V</td><td></td></tr><tr><td>Force-Sensing Tensegrity for Investigating Physical Human-Robot Interaction in Compliant Robotic  Systems</td><td>3292</td></tr><tr><td>Risk-Aware Decision Making for Service Robots to Minimize Risk of Patient Falls in Hospitals</td><td>3299</td></tr><tr><td>Haptic Feedback Improves Human-Robot Agreement and User Satisfaction in Shared-Autonomy  Teleoperation</td><td>3306</td></tr><tr><td>Effect of Robot Assistance, Operator Cognitive Fatigue, and Sex on Task Efficiency, Workload,  and Situation Awareness in Human-Robot Collaboration</td><td>3313</td></tr><tr><td><strong>Session</strong> TuGT17 : Human-Robot Interaction VI</td><td></td></tr><tr><td>Composing HARMONI: An Open-Source Tool for Human and Robot Modular OpeN Interaction</td><td>3322</td></tr><tr><td>Robot Interaction Studio: A Platform for Unsupervised HRI</td><td>3330</td></tr><tr><td>MorphFace: A Hybrid Morphable Face for a Robopatient</td><td>3337</td></tr><tr><td>Which Gesture Generator Performs Better?</td><td>3345</td></tr><tr><td><strong>Session</strong> WeCT3 : Human-Robot Interaction VIITwo-Stream 2D/3D Residual Networks for Learning Robot Manipulations from Human</td><td></td></tr><tr><td>Demonstration Videos</td><td>3353</td></tr><tr><td>Waypoints Updating Based on Adam and ILC for Path Learning in Physical Human-Robot  Interaction</td><td>3359</td></tr><tr><td>Virtual-Fixture Based Drilling Control for Robot-Assisted Craniotomy: Learning from Demonstration</td><td>3366</td></tr><tr><td>A Graph Attention Spatio-Temporal Convolutional Network for 3D Human Pose Estimation in Video</td><td>3374</td></tr><tr><td><strong>Session</strong> TuBT18 : Human-Robot Interaction VIII</td><td></td></tr><tr><td>Human-In-The-Loop Auditory Cueing Strategy for Gait Modification</td><td>3381</td></tr><tr><td>A Self-Training Approach-Based Traversability Analysis for Mobile Robots in Urban Environments</td><td>3389</td></tr><tr><td>Active and Interactive Mapping with Dynamic Gaussian Process Implicit Surfaces for Mobile  Manipulators</td><td>3395</td></tr><tr><td>Proactive Interaction Framework for Intelligent Social Receptionist Robots</td><td>3403</td></tr><tr><td><strong>Session</strong> TuGT16 : Human-Robot Interaction X</td><td></td></tr><tr><td>Interpreting Contact Interactions to Overcome Failure in Robot Assembly Task</td><td>3410</td></tr><tr><td>Decentralized Ability-Aware Adaptive Control for Multi-Robot Collaborative Manipulation</td><td>3418</td></tr><tr><td>Learning Interaction-Aware Trajectory Predictions for Decentralized Multi-Robot Motion Planning in  Dynamic Environments</td><td>3426</td></tr><tr><td>Real-Time Surgical Environment Enhancement for Robot-Assisted Minimally Invasive Surgery  Based on Super-Resolution</td><td>3434</td></tr><tr><td><strong>Session</strong> TuAT17 : Human-Robot Interaction XIExploiting Inherent Human Motor Behaviour in the Online Personalisation of Human-Prosthetic</td><td></td></tr><tr><td>Interfaces</td><td>3441</td></tr><tr><td>Design and Clinical Validation of a Robotic Ankle-Foot Simulator with Series Elastic Actuator for  Ankle Clonus Assessment Training</td><td>3450</td></tr><tr><td>A Hybrid Impedance Controller for Series Elastic Actuators to Render a Wide Range of Stable  Stiffness in Uncertain Environments</td><td>3458</td></tr><tr><td>Soft-Jig-Driven Assembly Operations</td><td>3466</td></tr><tr><td><strong>Session</strong> TuIT13 : Human-Robot Interaction:   Learning to Predict</td><td></td></tr><tr><td>Identifying Driver Interactions Via Conditional Behavior Prediction</td><td>3473</td></tr><tr><td>Sapp, Benjamin; Anguelov, Dragomir Autonomous Robotic Escort Incorporating Motion Prediction and Human Intention</td><td>3480</td></tr><tr><td>Two-Stage Clustering of Human Preferences for Action Prediction in Assembly Tasks</td><td>3487</td></tr><tr><td>Dynamically Switching Human Prediction Models for Efficient Planning</td><td>3495</td></tr><tr><td><strong>Session</strong> TuJT15 : Human-Robot Interaction:  Robot Navigation I</td><td></td></tr><tr><td>Socially-Compatible Behavior Design of Autonomous Vehicles with Verification on Real Human  Data</td><td>3502</td></tr><tr><td>Social Navigation for Mobile Robots in the Emergency Department</td><td>3510</td></tr><tr><td>Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning</td><td>3517</td></tr><tr><td>Range Limited Coverage Control Using Air-Ground Multi-Robot Teams</td><td>3525</td></tr><tr><td><strong>Session</strong> TuHT13 : Human-Robot Interaction:  Robot Navigation II</td><td></td></tr><tr><td>Investigation of Unmanned Aerial Vehicle Gesture Perceptibility and Impact of Viewpoint Variance</td><td>3531</td></tr><tr><td>Can a Robot Trust You? A DRL-Based Approach to Personality-Driven, Human-Guided Navigation</td><td>3538</td></tr><tr><td>Mesh Based Analysis of Low Fractal Dimension Reinforcement Learning Policies</td><td>3546</td></tr><tr><td>Watch Where You’re Going! Gaze and Head Orientation As Predictors for Social Robot Navigation</td><td>3553</td></tr><tr><td><strong>Session</strong> TuDT15 : Human-Robot Interaction: Control</td><td></td></tr><tr><td>Robust Classification of Grasped Objects in Intuitive Human-Robot Collaboration Using a  Wearable Force-Myography Device</td><td>3560</td></tr><tr><td>Augmented Hierarchical Quadratic Programming for Adaptive Compliance Robot Control</td><td>3568</td></tr><tr><td>An Optimization Approach for a Robust and Flexible Control in Collaborative Applications</td><td>3575</td></tr><tr><td>Probabilistic Adaptive Control for Robust Behavior Imitation</td><td>3582</td></tr><tr><td><strong>Session</strong> TuET15 : Human-Robot Interaction: Detection</td><td></td></tr><tr><td>CSM: Contact Sensitivity Maps for Benchmarking Robot Collision Handling Systems</td><td>3590</td></tr><tr><td>A Data-Driven Approach for Contact Detection, Classification and Reaction in Physical Human-Robot Collaboration</td><td>3597</td></tr><tr><td>Pointing at Moving Robots: Detecting Events from Wrist IMU Data</td><td>3604</td></tr><tr><td><strong>Session</strong> TuFT15 : Human-Robot Interaction: Haptics</td><td></td></tr><tr><td>Learning Human-like Hand Reaching for Human-Robot Handshaking</td><td>3612</td></tr><tr><td>Simultaneous Haptic Guidance and Learning of Task Parameters During Robotic Teleoperation - a  Geometrical Approach</td><td>3619</td></tr><tr><td>Human-Like Artificial Skin Sensor for Physical Human-Robot Interaction</td><td>3626</td></tr><tr><td>A Unified Perception Benchmark for Capacitive Proximity Sensing towards Safe Human-Robot Collaboration (HRC)</td><td>3634</td></tr><tr><td>Gergely; Rathmair, Michael; Mühlbacher-Karrer, Stephan; Thomas, Ulrike; Hein, Björn;</td><td></td></tr><tr><td>Hofbaur, Michael; Zangl, Hubert</td><td></td></tr><tr><td><strong>Session</strong> TuGT15 : Human-Robot Interaction: Learning</td><td></td></tr><tr><td>Engagement Estimation During Child Robot Interaction Using Deep Convolutional Networks  Focusing on ASD Children</td><td>3641</td></tr><tr><td>Ergodic Imitation: Learning from What to Do and What Not to Do</td><td>3648</td></tr><tr><td>Imitation Learning with Inconsistent Demonstrations through Uncertainty-Based Data Manipulation</td><td>3655</td></tr><tr><td>Learning Motor Resonance in Human-Human and Human-Robot Interaction with Coupled  Dynamical Systems</td><td>3662</td></tr><tr><td><strong>Session</strong> TuKT15 : Human-Robot Interaction: Medical Robots and Systems I</td><td></td></tr><tr><td>Can Therapists Design Robot-Mediated Interventions and Teleoperate Robots Using VR to Deliver  Interventions for ASD?</td><td>3669</td></tr><tr><td>A Low-Cost Intrinsically Safe Mechanism for Physical Distancing between Clinicians and Patients</td><td>3677</td></tr><tr><td>Collaborative Fall Detection Using a Wearable Device and a Companion Robot</td><td>3684</td></tr><tr><td>Conversation-Based Medication Management System for Older Adults Using a Companion Robot  and Cloud</td><td>3691</td></tr><tr><td><strong>Session</strong> TuHT14 : Human-Robot Interaction: Medical Robots and Systems II</td><td></td></tr><tr><td>Variable Impedance Control for pHRI: Impact on Stability, Agility, and Human Effort in Controlling a  Wearable Ankle Robot</td><td>3699</td></tr><tr><td>Design and Validation of a Novel Exoskeleton Hand Interface: The Eminence Grip</td><td>3707</td></tr><tr><td>Entrainment During Human Locomotion Using a Soft Wearable Ankle Robot</td><td>3714</td></tr><tr><td>Active Telepresence Assistance for Supervisory Control: A User Study with a Multi-Camera Tele-Nursing Robot</td><td>3722</td></tr><tr><td><strong>Session</strong> TuIT14 : Human-Robot Interaction: Motion Planning</td><td></td></tr><tr><td>A Scalable Approach to Predict Multi-Agent Motion for Human-Robot Collaboration</td><td>3728</td></tr><tr><td>Temporal Anticipation and Adaptation Methods for Fluent Human-Robot Teaming</td><td>3736</td></tr><tr><td>Robust Planning with Emergent Human-Like Behavior for Agents Traveling in Groups</td><td>3744</td></tr><tr><td>Order Matters: Generating Progressive Explanations for Planning Tasks in Human-Robot Teaming</td><td>3751</td></tr><tr><td><strong>Session</strong> TuDT14 : Human-Robot Interaction: Motion Prediction</td><td></td></tr><tr><td>Human-Robot Collaborative Object Transfer Using Human Motion Prediction Based on Cartesian  Pose Dynamic Movement Primitives</td><td>3758</td></tr><tr><td>Dynamic Projection of Human Motion for Safe and Efficient Human-Robot Collaboration</td><td>3765</td></tr><tr><td>Achieving Hard Real-Time Capability for 3D Human Pose Estimation Systems</td><td>3772</td></tr><tr><td>Zoomorphic Gestures for Cobots</td><td>3779</td></tr><tr><td>Session TuJT14 : Human-Robot Interaction: MultimediaARROCH: Augmented Reality for Robots Collaborating with a Human</td><td>3787</td></tr><tr><td>ARC-LfD: Using Augmented Reality for Interactive Long-Term Robot Skill Maintenance Via  Constrained Learning from Demonstration</td><td>3794</td></tr><tr><td>Bringing WALL-E Out of the Silver Screen: Understanding How Transformative Robot Sound  Affects Human Perception</td><td>3801</td></tr><tr><td>How People Use Active Telepresence Cameras in Tele-manipulation</td><td>3808</td></tr><tr><td><strong>Session</strong> TuET14 : Human-Robot Interaction: Safety</td><td></td></tr><tr><td>Improving Safety and Accuracy of Impedance Controlled Robot Manipulators with Proximity  Perception and Proactive Impact Reactions</td><td>3816</td></tr><tr><td>Optimal Scaling of Dynamic Safety Zones for Collaborative Robotics</td><td>3822</td></tr><tr><td>3D Collision-Force-Map for Safe Human-Robot Collaboration</td><td>3829</td></tr><tr><td>Safe, Passive Control for Mechanical Systems with Application to Physical Human-Robot  Interactions</td><td>3836</td></tr><tr><td><strong>Session</strong> TuKT14 : Human-Robot Interaction: Scheduling and Teleoperation</td><td></td></tr><tr><td>Online Dynamic Time Warping Algorithm for Human-Robot Imitation</td><td>3843</td></tr><tr><td>Sumit Kumar; Popa, Dan Discrete Windowed-Energy Variable Structure Passivity Signature Control for Physical Human-(Tele)Robot Interaction</td><td>3850</td></tr><tr><td>Investigation of Multiple Resource Theory Design Principles on Robot Teleoperation and Workload  Management</td><td>3858</td></tr><tr><td>Time-Domain Passivity-Based Controller with an Optimal Two-Channel Lawrence Telerobotic  Architecture</td><td>3865</td></tr><tr><td><strong>Session</strong> TuFT14 : Human-Robot Interaction: Simulation and Experiment</td><td></td></tr><tr><td>Virtual Adversarial Humans Finding Hazards in Robot Workplaces</td><td>3872</td></tr><tr><td>Crowd against the Machine: A Simulation-Based Benchmark Tool to Evaluate and Compare Robot  Capabilities to Navigate a Human Crowd</td><td>3879</td></tr><tr><td>DROID: Minimizing the Reality Gap Using Single-Shot Human Demonstration</td><td>3886</td></tr><tr><td>Roboticists and Reporters. a Rhetorical Experiment at the Cité Des Sciences Et De l’Industrie (Paris, France) (I)</td><td>3894</td></tr><tr><td><strong>Session</strong> TuGT14 : Human-Robot Interaction: Task Planning</td><td></td></tr><tr><td>Task Planning with a Weighted Functional Object-Oriented Network</td><td>3904</td></tr><tr><td>Haptic-Guided Path Generation for Remote Car-Like Vehicles</td><td>3911</td></tr><tr><td>Task-Based Role Adaptation For Human-Robot Cooperative Object Handling</td><td>3919</td></tr><tr><td>Towards providing explanations for robot motion planning</td><td>3927</td></tr><tr><td><strong>Session</strong> TuDT13 : Human-Robot Interaction: Teleoperation</td><td></td></tr><tr><td>Stabilization of User-defined Feedback Controllers in Teleoperation with Passive Coupling  Reference</td><td>3934</td></tr><tr><td>Rate Mode Bilateral Teleoperation Based on Passivity Tanks and Variable Admittance Control</td><td>3942</td></tr><tr><td>Task Autocorrection for Immersive Teleoperation</td><td>3949</td></tr><tr><td>Manipulability Optimization for Multi-Arm Teleoperation</td><td>3956</td></tr><tr><td><strong>Session</strong> TuJT13 : Human-Robots Interface System</td><td></td></tr><tr><td>UAV Target-Selection: 3D Pointing Interface System for Large-Scale Environment</td><td>3963</td></tr><tr><td>A Framework for Customizable Multi-User Teleoperated Control</td><td>3970</td></tr><tr><td>Scott SQRP: Sensing Quality-Aware Robot Programming System for Non-Expert Programmers</td><td>3978</td></tr><tr><td>Automated Environment Reduction for Debugging Robotic Systems</td><td>3985</td></tr><tr><td><strong>Session</strong> WeAT14 : IMU-Based Localization</td><td></td></tr><tr><td>IMU Data Processing for Inertial Aided Navigation: A Recurrent Neural Network Based Approach</td><td>3992</td></tr><tr><td>Highly Efficient Line Segment Tracking with an IMU-KLT Prediction and a Convex Geometric  Distance Minimization</td><td>3999</td></tr><tr><td>Robust Localization for Planar Moving Robot in Changing Environment: A Perspective on Density  of Correspondence and Depth</td><td>4006</td></tr><tr><td>IMU/Vehicle Calibration and Integrated Localization for Autonomous Driving</td><td>4013</td></tr><tr><td><strong>Session</strong> TuKT12 : Intelligence Design</td><td></td></tr><tr><td>Optimizing Cellular Networks Via Continuously Moving Base Stations on Road Networks</td><td>4020</td></tr><tr><td>The Resh Programming Language for Multirobot Orchestration</td><td>4026</td></tr><tr><td>Sensing Via Collisions: A Smart Cage for Quadrotors with Applications to Self-Localization</td><td>4033</td></tr><tr><td>Generative Design of NU’s Husky Carbon: A Morpho-Functional, Legged Robot</td><td>4040</td></tr><tr><td><strong>Session</strong> TuBT16 : Learning and Control in Robotics and Automation</td><td></td></tr><tr><td>Hyperparameter Auto-Tuning in Self-Supervised Robotic Learning</td><td>4047</td></tr><tr><td>An Analytical Diabolo Model for Robotic Learning and Control</td><td>4055</td></tr><tr><td>Peer-Assisted Robotic Learning: A Data-Driven Collaborative Learning Approach for Cloud Robotic  Systems</td><td>4062</td></tr><tr><td>Imitation Learning of Hierarchical Driving Model: From Continuous Intention to Continuous  Trajectory</td><td>4071</td></tr><tr><td><strong>Session</strong> TuCT16 : Learning and Optimization</td><td></td></tr><tr><td>Evolvable Motion-Planning Method Using Deep Reinforcement Learning</td><td>4079</td></tr><tr><td>Learning Sequences of Manipulation Primitives for Robotic Assembly</td><td>4086</td></tr><tr><td>Data-Efficient Learning for Complex and Real-Time Physical Problem Solving Using Augmented  Simulation</td><td>4093</td></tr><tr><td>EGO-Swarm: A Fully Autonomous and Decentralized Quadrotor Swarm System in Cluttered  Environments</td><td>4101</td></tr><tr><td><strong>Session</strong> TuAT15 : Learning for Motion Planning</td><td></td></tr><tr><td>Deep Imitation Learning for Autonomous Navigation in Dynamic Pedestrian Environments</td><td>4108</td></tr><tr><td>Learning from Demonstration without Demonstrations</td><td>4116</td></tr><tr><td>Optimal Cooperative Maneuver Planning for Multiple Nonholonomic Robots in a Tiny Environment  via Adaptive-scaling Constrained Optimization</td><td>4123</td></tr><tr><td>Optimization-Based Framework for Excavation Trajectory Generation</td><td>4131</td></tr><tr><td><strong>Session</strong> TuDT12 : Learning for Robotics I</td><td></td></tr><tr><td>Adversarial Training Is Not Ready for Robot Learning</td><td>4140</td></tr><tr><td>Deep Learning on 3D Object Detection for Automatic Plug-In Charging Using a Mobile Manipulator</td><td>4148</td></tr><tr><td>Decentralized Multi-Agent Pursuit Using Deep Reinforcement Learning</td><td>4155</td></tr><tr><td>Differentiable Physics Models for Real-World Offline Model-Based Reinforcement Learning</td><td>4163</td></tr><tr><td><strong>Session</strong> TuET12 : Learning for Robotics II</td><td></td></tr><tr><td>Sample-Efficient Reinforcement Learning in Robotic Table Tennis</td><td>4171</td></tr><tr><td>Super-Human Performance in Gran Turismo Sport Using Deep Reinforcement Learning</td><td>4179</td></tr><tr><td>No Face-Touch: Exploiting Wearable Devices and Machine Learning for Gesture Detection</td><td>4187</td></tr><tr><td>Robot Learning with Crash Constraints</td><td>4194</td></tr><tr><td><strong>Session</strong> TuAT14 : Learning in Control</td><td></td></tr><tr><td>Sample Efficient Reinforcement Learning via Model-Ensemble Exploration and Exploitation</td><td>4202</td></tr><tr><td>Dreaming: Model-Based Reinforcement Learning by Latent Imagination without Reconstruction</td><td>4209</td></tr><tr><td>A Variational Infinite Mixture for Probabilistic Inverse Dynamics Learning</td><td>4216</td></tr><tr><td>Model-Based Domain Randomization of Dynamics System with Deep Bayesian Locally Linear  Embedding</td><td>4223</td></tr><tr><td><strong>Session</strong> TuBT15 : Learning in Robotics and Automation I</td><td></td></tr><tr><td>Learning Spatial Context with Graph Neural Network for Multi-Person Pose Grouping</td><td>4230</td></tr><tr><td>Automatic Hanging Point Learning from Random Shape Generation and Physical Function  Validation</td><td>4237</td></tr><tr><td>Gaze-based dual resolution deep imitation learning for high-precision dexterous robot manipulation</td><td>4244</td></tr><tr><td>Graph Convolutional Network Based Configuration Detection for Freeform Modular Robot Using  Magnetic Sensor Array</td><td>4252</td></tr><tr><td><strong>Session</strong> TuCT15 : Learning in Robotics and Automation II</td><td></td></tr><tr><td>PVStereo: Pyramid Voting Module for End-To-End Self-Supervised Stereo Matching</td><td>4259</td></tr><tr><td>Embedding Symbolic Temporal Knowledge into Deep Sequential Models</td><td>4267</td></tr><tr><td>Multi-Modal Mutual Information (MuMMI) Training for Robust Self-Supervised Deep Reinforcement Learning</td><td>4274</td></tr><tr><td>Linguistic Descriptions of Human Motion with Generative Adversarial Seq2Seq Learning</td><td>4281</td></tr><tr><td><strong>Session</strong> WeBT14 : Learning in Robotics and Automation III</td><td></td></tr><tr><td>MDANet: Multi-Modal Deep Aggregation Network for Depth Completion</td><td>4288</td></tr><tr><td>GPR: Grasp Pose Refinement Network for Cluttered Scenes</td><td>4295</td></tr><tr><td>Diversity-Aware Label Distribution Learning for Microscopy Auto Focusing</td><td>4303</td></tr><tr><td>Contour Primitive of Interest Extraction Network Based on One-Shot Learning for Object-Agnostic  Vision Measurement</td><td>4311</td></tr><tr><td><strong>Session</strong> WeCT14 : Learning in Robotics and Automation IV</td><td></td></tr><tr><td>UMLE: Unsupervised Multi-Discriminator Network for Low Light Enhancement</td><td>4318</td></tr><tr><td>Unsupervised Learning of 3D Scene Flow from Monocular Camera</td><td>4325</td></tr><tr><td>Monocular 3D Detection with Geometric Constraints Embedding and Semi-Supervised Training</td><td>4332</td></tr><tr><td>Deep3DRanker: A Novel Framework for Learning to Rank 3D Models with Self-Attention in Robotic  Vision</td><td>4341</td></tr><tr><td>FGR: Frustum-Aware Geometric Reasoning for Weakly Supervised 3D Vehicle Detection</td><td>4348</td></tr><tr><td><strong>Session</strong> TuFT12 : Learning to Predict</td><td></td></tr><tr><td>Combining Events and Frames Using Recurrent Asynchronous Multimodal Networks for Monocular  Depth Prediction</td><td>4355</td></tr><tr><td>Predicting Disparity Distributions</td><td>4363</td></tr><tr><td>Scoring Graspability Based on Grasp Regression for Better Grasp Prediction</td><td>4370</td></tr><tr><td>MonoSOD: Monocular Salient Object Detection Based on Predicted Depth</td><td>4377</td></tr><tr><td><strong>Session</strong> TuHT11 : Learning-Based Control</td><td></td></tr><tr><td>Efficient Reachability Analysis of Closed-Loop Systems with Neural Network Controllers</td><td>4384</td></tr><tr><td>Reachability-Based Trajectory Safeguard (RTS): A Safe and Fast Reinforcement Learning Safety Layer for Continuous Control</td><td>4391</td></tr><tr><td>Neural Identification for Control</td><td>4399</td></tr><tr><td>Learning Variable Impedance Control Via Inverse Reinforcement Learning for Force-Related  Tasks</td><td>4407</td></tr><tr><td><strong>Session</strong> TuGT12 : Learning-Based Control I</td><td></td></tr><tr><td>Interactive Learning of Temporal Features for Control</td><td>4415</td></tr><tr><td>A Fully Spiking Neural Control System Based on Cerebellar Predictive Learning for Sensor-Guided  Robots</td><td>4423</td></tr><tr><td>Learning to Steer a Locomotion Contact Planner</td><td>4430</td></tr><tr><td>Learning Shape Control of Elastoplastic Deformable Linear Objects</td><td>4438</td></tr><tr><td><strong>Session</strong> TuDT11 : Learning-Based Control II</td><td></td></tr><tr><td>Leveraging Forward Model Prediction Error for Learning Control</td><td>4445</td></tr><tr><td>GoSafe: Globally Optimal Safe Robot Learning</td><td>4452</td></tr><tr><td>Distilling a Hierarchical Policy for Planning and Control Via Representation and Reinforcement  Learning</td><td>4459</td></tr><tr><td>Active Model Learning Using Informative Trajectories for Improved Closed-Loop Control on Real  Robots</td><td>4467</td></tr><tr><td><strong>Session</strong> TuET11 : Learning-Based Grasping</td><td></td></tr><tr><td>Robot Learning of 6 DoF Grasping Using Model-Based Adaptive Primitives</td><td>4474</td></tr><tr><td>Conditional StyleGAN for Grasp Generation</td><td>4481</td></tr><tr><td>Go Fetch! - Dynamic Grasps Using Boston Dynamics Spot with External Robotic Arm</td><td>4488</td></tr><tr><td>Multi-FinGAN: Generative Coarse-To-Fine Sampling of Multi-Finger Grasps</td><td>4495</td></tr><tr><td><strong>Session</strong> TuBT14 : Learning-Based Human-Robot Interaction</td><td></td></tr><tr><td>Machine Learning-Based Human-Following System: Following the Predicted Position of a Walking  Human</td><td>4502</td></tr><tr><td>Anytime Game-Theoretic Planning with Active Reasoning About Humans’ Latent States for  Human-Centered Robots</td><td>4509</td></tr><tr><td>Momentum Observer-Based Collision Detection Using LSTM for Model Uncertainty Learning</td><td>4516</td></tr><tr><td>Deep Learning and Mixed Reality to Autocomplete Teleoperation</td><td>4523</td></tr><tr><td><strong>Session</strong> WeAT10 : Learning-Based Manipulation I</td><td></td></tr><tr><td>Mechanical Intelligence for Adaptive Precision Grasp</td><td>4530</td></tr><tr><td>Learning Multi-Object Dense Descriptor for Autonomous Goal-Conditioned Grasping</td><td>4537</td></tr><tr><td>Hierarchical Learning from Demonstrations for Long-Horizon Tasks</td><td>4545</td></tr><tr><td>How to Select and Use Tools? : Active Perception of Target Objects Using Multimodal Deep  Learning</td><td>4552</td></tr><tr><td><strong>Session</strong> TuHT10 : Learning-Based Manipulation II</td><td></td></tr><tr><td>Robots of the Lost Arc: Self-Supervised Learning to Dynamically Manipulate Fixed-Endpoint  Cables</td><td>4560</td></tr><tr><td>Learning to Rearrange Deformable Cables, Fabrics, and Bags with Goal-Conditioned Transporter  Networks</td><td>4568</td></tr><tr><td>A Joint Network for Grasp Detection Conditioned on Natural Language Commands</td><td>4576</td></tr><tr><td>ReLMoGen: Integrating Motion Generation in Reinforcement Learning for Mobile Manipulation</td><td>4583</td></tr><tr><td><strong>Session</strong> TuFT11 : Learning-Based Manipulation III</td><td></td></tr><tr><td>Learning Behavior Trees with Genetic Programming in Unpredictable Environments</td><td>4591</td></tr><tr><td>Active Learning of Bayesian Probabilistic Movement Primitives</td><td>4598</td></tr><tr><td>Learning Efficient Constraint Graph Sampling for Robotic Sequential Manipulation</td><td>4606</td></tr><tr><td>Coarse-to-Fine Imitation Learning: Robot Manipulation from a Single Demonstration</td><td>4613</td></tr><tr><td><strong>Session</strong> TuCT14 : Learning-Based Manipulation IV</td><td></td></tr><tr><td>AdaGrasp: Learning a Gripper-Aware Grasping Policy</td><td>4620</td></tr><tr><td>TRANS-AM: Transfer Learning by Aggregating Dynamics Models for Soft Robotic Assembly</td><td>4627</td></tr><tr><td>Learning Deep Nets for Gravitational Dynamics with Unknown Disturbance through Physical  Knowledge Distillation: Initial Feasibility Study</td><td>4634</td></tr><tr><td>Learning to Place Objects Onto Flat Surfaces in Upright Orientations</td><td>4642</td></tr><tr><td><strong>Session</strong> TuGT11 : Learning-Based Manipulation IX</td><td></td></tr><tr><td>Efficient Self-Supervised Data Collection for Offline Robot Learning</td><td>4650</td></tr><tr><td>Total Singulation with Modular Reinforcement Learning</td><td>4657</td></tr><tr><td>Active Inference for Integrated State-Estimation, Control, and Learning</td><td>4665</td></tr><tr><td>Robot Program Parameter Inference Via Differentiable Shadow Program Inversion</td><td>4672</td></tr><tr><td><strong>Session</strong> TuIT10 : Learning-Based Manipulation V</td><td></td></tr><tr><td>Learning Multimodal Contact-Rich Skills from Demonstrations without Reward Engineering</td><td>4679</td></tr><tr><td>Keep It Simple: Data-Efficient Learning for Controlling Complex Systems with Simple Models</td><td>4686</td></tr><tr><td>DIPN: Deep Interaction Prediction Network with Application to Clutter Removal</td><td>4694</td></tr><tr><td>Toward Agile Maneuvers in Highly Constrained Spaces: Learning from Hallucination</td><td>4702</td></tr><tr><td><strong>Session</strong> TuDT10 : Learning-Based Manipulation VI</td><td></td></tr><tr><td>Learning Conditional Postural Synergies for Dexterous Hands: A Generative Approach Based on  Variational Auto-Encoders and Conditioned on Object Size and Category</td><td>4710</td></tr><tr><td>ReForm: A Robot Learning Sandbox for Deformable Linear Object Manipulation</td><td>4717</td></tr><tr><td>Adversarial Imitation Learning with Trajectorial Augmentation and Correction</td><td>4724</td></tr><tr><td>Learning Reachable Manifold and Inverse Mapping for a Redundant Robot Manipulator</td><td>4731</td></tr><tr><td><strong>Session</strong> TuAT13 : Learning-Based Manipulation VII</td><td></td></tr><tr><td>Living Object Grasping Using Two-Stage Graph Reinforcement Learning</td><td>4738</td></tr><tr><td>Reinforcement Learning for Robotic Assembly Using Non-Diagonal Stiffness Matrix</td><td>4746</td></tr><tr><td>Uncertainty-Aware Contact-Safe Model-Based Reinforcement Learning</td><td>4754</td></tr><tr><td>Reducing the Deployment-Time Inference Control Costs of Deep Reinforcement Learning Agents  via an Asymmetric Architecture</td><td>4762</td></tr><tr><td><strong>Session</strong> TuJT10 : Learning-Based Manipulation VIII</td><td></td></tr><tr><td>ECNNs: Ensemble Learning Methods for Improving Planar Grasp Quality Estimation</td><td>4769</td></tr><tr><td>Causal Reasoning in Simulation for Structure and Transfer Learning of Robot Manipulation Policies</td><td>4776</td></tr><tr><td>SuPer Deep: A Surgical Perception Framework for Robotic Tissue Manipulation Using Deep  Learning for Feature Extraction</td><td>4783</td></tr><tr><td>An Affordance Keypoint Detection Network for Robot Manipulation</td><td>4790</td></tr><tr><td><strong>Session</strong> TuET10 : Learning-Based Motion Planning</td><td></td></tr><tr><td>Learning Robot Trajectories Subject to Kinematic Joint Constraints</td><td>4799</td></tr><tr><td>Enhancing Lattice-Based Motion Planning with Introspective Learning and Reasoning</td><td>4806</td></tr><tr><td>Learning Functionally Decomposed Hierarchies for Continuous Control Tasks with Path Planning</td><td>4815</td></tr><tr><td>Self-Imitation Learning by Planning</td><td>4823</td></tr><tr><td><strong>Session</strong> TuIT11 : Learning-Based Motion Planning I</td><td></td></tr><tr><td>Learning and Planning for Temporally Extended Tasks in Unknown Environments</td><td>4830</td></tr><tr><td>Behavior Tree Learning for Robotic Task Planning through Monte Carlo DAG Search Over a  Formal Grammar</td><td>4837</td></tr><tr><td>Improving Off-Road Planning Techniques with Learned Costs from Physical Interactions</td><td>4844</td></tr><tr><td>Sebastian</td><td></td></tr><tr><td><strong>Session</strong> TuJT11 : Learning-Based Motion Planning IIPlanning with Learned Dynamics: Probabilistic Guarantees on Safety and Reachability via Lipschitz</td><td></td></tr><tr><td>Constants</td><td>4851</td></tr><tr><td>Single-Query Path Planning Using Sample-Efficient Probability Informed Trees</td><td>4859</td></tr><tr><td>Learning from Imperfect Demonstrations from Agents with Varying Dynamics</td><td>4867</td></tr><tr><td>Perceive, Attend, and Drive: Learning Spatial Attention for Safe Self-Driving</td><td>4875</td></tr><tr><td><strong>Session</strong> TuKT11 : Learning-Based Motion Planning III</td><td></td></tr><tr><td>Robotic Information Gathering Using Semantic Language Instructions</td><td>4882</td></tr><tr><td>MPC-MPNet: Model-Predictive Motion Planning Networks for Fast, Near-Optimal Planning under  Kinodynamic Constraints</td><td>4889</td></tr><tr><td>Deep Structured Reactive Planning</td><td>4897</td></tr><tr><td>Learning a Centroidal Motion Planner for Legged Locomotion</td><td>4905</td></tr><tr><td><strong>Session</strong> TuHT9 : Legged Robots I</td><td></td></tr><tr><td>Optimal Estimation of the Centroidal Dynamics of Legged Robots</td><td>4912</td></tr><tr><td>A Unified Optimization Framework and New Set of Performance Metrics for Robot Leg Design</td><td>4919</td></tr><tr><td>A Novel Model Predictive Control Framework Using Dynamic Model Decomposition Applied to  Dynamic Legged Locomotion</td><td>4926</td></tr><tr><td>Generating Continuous Motion and Force Plans in Real-Time for Legged Mobile Manipulation</td><td>4933</td></tr><tr><td><strong>Session</strong> TuIT9 : Legged Robots II</td><td></td></tr><tr><td>Planning in Learned Latent Action Spaces for Generalizable Legged Locomotion</td><td>4940</td></tr><tr><td>AksharaThe Fluid Field SLIP Model: Terrestrial-Aquatic Dynamic Legged Locomotion</td><td>4948</td></tr><tr><td>Dynamics Randomization Revisited: A Case Study for Quadrupedal Locomotion</td><td>4955</td></tr><tr><td>Coupled Control Lyapunov Functions for Interconnected Systems, with Application to Quadrupedal  Locomotion</td><td>4962</td></tr><tr><td><strong>Session</strong> TuFT10 : Legged Robots III</td><td></td></tr><tr><td>Balancing on a Springy Leg</td><td>4970</td></tr><tr><td>Gyrubot: Nonanthropomorphic Stabilization for a Biped</td><td>4976</td></tr><tr><td>Feasible Region: An Actuation-Aware Extension of the Support Region</td><td>4983</td></tr><tr><td>A Novel Method for Computing the 3D Friction Cone Using Complimentary Constraints</td><td>5000</td></tr><tr><td><strong>Session</strong> TuGT10 : Legged Robots IV</td><td></td></tr><tr><td>Implementation of a Reactive Walking Controller for the New Open-Hardware Quadruped Solo-12</td><td>5007</td></tr><tr><td>Soueres, Philippe Imitation Learning from MPC for Quadrupedal Multi-Gait Control</td><td>5014</td></tr><tr><td>Comparison of Predictive Controllers for Locomotion and Balance Recovery of Quadruped Robots</td><td>5021</td></tr><tr><td>Locomotion Adaptation in Heavy Payload Transportation Tasks with the Quadruped Robot  CENTAURO</td><td>5028</td></tr><tr><td><strong>Session</strong> WeCT10 : LiDAR-Based Localization I</td><td></td></tr><tr><td>Elastic and Efficient LiDAR Reconstruction for Large-Scale Exploration Tasks</td><td>5035</td></tr><tr><td>KFS-LIO: Key-Feature Selection for Lightweight Lidar Inertial Odometry</td><td>5042</td></tr><tr><td>CamVox: A Low-Cost and Accurate Lidar-Assisted Visual SLAM System</td><td>5049</td></tr><tr><td>PSF-LO: Parameterized Semantic Features Based Lidar Odometry</td><td>5056</td></tr><tr><td><strong>Session</strong> TuBT13 : LiDAR-Based Localization II</td><td></td></tr><tr><td>LiDAR-Based Initial Global Localization Using Two-Dimensional (2D) Submap Projection Image (SPI)</td><td>5063</td></tr><tr><td>Automatic Hyper-Parameter Tuning for Black-Box LiDAR Odometry</td><td>5069</td></tr><tr><td>Locus: LiDAR-based Place Recognition Using Spatiotemporal Higher-Order Pooling</td><td>5075</td></tr><tr><td>Automated Extrinsic Calibration for 3D LiDARs with Range Offset Correction Using an Arbitrary  Planar Board</td><td>5082</td></tr><tr><td><strong>Session</strong> TuKT10 : Localization and Control</td><td></td></tr><tr><td>Model Predictive Control for Cooperative Hunting in Obstacle Rich and Dynamic Environments</td><td>5089</td></tr><tr><td>Instance-Aware Predictive Navigation in Multi-Agent Environments</td><td>5096</td></tr><tr><td>SLAAM: Simultaneous Localization and Additive Manufacturing</td><td>5103</td></tr><tr><td>SimNet: Learning Reactive Self-Driving Simulations from Real-World Observations</td><td>5119</td></tr><tr><td><strong>Session</strong> TuDT9 : Localization and Estimation</td><td></td></tr><tr><td>MonStereo: When Monocular and Stereo Meet at the Tail of 3D Human Localization</td><td>5126</td></tr><tr><td>Enabling Spatio-Temporal Aggregation in Birds-Eye-View Vehicle Estimation</td><td>5133</td></tr><tr><td>Multimodal Scale Consistency and Awareness for Monocular Self-Supervised Depth Estimation</td><td>5140</td></tr><tr><td>There and Back Again: Self-Supervised Multispectral Correspondence Estimation</td><td>5147</td></tr><tr><td><strong>Session</strong> TuET9 : Localization and Mapping I</td><td></td></tr><tr><td>Deep Compression for Dense Point Cloud Maps</td><td>5155</td></tr><tr><td>Exploration of Large Outdoor Environments Using Multi-Criteria Decision Making</td><td>5163</td></tr><tr><td>SD-DefSLAM: Semi-Direct Monocular SLAM for Deformable and Intracorporeal Scenes</td><td>5170</td></tr><tr><td>Hough2Map – Iterative Event-Based Hough Transform for High-Speed Railway Mapping</td><td>5178</td></tr><tr><td><strong>Session</strong> TuJT9 : Localization and Mapping II</td><td></td></tr><tr><td>3D Motion Capture of an Unmodified Drone with Single-Chip Millimeter Wave Radar</td><td>5186</td></tr><tr><td>Zero-Shot Reinforcement Learning on Graphs for Autonomous Exploration Under Uncertainty</td><td>5193</td></tr><tr><td>Fast Uncertainty Quantification for Deep Object Pose Estimation</td><td>5200</td></tr><tr><td>Mesh Reconstruction from Aerial Images for Outdoor Terrain Mapping Using Joint 2D-3D Learning</td><td>5208</td></tr><tr><td><strong>Session</strong> WeAT2 : Localization and Mapping III</td><td></td></tr><tr><td>Tightly-Coupled Multi-Sensor Fusion for Localization with LiDAR Feature Maps</td><td>5215</td></tr><tr><td>Greedy-Based Feature Selection for Efficient LiDAR SLAM</td><td>5222</td></tr><tr><td>Road Mapping and Localization Using Sparse Semantic Visual Features</td><td>5229</td></tr><tr><td>Retrieval and Localization with Observation Constraints</td><td>5237</td></tr><tr><td><strong>Session</strong> TuCT13 : Localization and Mapping IV</td><td></td></tr><tr><td>MSTSL: Multi-Sensor Based Two-Step Localization in Geometrically Symmetric Environments</td><td>5245</td></tr><tr><td>Range-Focused Fusion of Camera-IMU-UWB for Accurate and Drift-Reduced Localization</td><td>5252</td></tr><tr><td>Interactive Planning for Autonomous Urban Driving in Adversarial Scenarios</td><td>5261</td></tr><tr><td>Kernel-Based 3-D Dynamic Occupancy Mapping with Particle Tracking</td><td>5268</td></tr><tr><td><strong>Session</strong> WeAT16 : Localization and Mapping IX</td><td></td></tr><tr><td>Robust Dual Quadric Initialization for Forward-Translating Camera Movements</td><td>5275</td></tr><tr><td>Robust Motion Averaging under Maximum Correntropy Criterion</td><td>5283</td></tr><tr><td>Robust Semantic Map Matching Algorithm Based on Probabilistic Registration Model</td><td>5289</td></tr><tr><td>Accurate and Robust Scale Recovery for Monocular Visual Odometry Based on Plane Geometry</td><td>5296</td></tr><tr><td><strong>Session</strong> TuKT9 : Localization and Mapping V</td><td></td></tr><tr><td>Polarimetric Monocular Dense Mapping Using Relative Deep Depth Prior</td><td>5303</td></tr><tr><td>Learned Uncertainty Calibration for Visual Inertial Localization</td><td>5311</td></tr><tr><td>CLEAR: A Consistent Lifting, Embedding, and Alignment Rectification Algorithm for Multiview Data  Association</td><td>5318</td></tr><tr><td>Distributed Client-Server Optimization for SLAM with Limited On-Device Resources</td><td>5336</td></tr><tr><td><strong>Session</strong> WeAT12 : Localization and Mapping VI</td><td></td></tr><tr><td>Multi-Parameter Optimization for a Robust RGB-D SLAM System</td><td>5343</td></tr><tr><td>Invariant EKF Based 2D Active SLAM with Exploration Task</td><td>5350</td></tr><tr><td>2D Laser SLAM with Closed Shape Features: Fourier Series Parameterization and Submap  Joining</td><td>5357</td></tr><tr><td>A Switching-Coupled Backend for Simultaneous Localization and Dynamic Object Tracking</td><td>5365</td></tr><tr><td><strong>Session</strong> TuAT12 : Localization and Mapping VII</td><td></td></tr><tr><td>B-Splines for Purely Vision-Based Localization and Mapping on Non-Holonomic Ground Vehicles</td><td>5374</td></tr><tr><td>Robust SRIF-Based LiDAR-IMU Localization for Autonomous Vehicles</td><td>5381</td></tr><tr><td>Structure Reconstruction Using Ray-Point-Ray Features: Representation and Camera Pose  Estimation</td><td>5388</td></tr><tr><td>Lightweight 3-D Localization and Mapping for Solid-State LiDAR</td><td>5395</td></tr><tr><td><strong>Session</strong> TuHT8 : Localization and Mapping VIII</td><td></td></tr><tr><td>Simultaneous Estimation and Modeling of Robotic Systems with Non-Gaussian State Belief</td><td>5403</td></tr><tr><td>Efficient Online Calibration for Autonomous Vehicle’s Longitudinal Dynamical System: A Gaussian  Model Approach</td><td>5410</td></tr><tr><td>Fuzzing Mobile Robot Environments for Fast Automated Crash Detection</td><td>5417</td></tr><tr><td>Multimodal Safety-Critical Scenarios Generation for Decision-Making Algorithms Evaluation</td><td>5424</td></tr><tr><td><strong>Session</strong> TuBT12 : Localization and Mapping X</td><td></td></tr><tr><td>Intelligent Reference Curation for Visual Place Recognition Via Bayesian Selective Fusion</td><td>5432</td></tr><tr><td>Accelerating Probabilistic Volumetric Mapping Using Ray-Tracing Graphics Hardware</td><td>5440</td></tr><tr><td>ERASOR: Egocentric Ratio of Pseudo Occupancy-Based Dynamic Object Removal for Static 3D  Point Cloud Map Building</td><td>5446</td></tr><tr><td>UVIP: Robust UWB Aided Visual-Inertial Positioning System for Complex Indoor Environments</td><td>5454</td></tr><tr><td><strong>Session</strong> TuIT8 : Localization and Mapping XI</td><td></td></tr><tr><td>Do We Need to Compensate for Motion Distortion and Doppler Effects in Spinning Radar  Navigation?</td><td>5461</td></tr><tr><td>Robust Place Recognition Using an Imaging Lidar</td><td>5469</td></tr><tr><td>High-Speed Robot Navigation Using Predicted Occupancy Maps</td><td>5476</td></tr><tr><td><strong>Session</strong> TuCT12 : Localization and Mapping XII</td><td></td></tr><tr><td>Signal Temporal Logic Synthesis As Probabilistic Inference</td><td>5483</td></tr><tr><td>Bias Compensated UWB Anchor Initialization Using Information-Theoretic Supported Triangulation  Points</td><td>5490</td></tr><tr><td>Multiresolution Representations for Large-Scale Terrain with Local Gaussian Process Regression</td><td>5497</td></tr><tr><td>DiSCO: Differentiable Scan Context with Orientation</td><td>5504</td></tr><tr><td><strong>Session</strong> TuCT11 : Localization and Mapping XIII</td><td></td></tr><tr><td>FAST-LIO: A Fast, Robust LiDAR-Inertial Odometry Package by Tightly-Coupled Iterated Kalman  Filter</td><td>5512</td></tr><tr><td>BALM: Bundle Adjustment for Lidar Mapping</td><td>5520</td></tr><tr><td>Extrinsic Calibration of Multiple LiDARs of Small FoV in Targetless Environments</td><td>5528</td></tr><tr><td>MOLTR: Multiple Object Localisation, Tracking and Reconstruction from Monocular RGB Videos</td><td>5536</td></tr><tr><td>Efficient Modification of the Upper Triangular Square Root Matrix on Variable Reordering</td><td>5544</td></tr><tr><td><strong>Session</strong> WeBT2 : Localization and Mapping: Dataset</td><td></td></tr><tr><td>VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic  Environments</td><td>5552</td></tr><tr><td>A Multi-spectral Dataset for Evaluating Motion Estimation Systems</td><td>5560</td></tr><tr><td>PicoVO: A Lightweight RGB-D Visual Odometry Targeting Resource-Constrained IoT Devices</td><td>5567</td></tr><tr><td>3D Surfel Map-Aided Visual Relocalization with Learned Descriptors</td><td>5574</td></tr><tr><td><strong>Session</strong> TuJT8 : Localization and Mapping: Distributed Systems</td><td></td></tr><tr><td>Invariant Extended Kalman Filtering Using Two Position Receivers for Extended Pose Estimation</td><td>5582</td></tr><tr><td>Compartmentalized Covariance Intersection: A Novel Filter Architecture for Distributed Localization</td><td>5589</td></tr><tr><td>Optimizing Non-Markovian Information Gain under Physics-Based Communication Constraints</td><td>5596</td></tr><tr><td>Towards Robust State Estimation by Boosting the Maximum Correntropy Criterion Kalman Filter  with Adaptive Behaviors</td><td>5603</td></tr><tr><td><strong>Session</strong> TuFT9 : Localization and Mapping: LiDAR</td><td></td></tr><tr><td>Robust LiDAR Feature Localization for Autonomous Vehicles Using Geometric Fingerprinting on  Open Datasets</td><td>5610</td></tr><tr><td>RADIATE: A Radar Dataset for Automotive Perception in Bad Weather</td><td>5617</td></tr><tr><td>Poisson Surface Reconstruction for LiDAR Odometry and Mapping</td><td>5624</td></tr><tr><td>Lidar-Monocular Surface Reconstruction Using Line Segments</td><td>5631</td></tr><tr><td><strong>Session</strong> TuGT9 : Localization and Mapping: Point Cloud</td><td></td></tr><tr><td>SKD: Keypoint Detection for Point Clouds Using Saliency Estimation</td><td>5638</td></tr><tr><td>Panoster: End-To-End Panoptic Segmentation of LiDAR Point Clouds</td><td>5646</td></tr><tr><td>NDT-Transformer: Large-Scale 3D Point Cloud Localisation Using the Normal Distribution  Transform Representation</td><td>5654</td></tr><tr><td>PHASER: A Robust and Correspondence-Free Global Pointcloud Registration</td><td>5661</td></tr><tr><td><strong>Session</strong> TuKT8 : Localization and Mapping: Sensor Fusion I</td><td></td></tr><tr><td>Asynchronous Multi-View SLAM</td><td>5669</td></tr><tr><td>Fusion-DHL: WiFi, IMU, and Floorplan Fusion for Dense History of Locations in Indoor  Environments</td><td>5677</td></tr><tr><td>Relative Position Estimation between Two UWB Devices with IMUs</td><td>5684</td></tr><tr><td>LVI-SAM: Tightly-Coupled Lidar-Visual-Inertial Odometry Via Smoothing and Mapping</td><td>5692</td></tr><tr><td><strong>Session</strong> TuHT7 : Localization and Mapping: Sensor Fusion II</td><td></td></tr><tr><td>Visual-Laser-Inertial SLAM Using a Compact 3D Scanner for Confined Space</td><td>5699</td></tr><tr><td>Efficient Multi-Sensor Aided Inertial Navigation with Online Calibration</td><td>5706</td></tr><tr><td>Robust Monocular Visual-Inertial Depth Completion for Embedded Systems</td><td>5713</td></tr><tr><td>Range-Visual-Inertial Odometry: Scale Observability without Excitation</td><td>5720</td></tr><tr><td><strong>Session</strong> TuIT7 : Localization and Mapping: Sensor Fusion III</td><td></td></tr><tr><td>Reconfigurable Curved Beams for Selectable Swimming Gaits in an Underwater Robot</td><td>5728</td></tr><tr><td>Airflow-Inertial Odometry for Resilient State Estimation on Multirotors</td><td>5736</td></tr><tr><td>Cirrus: A Long-Range Bi-Pattern LiDAR Dataset</td><td>5744</td></tr><tr><td>π-LSAM: LiDAR Smoothing and Mapping with Planes</td><td>5751</td></tr><tr><td><strong>Session</strong> TuJT7 : Localization for Robotics</td><td></td></tr><tr><td>Improving Ranging-Based Location Estimation with Rigidity-Constrained CRLB-Based Motion  Planning</td><td>5758</td></tr><tr><td>Relative Position Estimation in Multi-Agent Systems Using Attitude-Coupled Range Measurements</td><td>5765</td></tr><tr><td>Vehicle-To-Vehicle Collaborative Graph-Based Proprioceptive Localization</td><td>5772</td></tr><tr><td>Rover Relocalization for Mars Sample Return by Virtual Template Synthesis and Matching</td><td>5780</td></tr><tr><td>Thrush, Tristan; Van der Merwe, Mark; Maggiolino, Gerard; Brinkman, Alexander; Mayo,</td><td></td></tr><tr><td>John; Cheng, Yang; Padgett, Curtis; Kulczycki, Eric; Detry, Renaud</td><td></td></tr><tr><td><strong>Session</strong> TuDT8 : Localization I</td><td></td></tr><tr><td>Global Aerial Localisation Using Image and Map Embeddings</td><td>5788</td></tr><tr><td>UWB Indoor Global Localisation for Nonholonomic Robots with Unknown Offset Compensation</td><td>5795</td></tr><tr><td>Range Image-Based LiDAR Localization for Autonomous Vehicles</td><td>5802</td></tr><tr><td>RadarLoc: Learning to Relocalize in FMCW Radar</td><td>5809</td></tr><tr><td><strong>Session</strong> TuET8 : Localization II</td><td></td></tr><tr><td>Freetures: Localization in Signed Distance Function Maps</td><td>5816</td></tr><tr><td>End-To-End Semi-Supervised Learning for Differentiable Particle Filters</td><td>5825</td></tr><tr><td>Self-Supervised Learning of Domain-Invariant Local Features for Robust Visual Localization under  Challenging Conditions</td><td>5832</td></tr><tr><td>Learning to Localize in New Environments from Synthetic Training Data</td><td>5840</td></tr><tr><td><strong>Session</strong> TuFT8 : Localization III</td><td></td></tr><tr><td>SoftMP: Attentive feature pooling for joint local feature detection and description for place  recognition in changing environments</td><td>5847</td></tr><tr><td>Resolving Place Recognition Inconsistencies Using Intra-Set Similarities</td><td>5854</td></tr><tr><td>Beyond ANN: Exploiting Structural Knowledge for Efficient Place Recognition</td><td>5861</td></tr><tr><td>Simultaneous Multi-Level Descriptor Learning and Semantic Segmentation for Domain-Specific  Relocalization</td><td>5868</td></tr><tr><td><strong>Session</strong> TuBT11 : Localization IV</td><td></td></tr><tr><td>GCC-PHAT with Speech-Oriented Attention for Robotic Sound Source Localization</td><td>5876</td></tr><tr><td>Towards Robust GNSS Positioning and Real-Time Kinematic Using Factor Graph Optimization</td><td>5884</td></tr><tr><td>Camera Relocalization Using Deep Point Cloud Generation and Hand-Crafted Feature Refinement</td><td>5891</td></tr><tr><td>Semantic Histogram Based Graph Matching for Real-Time Multi-Robot Global Localization in  Large Scale Environment</td><td>5898</td></tr><tr><td><strong>Session</strong> TuKT7 : Machine Learning for Control</td><td></td></tr><tr><td>Reinforced iLQR: A Sample-Efficient Robot Locomotion Learning</td><td>5906</td></tr><tr><td>Scalable Learning of Safety Guarantees for Autonomous Systems Using Hamilton-Jacobi  Reachability</td><td>5914</td></tr><tr><td>OmniHang: Learning to Hang Arbitrary Objects Using Contact Point Correspondences and Neural  Collision Estimation</td><td>5921</td></tr><tr><td><strong>Session</strong> TuAT11 : Machine Learning for Pose Estimation</td><td></td></tr><tr><td>HueCode: A Meta-Marker Exposing Relative Pose and Additional Information in Different Colored  Layers</td><td>5928</td></tr><tr><td>REDE: End-To-End Object 6D Pose Robust Estimation Using Differentiable Outliers Elimination</td><td>5935</td></tr><tr><td>PREGAN: Pose Randomization and Estimation for Weakly Paired Image Style Translation</td><td>5943</td></tr><tr><td>Deep Samplable Observation Model for Global Localization and Kidnapping</td><td>5951</td></tr><tr><td><strong>Session</strong> TuGT8 : Machine Learning for Robotic Applications</td><td></td></tr><tr><td>Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour</td><td>5959</td></tr><tr><td>Model Identification of a Small Fully-Actuated Aquatic Surface Vehicle Using a Long Short-Term  Memory Neural Network</td><td>5966</td></tr><tr><td>Real-Time Trajectory Adaptation for Quadrupedal Locomotion Using Deep Reinforcement Learning</td><td>5973</td></tr><tr><td>Robust Iterative Learning Control for Pneumatic Muscle with State Constraint and Model  Uncertainty</td><td>5980</td></tr><tr><td><strong>Session</strong> TuHT6 : Machine Learning I</td><td></td></tr><tr><td>MCMC Occupancy Grid Mapping with a Data-Driven Patch Prior</td><td>5988</td></tr><tr><td>Shape-Based Transfer of Generic Skills</td><td>5996</td></tr><tr><td>Safety Uncertainty in Control Barrier Functions Using Gaussian Processes</td><td>6003</td></tr><tr><td>Object Rearrangement Using Learned Implicit Collision Functions</td><td>6010</td></tr><tr><td><strong>Session</strong> TuIT6 : Machine Learning II</td><td></td></tr><tr><td>Continual Learning of Knowledge Graph Embeddings</td><td>6018</td></tr><tr><td>Learning Topology from Synthetic Data for Unsupervised Depth Completion</td><td>6026</td></tr><tr><td>PTP: Parallelized Tracking and Prediction with Graph Neural Networks and Diversity Sampling</td><td>6034</td></tr><tr><td>Feedback Linearization for Quadrotors with a Learned Acceleration Error Model</td><td>6042</td></tr><tr><td><strong>Session</strong> TuJT6 : Machine Learning Method for Navigation</td><td></td></tr><tr><td>Bi-Directional Domain Adaptation for Sim2Real Transfer of Embodied Navigation Agents</td><td>6049</td></tr><tr><td>DWA-RL: Dynamically Feasible Deep Reinforcement Learning Policy for Robot Navigation among  Mobile Obstacles</td><td>6057</td></tr><tr><td>Reinforcement Learning for Autonomous Driving with Latent State Inference and Spatial-Temporal  Relationships</td><td>6064</td></tr><tr><td>A Lifelong Learning Approach to Mobile Robot Navigation</td><td>6072</td></tr><tr><td><strong>Session</strong> TuKT6 : Machine Learning: Adaptive Systems</td><td></td></tr><tr><td>APPLI: Adaptive Planner Parameter Learning from Interventions</td><td>6079</td></tr><tr><td>APPLR: Adaptive Planner Parameter Learning from Reinforcement</td><td>6086</td></tr><tr><td>An Adaptive Framework For Learning Unsupervised Depth Completion</td><td>6093</td></tr><tr><td>PennSyn2Real: Training Object Recognition Models without Human Labeling</td><td>6101</td></tr><tr><td><strong>Session</strong> TuAT10 : Machine Learning: Applications</td><td></td></tr><tr><td>Robotic Indoor Scene Captioning from Streaming Video</td><td>6109</td></tr><tr><td>Geometry-Aware Unsupervised Domain Adaptation for Stereo Matching</td><td>6116</td></tr><tr><td>Reasoning Operational Decisions for Robots Via Time Series Causal Inference</td><td>6124</td></tr><tr><td>Embodying Pre-Trained Word Embeddings through Robot Actions</td><td>6132</td></tr><tr><td><strong>Session</strong> TuHT5 : Manipulation and Grasping I</td><td></td></tr><tr><td>Grasp Analysis and Manipulation Kinematics for Isoperimetric Truss Robots</td><td>6140</td></tr><tr><td>Improving Grasp Classification through Spatial Metrics Available from Sensors</td><td>6147</td></tr><tr><td>Assistive Supernumerary Grasping with the Back of the Hand</td><td>6154</td></tr><tr><td>Robotic Pick-and-Place With Uncertain Object Instance Segmentation and Shape Completion</td><td>6161</td></tr><tr><td><strong>Session</strong> TuIT5 : Manipulation and Grasping II</td><td></td></tr><tr><td>Learning Dexterous Grasping with Object-Centric Visual Affordances</td><td>6169</td></tr><tr><td>Learning Collaborative Pushing and Grasping Policies in Dense Clutter</td><td>6177</td></tr><tr><td>Grasping with Chopsticks: Combating Covariate Shift in Model-Free Imitation Learning for Fine  Manipulation</td><td>6185</td></tr><tr><td>Siddhartha Learning Task-Oriented Dexterous Grasping from Human Knowledge</td><td>6192</td></tr><tr><td><strong>Session</strong> TuJT5 : Manipulation and Grasping III</td><td></td></tr><tr><td>Decision Making in Joint Push-Grasp Action Space for Large-Scale Object Sorting</td><td>6199</td></tr><tr><td>Deep Affordance Foresight: Planning through What Can Be Done in the Future</td><td>6206</td></tr><tr><td>Learning Dense Rewards for Contact-Rich Manipulation Tasks</td><td>6214</td></tr><tr><td>Stefan ACRONYM: A Large-Scale Grasp Dataset Based on Simulation</td><td>6222</td></tr><tr><td><strong>Session</strong> TuAT2 : Manipulation Award Session</td><td></td></tr><tr><td>KPAM 2.0: Feedback Control for Category-Level Robotic Manipulation</td><td>6228</td></tr><tr><td>Policy Blending and Recombination for Multimodal Contact-Rich Tasks</td><td>6236</td></tr><tr><td><strong>Session</strong> TuBT10 : Manipulation Control I</td><td></td></tr><tr><td>Position and Orientation Control of Polygonal Objects by Sensorless In-Hand Caging Manipulation</td><td>6244</td></tr><tr><td>Non-Fixed Contact Manipulation Control Framework for Deformable Objects with Active Contact  Adjustment</td><td>6250</td></tr><tr><td>3D Biped Locomotion Control Including Seamless Transition between Walking and Running Via 3D  ZMP Manipulation</td><td>6258</td></tr><tr><td>Modeling and Balance Control of SuperArm for Overhead Tasks</td><td>6264</td></tr><tr><td><strong>Session</strong> TuCT10 : Manipulation Control II</td><td></td></tr><tr><td>Generation of Efficient Rectilinear Gait Based on Dynamic Morphological Computation and Its  Theoretical Analysis</td><td>6272</td></tr><tr><td>Simultaneous Precision Assembly of Multiple Objects through Coordinated Micro-Robot  Manipulation</td><td>6280</td></tr><tr><td>Dynamic Compensation in Throwing Motion with High-Speed Robot Hand-Arm</td><td>6287</td></tr><tr><td><strong>Session</strong> TuAT9 : Manipulation Control III</td><td></td></tr><tr><td>Introspective Visuomotor Control: Exploiting Uncertainty in Deep Visuomotor Control for Failure  Recovery</td><td>6293</td></tr><tr><td>Sim-To-Real Visual Grasping Via State Representation Learning Based on Combining Pixel-Level  and Feature-Level Domain Adaptation</td><td>6300</td></tr><tr><td>Dexterous Manoeuvre through Touch in a Cluttered Scene</td><td>6308</td></tr><tr><td>Mapless-Planner: A Robust and Fast Planning Framework for Aggressive Autonomous Flight  without Map Fusion</td><td>6315</td></tr><tr><td><strong>Session</strong> TuIT4 : Manipulation I</td><td></td></tr><tr><td>Contact Localization for Robot Arms in Motion without Torque Sensing</td><td>6322</td></tr><tr><td>Semi-Infinite Programming with Complementarity Constraints for Pose Optimization with Pervasive  Contact</td><td>6329</td></tr><tr><td>Finite Horizon Synthesis for Probabilistic Manipulation Domains</td><td>6336</td></tr><tr><td>IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks</td><td>6343</td></tr><tr><td><strong>Session</strong> TuJT4 : Manipulation II</td><td></td></tr><tr><td>Robotic Grasping through Combined Image-Based Grasp Proposal and 3D Reconstruction</td><td>6350</td></tr><tr><td>Attribute-Based Robotic Grasping with One-Grasp Adaptation</td><td>6357</td></tr><tr><td>Collision-Aware Target-Driven Object Grasping in Constrained Environments</td><td>6364</td></tr><tr><td>6-DoF Contrastive Grasp Proposal Network</td><td>6371</td></tr><tr><td><strong>Session</strong> TuKT4 : Manipulation III</td><td></td></tr><tr><td>RASCAL: Robotic Arm for Sherds and Ceramics Automated Locomotion</td><td>6378</td></tr><tr><td>Reactive Planning for Mobile Manipulation Tasks in Unexplored Semantic Environments</td><td>6385</td></tr><tr><td>Dynamic Grasping for Object Picking Using Passive Zero-DOF End Effectors</td><td>6393</td></tr><tr><td>Arm-Hand Systems As Hybrid Parallel-Serial Systems: A Novel Inverse Kinematics Solution</td><td>6401</td></tr><tr><td><strong>Session</strong> WeAT3 : Manipulation IV</td><td></td></tr><tr><td>An Integrated Approach for Determining Objects to Be Relocated and Their Goal Positions Inside  Clutter for Object Retrieval</td><td>6408</td></tr><tr><td>A Hybrid Position/Force Controller for Joint Robots</td><td>6415</td></tr><tr><td>DIMSAN: Fast Exploration with the Synergy between Density-Based Intrinsic Motivation and Self-Adaptive Action Noise</td><td>6422</td></tr><tr><td>A Unified Approach for Hybrid Motion Control of MOCA Based on Weighted Whole-Body Cartesian  Impedance Formulation</td><td>6429</td></tr><tr><td><strong>Session</strong> TuKT5 : Manipulation: Haptics</td><td></td></tr><tr><td>Tactile-RL for Insertion: Generalization to Objects of Unknown Geometry</td><td>6437</td></tr><tr><td>Sim-To-Real for Robotic Tactile Sensing Via Physics-Based Simulation and Learned Latent  Projections</td><td>6444</td></tr><tr><td>Fingers See Things Differently (FIST-D): An Object Aware Visualization and Manipulation  Framework Based on Tactile Observations</td><td>6452</td></tr><tr><td><strong>Session</strong> TuIT2 : Manipulation: Measurement</td><td></td></tr><tr><td>Mass Estimation of a Moving Object through Minimal Manipulation Interaction</td><td>6461</td></tr><tr><td>GelSight Wedge: Measuring High-Resolution 3D Contact Geometry with a Compact Robot Finger</td><td>6468</td></tr><tr><td>Identifying External Contacts from Joint Torque Measurements on Serial Robotic Arms and Its  Limitations</td><td>6476</td></tr><tr><td>Cable-Driven Parallel Robot Pose Estimation Using Extended Kalman Filtering with Inertial Payload  Measurements</td><td>6483</td></tr><tr><td>Session TuDT7 : Manipulation: PerceptionVision Based Adaptation to Kernelized Synergies for Human Inspired Robotic Manipulation</td><td>6491</td></tr><tr><td>Vision-Based Robotic Pushing and Grasping for Stone Sample Collection under Computing  Resource Constraints</td><td>6498</td></tr><tr><td>Friction Estimation for Tendon-Driven Robotic Hands</td><td>6505</td></tr><tr><td>Representation Matters: Improving Perception and Exploration for Robotics</td><td>6512</td></tr><tr><td>Ankush; Kulkarni, Tejas; Reynolds, Malcolm; Teplyashin, Denis; Hafner, Roland; Lampe,</td><td></td></tr><tr><td>Thomas; Riedmiller, Martin</td><td></td></tr><tr><td><strong>Session</strong> TuIT3 : Manipulation: Planning I</td><td></td></tr><tr><td>Contact Mode Guided Sampling-Based Planning for Quasistatic Dexterous Manipulation in 2D</td><td>6520</td></tr><tr><td>KPAM-SC: Generalizable Manipulation Planning Using KeyPoint Affordance and Shape  Completion</td><td>6527</td></tr><tr><td>Alternative Paths Planner (APP) for Provably Fixed-Time Manipulation Planning in Semi-Structured  Environments</td><td>6534</td></tr><tr><td>Hierarchical Planning for Long-Horizon Manipulation with Geometric and Symbolic Scene Graphs</td><td>6541</td></tr><tr><td><strong>Session</strong> TuJT3 : Manipulation: Planning II</td><td></td></tr><tr><td>Region-Based Planning for 3D Within-Hand-Manipulation via Variable Friction Robot Fingers and  Extrinsic Contacts</td><td>6549</td></tr><tr><td>Planning for Multi-Stage Forceful Manipulation</td><td>6556</td></tr><tr><td>Towards Robust Planar Translations Using Delta-Manipulator Arrays</td><td>6563</td></tr><tr><td>Manipulation Planning among Movable Obstacles Using Physics-Based Adaptive Motion Primitives</td><td>6570</td></tr><tr><td>Session TuET7 : Manipulation: Planning IIIReactive Cooperative Manipulation Based on Set Primitives and Circular Fields</td><td>6577</td></tr><tr><td>Sami Efficient Multi-Scale POMDPs for Robotic Object Search and Delivery</td><td>6585</td></tr><tr><td>Path Planning for Manipulation Using Experience-Driven Random Trees</td><td>6592</td></tr><tr><td>Co-Optimizing Robot, Environment, and Tool Design Via Joint Manipulation Planning</td><td>6600</td></tr><tr><td><strong>Session</strong> TuKT3 : Manipulation: Real World Applications</td><td></td></tr><tr><td>Robotic Slicing of Fruits and Vegetables: Modeling the Effects of Fracture Toughness and Knife  Geometry</td><td>6607</td></tr><tr><td>A Convex Quasistatic Time-Stepping Scheme for Rigid Multibody Systems with Contact and  Friction</td><td>6614</td></tr><tr><td>Uniform Object Rearrangement: From Complete Monotone Primitives to Efficient Non-Monotone  Informed Search</td><td>6621</td></tr><tr><td><strong>Session</strong> TuJT2 : Manipulation: Reinforcement Learning I</td><td></td></tr><tr><td>Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations Using Generative  Models</td><td>6628</td></tr><tr><td>DisCo RL: Distribution-Conditioned Reinforcement Learning for General-Purpose Policies</td><td>6635</td></tr><tr><td>Recovery RL: Safe Reinforcement Learning with Learned Recovery Zones</td><td>6642</td></tr><tr><td>LASER: Learning a Latent Action Space for Efficient Reinforcement Learning</td><td>6650</td></tr><tr><td>Session TuKT2 : Manipulation: Reinforcement Learning IIMulti-Step Recurrent Q-Learning for Robotic Velcro Peeling</td><td>6657</td></tr><tr><td>Reset-Free Reinforcement Learning Via Multi-Task Learning: Learning Dexterous Manipulation  Behaviors without Human Intervention</td><td>6664</td></tr><tr><td>Model Predictive Actor-Critic: Accelerating Robot Skill Acquisition with Deep Reinforcement  Learning</td><td>6672</td></tr><tr><td>Batch Exploration with Examples for Scalable Robotic Reinforcement Learning</td><td>6679</td></tr><tr><td><strong>Session</strong> TuFT7 : Mapping I</td><td></td></tr><tr><td>ManhattanSLAM: Robust Planar Tracking and Mapping Leveraging Mixture of Manhattan Frames</td><td>6687</td></tr><tr><td>Multi-Resolution 3D Mapping with Explicit Free Space Representation for Fast and Accurate Mobile  Robot Motion Planning</td><td>6694</td></tr><tr><td>Weighted Node Mapping and Localisation on a Pixel Processor Array</td><td>6702</td></tr><tr><td>Direct Sparse Mapping</td><td>6709</td></tr><tr><td><strong>Session</strong> TuGT7 : Mapping II</td><td></td></tr><tr><td>Dynamic Occupancy Grid Mapping with Recurrent Neural Networks</td><td>6717</td></tr><tr><td>Automatic Mapping of Tailored Landmark Representations for Automated Driving and Map  Learning</td><td>6725</td></tr><tr><td>Lightweight Semantic Mesh Mapping for Autonomous Vehicles</td><td>6732</td></tr><tr><td>LatentSLAM: Unsupervised Multi-Sensor Representation Learning for Localization and Mapping</td><td>6739</td></tr><tr><td><strong>Session</strong> TuIT0 : Marine RoboticsAutonomous Data Collection with Timed Communication Constraints for Unmanned Underwater</td><td></td></tr><tr><td>Vehicles</td><td>6746</td></tr><tr><td>Docking and Undocking a Modular Underactuated Oscillating Swimming Robot</td><td>6754</td></tr><tr><td>Predictive 3D Sonar Mapping of Underwater Environments via Object-Specific Bayesian Inference</td><td>6761</td></tr><tr><td><strong>Session</strong> WeAT7 : Mechanism and Control I</td><td></td></tr><tr><td>Reciprocally Rotating Magnetic Actuation and Automatic Trajectory Following for Wireless Capsule  Endoscopy</td><td>6768</td></tr><tr><td>Reduced Dynamics and Control for an Autonomous Bicycle</td><td>6775</td></tr><tr><td>Balance Control of a Novel Wheel-Legged Robot: Design and Experiments</td><td>6782</td></tr><tr><td>Blending of Series-Parallel Compliant Actuation with Field-Weakening Control for Explosive Motion  Generation</td><td>6789</td></tr><tr><td><strong>Session</strong> TuCT8 : Mechanism and Control II</td><td></td></tr><tr><td>Pneumatic Actuation-Based Bidirectional Modules with Variable Stiffness and Closed-Loop  Position Control</td><td>6797</td></tr><tr><td>A Capturability-Based Control Framework for the Underactuated Bipedal Walking</td><td>6804</td></tr><tr><td>Appearance-based Loop Closure Detection via Bidirectional Manifold Representation Consensus</td><td>6811</td></tr><tr><td>Synergetic Effect between Limbs and Spine Dynamics in Quadruped Walking Robots</td><td>6818</td></tr><tr><td><strong>Session</strong> TuJT0 : Mechanism and Verification</td><td></td></tr><tr><td>Assumption Monitoring Using Runtime Verification for UAV Temporal Task Plan Executions</td><td>6824</td></tr><tr><td>Sebastian Scalable POMDP Decision-Making Using Circulant Controllers</td><td>6831</td></tr><tr><td>Granular Resistive Force Theory Implementation for Three-Dimensional Trajectories</td><td>6838</td></tr><tr><td>Implicit Integration for Articulated Bodies with Contact Via the Nonconvex Maximal Dissipation  Principle</td><td>6846</td></tr><tr><td><strong>Session</strong> TuDT6 : Mechanism Design and Control I</td><td></td></tr><tr><td>Efficient and Goal-Directed Oscillations in Articulated Soft Robots: the Point-to-Point Case</td><td>6853</td></tr><tr><td>Visual Servoing of Cable-Driven Parallel Robots with Tension Management</td><td>6861</td></tr><tr><td>Automated design of underactuated monolithic soft robotics structures with multiple predefined end  poses</td><td>6868</td></tr><tr><td>Design and Control of a Highly Redundant Rigid–Flexible Coupling Robot to Assist the COVID-19 Oropharyngeal-Swab Sampling</td><td>6875</td></tr><tr><td><strong>Session</strong> TuET6 : Mechanism Design and Control II</td><td></td></tr><tr><td>Multifunctional Arm for Telerobotic Wind Turbine Blade Repair</td><td>6883</td></tr><tr><td>Modeling, Gait Sequence Design, and Control Architecture of BADGER Underground Robot</td><td>6890</td></tr><tr><td>Automated Behavior Tree Error Recovery Framework for Robotic Systems</td><td>6898</td></tr><tr><td>Design of a Magnetic Actuation System for a Microbiota-Collection Ingestible Capsule</td><td>6905</td></tr><tr><td><strong>Session</strong> TuBT9 : Mechanism Design IDevelopment of a Humanoid Shoulder Based on 3-Motor 3 Degrees-Of-Freedom Coupled</td><td></td></tr><tr><td>Tendon-Driven Joint Module</td><td>6912</td></tr><tr><td>Mecanum Crank: A Novel Omni-Directional Vehicle Using Crank Leg</td><td>6919</td></tr><tr><td>Internally-Balanced Displacement-Force Converter for Stepless Control of Spring Deformation  Compensated by Cam with Variable Pressure Angle</td><td>6925</td></tr><tr><td>2-DOF Spherical Parallel Mechanism Capable of Biaxial Swing Motion with Active Arc Sliders</td><td>6933</td></tr><tr><td><strong>Session</strong> TuCT9 : Mechanism Design II</td><td></td></tr><tr><td>A Locally-Adaptive, Parallel-Jaw Gripper with Clamping and Rolling Capable, Soft Fingertips for  Fine Manipulation of Flexible Flat Cables</td><td>6941</td></tr><tr><td>Stable, Sensor-Less and Compliance-Less Module Connection for Automated Construction  System of a Modularized Rail Structure</td><td>6948</td></tr><tr><td>Numerical Simulations of A Novel Force Controller Serially Combining The Admittance and  Impedance Controllers</td><td>6955</td></tr><tr><td>Kinematic Stability Based AFG-RRT* Path Planning for Cable-Driven Parallel Robots</td><td>6963</td></tr><tr><td><strong>Session</strong> WeAT4 : Mechanism Design III</td><td></td></tr><tr><td>Implementing Rat-Like Motion for a Small-Sized Biomimetic Robot Based on Extraction of Key  Movement Joints</td><td>6970</td></tr><tr><td>Design and Testing of a Damped Piezo-Driven Decoupled XYZ Stage</td><td>6986</td></tr><tr><td>Innovative Design and Simulation of a Transformable Robot with Flexibility and Versatility, RHex-T3</td><td>6992</td></tr><tr><td>A Variable Stiffness Actuator Based on Second-order Lever Mechanism and Its Manipulator  Integration</td><td>6999</td></tr><tr><td><strong>Session</strong> TuAT8 : Mechanism Design IV</td><td></td></tr><tr><td>Temperature Compensated 3D Printed Strain Sensor for Advanced Manufacturing Applications</td><td>7006</td></tr><tr><td>Design of a Deployable Underwater Robot for the Recovery of Autonomous Underwater Vehicles  Based on Origami Technique</td><td>7013</td></tr><tr><td>Modelling and Optimisation of a Mechanism-Based Metamaterial for a Wrist Flexion-Extension  Assistive Device</td><td>7020</td></tr><tr><td>Mechatronic Design of a Low-Noise Active Knee Prosthesis with High Backdrivability</td><td>7027</td></tr><tr><td><strong>Session</strong> TuBT8 : Mechanism Design V</td><td></td></tr><tr><td>Restoring Force Design of Active Self-Healing Tension Transmission System and Application to  Tendon-Driven Legged Robot</td><td>7033</td></tr><tr><td>A Translational Parallel Continuum Robot Reinforced by Origami and Cross-Routing Tendons</td><td>7039</td></tr><tr><td>Design of a 3-DOF Coupled Tendon-Driven Waist Joint</td><td>7046</td></tr><tr><td>Design and Modeling of a Variable-Stiffness Spring Mechanism for Impedance Modulation in  Physical Human–Robot Interaction</td><td>7052</td></tr><tr><td><strong>Session</strong> TuKT0 : Mechanism Design VII</td><td></td></tr><tr><td>Exploratory Hand: Leveraging Safe Contact to Facilitate Manipulation in Cluttered Spaces</td><td>7058</td></tr><tr><td>An Autonomous Vault-Building Robot System for Creating Spanning Structures</td><td>7066</td></tr><tr><td>Towards the Unification of System Design and Motion Synthesis for High-Performance Hopping  Robots</td><td>7073</td></tr><tr><td><strong>Session</strong> ThJT7 : Mechanism Design VI</td><td></td></tr><tr><td>Neural Fidelity Warping for Efficient Robot Morphology Design</td><td>7079</td></tr><tr><td>Computational Design and Fabrication of Corrugated Mechanisms from Behavioral Specifications</td><td>7087</td></tr><tr><td>Human Driven Compliant Transmission Mechanism</td><td>7094</td></tr><tr><td>Design Paradigms Based on Spring Agonists for Underactuated Robot Hands: Concepts and  Application</td><td>7100</td></tr><tr><td><strong>Session</strong> TuDT3 : Mechatronics and Design Award Session</td><td></td></tr><tr><td>Soft Hybrid Aerial Vehicle Via Bistable Mechanism</td><td>7107</td></tr><tr><td>A Versatile Inverse Kinematics Formulation for Retargeting Motions Onto Robots with Kinematic  Loops</td><td>7114</td></tr><tr><td><strong>Session</strong> TuAT7 : Medical Imaging and Sensing I</td><td></td></tr><tr><td>Robust Three-Dimensional Shape Sensing for Flexible Endoscopic Surgery Using Multi-Core FBG  Sensors</td><td>7122</td></tr><tr><td>Robot-To-Image Registration with Geometric Marker for CT-Guided Robotic Needle Insertion</td><td>7130</td></tr><tr><td>Shape Sensor Using Magnetic Induction with Frequency Sweeping for Medical Catheters</td><td>7137</td></tr><tr><td>Robotically Surgical Vessel Localization Using Robust Hybrid Video Motion Magnification</td><td>7144</td></tr><tr><td><strong>Session</strong> WeAT6 : Medical Imaging and Sensing II</td><td></td></tr><tr><td>Generalized Point Set Registration with the Kent Distribution</td><td>7151</td></tr><tr><td>Self-Supervised Learning for Monocular Depth Estimation on Minimally Invasive Surgery Scenes</td><td>7159</td></tr><tr><td>Dianmin; Doermann, DavidIntermittent Visual Servoing: Efficiently Learning Policies Robust to Instrument Changes for High-Precision Surgical Manipulation</td><td>7166</td></tr><tr><td>Towards Fully Autonomous Ultrasound Scanning Robot with Imitation Learning Based on Clinical  Protocols</td><td>7174</td></tr><tr><td><strong>Session</strong> ThKT6 : Micro/Nano Robotics I</td><td></td></tr><tr><td>Tailored Magnetic Torsion Springs for Miniature Magnetic Robots</td><td>7182</td></tr><tr><td>Real-Time Teleoperation of Magnetic Force-Driven Microrobots with 3D Haptic Force Feedback for  Micro-Navigation and Micro-Transportation</td><td>7189</td></tr><tr><td>Yaw Control of a Hovering Flapping-Wing Aerial Vehicle with a Passive Wing Hinge</td><td>7197</td></tr><tr><td>Automated End-Effector Alignment for Robotic Cell Manipulation</td><td>7205</td></tr><tr><td>A High-Voltage Power Electronics Unit for Flying Insect Robots That Can Modulate Wing Thrust</td><td>7212</td></tr><tr><td><strong>Session</strong> ThKT7 : Micro/Nano Robotics III</td><td></td></tr><tr><td>Residual Model Learning for Microrobot Control</td><td>7219</td></tr><tr><td>Small Autonomous Robot Actuator (SARA): A Solar-Powered Wireless MEMS Gripper</td><td>7227</td></tr><tr><td>Path Planning and Tracking for an Underactuated Two-Microrobot System</td><td>7234</td></tr><tr><td>Tiny Robot Learning (tinyRL) for Source Seeking on a Nano Quadcopter</td><td>7242</td></tr><tr><td><strong>Session</strong> WeCT4 : Micro/Nano Robotics IV</td><td></td></tr><tr><td>Micro Robotic Manipulation System for the Force Stimulation of Muscle Fiber-Like Cell Structure</td><td>7249</td></tr><tr><td>Fukuda, ToshioAutomated Fabrication of the High-Fidelity Cellular Micro-Scaffold through Proportion-Corrective  Control of the Photocuring Process</td><td>7255</td></tr><tr><td>A Versatile Vision-Pheromone-Communication Platform for Swarm Robotics</td><td>7261</td></tr><tr><td>3D Periodic Magnetic Servoing System for Microrobot Actuation Using Decoupled Asynchronous  Repetitive Control Approach</td><td>7267</td></tr><tr><td><strong>Session</strong> WeBT6 : Micro/Nano Robotis II</td><td></td></tr><tr><td>Modeling and Control of an Untethered Magnetic Gripper</td><td>7274</td></tr><tr><td>A Flexible Magnetic Field Mapping Model for Calibration of Magnetic Manipulation System</td><td>7281</td></tr><tr><td>Dynamic Tracking of Microrobot with Active Magnetic Sensor Array</td><td>7288</td></tr><tr><td>Dynamic Modeling of Magnetic Helical Microrobots</td><td>7295</td></tr><tr><td><strong>Session</strong> ThJT6 : Model Learning for Control</td><td></td></tr><tr><td>Batteries, Camera, Action! Learning a Semantic Control Space for Expressive Robot  Cinematography</td><td>7302</td></tr><tr><td>Sim-To-Real Learning of All Common Bipedal Gaits Via Periodic Reward Composition</td><td>7309</td></tr><tr><td>Agile Robot Navigation through Hallucinated Learning and Sober Deployment</td><td>7316</td></tr><tr><td>Nonholonomic Yaw Control of an Underactuated Flying Robot with Model-Based Reinforcement  Learning</td><td>7323</td></tr><tr><td><strong>Session</strong> ThHT19 : Model Predictive Control I</td><td></td></tr><tr><td>High-Frequency Nonlinear Model Predictive Control of a Manipulator</td><td>7330</td></tr><tr><td>Adaptive Nonlinear Model Predictive Control for Autonomous Surface Vessels with Largely Varying  Payload</td><td>7337</td></tr><tr><td>Time-Varying Model Predictive Control for Highly Dynamic Motions of Quadrupedal Robots</td><td>7344</td></tr><tr><td>Koopman NMPC: Koopman-Based Learning and Nonlinear Model Predictive Control of Control-Affine Systems</td><td>7350</td></tr><tr><td><strong>Session</strong> ThHT6 : Model Predictive Control II</td><td></td></tr><tr><td>ALTRO-C: A Fast Solver for Conic Model-Predictive Control</td><td>7357</td></tr><tr><td>Model Predictive Control of Nonlinear Latent Force Models: A Scenario-Based Approach</td><td>7365</td></tr><tr><td>The Value of Planning for Infinite-Horizon Model Predictive Control</td><td>7372</td></tr><tr><td>Automatic Tuning for Data-Driven Model Predictive Control</td><td>7379</td></tr><tr><td><strong>Session</strong> WeCT5 : Motion and Path Planning I</td><td></td></tr><tr><td>Efficient Heuristic Generation for Robot Path Planning with Recurrent Generative Model</td><td>7386</td></tr><tr><td>Scalable Coverage Path Planning of Multi-Robot Teams for Monitoring Non-Convex Areas</td><td>7393</td></tr><tr><td>Time and Energy Optimized Trajectory Generation for Multi-Agent Constellation Changes</td><td>7400</td></tr><tr><td>Towards an Online RRT-Based Path Planning Algorithm forAckermann-Steering Vehicles</td><td>7407</td></tr><tr><td><strong>Session</strong> TuBT7 : Motion and Path Planning II</td><td></td></tr><tr><td>A Global-Local Coupling Two-Stage Path Planning Method for Mobile Robots</td><td>7414</td></tr><tr><td>Learn to Navigate Maplessly with Varied LiDAR Configurations: A Support Point-Based Approach</td><td>7422</td></tr><tr><td>Fast Replanning Multi-Heuristic A*</td><td>7430</td></tr><tr><td>Generating Large-Scale Trajectories Efficiently Using Double Descriptions of Polynomials</td><td>7436</td></tr><tr><td><strong>Session</strong> ThIT6 : Motion and Path Planning III</td><td></td></tr><tr><td>AXLE: Computationally-Efficient Trajectory Smoothing Using Factor Graph Chains</td><td>7443</td></tr><tr><td>Computationally-Efficient Roadmap-based Inspection Planning via Incremental Lazy Search</td><td>7449</td></tr><tr><td>Multi-Query Serverless Motion Planning for Fog Robotics</td><td>7457</td></tr><tr><td>Composable Geometric Motion Policies using Multi-Task Pullback Bundle Dynamical Systems</td><td>7464</td></tr><tr><td><strong>Session</strong> ThKT5 : Motion and Path Planning IV</td><td></td></tr><tr><td>A Gravity-Referenced Moving Frame for Vehicle Path Following Applications in 3D</td><td>7471</td></tr><tr><td>Safe, Optimal, Real-Time Trajectory Planning with a Parallel Constrained Bernstein Algorithm</td><td>7479</td></tr><tr><td>A Spatial Searching Method for Planning under Time Dependent Constraints for Eco-Driving in  Signalized Traffic Intersection</td><td>7495</td></tr><tr><td>A Generalized A* Algorithm for Finding Globally Optimal Paths in Weighted Colored Graphs</td><td>7503</td></tr><tr><td><strong>Session</strong> ThHT22 : Motion and Path Planning V</td><td></td></tr><tr><td>Chance Constrained Simultaneous Path Planning and Task Assignment with Bottleneck Objective</td><td>7510</td></tr><tr><td>Planning with Attitude</td><td>7517</td></tr><tr><td>Constrained Path Planning and Guidance in General Wind Fields</td><td>7526</td></tr><tr><td>LTO: Lazy Trajectory Optimization with Graph-Search Planning for High DOF Robots in Cluttered  Environments</td><td>7533</td></tr><tr><td><strong>Session</strong> ThIT22 : Motion Control for Manipulators I</td><td></td></tr><tr><td>Emergent Hand Morphology and Control from Optimizing Robust Grasps of Diverse Objects</td><td>7540</td></tr><tr><td>Generalizing Object-Centric Task-Axes Controllers Using Keypoints</td><td>7548</td></tr><tr><td>Dynamic Primitives and Optimal Feedback Control for the Manipulation of Complex Objects</td><td>7555</td></tr><tr><td>Learning Reactive and Predictive Differentiable Controllers for Switching Linear Dynamical Models</td><td>7563</td></tr><tr><td><strong>Session</strong> TuFT6 : Motion Control for Manipulators II</td><td></td></tr><tr><td>Globally Optimal Online Redundancy Resolution for Serial 7-DOF Kinematics Along SE(3) Trajectories</td><td>7570</td></tr><tr><td>A Real-Time-Capable Closed-Form Multi-Objective Redundancy Resolution Scheme for Seven-DoF Serial Manipulators</td><td>7577</td></tr><tr><td>Robot Arm Motion Planning Based on Geodesics</td><td>7585</td></tr><tr><td>FlexDMP - Extending Dynamic Movement Primitives towards Flexible Joint Robots</td><td>7592</td></tr><tr><td><strong>Session</strong> TuGT6 : Motion Estimation</td><td></td></tr><tr><td>Unsupervised 3D Motion Estimation of Vehicles Using ICP</td><td>7599</td></tr><tr><td>CNN-Based Ego-Motion Estimation for Fast MAV Maneuvers</td><td>7606</td></tr><tr><td>Mid-Air Range-Visual-Inertial Estimator Initialization for Micro Air Vehicles</td><td>7613</td></tr><tr><td>Pose Estimation for Vehicle-Mounted Cameras Via Horizontal and Vertical Planes</td><td>7620</td></tr><tr><td><strong>Session</strong> TuCT7 : Motion Planning and Control I</td><td></td></tr><tr><td>SA-LOAM: Semantic-Aided LiDAR SLAM with Loop Closure</td><td>7627</td></tr><tr><td>Reinforcement Learning-Based Visual Navigation with Information-Theoretic Regularization</td><td>7635</td></tr><tr><td>An On-Line POMDP Solver for Continuous Observation Spaces</td><td>7643</td></tr><tr><td><strong>Session</strong> TuAT6 : Motion Planning and Control II</td><td></td></tr><tr><td>NEO: A Novel Expeditious Optimisation Algorithm for Reactive Motion Control of Manipulators</td><td>7650</td></tr><tr><td>Optimized Method for Planning and Controlling the Somersault Motion of Quadruped Robot</td><td>7658</td></tr><tr><td>Motion Coupling Analysis for the Decoupled Design of a Two-Segment Notched Continuum Robot</td><td>7665</td></tr><tr><td>VINS-Motion: Tightly-Coupled Fusion of VINS and Motion Constraint</td><td>7672</td></tr><tr><td><strong>Session</strong> ThIT23 : Motion Planning for Aerial Robotics</td><td></td></tr><tr><td>The Reachable Set of a Drone: Exploring the Position Isochrones for a Quadcopter</td><td>7679</td></tr><tr><td>Two-Stage Trajectory Optimization for Flapping Flight with Data-Driven Models</td><td>7686</td></tr><tr><td>Online Trajectory Optimization for Dynamic Aerial Motions of a Quadruped Robot</td><td>7693</td></tr><tr><td>SwarmCCO: Probabilistic Reactive Collision Avoidance for Quadrotor Swarms under Uncertainty</td><td>7700</td></tr><tr><td>Session ThHT23 : Motion Planning for Autonomous VehiclePath Optimization for Ground Vehicles in Off-Road Terrain</td><td>7708</td></tr><tr><td>Robust &amp; Asymptotically Locally Optimal UAV-Trajectory Generation Based on Spline Subdivision</td><td>7715</td></tr><tr><td>Vehicle Trajectory Prediction Using Generative Adversarial Network with Temporal Logic Syntax  Tree Features</td><td>7722</td></tr><tr><td>Autonomous Vehicle Motion Planning Via Recurrent Spline Optimization</td><td>7730</td></tr><tr><td><strong>Session</strong> ThHT21 : Motion Planning for Surgical Robots</td><td></td></tr><tr><td>Bimanual Regrasping for Suture Needles Using Reinforcement Learning for Rapid Motion Planning</td><td>7737</td></tr><tr><td>Dual-Arm Needle Manipulation with the Da Vinci® Surgical Robot under Uncertainty</td><td>7744</td></tr><tr><td>Learning Surgical Motion Pattern from Small Data in Endoscopic Sinus and Skull Base Surgeries</td><td>7751</td></tr><tr><td>Backward Planning for a Multi-Stage Steerable Needle Lung Robot</td><td>7758</td></tr><tr><td><strong>Session</strong> ThIT21 : Motion Planning for Task-Specific Robots I</td><td></td></tr><tr><td>A Primitive-Based Approach to Good Seamanship Path Planning for Autonomous Surface Vessels</td><td>7767</td></tr><tr><td>A Scavenger Hunt for Service Robots</td><td>7774</td></tr><tr><td>Exploring Large and Complex Environments Fast and Efficiently</td><td>7781</td></tr><tr><td>Planning Laser-Forming Folding Motion with Thermal Simulation</td><td>7788</td></tr><tr><td>Session ThJT21 : Motion Planning for Task-Specific Robots IIRobot Development and Path Planning for Indoor Ultraviolet Light Disinfection</td><td>7795</td></tr><tr><td>Piecewise-Linear Motion Planning Amidst Static, Moving, or Morphing Obstacles</td><td>7802</td></tr><tr><td>Smooth Path Planning for Continuum Arms</td><td>7809</td></tr><tr><td>Anticipatory Path Planning for Continuum Arms in Dynamic Environments</td><td>7815</td></tr><tr><td><strong>Session</strong> TuDT5 : Motion Planning I</td><td></td></tr><tr><td>Reactive Navigation in Crowds for Non-holonomic Robots with Convex Bounding Shape</td><td>7821</td></tr><tr><td>NavRep: Unsupervised Representations for Reinforcement Learning of Robot Navigation in  Dynamic Human Environments</td><td>7829</td></tr><tr><td>Scenario-Based Trajectory Optimization in Uncertain Dynamic Environments</td><td>7836</td></tr><tr><td>High Speed Planning in Unknown Environments for Multirotors Considering Drag</td><td>7844</td></tr><tr><td><strong>Session</strong> TuET5 : Motion Planning II</td><td></td></tr><tr><td>Sparse Multilevel Roadmaps for High-Dimensional Robotic Motion Planning</td><td>7851</td></tr><tr><td>Saliency Features for 3D CAD-Data in the Context of Sampling-Based Motion Planning</td><td>7858</td></tr><tr><td>Search-Based Planning of Dynamic MAV Trajectories Using Local Multiresolution State Lattices</td><td>7865</td></tr><tr><td>Bench-MR: A Motion Planning Benchmark for Wheeled Mobile Robots</td><td>7872</td></tr><tr><td><strong>Session</strong> TuFT5 : Motion Planning III</td><td></td></tr><tr><td>Expansive Voronoi Tree: A Motion Planner for Assembly Sequence Planning</td><td>7880</td></tr><tr><td>MS2MP: A Min-Sum Message Passing Algorithm for Motion Planning</td><td>7887</td></tr><tr><td>Cubic Bézier Local Path Planner for Non-Holonomic Feasible and Comfortable Path Generation</td><td>7894</td></tr><tr><td>Voxplan: A 3D Global Planner Using Signed Distance Function Submaps</td><td>7901</td></tr><tr><td><strong>Session</strong> WeBT13 : Motion Planning in Automation</td><td></td></tr><tr><td>Prediction-Based Reachability for Collision Avoidance in Autonomous Driving</td><td>7908</td></tr><tr><td>Lane-free Autonomous Intersection Management: A Batch-processing Framework Integrating  Reservation-based and Planning-based Methods</td><td>7915</td></tr><tr><td>Pheromone-Diffusion-Based Conscientious Reactive Path Planning for Road Network Persistent  Surveillance</td><td>7922</td></tr><tr><td><strong>Session</strong> ThKT21 : Motion Planning in Multi-Agents System I</td><td></td></tr><tr><td>Towards Safe Motion Planning in Human Workspaces: A Robust Multi-Agent Approach</td><td>7929</td></tr><tr><td>Anytime Fault-Tolerant Adaptive Routing for Multi-Robot Teams</td><td>7936</td></tr><tr><td>Exploiting Collisions for Sampling-Based Multicopter Motion Planning</td><td>7943</td></tr><tr><td>Multi-Robot Motion Planning with Unlabeled Goals for Mobile Robots with Differential Constraints</td><td>7950</td></tr><tr><td><strong>Session</strong> ThHT20 : Motion Planning in Multi-Agents System II</td><td></td></tr><tr><td>A Visibility Roadmap Sampling Approach for a Multi-Robot Visibility-Based Pursuit-Evasion  Problem</td><td>7957</td></tr><tr><td>Time-Optimal Multi-Quadrotor Trajectory Planning for Pesticide Spraying</td><td>7965</td></tr><tr><td>Do You See What I See? Coordinating Multiple Aerial Cameras for Robot Cinematography</td><td>7972</td></tr><tr><td>MIDAS: Multi-Agent Interaction-Aware Decision-Making with Adaptive Strategies for Urban  Autonomous Navigation</td><td>7980</td></tr><tr><td><strong>Session</strong> ThIT20 : Motion Planning in Multi-Agents System III</td><td></td></tr><tr><td>Scalable Active Information Acquisition for Multi-Robot Systems</td><td>7987</td></tr><tr><td>MAPS-X: Explainable Multi-Robot Motion Planning Via Segmentation</td><td>7994</td></tr><tr><td>Representation-Optimal Multi-Robot Motion Planning Using Conflict-Based Search</td><td>8001</td></tr><tr><td>Spatial and Temporal Splitting Heuristics for Multi-Robot Motion Planning</td><td>8009</td></tr><tr><td><strong>Session</strong> ThJT20 : Motion Planning IV</td><td></td></tr><tr><td>Multi-Hypothesis Interactions in Game-Theoretic Motion Planning</td><td>8016</td></tr><tr><td>An Approximation Algorithm for an Assisted Shortest Path Problem</td><td>8024</td></tr><tr><td>TAMPC: A Controller for Escaping Traps in Novel Environments</td><td>8031</td></tr><tr><td>Projector-Guided Non-Holonomic Mobile 3D Printing</td><td>8039</td></tr><tr><td><strong>Session</strong> TuGT5 : Motion Planning V</td><td></td></tr><tr><td>Learning from Simulation, Racing in Reality</td><td>8046</td></tr><tr><td>Equality Constrained Differential Dynamic Programming</td><td>8053</td></tr><tr><td>Learning Constrained Distributions of Robot Configurations with Generative Adversarial Network</td><td>8060</td></tr><tr><td>Shape-Preserving and Reactive Adaptation of Robot End-Effector Trajectories</td><td>8068</td></tr><tr><td><strong>Session</strong> TuET4 : Motion Planning VI</td><td></td></tr><tr><td>Image Representation of a City and Its Taxi Fleet for End-To-End Learning of Rebalancing Policies</td><td>8076</td></tr><tr><td>COLREGs-Informed RRT* for Collision Avoidance of Marine Crafts</td><td>8083</td></tr><tr><td>Learning to Robustly Negotiate Bi-Directional Lane Usage in High-Conflict Driving Scenarios</td><td>8090</td></tr><tr><td>Self-Supervised Motion Retargeting with Safety Guarantee</td><td>8097</td></tr><tr><td><strong>Session</strong> ThKT20 : Motion Planning with Partial Information</td><td></td></tr><tr><td>Data-Based Control of Partially-Observed Robotic Systems</td><td>8104</td></tr><tr><td>Partial Information Target Defense Game</td><td>8111</td></tr><tr><td>Stochastic Motion Planning under Partial Observability for Mobile Robots with Continuous Range  Measurements</td><td>8118</td></tr><tr><td>Long-Horizon Motion Planning for Autonomous Vehicle Parking Incorporating Incomplete Map  Information</td><td>8135</td></tr><tr><td><strong>Session</strong> TuBT6 : Motion Planning: Autonomous Driving</td><td></td></tr><tr><td>ICurb: Imitation Learning-Based Detection of Road Curbs Using Aerial Images for Autonomous  Driving</td><td>8143</td></tr><tr><td>Search-Based Online Trajectory Planning for Car-Like Robots in Highly Dynamic Environments</td><td>8151</td></tr><tr><td>Task-Space Decomposed Motion Planning Framework for Multi-Robot Loco-Manipulation</td><td>8158</td></tr><tr><td>SMT-Based Optimal Deployment of Mobile Robot Rechargers</td><td>8165</td></tr><tr><td><strong>Session</strong> TuCT6 : Motion Planning: Collision Avoidance</td><td></td></tr><tr><td>VR-ORCA: Variable Responsibility Optimal Reciprocal Collision Avoidance</td><td>8172</td></tr><tr><td>Dynamic Window Approach with Human Imitating Collision Avoidance</td><td>8180</td></tr><tr><td>Disruption-Resistant Deformable Object Manipulation on Basis of Online Shape Estimation and  Prediction-Driven Trajectory Correction</td><td>8187</td></tr><tr><td>Dynamic Movement Primitive Based Motion Retargeting for Dual-Arm Sign Language Motions</td><td>8195</td></tr><tr><td><strong>Session</strong> TuFT4 : Motion Planning: Control</td><td></td></tr><tr><td>Whole Body Model Predictive Control with Memory of Motion: Experiments on a Torque-Controlled  TALOS</td><td>8202</td></tr><tr><td>Guilhem; Stasse, Olivier; Fernbach, Pierre; Tonneau, Steve; Calinon, Sylvain; Vijayakumar,</td><td></td></tr><tr><td>Sethu; Taïx, Michel; Mansard, Nicolas Constraint Handling in Continuous-Time DDP-Based Model Predictive Control</td><td>8209</td></tr><tr><td>Sparsity-Inducing Optimal Control Via Differential Dynamic Programming</td><td>8216</td></tr><tr><td>Sethu A Passive Navigation Planning Algorithm for Collision-Free Control of Mobile Robots</td><td>8223</td></tr><tr><td><strong>Session</strong> WeAT13 : Motion Planning: Decision</td><td></td></tr><tr><td>TIE: Time-Informed Exploration for Robot Motion Planning</td><td>8230</td></tr><tr><td>MRPB 1.0: A Unified Benchmark for the Evaluation of Mobile Robot Local Planning Approaches</td><td>8238</td></tr><tr><td>Belief Space Partitioning for Symbolic Motion Planning</td><td>8245</td></tr><tr><td>Anticipatory Planning and Dynamic Lost Person Models for Human-Robot Search and Rescue</td><td>8252</td></tr><tr><td><strong>Session</strong> TuGT4 : Motion Planning: Kinematics and Dynamics</td><td></td></tr><tr><td>The Virtual Wheel Concept for the Singularity-Free Kinematic and Dynamic Modeling of Pseudo-Omnidirectional Vehicles</td><td>8259</td></tr><tr><td>Collision-Free MPC for Legged Robots in Static and Dynamic Scenes</td><td>8266</td></tr><tr><td>Temporal Coupling of Dynamical Movement Primitives for Constrained Velocities and  Accelerations</td><td>8273</td></tr><tr><td>Obstacle Avoidance with Kinetic Energy Buffer</td><td>8280</td></tr><tr><td><strong>Session</strong> WeBT5 : Motion Planning: Learning</td><td></td></tr><tr><td>Tra2Tra: Trajectory-To-Trajectory Prediction with a Global Social Spatial-Temporal Attentive  Neural Network</td><td>8287</td></tr><tr><td>Remote-Center-Of-Motion Recommendation Toward Brain Needle Intervention Using Deep  Reinforcement Learning</td><td>8295</td></tr><tr><td>Autonomous Navigation of an Ultrasound Probe towards Standard Scan Planes with Deep  Reinforcement Learning</td><td>8302</td></tr><tr><td>A Knowledge-Based Fast Motion Planning Method through Online Environmental Feature Learning</td><td>8309</td></tr><tr><td><strong>Session</strong> TuAT5 : Motion Planning: Learning-Based Prediction</td><td></td></tr><tr><td>Uncertainty-aware Non-linear Model Predictive Control for Human-following Companion Robot</td><td>8316</td></tr><tr><td>Path Planning in Uncertain Ocean Currents Using Ensemble Forecasts</td><td>8323</td></tr><tr><td>Distributed Motion Coordination Using Convex Feasible Set Based Model Predictive Control</td><td>8330</td></tr><tr><td>Risk Conditioned Distributional Soft Actor-Critic for Risk-Sensitive Navigation</td><td>8337</td></tr><tr><td><strong>Session</strong> TuET3 : Motion Planning: Legged Robots</td><td></td></tr><tr><td>Optimization-Inspired Controller Design for Transient Legged Locomotion</td><td>8345</td></tr><tr><td>Multi-Layered Safety for Legged Robots Via Control Barrier Functions and Model Predictive Control</td><td>8352</td></tr><tr><td>Agile Actions with a Centaur-Type Humanoid: A Decoupled Approach</td><td>8359</td></tr><tr><td>Combined Sampling and Optimization Based Planning for Legged-Wheeled Robots</td><td>8366</td></tr><tr><td><strong>Session</strong> WeAT5 : Motion Planning: Manipulator</td><td></td></tr><tr><td>Robot Motion Planning with Human-Like Motion Patterns based on Human Arm Movement  Primitive Chains</td><td>8373</td></tr><tr><td>A Model-Free Synchronous Control of Humanoid Robot Finger</td><td>8380</td></tr><tr><td>An Overall Configuration Planning Method of Continuum Hyper-Redundant Manipulators Based on  Improved Artificial Potential Field Method</td><td>8386</td></tr><tr><td>Autonomous UAV Exploration of Dynamic Environments Via Incremental Sampling and  Probabilistic Roadmap</td><td>8394</td></tr><tr><td><strong>Session</strong> TuBT5 : Motion Planning: Optimization</td><td></td></tr><tr><td>Smooth-RRT*: Asymptotically Optimal Motion Planning for Mobile Robots under Kinodynamic  Constraints</td><td>8402</td></tr><tr><td>Continuous Optimization-Based Task and Motion Planning with Signal Temporal Logic  Specifications for Sequential Manipulation</td><td>8409</td></tr><tr><td>Proximal Policy Optimization with Relative Pearson Divergence</td><td>8416</td></tr><tr><td>Optimal Object Placement for Minimum Discontinuity Non-Revisiting Coverage Task</td><td>8422</td></tr><tr><td>Session TuCT5 : Motion Planning: Robot PerceptionActive Information Acquisition under Arbitrary Unknown Disturbances</td><td>8429</td></tr><tr><td>Real-Time Obstacle Avoidance with a Virtual Torque Approach for a Robotic Tool in the End  Effector</td><td>8436</td></tr><tr><td>A Robotic Platform to Navigate MRI-Guided Focused Ultrasound System</td><td>8443</td></tr><tr><td>Approximating Constraint Manifolds Using Generative Models for Sampling-Based Constrained  Motion Planning</td><td>8451</td></tr><tr><td><strong>Session</strong> TuBT4 : Motion Planning: Semantic Scene</td><td></td></tr><tr><td>Anticipatory Navigation in Crowds by Probabilistic Prediction of Pedestrian Future Movements</td><td>8458</td></tr><tr><td>Real-Time Human Lower Limbs Motion Estimation and Feedback for Potential Applications in  Robotic Gait Aid and Training</td><td>8465</td></tr><tr><td>Virtual Surfaces and Attitude Aware Planning and Behaviours for Negative Obstacle Navigation</td><td>8472</td></tr><tr><td>Cost-To-Go Function Generating Networks for High Dimensional Motion Planning</td><td>8480</td></tr><tr><td><strong>Session</strong> TuCT4 : Motion Planning: Task-Based Planning</td><td></td></tr><tr><td>Integrated Task Assignment and Path Planning for Capacitated Multi-Agent Pickup and Delivery</td><td>8487</td></tr><tr><td>Social Trajectory Planning for Urban Autonomous Surface Vessels</td><td>8495</td></tr><tr><td>A Geometric Folding Pattern for Robot Coverage Path Planning</td><td>8509</td></tr><tr><td>Tree Search-Based Task and Motion Planning with Prehensile and Non-Prehensile Manipulation  for Obstacle Rearrangement in Clutter</td><td>8516</td></tr><tr><td>Session TuFT3 : Motion PredictionDesign, Development and Validation of a Dynamic Fall Prediction System for Excavators</td><td>8523</td></tr><tr><td>Satoshi; Ragaglia, Matteo; Sugiura, Hisashi; Niccolini, Marta Feasible and Adaptive Multimodal Trajectory Prediction with Semantic Maneuver Fusion</td><td>8530</td></tr><tr><td>Exploiting Latent Representation of Sparse Semantic Layers for Improved Short-Term Motion  Prediction with Capsule Networks</td><td>8537</td></tr><tr><td>Movement Recognition and Prediction Using DMPs</td><td>8544</td></tr><tr><td><strong>Session</strong> ThJT22 : Motion Prediction in Navigation</td><td></td></tr><tr><td>Occupancy Map Inpainting for Online Robot Navigation</td><td>8551</td></tr><tr><td>Ellipse Loss for Scene-Compliant Motion Prediction</td><td>8558</td></tr><tr><td>Predictive Runtime Monitoring for Mobile Robots Using Logic-Based Bayesian Intent Inference</td><td>8565</td></tr><tr><td>BiTraP: Bi-Directional Pedestrian Trajectory Prediction with Multi-Modal Goal Estimation</td><td>8572</td></tr><tr><td>Graph-SIM: A Graph-Based Spatiotemporal Interaction Modelling for Pedestrian Action Prediction</td><td>8580</td></tr><tr><td><strong>Session</strong> ThJT19 : Multiple and Distributed Intelligence</td><td></td></tr><tr><td>Multi-Robot Distributed Semantic Mapping in Unfamiliar Environments through Online Matching of  Learned Representations</td><td>8587</td></tr><tr><td>Learning to Herd Agents Amongst Obstacles: Training Robust Shepherding Behaviors Using Deep  Reinforcement Learning</td><td>8594</td></tr><tr><td>Sensor Placement for Globally Optimal Coverage of 3D-Embedded Surfaces</td><td>8600</td></tr><tr><td>Reachability Analysis for FollowerStopper: Safety Analysis and Experimental Results</td><td>8607</td></tr><tr><td><strong>Session</strong> TuBT2 : Multiple and Distributed Systems I</td><td></td></tr><tr><td>PRIMAL2: Pathfinding Via Reinforcement and Imitation Multi-Agent Learning - Lifelong</td><td>8614</td></tr><tr><td>Consensus-Based Control Barrier Function for Swarm</td><td>8623</td></tr><tr><td>Bayesian Disturbance Injection: Robust Imitation Learning of Flexible Policies</td><td>8629</td></tr><tr><td>Active Modular Environment for Robot Navigation</td><td>8636</td></tr><tr><td><strong>Session</strong> TuCT2 : Multiple and Distributed Systems II</td><td></td></tr><tr><td>Command Filtered Tracking Control for High-Order Systems with Limited Transmission Bandwidth</td><td>8643</td></tr><tr><td>Online Trajectory Planning for Multiple Quadrotors in Dynamic Environments Using Relative Safe  Flight Corridor</td><td>8649</td></tr><tr><td>Multi-Scale Cost Volumes Cascade Network for Stereo Matching</td><td>8657</td></tr><tr><td>Hierarchical MCTS for Scalable Multi-Vessel Multi-Float Systems</td><td>8664</td></tr><tr><td><strong>Session</strong> TuBT3 : Multiple and Distributed Systems III</td><td></td></tr><tr><td>Deep Reinforcement Learning of Event-Triggered Communication and Control for Multi-Agent  Cooperative Transport</td><td>8671</td></tr><tr><td>Multi-Robot Task Allocation Games in Dynamically Changing Environments</td><td>8678</td></tr><tr><td>An Upper Confidence Bound for Simultaneous Exploration and Exploitation in Heterogeneous  Multi-Robot Systems</td><td>8685</td></tr><tr><td>Johnson, David; Yoo, Chanyeol; Fitch, RobertPriority Patrolling Using Multiple Agents</td><td>8692</td></tr><tr><td><strong>Session</strong> TuCT3 : Multiple and Distributed Systems IV</td><td></td></tr><tr><td>Distributed Heuristic Multi-Agent Path Finding with Communication</td><td>8699</td></tr><tr><td>Distributed PDOP Coverage Control: Providing Large-Scale Positioning Service Using a Multi-Robot System</td><td>8706</td></tr><tr><td>Autonomous Distributed System for Gait Generation for Single-Legged Modular Robots Connected  in Various Configurations</td><td>8714</td></tr><tr><td>A Distributed Two-Layer Framework for Teleoperated Platooning of Fixed-Wing UAVs Via  Decomposition and Backstepping</td><td>8734</td></tr><tr><td><strong>Session</strong> ThIT18 : Multiple and Distributed Systems IX</td><td></td></tr><tr><td>PuzzleBots: Physical Coupling of Robot Swarms</td><td>8742</td></tr><tr><td>Spatial Intention Maps for Multi-Agent Mobile Manipulation</td><td>8749</td></tr><tr><td>Flocking-Segregative Swarming Behaviors Using Gibbs Random Fields</td><td>8757</td></tr><tr><td>Multi-Agent Ergodic Coverage in Urban Environments</td><td>8764</td></tr><tr><td><strong>Session</strong> WeBT4 : Multiple and Distributed Systems V</td><td></td></tr><tr><td>Multi-Target Coverage with Connectivity Maintenance Using Knowledge-Incorporated Policy  Framework</td><td>8772</td></tr><tr><td>SMMR-Explore: SubMap-Based Multi-Robot Exploration System with Multi-Robot Multi-Target  Potential Field Exploration Method</td><td>8779</td></tr><tr><td>Multi-Objective Conflict-Based Search for Multi-Agent Path Finding</td><td>8786</td></tr><tr><td>Simultaneous Calibration of Multi-Coordinates for a Dual-Robot System by Solving the AXB=YCZ  Problem</td><td>8792</td></tr><tr><td><strong>Session</strong> WeAT11 : Multiple and Distributed Systems VI</td><td></td></tr><tr><td>Pylot: A Modular Platform for Exploring Latency-Accuracy Tradeoffs in Autonomous Vehicles</td><td>8806</td></tr><tr><td>Decentralized Circle Formation Control for Fish-Like Robots in Real-World Via Reinforcement  Learning</td><td>8814</td></tr><tr><td>Graph Connectivity Control of a Mobile Robot Network with Mixed Dynamic Multi-Tasks</td><td>8821</td></tr><tr><td>Distributed Rendezvous Control of Networked Uncertain Robotic Systems with Bearing  Measurements</td><td>8829</td></tr><tr><td><strong>Session</strong> ThJT18 : Multiple and Distributed Systems VII</td><td></td></tr><tr><td>Flow-FL: Data-Driven Federated Learning for Spatio-Temporal Predictions in Multi-Robot Systems</td><td>8836</td></tr><tr><td>CHORD: Distributed Data-Sharing Via Hybrid ROS 1 and 2 for Multi-Robot Exploration of Large-Scale Complex Environments</td><td>8843</td></tr><tr><td>ROS-NetSim: A Framework for the Integration of Robotic and Network Simulators</td><td>8851</td></tr><tr><td>Non-Monotone Energy-Aware Information Gathering for Heterogeneous Robot Teams</td><td>8859</td></tr><tr><td><strong>Session</strong> ThKT19 : Multiple and Distributed Systems VIII</td><td></td></tr><tr><td>Probabilistic Resilience of Dynamic Multi-Robot Systems</td><td>8866</td></tr><tr><td>Distributed Topology Correction for Flexible Connectivity Maintenance in Multi-Robot Systems</td><td>8874</td></tr><tr><td>Decentralized Nested Gaussian Processes for Multi-Robot Systems</td><td>8881</td></tr><tr><td>Cascaded Filtering Using the Sigma Point Transformation</td><td>8888</td></tr><tr><td><strong>Session</strong> ThHT18 : Multiple and Distributed Systems X</td><td></td></tr><tr><td>The Robotarium: Automation of a Remotely Accessible, Multi-Robot Testbed</td><td>8896</td></tr><tr><td>Multiplexing Robot Experiments: Theoretical Underpinnings, Conditions for Existence, and  Demonstrations</td><td>8904</td></tr><tr><td>SMAC: Symbiotic Multi-Agent Construction</td><td>8911</td></tr><tr><td>Efficient Multi-Robot Inspection of Row Crops Via Kernel Estimation and Region-Based Task  Allocation</td><td>8919</td></tr><tr><td><strong>Session</strong> ThKT18 : Multiple and Distributed Systems XI</td><td></td></tr><tr><td>An Adaptive Fuzzy Reinforcement Learning Cooperative Approach for the Autonomous Control of  Flock Systems</td><td>8927</td></tr><tr><td>Optimal Sequential Stochastic Deployment of Multiple Passenger Robots</td><td>8934</td></tr><tr><td>Online Connectivity-Aware Dynamic Deployment for Multi-Robot System</td><td>8941</td></tr><tr><td>Achieving Multitasking Robots in Multi-Robot Tasks</td><td>8948</td></tr><tr><td><strong>Session</strong> ThHT17 : Multiple and Distributed Systems: Control</td><td></td></tr><tr><td>Communication-Aware Multi-Robot Coordination with Submodular Maximization</td><td>8955</td></tr><tr><td>Controllability and Stabilization for Herding a Robotic Swarm Using a Leader: A Mean-Field  Approach</td><td>8962</td></tr><tr><td>Online Flocking Control of UAVs with Mean-Field Approximation</td><td>8977</td></tr><tr><td>Proportional and Reachable Cluster Teleoperation of a Distributed Multi-Robot System</td><td>8984</td></tr><tr><td><strong>Session</strong> ThIT17 : Multiple and Distributed Systems: Monitoring and Planning I</td><td></td></tr><tr><td>Planning of Heterogeneous Multi-Agent Systems under Signal Temporal Logic Specifications with  Integral Predicates</td><td>8991</td></tr><tr><td>Multi-Agent Aerial Monitoring of Moving Convoys using Elliptical Orbits</td><td>8999</td></tr><tr><td>LUCIDGames: Online Unscented Inverse Dynamic Games for Adaptive Trajectory Prediction and  Planning</td><td>9006</td></tr><tr><td>Event-Based Signal Temporal Logic Synthesis for Single and Multi-Robot Tasks</td><td>9014</td></tr><tr><td><strong>Session</strong> ThJT17 : Multiple and Distributed Systems: Monitoring and Planning II</td><td></td></tr><tr><td>Affordable Autonomy through Cooperative Sensing and Planning</td><td>9022</td></tr><tr><td>Reachable Polyhedral Marching (RPM): A Safety Verification Algorithm for Robotic Systems with Deep Neural Network Components</td><td>9029</td></tr><tr><td>Multi-Robot Dynamical Source Seeking in Unknown Environments</td><td>9036</td></tr><tr><td>Volumetric Objectives for Multi-Robot Exploration of Three-Dimensional Environments</td><td>9043</td></tr><tr><td><strong>Session</strong> ThKT17 : Multiple and Distributed Systems: Perception</td><td></td></tr><tr><td>Adaptation to Team Composition Changes for Heterogeneous Multi-Robot Sensor Coverage</td><td>9051</td></tr><tr><td>Distributed Multi-Target Tracking for Heterogeneous Mobile Sensing Networks with Limited Field of  Views</td><td>9058</td></tr><tr><td>Safety with Limited Range Sensing Constraints for Fixed Wing Aircraft</td><td>9065</td></tr><tr><td>A Queue-Stabilizing Framework for Networked Multi-Robot Exploration</td><td>9072</td></tr><tr><td><strong>Session</strong> ThHT16 : Multiple and Distributed Systems: Search Algorithm</td><td></td></tr><tr><td>Multi-Robot Gaussian Process Estimation and Coverage: A Deterministic Sequencing Algorithm  and Regret Analysis</td><td>9080</td></tr><tr><td>Multi-agent Receding Horizon Search with Terminal Cost</td><td>9086</td></tr><tr><td>Shaped Policy Search for Evolutionary Strategies Using Waypoints</td><td>9093</td></tr><tr><td>Multi-Agent Active Search Using Realistic Depth-Aware Noise Model</td><td>9101</td></tr><tr><td><strong>Session</strong> ThIT16 : Multiple and Distributed Systems: Task Allocation</td><td></td></tr><tr><td>Fair Robust Assignment Using Redundancy</td><td>9109</td></tr><tr><td>Fast Near-Optimal Heterogeneous Task Allocation Via Flow Decomposition</td><td>9117</td></tr><tr><td>Data-Driven Adaptive Task Allocation for Heterogeneous Multi-Robot Teams Using Robust Control  Barrier Functions</td><td>9124</td></tr><tr><td>Resilient Task Allocation in Heterogeneous Multi-Robot Systems</td><td>9131</td></tr><tr><td><strong>Session</strong> TuET2 : Multi-Robot Systems I</td><td></td></tr><tr><td>Self-Organised Saliency Detection and Representation in Robot Swarms</td><td>9139</td></tr><tr><td>A Practical Method to Cover Evenly a Dynamic Region with a Swarm</td><td>9147</td></tr><tr><td>Robust Distributed Estimation of the Algebraic Connectivity for Networked Multi-Robot Systems</td><td>9155</td></tr><tr><td>ModGNN: Expert Policy Approximation in Multi-Agent Systems with a Modular Graph Neural  Network Architecture</td><td>9161</td></tr><tr><td><strong>Session</strong> TuGT3 : Multi-Robot Systems II</td><td></td></tr><tr><td>WRAPP-Up: A Dual-Arm Robot for Intralogistics</td><td>9168</td></tr><tr><td>Chiara; Gugliotta, Marco; Settimi, Alessandro; Catalano, Manuel Giuseppe; Grioli,</td><td></td></tr><tr><td>Giorgio; Pallottino, Lucia A Laser-Based Dual-Arm System for Precise Control of Collaborative Robots</td><td>9183</td></tr><tr><td>Near-Optimal Multi-Robot Motion Planning with Finite Sampling</td><td>9190</td></tr><tr><td>Whole-Body Real-Time Motion Planning for Multicopters</td><td>9197</td></tr><tr><td><strong>Session</strong> TuHT3 : Multi-Robotic Systems Award Session</td><td></td></tr><tr><td>Self-Organized Evasive Fountain Maneuvers with a Bioinspired Underwater Robot Collective</td><td>9204</td></tr><tr><td>Learning Multi-Arm Manipulation through Collaborative Teleoperation</td><td>9212</td></tr><tr><td><strong>Session</strong> ThIT19 : Multi-View Perception</td><td></td></tr><tr><td>Probabilistic Multi-View Fusion of Active Stereo Depth Maps for Robotic Bin-Picking</td><td>9220</td></tr><tr><td>Multi-View Sensor Fusion by Integrating Model-Based Estimation and Graph Learning for  Collaborative Object Localization</td><td>9228</td></tr><tr><td>Deep Multi-View Depth Estimation with Predicted Uncertainty</td><td>9235</td></tr><tr><td>MultiViewStereoNet: Fast Multi-View Stereo Depth Estimation Using Incremental Viewpoint-Compensated Feature Extraction</td><td>9242</td></tr><tr><td><strong>Session</strong> TuBT0 : Navigation and Mapping</td><td></td></tr><tr><td>Differential Information Aided 3-D Registration for Accurate Navigation and Scene Reconstruction</td><td>9249</td></tr><tr><td>MingAutonomous Navigation in Dynamic Environments with Multi-Modal Perception Uncertainties</td><td>9255</td></tr><tr><td>Learning World Transition Model for Socially Aware Robot Navigation</td><td>9262</td></tr><tr><td>Probabilistic Dynamic Crowd Prediction for Social Navigation</td><td>9269</td></tr><tr><td><strong>Session</strong> TuCT0 : Navigation in Humanoids and Animaloids</td><td></td></tr><tr><td>Autonomous Decentralized Shape-Based Navigation for Snake Robots in Dense Environments</td><td>9276</td></tr><tr><td>Real-Time Optimal Navigation Planning Using Learned Motion Costs</td><td>9283</td></tr><tr><td>Humanoid Loco-Manipulation Planning Based on Graph Search and Reachability Maps</td><td>9290</td></tr><tr><td>Autonomous Navigation for Adaptive Unmanned Underwater Vehicles Using Fiducial Markers</td><td>9298</td></tr><tr><td><strong>Session</strong> ThDT4 : Novel Applications I</td><td></td></tr><tr><td>OpenBot: Turning Smartphones into Robots</td><td>9305</td></tr><tr><td>Quasi-LPV Unknown Input Observer with Nonlinear Outputs: Application to Motorcycles</td><td>9312</td></tr><tr><td>A Novel Torsional Actuator Augmenting Twisting Skeleton and Artificial Muscle for Robots in  Extreme Environments</td><td>9318</td></tr><tr><td>Compact Digital Microrobot Based on Multistable Modules</td><td>9325</td></tr><tr><td><strong>Session</strong> WeCT2 : Novel Applications II</td><td></td></tr><tr><td>A General Elimination Strategy for Camera Motion Estimation</td><td>9333</td></tr><tr><td>Group Feature Learning and Domain Adversarial Neural Network for aMCI Diagnosis System Based on EEG</td><td>9340</td></tr><tr><td>Line-Based Automatic Extrinsic Calibration of LiDAR and Camera</td><td>9347</td></tr><tr><td>RIL: Riemannian Incremental Learning of the Inertial Properties of the Robot Body Schema</td><td>9354</td></tr><tr><td><strong>Session</strong> ThET4 : Novel Applications III</td><td></td></tr><tr><td>ChoiRbot: A ROS 2 Toolbox for Cooperative Robotics</td><td>9361</td></tr><tr><td>Formal Verification of ROS Based Systems Using a Linear Logic Theorem Prover</td><td>9368</td></tr><tr><td>Fuzz Testing in Behavior-Based Robotics</td><td>9375</td></tr><tr><td>The Robot Household Marathon Experiment</td><td>9382</td></tr><tr><td>Sebastian; Beetz, Michael</td><td></td></tr><tr><td><strong>Session</strong> WeCT9 : Novel Applications IV</td><td></td></tr><tr><td>Sliding Mode Control of the Semi-Active Hover Backpack Based on the Bioinspired Skyhook  Damper Model</td><td>9389</td></tr><tr><td>Fast Light Show Design Platform for K-12 Children</td><td>9396</td></tr><tr><td>Autonomous Overtaking in Gran Turismo Sport Using Curriculum Reinforcement Learning</td><td>9403</td></tr><tr><td>An MR Safe Rotary Encoder Based on Eccentric Sheave and FBG Sensors</td><td>9410</td></tr><tr><td><strong>Session</strong> ThFT5 : Novel Applications V</td><td></td></tr><tr><td>A Relative Dynamics Formulation for Hardware-In-The-Loop Simulation of On-Orbit Robotic  Missions</td><td>9417</td></tr><tr><td>Structured Prediction for CRiSP Inverse Kinematics Learning with Misspecified Robot Models</td><td>9425</td></tr><tr><td>Rapid Solution of Cosserat Rod Equations Via a Nonlinear Partial Observer</td><td>9433</td></tr><tr><td>The Effects of Robot Cognitive Reliability and Social Positioning on Child-Robot Team Dynamics</td><td>9439</td></tr><tr><td><strong>Session</strong> ThET5 : Novel Applications: Manipulation</td><td></td></tr><tr><td>ProbRobScene: A Probabilistic Specification Language for 3D Robotic Manipulation Environments</td><td>9446</td></tr><tr><td>Towards Real-Time Interaction with Industrial Robots in the Creative Industries</td><td>9453</td></tr><tr><td>Automated Acquisition of Structured, Semantic Models of Manipulation Activities from Human VR  Demonstration</td><td>9460</td></tr><tr><td>A Shared Control Framework for Robotic Telemanipulation Combining Electromyography Based  Motion Estimation and Compliance Control</td><td>9467</td></tr><tr><td><strong>Session</strong> WeBT10 : Novel Design Technologies</td><td></td></tr><tr><td>NeuralSim: Augmenting Differentiable Simulators with Neural Networks</td><td>9474</td></tr><tr><td>V-Stability Based Control for Energy-Saving towards Long Range Sailing*</td><td>9482</td></tr><tr><td>Continuous Transition: Improving Sample Efficiency for Continuous Control Problems Via MixUp</td><td>9490</td></tr><tr><td>Effective Crash Recovery of Robot Software Programs in ROS</td><td>9498</td></tr><tr><td><strong>Session</strong> ThFT4 : Object Detection and Segmentation I</td><td></td></tr><tr><td>Self-Supervised Visual Terrain Classification from Unsupervised Acoustic Feature Learning</td><td>9505</td></tr><tr><td>Fast Few-Shot Classification by Few-Iteration Meta-Learning</td><td>9522</td></tr><tr><td>Deep Hierarchical Rotation Invariance Learning with Exact Geometry Feature Representation for  Point Cloud Classification</td><td>9529</td></tr><tr><td>Fool Me Once: Robust Selective Segmentation Via Out-Of-Distribution Detection with Contrastive  Learning</td><td>9536</td></tr><tr><td><strong>Session</strong> ThJT16 : Object Recognition and Segmentation II</td><td></td></tr><tr><td>TORNADO-Net: MulTiview tOtal vaRiatioN semAntic Segmentation with Diamond inceptiOn  Module</td><td>9543</td></tr><tr><td>Lite-HDSeg: LiDAR Semantic Segmentation Using Lite Harmonic Dense Convolutions</td><td>9550</td></tr><tr><td>Real-Time Semantic Segmentation with Fast Attention</td><td>9557</td></tr><tr><td>A Graph-Based Method for Joint Instance Segmentation of Point Clouds and Image Sequences</td><td>9565</td></tr><tr><td><strong>Session</strong> ThKT16 : Object Recognition and Segmentation III</td><td></td></tr><tr><td>Fusing RGBD Tracking and Segmentation Tree Sampling for Multi-Hypothesis Volumetric  Segmentation</td><td>9572</td></tr><tr><td>YolactEdge: Real-Time Instance Segmentation on the Edge</td><td>9579</td></tr><tr><td>Learning Panoptic Segmentation from Instance Contours</td><td>9586</td></tr><tr><td>0-MMS: Zero-Shot Multi-Motion Segmentation with a Monocular Event Camera</td><td>9594</td></tr><tr><td><strong>Session</strong> ThFT3 : Odometry I</td><td></td></tr><tr><td>Self-Supervised Learning of LiDAR Odometry for Robotic Applications</td><td>9601</td></tr><tr><td>Tight Integration of Feature-based Relocalization in Monocular Direct Visual Odometry</td><td>9608</td></tr><tr><td>Continuous Scale-Space Direct Image Alignment for Visual Odometry from RGB-D Images</td><td>9615</td></tr><tr><td>Unified Multi-Modal Landmark Tracking for Tightly Coupled Lidar-Visual-Inertial Odometry</td><td>9623</td></tr><tr><td><strong>Session</strong> ThDT5 : Odometry II</td><td></td></tr><tr><td>Simple but Effective Redundant Odometry for Autonomous Vehicles</td><td>9631</td></tr><tr><td>Markov Localisation Using Heatmap Regression and Deep Convolutional Odometry</td><td>9638</td></tr><tr><td>R-LOAM: Improving LiDAR Odometry and Mapping with Point-To-Mesh Features of a Known 3D  Reference Object</td><td>9645</td></tr><tr><td>Autonomous Cooperative Visual Navigation for Planetary Exploration Robots</td><td>9653</td></tr><tr><td><strong>Session</strong> ThET6 : Optimal Control for Motion Planning</td><td></td></tr><tr><td>Optimal TCP and Robot Base Placement for a Set of Complex Continuous Paths</td><td>9659</td></tr><tr><td>Control-Tree Optimization: An Approach to MPC under Discrete Partial Observability</td><td>9666</td></tr><tr><td>Leveraging Neural Network Gradients within Trajectory Optimization for Proactive Human-Robot  Interactions</td><td>9673</td></tr><tr><td>Gramian-based optimal active sensing control under intermittent measurements</td><td>9680</td></tr><tr><td><strong>Session</strong> TuHT22 : Optimization</td><td></td></tr><tr><td>A Complete, Accurate and Efficient Solution for the Perspective-N-Line Problem</td><td>9687</td></tr><tr><td>Accelerating Robot Dynamics Gradients on a CPU, GPU, and FPGA</td><td>9695</td></tr><tr><td>Srini; Janapa Reddi, Vijay Accelerating Combinatorial Filter Reduction through Constraints</td><td>9703</td></tr><tr><td>Persistent Covering with Latency and Energy Constraints</td><td>9710</td></tr><tr><td><strong>Session</strong> ThHT15 : Optimization and Control I</td><td></td></tr><tr><td>Equality Constrained Linear Optimal Control with Factor Graphs</td><td>9717</td></tr><tr><td>Robust Optimization-based Motion Planning for high-DOF Robots under Sensing Uncertainty</td><td>9724</td></tr><tr><td>Optimized Coverage Planning for UV Surface Disinfection</td><td>9731</td></tr><tr><td>Constrained Differential Dynamic Programming Revisited</td><td>9738</td></tr><tr><td><strong>Session</strong> ThIT15 : Optimization and Control II</td><td></td></tr><tr><td>Computing All Solutions to a Discretization-Invariant Formulation for Optimal Mechanism Design</td><td>9745</td></tr><tr><td>Optimal Multi-Manipulator Arm Placement for Maximal Dexterity During Robotics Surgery</td><td>9752</td></tr><tr><td>Balancing Stability and Stiffness through Optimization of Parallel Compliance</td><td>9759</td></tr><tr><td>Direct Policy Optimization Using Deterministic Sampling and Collocation</td><td>9767</td></tr><tr><td><strong>Session</strong> ThFT6 : Optimization and Control III</td><td></td></tr><tr><td>Linear-Quadratic Optimal Control in Maximal Coordinates</td><td>9775</td></tr><tr><td>Safe and Efficient Model-Free Adaptive Control Via Bayesian Optimization</td><td>9782</td></tr><tr><td>Data-efficient Domain Randomization with Bayesian Optimization</td><td>9789</td></tr><tr><td>Adaptive Robust Kernels for Non-Linear Least Squares Problems</td><td>9797</td></tr><tr><td><strong>Session</strong> ThET7 : Optimization for Legged RobotsReceding-Horizon Perceptive Trajectory Optimization for Dynamic Legged Locomotion with</td><td></td></tr><tr><td>Learned Initialization</td><td>9805</td></tr><tr><td>Trajectory Optimization of Contact-Rich Motions Using Implicit Differential Dynamic Programming</td><td>9812</td></tr><tr><td>Friction-Driven Three-Foot Robot Inspired by Snail Movement</td><td>9820</td></tr><tr><td>Modeling and Optimal Control for Rope-Assisted Rappelling Maneuvers</td><td>9826</td></tr><tr><td><strong>Session</strong> ThDT7 : Optimization for Multi-Robot Systems</td><td></td></tr><tr><td>General-Sum Multi-Agent Continuous Inverse Optimal Control</td><td>9833</td></tr><tr><td>Shared Control of Robot-Robot Collaborative Lifting with Agent Postural and Force Ergonomic  Optimization</td><td>9840</td></tr><tr><td>Rapidly Adapting Robot Swarms with Swarm Map-Based Bayesian Optimisation</td><td>9848</td></tr><tr><td>GPU Accelerated Convex Approximations for Fast Multi-Agent Trajectory Optimization</td><td>9855</td></tr><tr><td><strong>Session</strong> ThIT14 : Optimization in Robotic Design I</td><td></td></tr><tr><td>Multi-Objective Graph Heuristic Search for Terrestrial Robot Design</td><td>9863</td></tr><tr><td>Factor Graph-Based Trajectory Optimization for a Pneumatically-Actuated Jumping Robot</td><td>9870</td></tr><tr><td>MO-BBO: Multi-Objective Bilevel Bayesian Optimization for Robot and Behavior Co-Design</td><td>9877</td></tr><tr><td>Manipulator Task Space Trajectory Tracking with Kinematics and Dynamics Uncertainties</td><td>9884</td></tr><tr><td>Session ThDT6 : Optimization in Robotic Design IIMinimum-Effort Task-Based Design Optimization of Modular Reconfigurable Robots</td><td>9891</td></tr><tr><td>Computational Design of Energy-Efficient Legged Robots: Optimizing for Size and Actuators</td><td>9898</td></tr><tr><td>On the Effect of Robotic Leg Design on Energy Efficiency</td><td>9905</td></tr><tr><td>Elastic Structure Preserving Control for Compliant Robots Driven by Agonistic-Antagonistic Actuators (ESPaa)</td><td>9912</td></tr><tr><td><strong>Session</strong> ThJT15 : Optimization-Based Motion Planning I</td><td></td></tr><tr><td>Contact-Implicit Trajectory Optimization with Learned Deformable Contacts Using Bilevel  Optimization</td><td>9921</td></tr><tr><td>Energy-Optimal Path Planning with Active Flow Perception for Autonomous Underwater Vehicles</td><td>9928</td></tr><tr><td>Double Meta-Learning for Data Efficient Policy Optimization in Non-Stationary Environments</td><td>9935</td></tr><tr><td>Adversarial Attacks on Optimization Based Planners</td><td>9943</td></tr><tr><td><strong>Session</strong> ThKT15 : Optimization-Based Motion Planning II</td><td></td></tr><tr><td>Strobe: An Acceleration Meta-Algorithm for Optimizing Robot Paths Using Concurrent Interleaved  Sub-Epoch Pods</td><td>9950</td></tr><tr><td>Designing Multi-Stage Coupled Convex Programming with Data-Driven McCormick Envelope  Relaxations for Motion Planning</td><td>9957</td></tr><tr><td>Robust Model Predictive Path Integral Control: Analysis and Performance Guarantees</td><td>9964</td></tr><tr><td>Belief Space Planning for Mobile Robots with Range Sensors Using ILQG</td><td>9973</td></tr><tr><td>Session ThHT14 : Optimization-Based Motion Planning IIIMulti-Modal Motion Planning Using Composite Pose Graph Optimization</td><td>9981</td></tr><tr><td>Asymptotically Optimal Kinodynamic Planning Using Bundles of Edges</td><td>9988</td></tr><tr><td>CollisionIK: A Per-Instant Pose Optimization Method for Generating Robot Motions with  Environment Collision Avoidance</td><td>9995</td></tr><tr><td>Trajectory Optimization for Manipulation of Deformable Objects: Assembly of Belt Drive Units</td><td>10002</td></tr><tr><td><strong>Session</strong> ThFT7 : Path Planning for Multiple Mobile Robots</td><td></td></tr><tr><td>Hierarchical and Flexible Traffic Management of Multi-AGV Systems Applied to Industrial  Environments</td><td>10009</td></tr><tr><td>Combining Multi-Robot Motion Planning and Goal Allocation Using Roadmaps</td><td>10016</td></tr><tr><td>Asynchronous Reliability-Aware Multi-UAV Coverage Path Planning</td><td>10023</td></tr><tr><td>Distributed Coordinated Path Following Using Guiding Vector Fields</td><td>10030</td></tr><tr><td><strong>Session</strong> WeBT16 : Path Planning for Multiple Robots</td><td></td></tr><tr><td>An Efficient Parallel Self-Assembly Planning Algorithm for Modular Robots in Environments with  Obstacles</td><td>10038</td></tr><tr><td>Multi-Robot Informative Path Planning Using a Leader-Follower Architecture</td><td>10045</td></tr><tr><td>Tightly-Coupled Perception and Navigation of Heterogeneous Land-Air Robots in Complex  Scenarios</td><td>10052</td></tr><tr><td>Fully Distributed Cooperation for Networked Uncertain Mobile Manipulators</td><td>10059</td></tr><tr><td><strong>Session</strong> ThET8 : Path Planning I</td><td></td></tr><tr><td>FT-BSP: Focused Topological Belief Space Planning</td><td>10079</td></tr><tr><td>Path Planning for a Reconfigurable Robot in Extreme Environments</td><td>10087</td></tr><tr><td>AM-RRT*: Informed Sampling-Based Planning with Assisting Metric</td><td>10093</td></tr><tr><td>Complete Path Planning That Simultaneously Optimizes Length and Clearance</td><td>10100</td></tr><tr><td><strong>Session</strong> ThFT8 : Path Planning II</td><td></td></tr><tr><td>On Smooth Time-Optimal Trajectory Planning in Twisted String Actuators</td><td>10107</td></tr><tr><td>Fast Swing-Up Trajectory Optimization for a Spherical Pendulum on a 7-DoF Collaborative Robot</td><td>10114</td></tr><tr><td>Surface-Based Path Following Control: Application of Curved Tapes on 3D Objects</td><td>10121</td></tr><tr><td>Human-Robot Collaborative Multi-Agent Path Planning Using Monte Carlo Tree Search and Social  Reward Sources</td><td>10133</td></tr><tr><td><strong>Session</strong> TuET0 : Perception for Manipulation I</td><td></td></tr><tr><td>Embodied Reasoning for Discovering Object Properties Via Manipulation</td><td>10139</td></tr><tr><td>Robust High-Transparency Haptic Exploration for Dexterous Telemanipulation</td><td>10146</td></tr><tr><td>Unsupervised Feature Learning for Manipulation with Contrastive Domain Randomization</td><td>10153</td></tr><tr><td>“What’s This?” - Learning to Segment Unknown Objects from Manipulation Sequences</td><td>10160</td></tr><tr><td><strong>Session</strong> TuGT0 : Perception for Manipulation II</td><td></td></tr><tr><td>Polyhedral Friction Cone Estimator for Object Manipulation</td><td>10168</td></tr><tr><td>Interpretability in Contact-Rich Manipulation via Kinodynamic Images</td><td>10175</td></tr><tr><td>Differentiable Simulation for Physical System Identification</td><td>10182</td></tr><tr><td>Few-Shot Model-Based Adaptation in Noisy Conditions</td><td>10190</td></tr><tr><td><strong>Session</strong> ThJT14 : Planning Algorithms for Robotics</td><td></td></tr><tr><td>Minimal Exposure Dubins Orienteering Problem</td><td>10198</td></tr><tr><td>Generalized Nonlinear and Finsler Geometry for Robotics</td><td>10206</td></tr><tr><td>A Fast and Approximate Medial Axis Sampling Technique</td><td>10213</td></tr><tr><td>An Adaptive Method for the Stochastic Orienteering Problem</td><td>10220</td></tr><tr><td><strong>Session</strong> ThDT8 : Pose Estimation</td><td></td></tr><tr><td>Probabilistic Scan Matching: Bayesian Pose Estimation from Point Clouds</td><td>10228</td></tr><tr><td>Learning a State Representation and Navigation in Cluttered and Dynamic Environments</td><td>10235</td></tr><tr><td>Reinforcement Learning for Orientation Estimation Using Inertial Sensors with Performance  Guarantee</td><td>10243</td></tr><tr><td>Consistent State Estimation on Manifolds for Autonomous Metal Structure Inspection</td><td>10250</td></tr><tr><td><strong>Session</strong> ThKT14 : Probabilistic Method in Motion Planning</td><td></td></tr><tr><td>Planning on a (Risk) Budget: Safe Non-Conservative Planning in Probabilistic Dynamic Environments</td><td>10257</td></tr><tr><td>Avoidance Critical Probabilistic Roadmaps for Motion Planning in Dynamic Environments</td><td>10264</td></tr><tr><td>Robust Trajectory Optimization Over Uncertain Terrain with Stochastic Complementarity</td><td>10271</td></tr><tr><td>Planning under Non-Rational Perception of Uncertain Spatial Costs</td><td>10279</td></tr><tr><td><strong>Session</strong> ThAT7 : Reconstruction and Perception</td><td></td></tr><tr><td>Rapid Pose Label Generation through Sparse Representation of Unknown Objects</td><td>10287</td></tr><tr><td>Learning to Predict Repeatability of Interest Points</td><td>10294</td></tr><tr><td>DRACO: Weakly Supervised Dense Reconstruction and Canonicalization of Objects</td><td>10302</td></tr><tr><td>FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation</td><td>10310</td></tr><tr><td><strong>Session</strong> ThHT13 : Rehabilitation and Assistive Robotics I</td><td></td></tr><tr><td>Drumming Arm: An Upper-Limb Prosthetic System to Restore Grip Control for a Transradial  Amputee Drummer</td><td>10317</td></tr><tr><td>Analysis of the Effect of Common Disturbances on the Safety of a Wearable Tremor Suppression  Device</td><td>10324</td></tr><tr><td>FLEXotendon Glove-III: Soft Robotic Hand Rehabilitation Exoskeleton for Spinal Cord Injury</td><td>10332</td></tr><tr><td>Development of a Series Elastic Elbow Neurological Exam Training Simulator for Lead-Pipe  Rigidity</td><td>10340</td></tr><tr><td>Session TuFT0 : Rehabilitation and Assistive Robotics IIA Variable Soft Finger Exoskeleton for Quantifying Fatigue-Induced Mechanical Impedance</td><td>10347</td></tr><tr><td>A Constant-Force End-Effector with Online Force Adjustment for Robotic Ultrasonography</td><td>10353</td></tr><tr><td>Affordance-Aware Handovers with Human Arm Mobility Constraints</td><td>10361</td></tr><tr><td>Subramanian; Lohan, Katrin Solveig; Cakmak, Maya Wearable Integrated Soft Haptics in a Prosthetic Socket</td><td>10369</td></tr><tr><td><strong>Session</strong> ThAT6 : Rehabilitation and Assistive Robotics III</td><td></td></tr><tr><td>Verbal Focus-Of-Attention System for Learning-From-Observation</td><td>10377</td></tr><tr><td>Hybrid Model Control of WalkON Suit for Precise and Robust Gait Assistance of Paraplegics</td><td>10385</td></tr><tr><td>A Novel Gait Phase Detection Algorithm for Foot Drop Correction through Optimal Hybrid FES-Orthosis Assistance</td><td>10391</td></tr><tr><td>Samer A Phase-Shifting Based Human Gait Phase Estimation for the Powered Transfemoral Prosthesis</td><td>10398</td></tr><tr><td><strong>Session</strong> ThIT13 : Rehabilitation and Assistive Robotics IV</td><td></td></tr><tr><td>Customized Handling of Unintended Interface Operation in Assistive Robots</td><td>10406</td></tr><tr><td>Integrated Voluntary-Reactive Control of a Human-SuperLimb Hybrid System for Hemiplegic  Patient Support</td><td>10413</td></tr><tr><td>Inverse Optimal Robust Adaptive Controller for Upper Limb Rehabilitation Exoskeletons with Inertia  and Load Uncertainties</td><td>10421</td></tr><tr><td>Perceived Usefulness of a Social Robot Augmented Telehealth Platform by Therapists in the  United States</td><td>10430</td></tr><tr><td><strong>Session</strong> TuFT2 : Rehabilitation and Assistive Robotics V</td><td></td></tr><tr><td>Toward Seamless Transitions between Shared Control and Supervised Autonomy in Robotic  Assistance</td><td>10438</td></tr><tr><td>Computing the Positioning Error of an Upper-Arm Robotic Prosthesis from the Observation of Its  Wearer’s Posture</td><td>10446</td></tr><tr><td>Intent-Aware Control in Kinematically Redundant Systems: Towards Collaborative Wearable  Robots</td><td>10453</td></tr><tr><td>Foot Placement Prediction for Assistive Walking by Fusing Sequential 3D Gaze and Environmental  Context</td><td>10461</td></tr><tr><td><strong>Session</strong> ThBT6 : Rehabilitation and Assistive Robotics VI</td><td></td></tr><tr><td>Nonlinear Disturbance Observer-Based Robust Position Control for Series Elastic Actuator-Driven  Robots</td><td>10469</td></tr><tr><td>Composing an Assistive Control Strategy Based on Linear Bellman Combination from Estimated  User’s Motor Goal</td><td>10476</td></tr><tr><td>Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-Type Muscle Model</td><td>10484</td></tr><tr><td>Control and Evaluation of Body Weight Support Walker for Overground Gait Training</td><td>10491</td></tr><tr><td><strong>Session</strong> WeAT15 : Rehabilitation and Assistive Robotics VII</td><td></td></tr><tr><td>Developing of a Rigid-Compliant Finger Joint Exoskeleton Using Topology Optimization Method</td><td>10499</td></tr><tr><td>Wheel-Legged Robotic Limb to Assist Human with Load Carriage: An Application for  Environmental Disinfection During COVID-19</td><td>10505</td></tr><tr><td>SpringExo, a Spring-Based Exoskeleton for Providing Knee Assistance: Design, Characterization  and Feasibility Study</td><td>10513</td></tr><tr><td>High-Force Fabric-Based Pneumatic Actuators with Asymmetric Chambers and Interference-Reinforced Structure for Soft Wearable Assistive Gloves</td><td>10520</td></tr><tr><td><strong>Session</strong> ThJT13 : Rehabilitation and Assistive Robotics: Machine Learning</td><td></td></tr><tr><td>Leveraging Post Hoc Context for Faster Learning in Bandit Settings with Applications in Robot-Assisted Feeding</td><td>10528</td></tr><tr><td>Task-Invariant Learning of Continuous Joint Kinematics During Steady-State and Transient  Ambulation Using Ultrasound Sensing</td><td>10536</td></tr><tr><td>Toward Deep Generalization of Peripheral EMG-Based Human-Robot Interfacing: A Hybrid  Explainable Solution for NeuroRobotic Systems</td><td>10543</td></tr><tr><td>Kinesthetic feedback improves grasp performance in cable-driven prostheses</td><td>10551</td></tr><tr><td><strong>Session</strong> ThKT13 : Rehabilitation and Assistive Robotics: Prosthetics and Exoskeletons</td><td></td></tr><tr><td>Real-Time User-Independent Slope Prediction Using Deep Learning for Modulation of Robotic  Knee Exoskeleton Assistance</td><td>10558</td></tr><tr><td>Real-Time Gait Phase Estimation for Robotic Hip Exoskeleton Control During Multimodal  Locomotion</td><td>10565</td></tr><tr><td>Evaluation of Continuous Walking Speed Determination Algorithms and Embedded Sensors for a  Powered Knee &amp; Ankle Prosthesis</td><td>10572</td></tr><tr><td>Validation of a Novel Parallel-Actuated Shoulder Exoskeleton Robot for the Characterization of  Human Shoulder Impedance</td><td>10580</td></tr><tr><td><strong>Session</strong> ThHT12 : Rehabilitation and Assistive Robotics: Reinforcement Learning</td><td></td></tr><tr><td>Human-Guided Robot Behavior Learning: A GAN-Assisted Preference-Based Reinforcement  Learning Approach</td><td>10587</td></tr><tr><td>Protective Policy Transfer</td><td>10595</td></tr><tr><td>Natural Walking with Musculoskeletal Models Using Deep Reinforcement Learning</td><td>10603</td></tr><tr><td>A Data-Driven Reinforcement Learning Solution Framework for Optimal and Adaptive  Personalization of a Hip Exoskeleton</td><td>10610</td></tr><tr><td><strong>Session</strong> ThIT12 : Reinforcement Learning for Robotics I</td><td></td></tr><tr><td>FISAR: Forward Invariant Safe Reinforcement Learning with a Deep Neural Network-Based  Optimizer</td><td>10617</td></tr><tr><td>Coding for Distributed Multi-Agent Reinforcement Learning</td><td>10625</td></tr><tr><td>Model-Based Meta-Reinforcement Learning for Flight with Suspended Payloads</td><td>10632</td></tr><tr><td>Transfer Reinforcement Learning across Homotopy Classes</td><td>10640</td></tr><tr><td><strong>Session</strong> TuGT2 : Reinforcement Learning for Robotics II</td><td></td></tr><tr><td>Model-Free Reinforcement Learning for Stochastic Games with Linear Temporal Logic Objectives</td><td>10649</td></tr><tr><td>Secure Planning against Stealthy Attacks Via Model-Free Reinforcement Learning</td><td>10656</td></tr><tr><td>Harmonic-Based Optimal Motion Planning in Constrained Workspaces Using Reinforcement  Learning</td><td>10663</td></tr><tr><td>Reward Learning from Very Few Demonstrations</td><td>10670</td></tr><tr><td>Hierarchies of Planning and Reinforcement Learning for Robot Navigation</td><td>10682</td></tr><tr><td><strong>Session</strong> ThBT7 : Reinforcement Learning for Robotics III</td><td></td></tr><tr><td>Context-Aware Safe Reinforcement Learning for Non-Stationary Environments</td><td>10689</td></tr><tr><td>DingDeep Learning Assisted Robotic Magnetic Anchored and Guided Endoscope for Real-Time  Instrument Tracking</td><td>10696</td></tr><tr><td>Incorporating Multi-Context into the Traversability Map for Urban Autonomous Driving Using Deep  Inverse Reinforcement Learning</td><td>10704</td></tr><tr><td>Quantification of Joint Redundancy Considering Dynamic Feasibility Using Deep Reinforcement  Learning</td><td>10712</td></tr><tr><td><strong>Session</strong> ThDT14 : Reinforcement Learning in Navigation</td><td></td></tr><tr><td>A Novel Hybrid Approach for Fault-Tolerant Control of UAVs based on Robust Reinforcement  Learning</td><td>10719</td></tr><tr><td>Deep Probabilistic Feature-Metric Tracking</td><td>10726</td></tr><tr><td>Using Reinforcement Learning to Create Control Barrier Functions for Explicit Risk Mitigation in  Adversarial Environments</td><td>10734</td></tr><tr><td>Edge Computing in 5G for Drone Navigation: What to Offload?</td><td>10741</td></tr><tr><td><strong>Session</strong> ThJT12 : Robot Safety</td><td></td></tr><tr><td>Encoding Defensive Driving As a Dynamic Nash Game</td><td>10749</td></tr><tr><td>Enhancing Safety of Students with Mobile Air Filtration During School Reopening from COVID-19</td><td>10757</td></tr><tr><td>Quinones Cortes, Jhon Jairo; Doosttalab, Ali; Esquivel-Puentes, ‪Helber Antonio; Purwar,</td><td></td></tr><tr><td>Tanya; Castillo, Luciano; Mahmoudian, Nina; Voyles, Richard Probabilistic Safety Assured Adaptive Merging Control for Autonomous Vehicles</td><td>10764</td></tr><tr><td>Negotiating Visibility for Safe Autonomous Navigation in Occluding and Uncertain Environments</td><td>10771</td></tr><tr><td><strong>Session</strong> ThKT12 : Robotic Learning with Visual Signal</td><td></td></tr><tr><td>Visionary: Vision Architecture Discovery for Robot Learning</td><td>10779</td></tr><tr><td>Zero-Shot Policy Learning with Spatial Temporal Reward Decomposition on Contingency-Aware  Observation</td><td>10786</td></tr><tr><td>Approximate Inverse Reinforcement Learning from Vision-Based Imitation Learning</td><td>10793</td></tr><tr><td>Efficient Robotic Object Search via HIEM: Hierarchical Policy Learning with Intrinsic-Extrinsic  Modeling</td><td>10800</td></tr><tr><td><strong>Session</strong> ThET17 : Robotic Manipulation</td><td></td></tr><tr><td>Reward Conditioned Neural Movement Primitives for Population-Based Variational Policy  Optimization</td><td>10808</td></tr><tr><td>Contextual Latent-Movements Off-Policy Optimization for Robotic Manipulation Skills</td><td>10815</td></tr><tr><td>Optimal Deep Learning for Robot Touch</td><td>10822</td></tr><tr><td>Learning Optimal Impedance Control During Complex 3D Arm Movements</td><td>10832</td></tr><tr><td><strong>Session</strong> ThBT15 : Robotic Mechanisms and Design I</td><td></td></tr><tr><td>Air-Hydraulic Servo Booster Toward Submersible Water-Driven Robots</td><td>10840</td></tr><tr><td>Joint Mechanical Design and Flight Control Optimization of a Nature-Inspired Unmanned Aerial  Vehicle via Collaborative Co-Evolution</td><td>10847</td></tr><tr><td>Shaohui Development of Cable-Driven Anthropomorphic Robot Hand</td><td>10855</td></tr><tr><td>Origami-Inspired Snap-Through Bistability in Parallel and Curved Mechanisms through the  Inflection of Degree Four Vertexes</td><td>10863</td></tr><tr><td>Lee, Zu Xuan; Tan, Chui Shien Janice; Ho, Jian Rong; Ma, Minhui Vienna; Huang, Hui; Ren,</td><td></td></tr><tr><td>Hongliang</td><td></td></tr><tr><td><strong>Session</strong> ThBT21 : Robotic Mechanisms and Design II</td><td></td></tr><tr><td>Applications: Twisted String Actuation-Based Compact Automatic Transmission</td><td>10870</td></tr><tr><td>Power Transmission Design of Fast and Energy-Efficient Stiffness Modulation for Human Power  Assistance</td><td>10877</td></tr><tr><td>A Novel Variable Resolution Torque Sensor Based on Variable Stiffness Principle</td><td>10884</td></tr><tr><td>A Motion Estimation Filter for Inertial Measurement Unit with On-board Ferromagnetic Materials</td><td>10890</td></tr><tr><td>Energy Saving of Schooling Robotic Fish in Three Dimensional Formations</td><td>10898</td></tr><tr><td><strong>Session</strong> ThHT11 : Robotic Perception I</td><td></td></tr><tr><td>Self-Guided Instance-Aware Network for Depth Completion and Enhancement</td><td>10905</td></tr><tr><td>World-in-the-Loop Simulation for Autonomous Systems Validation</td><td>10912</td></tr><tr><td>RetinaGAN: An Object-Aware Approach to Sim-To-Real Transfer</td><td>10920</td></tr><tr><td>A Framework for Multisensory Foresight for Embodied Agents</td><td>10927</td></tr><tr><td><strong>Session</strong> ThFT17 : Robotic Perception II</td><td></td></tr><tr><td>HDROmni: Optical Extension of Dynamic Range for Panoramic Robot Vision</td><td>10934</td></tr><tr><td>The GRIFFIN Perception Dataset: Bridging the Gap between Flapping-Wing Flight and Robotic  Perception</td><td>10942</td></tr><tr><td>OmniDet: Surround View Cameras Based Multi-Task Visual Perception Network for Autonomous  Driving</td><td>10950</td></tr><tr><td>Leang, Isabelle; Milz, Stefan; Mäder, PatrickOffline Dynamic Grid Generation for Automotive Environment Perception Using Temporal  Inference Methods</td><td>10958</td></tr><tr><td><strong>Session</strong> ThIT11 : Robotic Perception III</td><td></td></tr><tr><td>6D Object Pose Estimation with Pairwise Compatible Geometric Features</td><td>10966</td></tr><tr><td>Robust Skin-Feature Tracking in Free-Hand Video from Smartphone or Robot-Held Camera, to  Enable Clinical-Tool Localization and Guidance</td><td>10974</td></tr><tr><td>In-Hand Object-Dynamics Inference Using Tactile Fingertips</td><td>10981</td></tr><tr><td>From Multi-Target Sensory Coverage to Complete Sensory Coverage: An Optimization-Based  Robotic Sensory Coverage Approach</td><td>10994</td></tr><tr><td><strong>Session</strong> ThDT16 : Robotic Percetpion IV</td><td></td></tr><tr><td>A Minimally Supervised Approach Based on Variational Autoencoders for Anomaly Detection in  Autonomous Robots</td><td>11001</td></tr><tr><td>Faster R-CNN-Based Decision Making in a Novel Adaptive Dual-Mode Robotic Anchoring System</td><td>11010</td></tr><tr><td>Hearing What You Cannot See: Acoustic Vehicle Detection Around Corners</td><td>11017</td></tr><tr><td>Robot Action Diagnosis and Experience Correction by Falsifying Parameterised Execution Models</td><td>11025</td></tr><tr><td><strong>Session</strong> ThAT21 : Robotic Vision I</td><td></td></tr><tr><td>Robust 360-8PA: Redesigning the Normalized 8-Point Algorithm for 360-FoV Images</td><td>11032</td></tr><tr><td>STA-VPR: Spatio-Temporal Alignment for Visual Place Recognition</td><td>11039</td></tr><tr><td>Initialisation of Autonomous Aircraft Visual Inspection Systems Via CNN-Based Camera Pose  Estimation</td><td>11047</td></tr><tr><td>Poh Kang; Toh, Pei Lin Pearlin; Tan, U-XuanVoxelized GICP for Fast and Accurate 3D Point Cloud Registration</td><td>11054</td></tr><tr><td><strong>Session</strong> ThET16 : Robotic Vision II</td><td></td></tr><tr><td>Generic Hand-Eye Calibration of Uncertain Robots</td><td>11060</td></tr><tr><td>In-Situ Translational Hand-Eye Calibration of Laser Profile Sensors Using Arbitrary Objects</td><td>11067</td></tr><tr><td>Villagrossi, Enrico; Polo, Andrea; Ardesi, Alessandro; Maggiali, Marco; Natale, Lorenzo;</td><td></td></tr><tr><td>Pucci, Daniele; Traversaro, Silvio</td><td></td></tr><tr><td>Autonomous UAV Safety by Visual Human Crowd Detection Using Multi-Task Deep Neural  Networks</td><td>11074</td></tr><tr><td>CloudAAE: Learning 6D Object Pose Regression with On-Line Data Synthesis on Point Clouds</td><td>11081</td></tr><tr><td><strong>Session</strong> ThFT16 : Robust Control</td><td></td></tr><tr><td>No Need for Interactions: Robust Model-Based Imitation Learning Using Neural ODE</td><td>11088</td></tr><tr><td>Robust Trajectory Planning with Parametric Uncertainties</td><td>11095</td></tr><tr><td>Robust Policy Search for Robot Navigation</td><td>11102</td></tr><tr><td>Robust Footstep Planning and LQR Control for Dynamic Quadrupedal Locomotion</td><td>11110</td></tr><tr><td><strong>Session</strong> ThJT11 : Robust/Optimal Control</td><td></td></tr><tr><td>Towards Robust One-Shot Task Execution Using Knowledge Graph Embeddings</td><td>11118</td></tr><tr><td>An Efficient Closed-Form Method for Optimal Hybrid Force-Velocity Control</td><td>11125</td></tr><tr><td>RAT iLQR: A Risk Auto-Tuning Controller to Optimally Account for Stochastic Model Mismatch</td><td>11132</td></tr><tr><td>Sliding on Manifolds: Geometric Attitude Control with Quaternions</td><td>11140</td></tr><tr><td><strong>Session</strong> ThBT8 : Segmentation and Recognition</td><td></td></tr><tr><td>Deep Balanced Learning for Long-Tailed Facial Expressions Recognition</td><td>11147</td></tr><tr><td>AU-Expression Knowledge Constrained Representation Learning for Facial Expression  Recognition</td><td>11154</td></tr><tr><td>Covariance Self-Attention Dual Path UNet for Rectal Tumor Segmentation</td><td>11162</td></tr><tr><td>Fabric Defect Detection Using Tactile Information</td><td>11169</td></tr><tr><td><strong>Session</strong> ThAT20 : Semantic Planning</td><td></td></tr><tr><td>Towards Real-time Semantic RGB-D SLAM in Dynamic Environments</td><td>11175</td></tr><tr><td>Real-Time Robot Path Planning Using Rapid Visible Tree</td><td>11182</td></tr><tr><td>Semantically Guided Multi-View Stereo for Dense 3D Road Mapping</td><td>11189</td></tr><tr><td>Spatial Reasoning from Natural Language Instructions for Robot Manipulation</td><td>11196</td></tr><tr><td><strong>Session</strong> ThKT11 : Semantic Scene Understanding</td><td></td></tr><tr><td>Semantic SLAM with Autonomous Object-Level Data Association</td><td>11203</td></tr><tr><td>Kimera-Multi: A System for Distributed Multi-Robot Metric-Semantic Simultaneous Localization and  Mapping</td><td>11210</td></tr><tr><td>Any Way You Look at It: Semantic Crossview Localization and Mapping with LiDAR</td><td>11219</td></tr><tr><td>Semantic and Geometric Modeling with Neural Message Passing in 3D Scene Graphs for  Hierarchical Mechanical Search</td><td>11227</td></tr><tr><td><strong>Session</strong> WeBT11 : Semantics Localization</td><td></td></tr><tr><td>Point Set Registration with Semantic Region AssociationUsing Cascaded Expectation  Maximization</td><td>11234</td></tr><tr><td>A Flexible and Efficient Loop Closure Detection Based on Motion Knowledge</td><td>11241</td></tr><tr><td>RoadMap: A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving</td><td>11248</td></tr><tr><td>Visual Semantic Localization Based on HD Map for Autonomous Vehicles in Urban Scenarios</td><td>11255</td></tr><tr><td><strong>Session</strong> ThBT20 : Sensing in Manipulation</td><td></td></tr><tr><td>Extrinsic Contact Sensing with Relative-Motion Tracking from Distributed Tactile Measurements</td><td>11262</td></tr><tr><td>Needle Tip Tracking in 2D Ultrasound Based on Improved Compressive Tracking and Adaptive  Kalman Filter</td><td>11269</td></tr><tr><td>Robotic Imitation of Human Assembly Skills Using Hybrid Trajectory and Force Learning</td><td>11278</td></tr><tr><td>Contact Feature Recognition Based on MFCC of Force Signals</td><td>11285</td></tr><tr><td><strong>Session</strong> ThDT15 : Sensor Fusion</td><td></td></tr><tr><td>DSEC: A Stereo Event Camera Dataset for Driving Scenarios</td><td>11291</td></tr><tr><td>Interval-Based Visual-LiDAR Sensor Fusion</td><td>11299</td></tr><tr><td>Optimizing RGB-D Fusion for Accurate 6DoF Pose Estimation</td><td>11307</td></tr><tr><td>EagerMOT: 3D Multi-Object Tracking Via Sensor Fusion</td><td>11315</td></tr><tr><td><strong>Session</strong> TuDT2 : Service Robotics Award Session</td><td></td></tr><tr><td>Tactile SLAM: Real-time inference of shape and pose from planar pushing</td><td>11322</td></tr><tr><td>BADGR: An Autonomous Self-Supervised Learning-Based Navigation System</td><td>11329</td></tr><tr><td><strong>Session</strong> ThBT17 : Service Robotics I</td><td></td></tr><tr><td>Multiple-Place Swarm Foraging with Dynamic Robot Chains</td><td>11337</td></tr><tr><td>Collaborative Learning of Multiple-Discontinuous-Image Saliency Prediction for Drone Exploration</td><td>11343</td></tr><tr><td>Positioning Control for Underactuated Unmanned Surface Vehicles to Resist Environmental  Disturbances</td><td>11350</td></tr><tr><td>Not Your Grandmother’s Toolbox – the Robotics Toolbox Reinvented for Python</td><td>11357</td></tr><tr><td><strong>Session</strong> ThAT17 : Service Robotics II</td><td></td></tr><tr><td>A Robotic Defect Inspection System for Free-Form Specular Surfaces</td><td>11364</td></tr><tr><td>Keeping Social Distance During the Pandemic: Contactless Meal Order and Takeout Service Via  AI-Assisted Smart Robots</td><td>11371</td></tr><tr><td>Serverless Architecture for Service Robot Management System</td><td>11379</td></tr><tr><td>Can Non-Humanoid Social Robots Reduce Workload of Special Educators : An Online and In-Premises Field Study</td><td>11386</td></tr><tr><td><strong>Session</strong> ThAT18 : Service Robotics III</td><td></td></tr><tr><td>Heart Position Estimation Based on Bone Distribution Toward Autonomous Robotic Fetal Ultrasonography</td><td>11393</td></tr><tr><td>Chip-Less Wireless Sensing of Origami Structural Morphing under Various Mechanical Stimuli  Using Home-Based Ink-Jet Printable Materials</td><td>11400</td></tr><tr><td>Manivannan; Cai, Catherine; Ren, HongliangA 2-Dimensional Branch-And-Bound Algorithm for Hand-Eye Self-Calibration of SCARA Robots</td><td>11408</td></tr><tr><td>Long-Term Multiple Time-Constant Model of a Spring Roll Dielectric Elastomer Actuator under  Dynamic Loading</td><td>11415</td></tr><tr><td><strong>Session</strong> ThBT18 : Service Robotics IV</td><td></td></tr><tr><td>S2P2: Self-Supervised Goal-Directed Path Planning Using RGB-D Data for Robotic Wheelchairs</td><td>11422</td></tr><tr><td>HanGrawler: Large-Payload and High-Speed Ceiling Mobile Robot Using Crawler</td><td>11429</td></tr><tr><td>Multimodal Anomaly Detection Based on Deep Auto-Encoder for Object Slip Perception of Mobile  Manipulation Robots</td><td>11443</td></tr><tr><td>Route Coverage Testing for Autonomous Vehicles Via Map Modeling</td><td>11450</td></tr><tr><td><strong>Session</strong> ThAT19 : Service Robotics V</td><td></td></tr><tr><td>A Wheeled V-Shaped In-Pipe Robot with Clutched Underactuated Joints</td><td>11457</td></tr><tr><td>Walking Trajectory Design of Hydraulic Legged Robot with Limited Powered Pump</td><td>11463</td></tr><tr><td>Robotic Guide Dog: Leading a Human with Leash-Guided Hybrid Physical Interaction</td><td>11470</td></tr><tr><td>An Overconstrained Robotic Leg with Coaxial Quasi-Direct Drives for Omni-Directional Ground  Mobility</td><td>11477</td></tr><tr><td><strong>Session</strong> ThBT19 : Service Robotics VI</td><td></td></tr><tr><td>A Data-Set and a Method for Pointing Direction Estimation from Depth Images for Human-Robot  Interaction and VR Applications</td><td>11485</td></tr><tr><td>Learning-Based Optoelectronically Innervated Tactile Finger for Rigid-Soft Interactive Grasping</td><td>11492</td></tr><tr><td>ChaoyangSeqNet: Learning Descriptors for Sequence-based Hierarchical Place Recognition</td><td>11500</td></tr><tr><td>Extendable Navigation Network Based Reinforcement Learning for Indoor Robot Exploration</td><td>11508</td></tr><tr><td><strong>Session</strong> ThJT9 : Simulation and Control</td><td></td></tr><tr><td>Learning Dense Visual Correspondences in Simulation to Smooth and Fold Real Fabrics</td><td>11515</td></tr><tr><td>Daniel; Grannen, Jennifer; Hwang, Minho; Hoque, Ryan; Gonzalez, Joseph E.; Jamali,</td><td></td></tr><tr><td>Nawid; Yamane, Katsu; Iba, Soshi; Goldberg, Ken</td><td></td></tr><tr><td>Can I Pour into It? Robot Imagining Open Containability Affordance of Previously Unseen Objects  Via Physical Simulations</td><td>11523</td></tr><tr><td>Visualization of Stable Heteroclinic Channel-Based Movement Primitives</td><td>11531</td></tr><tr><td>Stable Learning-Based Tracking Control of Underactuated Balance Robots</td><td>11538</td></tr><tr><td><strong>Session</strong> WeBT12 : SLAM I</td><td></td></tr><tr><td>Hybrid Bird’s-Eye Edge Based Semantic Visual SLAM for Automated Valet Parking</td><td>11546</td></tr><tr><td>Collaborative Visual Inertial SLAM for Multiple Smart Phones</td><td>11553</td></tr><tr><td>MS*: A New Exact Algorithm for Multi-agent Simultaneous Multi-goal Sequencing and Path Finding</td><td>11560</td></tr><tr><td>Inertial Aided 3D LiDAR SLAM with Hybrid Geometric Primitives in Large-Scale Environments</td><td>11566</td></tr><tr><td><strong>Session</strong> ThET15 : SLAM II</td><td></td></tr><tr><td>Online Range-Based SLAM Using B-Spline Surfaces</td><td>11573</td></tr><tr><td>RGB-D SLAM with Structural Regularities</td><td>11581</td></tr><tr><td>Revisiting Visual-Inertial Structure-From-Motion for Odometry and SLAM Initialization</td><td>11588</td></tr><tr><td>RigidFusion: Robot Localisation and Mapping in Environments with Large Dynamic Rigid Objects</td><td>11596</td></tr><tr><td><strong>Session</strong> ThAT16 : SLAM III</td><td></td></tr><tr><td>Bidirectional Trajectory Computation for Odometer-Aided Visual-Inertial SLAM</td><td>11604</td></tr><tr><td>Optimization-Based Visual-Inertial SLAM Tightly Coupled with Raw GNSS Measurements</td><td>11612</td></tr><tr><td>LiTAMIN2: Ultra Light LiDAR-Based SLAM Using Geometric Approximation Applied with KL-Divergence</td><td>11619</td></tr><tr><td>Compositional and Scalable Object SLAM</td><td>11626</td></tr><tr><td><strong>Session</strong> ThFT15 : SLAM IV</td><td></td></tr><tr><td>MULLS: Versatile LiDAR SLAM Via Multi-Metric Linear Least Square</td><td>11633</td></tr><tr><td>Dynamic Object Aware LiDAR SLAM Based on Automatic Generation of Training Data</td><td>11641</td></tr><tr><td>A FastSLAM Approach Integrating Beamforming Maps for Ultrasound-Based Robotic Inspection of  Metal Structures</td><td>11648</td></tr><tr><td>Connecting Semantic Building Information Models and Robotics: An Application to 2D LiDAR-Based Localization</td><td>11654</td></tr><tr><td>René</td><td></td></tr><tr><td><strong>Session</strong> ThBT16 : SLAM V</td><td></td></tr><tr><td>Markov Parallel Tracking and Mapping for Probabilistic SLAM</td><td>11661</td></tr><tr><td>Multi-Session Underwater Pose-Graph SLAM Using Inter-Session Opti-Acoustic Two-View Factor</td><td>11668</td></tr><tr><td>Avoiding Degeneracy for Monocular Visual SLAM with Point and Line Features</td><td>11675</td></tr><tr><td>Intensity-SLAM: Intensity Assisted Localization and Mapping for Large Scale Environment</td><td>11682</td></tr><tr><td><strong>Session</strong> ThDT17 : SLAM VI</td><td></td></tr><tr><td>TT-SLAM: Dense Monocular SLAM for Planar Environments</td><td>11690</td></tr><tr><td>OV2SLAM : A Fully Online and Versatile Visual SLAM for Real-Time Applications</td><td>11697</td></tr><tr><td>DOT: Dynamic Object Tracking for Visual SLAM</td><td>11705</td></tr><tr><td>DefSLAM: Tracking and Mapping of Deforming Scenes from Monocular Sequences</td><td>11712</td></tr><tr><td><strong>Session</strong> ThHT10 : SLAM with Monocular Camera</td><td></td></tr><tr><td>CAROM - Vehicle Localization and Traffic Scene Reconstruction from Monocular Cameras on  Road Infrastructures</td><td>11725</td></tr><tr><td>A Front-End for Dense Monocular SLAM using a Learned Outlier Mask Prior</td><td>11732</td></tr><tr><td>HyperMap: Compressed 3D Map for Monocular Camera Registration</td><td>11739</td></tr><tr><td>Bidirectional Attention Network for Monocular Depth Estimation</td><td>11746</td></tr><tr><td><strong>Session</strong> ThIT10 : Soft Robotics I</td><td></td></tr><tr><td>Vision-Based Shape Reconstruction of Soft Continuum Arms Using a Geometric Strain  Parametrization</td><td>11753</td></tr><tr><td>Reconstruction of Backbone Curves for Snake Robots</td><td>11760</td></tr><tr><td>Hybrid Vine Robot with Internal Steering-Reeling Mechanism Enhances System-Level Capabilities</td><td>11767</td></tr><tr><td>A Dynamics Simulator for Soft Growing Robots</td><td>11775</td></tr><tr><td><strong>Session</strong> ThJT10 : Soft Robotics II</td><td></td></tr><tr><td>StRETcH: A Soft to Resistive Elastic Tactile Hand</td><td>11782</td></tr><tr><td>An Active Palm Enhances Dexterity of Soft Robotic In-Hand Manipulation</td><td>11790</td></tr><tr><td>Elastica: A compliant mechanics environment for soft robotic control</td><td>11797</td></tr><tr><td>Compensating for Unmodeled Forces Using Neural Networks in Soft Manipulator Planning</td><td>11805</td></tr><tr><td><strong>Session</strong> ThKT10 : Soft Robotics III</td><td></td></tr><tr><td>A Legged Soft Robot Platform for Dynamic Locomotion</td><td>11812</td></tr><tr><td>States and Contact Forces Estimation for a Fabric-Reinforced Inflatable Soft Robot</td><td>11820</td></tr><tr><td>Acoustic Communication and Sensing for Inflatable Modular Soft Robots</td><td>11827</td></tr><tr><td>Cooperative Collision Avoidance Control of Servo/IPMC Driven Robotic Fish with Back-Relaxation  Effect</td><td>11834</td></tr><tr><td><strong>Session</strong> WeAT9 : Soft Robotics IV</td><td></td></tr><tr><td>Elevation Control of a Soft Jumping Robot</td><td>11843</td></tr><tr><td>A Soft-Rigid Air-Propelled Pipe-Climbing Robot</td><td>11850</td></tr><tr><td>A Versatile Pneumatic Actuator Based on Scissor Mechanisms: Design, Modeling, and  Experiments</td><td>11856</td></tr><tr><td>A Lightweight Soft Gripper Driven by Self-Sensing Super-Coiled Polymer Actuator</td><td>11864</td></tr><tr><td><strong>Session</strong> WeBT9 : Soft Robotics V</td><td></td></tr><tr><td>Design and Analysis of a Novel Lightweight, Versatile Soft-Rigid Robot</td><td>11871</td></tr><tr><td>Kinetostatics for Variable Cross-Section Continuum Manipulators</td><td>11878</td></tr><tr><td>Numerical Simulation of an Untethered Omni-Directional Star-Shaped Swimming Robot</td><td>11884</td></tr><tr><td>Body Stiffness Variation of a Tensegrity Robotic Fish Using Antagonistic Stiffness in a  Kinematically Singular Configuration</td><td>11891</td></tr><tr><td><strong>Session</strong> ThAT15 : Soft Robotics: Actuation</td><td></td></tr><tr><td>Amplifying Laminar Jamming for Soft Robots by Geometry-Induced Rigidity</td><td>11907</td></tr><tr><td>Long Short Term Memory Model Based Position-Stiffness Control of Antagonistically Driven  Twisted-Coiled Polymer Actuators Using Model Predictive Control</td><td>11913</td></tr><tr><td>Expending Pouch Motor Patterns for Programmable Soft Bending Actuation</td><td>11921</td></tr><tr><td>Towards a Multi-Imager Compatible Continuum Robot with Improved Dynamics Driven by Modular  SMA</td><td>11930</td></tr><tr><td><strong>Session</strong> ThET14 : Soft Robotics: Analysis and Modeling</td><td></td></tr><tr><td>Screw Theory-Based Stiffness Analysis for a Fluidic-Driven Soft Robotic Manipulator</td><td>11938</td></tr><tr><td>Liquid Metal Logic for Soft Robotics</td><td>11945</td></tr><tr><td>Minimum Directed Information: A Design Principle for Compliant Robots</td><td>11953</td></tr><tr><td>Model and Validation of a Highly Extensible and Tough Actuator Based on a Ballooning Membrane</td><td>11961</td></tr><tr><td><strong>Session</strong> ThBT5 : Soft Robotics: Bionic Robots</td><td></td></tr><tr><td>SomBot: A Bio-Inspired Dynamic Somersaulting Soft Robot</td><td>11968</td></tr><tr><td>A Bioinspired Composite Finger with Self-Locking Joints</td><td>11976</td></tr><tr><td>A Multimodal, Enveloping Soft Gripper: Shape Conformation, Bioinspired Adhesion, and  Expansion-Driven Suction</td><td>11984</td></tr><tr><td>Design and Modeling of a Biomimetic Gastropod-Like Soft Robot with Wet Adhesive Locomotion</td><td>11997</td></tr><tr><td><strong>Session</strong> ThFT14 : Soft Robotics: Control I</td><td></td></tr><tr><td>Planning for a Tight Squeeze: Navigation of Morphing Soft Robots in Congested Environments</td><td>12004</td></tr><tr><td>Soft Robot Optimal Control Via Reduced Order Finite Element Models</td><td>12010</td></tr><tr><td>Multi-Point Orientation Control of Discretely-Magnetized Continuum Manipulators</td><td>12017</td></tr><tr><td>Design and Optimization of a Dextrous Robotic Finger: Incorporating a Sliding, Rotating, and Soft-Bending Mechanism While Maximizing Dexterity and Minimizing Dimensions</td><td>12025</td></tr><tr><td><strong>Session</strong> ThAT14 : Soft Robotics: Control II</td><td></td></tr><tr><td>Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot</td><td>12033</td></tr><tr><td>A Parallelized Iterative Algorithm for Real-Time Simulation of Long Flexible Cable Manipulation</td><td>12040</td></tr><tr><td>Compact Flat Fabric Pneumatic Artificial Muscle (ffPAM) for Soft Wearable Robotic Devices</td><td>12047</td></tr><tr><td>An Autonomous Robotic Flexible Endoscope System with a DNA-Inspired Continuum Mechanism</td><td>12055</td></tr><tr><td><strong>Session</strong> ThBT14 : Soft Robotics: Crawling Robots</td><td></td></tr><tr><td>Design and Experiment of a Pneumatic Soft Climbing Robot</td><td>12061</td></tr><tr><td>Starfish Inspired Milli Soft Robot with Omnidirectional Adaptive Locomotion Ability</td><td>12068</td></tr><tr><td>Surface Robots based on S-Isothermic Surfaces</td><td>12076</td></tr><tr><td>Ascidian-Inspired Soft Robots That Can Crawl, Tumble, and Pick-And-Place Objects</td><td>12082</td></tr><tr><td><strong>Session</strong> ThDT13 : Soft Robotics: Design</td><td></td></tr><tr><td>Highly Maneuverable Eversion Robot Based on Fusion of Function with Structure</td><td>12089</td></tr><tr><td>Automated Routing of Muscle Fibers for Soft Robots</td><td>12097</td></tr><tr><td>A Fluidic Soft Robot for Needle Guidance and Motion Compensation in Intratympanic Steroid  Injections</td><td>12110</td></tr><tr><td>B: Ionic Glove: A Soft Smart Wearable Sensory Feedback Device for Upper Limb Robotic  Prostheses</td><td>12118</td></tr><tr><td><strong>Session</strong> ThAT13 : Soft Robotics: Mechanism Design</td><td></td></tr><tr><td>Soft Twisting Pneumatic Actuators Enabled by Freeform Surface Design</td><td>12124</td></tr><tr><td>A Dual-Mode Actuator for Soft Robotic Hand</td><td>12132</td></tr><tr><td>Soft Gripper Design Based on the Integration of Flat Dry Adhesive, Soft Actuator, and Microspine</td><td>12140</td></tr><tr><td>Snap Pump: A Snap-Through Mechanism for a Pulsatile Pump</td><td>12156</td></tr><tr><td><strong>Session</strong> ThKT8 : Soft Sensors and Materials</td><td></td></tr><tr><td>A Soft Robotic Gripper with Anti-Freezing Ionic Hydrogel-Based Sensors for Learning-Based  Object Recognition</td><td>12164</td></tr><tr><td>Adaptive Tracking Control of Soft Robots Using Integrated Sensing Skins and Recurrent Neural  Networks</td><td>12170</td></tr><tr><td>WhiskSight: A reconfigurable, vision-based, optical whisker sensing array for simultaneous  contact, airflow, and inertia stimulus detection</td><td>12177</td></tr><tr><td>Embedded Neuromorphic Architecture for Form + Function 4-D Printing of Robotic Materials:  Emulation of Optimized Neurons</td><td>12185</td></tr><tr><td><strong>Session</strong> ThKT9 : Stereo Vision Applications</td><td></td></tr><tr><td>Toward Robust and Efficient Online Adaptation for Deep Stereo Depth Estimation</td><td>12192</td></tr><tr><td>Reconstructing Interactive 3D Scenes by Panoptic Mapping and CAD Model Alignments</td><td>12199</td></tr><tr><td>Learning the Next Best View for 3D Point Clouds Via Topological Features</td><td>12207</td></tr><tr><td>A New Framework for Registration of Semantic Point Clouds from Stereo and RGB-D Cameras</td><td>12214</td></tr><tr><td><strong>Session</strong> WeCT15 : Surgical Continuum Robots</td><td></td></tr><tr><td>Towards Collision Detection, Localization and Force Estimation for a Soft Cable-Driven  Manipulator</td><td>12222</td></tr><tr><td>Kinematic Analysis of a Flexible Surgical Instrument for Robot-Assisted Minimally Invasive Surgery</td><td>12229</td></tr><tr><td>Hybrid Adaptive Control Strategy for Continuum Surgical Robot under External Load</td><td>12236</td></tr><tr><td>Bing; Meng, Max Q.-H.A Multi-Contact-Aided Continuum Manipulator with Anisotropic Shapes</td><td>12244</td></tr><tr><td><strong>Session</strong> ThHT8 : Surgical Robotics I</td><td></td></tr><tr><td>Parallelism in Autonomous Robotic Surgery</td><td>12252</td></tr><tr><td>Septimiu E. A Confidence-Based Supervised-Autonomous Control Strategy for Robotic Vaginal Cuff Closure</td><td>12261</td></tr><tr><td>Design and Control of 5-DoF Robotically Steerable Catheter for the Delivery of the Mitral Valve  Implant</td><td>12268</td></tr><tr><td>A Robotic System for Implant Modification in Single-Stage Cranioplasty</td><td>12275</td></tr><tr><td><strong>Session</strong> ThBT13 : Surgical Robotics II</td><td></td></tr><tr><td>Design and Implementation of a Novel, Intrinsically Safe Rigid-Flexible Coupling Manipulator for  COVID-19 Oropharyngeal Swab Sampling</td><td>12282</td></tr><tr><td>Design and Control of Fully Handheld Microsurgical Robot for Active Tremor Cancellation</td><td>12289</td></tr><tr><td>Towards a Wristed Percutaneous Robot with Variable Stiffness for Pericardiocentesis</td><td>12296</td></tr><tr><td>Corneal Suturing Robot Capable of Producing Sutures with Desired Shape for Corneal  Transplantation Surgery</td><td>12305</td></tr><tr><td><strong>Session</strong> ThIT8 : Surgical Robotics III</td><td></td></tr><tr><td>Recovering Stress Distribution on Deformable Tissue for a Magnetic Actuated Insertable  Laparoscopic Surgical Camera</td><td>12314</td></tr><tr><td>A Novel Robotic System for Ultrasound-Guided Peripheral Vascular Localization</td><td>12321</td></tr><tr><td>Real-To-Sim Registration of Deformable Soft Tissue with Position-Based Dynamics for Surgical  Robot Autonomy</td><td>12328</td></tr><tr><td>Toward Force Estimation in Robot-Assisted Surgery Using Deep Learning with Vision and Robot  State</td><td>12335</td></tr><tr><td><strong>Session</strong> ThAT12 : Surgical Robotics IV</td><td></td></tr><tr><td>A Variable Curvature Model for Multi-Backbone Continuum Robots to Account for Inter-Segment  Coupling and External Disturbance</td><td>12342</td></tr><tr><td>Learning Domain Adaptation with Model Calibration for Surgical Report Generation in Robotic  Surgery</td><td>12350</td></tr><tr><td>Tele-Operative Low-Cost Robotic Lung Ultrasound Scanning Platform for Triage of COVID-19 Patients</td><td>12357</td></tr><tr><td>Olushola Segun; Zheng, Yihao; Hill, Jeffrey C.; Hoffmann, Beatrice; Soboyejo, Winston;</td><td></td></tr><tr><td>Zhang, Haichong Data-Driven Holistic Framework for Automated Laparoscope Optimal View Control with Learning-Based Depth Perception</td><td>12366</td></tr><tr><td><strong>Session</strong> ThJT8 : Surgical Robotics V</td><td></td></tr><tr><td>Multibranch Learning for Angiodysplasia Segmentation with Attention-Guided Networks and  Domain Adaptation</td><td>12373</td></tr><tr><td>Model-Predictive Control of Blood Suction for Surgical Hemostasis Using Differentiable Fluid  Simulations</td><td>12380</td></tr><tr><td>Autonomous Robotic Suction to Clear the Surgical Field for Hemostasis Using Image-Based Blood  Flow Detection</td><td>12387</td></tr><tr><td>Learning Invariant Representation of Tasks for Robust Surgical State Estimation</td><td>12395</td></tr><tr><td><strong>Session</strong> ThET13 : Surgical Robotics VI</td><td></td></tr><tr><td>Bayesian Neural Network Modeling and Hierarchical MPC for a Tendon-Driven Surgical Robot with  Uncertainty Minimization</td><td>12403</td></tr><tr><td>PetarMAMMOBOT: A Miniature Steerable Soft Growing Robot for Early Breast Cancer Detection</td><td>12411</td></tr><tr><td>Data-Driven Intra-Operative Estimation of Anatomical Attachments for Autonomous Tissue  Dissection</td><td>12420</td></tr><tr><td>Design and Development of a Robotic Bioreactor for in Vitro Tissue Engineering</td><td>12428</td></tr><tr><td><strong>Session</strong> ThFT13 : Surgical Robotics VII</td><td></td></tr><tr><td>Model-Based Design and Digital Implementation to Improve Control of the Da Vinci Research Kit  Telerobotic Surgical System</td><td>12435</td></tr><tr><td>Shared Control Strategy for Needle Insertion into Deformable Tissue Using Inverse Finite Element  Simulation</td><td>12442</td></tr><tr><td>An Optimized Two-Layer Approach for Efficient and Robustly Stable Bilateral Teleoperation</td><td>12449</td></tr><tr><td>Secchi, Cristian Design and Evaluation of a Foot-Controlled Robotic System for Endoscopic Surgery</td><td>12456</td></tr><tr><td><strong>Session</strong> WeCT13 : Surgical Robots IX</td><td></td></tr><tr><td>Cutting Depth Compensation Based on Milling Acoustic Signal for Robotic-Assisted Laminectomy</td><td>12464</td></tr><tr><td>Non-Linear Hysteresis Compensation of a Tendon-Sheath-Driven Robotic Manipulator Using Motor  Current</td><td>12470</td></tr><tr><td>Fast Localization and Segmentation of Tissue Abnormalities by Autonomous Robotic Palpation</td><td>12478</td></tr><tr><td>Hysteresis Modeling of Robotic Catheters Based on Long Short-Term Memory Network for  Improved Environment Reconstruction</td><td>12486</td></tr><tr><td><strong>Session</strong> ThDT12 : Surgical Robots VIII</td><td></td></tr><tr><td>Motion-Aware Robotic 3D Ultrasound</td><td>12494</td></tr><tr><td>A 3D Printed Mechanical Model of the Knee to Detect and Avoid Total Knee Replacement Surgery  Errors</td><td>12501</td></tr><tr><td>Detecting Blindspots in Colonoscopy by Modelling Curvature</td><td>12508</td></tr><tr><td>Out-Of-Plane Corrections for Autonomous Robotic Breast Ultrasound Acquisitions</td><td>12515</td></tr><tr><td><strong>Session</strong> ThET12 : Tactile Sensing for Manipulation</td><td></td></tr><tr><td>Improved Learning of Robot Manipulation Tasks Via Tactile Intrinsic Motivation</td><td>12522</td></tr><tr><td>Exploiting Distributed Tactile Sensors to Drive a Robot Arm through Obstacles</td><td>12530</td></tr><tr><td>Slip Detection for Grasp Stabilisation with a Multi-Fingered Tactile Robot Hand</td><td>12538</td></tr><tr><td>Grasp Detection for Robot to Human Handovers Using Capacitive Sensors</td><td>12552</td></tr><tr><td><strong>Session</strong> ThFT12 : Tactile Sensing in Surgical Appplications</td><td></td></tr><tr><td>Foot Control of a Surgical Laparoscopic Gripper Via 5DoF Haptic Robotic Platform: Design,  Dynamics and Haptic Shared Control</td><td>12559</td></tr><tr><td>Providing Automatic Feedback to Trainees after Automatic Evaluation</td><td>12567</td></tr><tr><td>An Abdominal Phantom with Tunable Stiffness Nodules and Force Sensing Capability for Palpation  Training</td><td>12574</td></tr><tr><td>A Haptic Mouse Design with Stiffening Muscle Layer for Simulating Guarding in Abdominal  Palpation Training</td><td>12588</td></tr><tr><td><strong>Session</strong> ThIT9 : Task Planning I</td><td></td></tr><tr><td>Deep Learning for Robotic Mass Transport Cloaking</td><td>12595</td></tr><tr><td>Collective Transport of Unconstrained Objects Via Implicit Coordination and Adaptive Compliance</td><td>12603</td></tr><tr><td>Approximate Solutions to a Class of Reachability Games</td><td>12610</td></tr><tr><td>Reactive Task and Motion Planning under Temporal Logic Specifications</td><td>12618</td></tr><tr><td><strong>Session</strong> ThHT9 : Task Planning II</td><td></td></tr><tr><td>Dispersion-Minimizing Motion Primitives for Search-Based Motion Planning</td><td>12625</td></tr><tr><td>Meta-Adversarial Inverse Reinforcement Learning for Decision-Making Tasks</td><td>12632</td></tr><tr><td>Min-Max Entropy Inverse RL of Multiple Tasks</td><td>12639</td></tr><tr><td>Task Planning on Stochastic Aisle Graphs for Precision Agriculture</td><td>12646</td></tr><tr><td><strong>Session</strong> ThDT11 : Task Planning III</td><td></td></tr><tr><td>Productive Multitasking for Industrial Robots</td><td>12654</td></tr><tr><td>Automated Planning of Workcell Layouts Considering Task Sequences</td><td>12662</td></tr><tr><td>Multi-Robot Task Sequencing &amp; Automatic Path Planning for Cycle Time Optimization: Application  for Car Production Line</td><td>12669</td></tr><tr><td>Multi-Goal Path Planning Using Multiple Random Trees</td><td>12677</td></tr><tr><td><strong>Session</strong> ThHT7 : Time Delay Systems</td><td></td></tr><tr><td>Delay-Robust Nonlinear Control of Bounded-Input Telerobotic Systems with Synchronization</td><td></td></tr><tr><td>Enhancement</td><td>12685</td></tr><tr><td>DESERTS: Delay-Tolerant Semi-Autonomous Robot Teleoperation for Surgery</td><td>12693</td></tr><tr><td>Discrete Time Delay Feedback Control of Stewart Platform with Intelligent Optimizer Weight Tuner</td><td>12701</td></tr><tr><td>The Effect of Input Signals Time-Delay on Stabilizing Traffic with Autonomous Vehicles</td><td>12708</td></tr><tr><td><strong>Session</strong> ThIT7 : Topology-Based Motion Planning</td><td></td></tr><tr><td>Homotopy-Driven Exploration of Human-Made Spaces Using Signs</td><td>12715</td></tr><tr><td>A Topologically Inspired Path-Following Method with Intermittent State Feedback</td><td>12722</td></tr><tr><td>Graph-Based Topological Exploration Planning in Large-Scale 3D Environments</td><td>12730</td></tr><tr><td>Roadmap Learning for Probabilistic Occupancy Maps with Topology-Informed Growing Neural Gas</td><td>12737</td></tr><tr><td><strong>Session</strong> ThET11 : Trajectory Optimization</td><td></td></tr><tr><td>Trajectory Optimisation in Learned Multimodal Dynamical Systems Via Latent-ODE Collocation</td><td>12745</td></tr><tr><td>Inverse Dynamics vs. Forward Dynamics in Direct Transcription Formulations for Trajectory  Optimization</td><td>12752</td></tr><tr><td>Coupled Mobile Manipulation Via Trajectory Optimization with Free Space Decomposition</td><td>12759</td></tr><tr><td>Designing Fast and Smooth Trajectories in Collaborative Workstations</td><td>12766</td></tr><tr><td>Session ThFT11 : Trajectory PlanningOnline Dynamic Trajectory Optimization and Control for a Quadruped Robot</td><td>12773</td></tr><tr><td>Online DCM Trajectory Adaptation for Push and Stumble Recovery during Humanoid Locomotion</td><td>12780</td></tr><tr><td>Circular Fields and Predictive Multi-Agents for Online Global Trajectory Planning</td><td>12787</td></tr><tr><td>Exploring Dynamic Context for Multi-Path Trajectory Prediction</td><td>12795</td></tr><tr><td><strong>Session</strong> ThDT10 : Transfer Learning</td><td></td></tr><tr><td>Benchmarking Domain Randomisation for Visual Sim-To-Real Transfer</td><td>12802</td></tr><tr><td>There and Back Again: Learning to Simulate Radar Data for Real-World Applications</td><td>12809</td></tr><tr><td>Generation of GelSight Tactile Images for Sim2Real Learning</td><td>12817</td></tr><tr><td>Virtual Radar: Real-Time Millimeter-Wave Radar Sensor Simulation for Perception-Driven Robotics</td><td>12825</td></tr><tr><td><strong>Session</strong> ThBT12 : Underactuated and Stable Control</td><td></td></tr><tr><td>A Stable Control Strategy for Industrial Robots with External Feedback Loop</td><td>12833</td></tr><tr><td>Distance-Based Formation Control with Goal Assignment for Global Asymptotic Stability of Multi-Robot Systems</td><td>12839</td></tr><tr><td>Operational Space Control Under Actuator Bandwidth Limitation</td><td>12847</td></tr><tr><td>Operational Space Control for Planar PA^{N-1} Underactuated Manipulators Using Orthogonal  Projection and Quadratic Programming</td><td>12853</td></tr><tr><td><strong>Session</strong> TuHT4 : Unmanned Aerial Vehicle Award Session</td><td></td></tr><tr><td>Dynamically Feasible Task Space Planning for Underactuated Aerial Manipulators</td><td>12860</td></tr><tr><td><strong>Session</strong> ThAT11 : Vision and Perception I</td><td></td></tr><tr><td>PLG-IN: Pluggable Geometric Consistency Loss with Wasserstein Distance in Monocular Depth  Estimation</td><td>12868</td></tr><tr><td>Real-Time Mesh Extraction from Implicit Functions via Direct Reconstruction of Decision Boundary</td><td>12875</td></tr><tr><td>Uncertainty-Aware Fast Curb Detection Using Convolutional Networks in Point Clouds</td><td>12882</td></tr><tr><td>OCR-Based Inventory Management Algorithms Robust to Damaged Images</td><td>12889</td></tr><tr><td><strong>Session</strong> ThBT11 : Vision and Perception II</td><td></td></tr><tr><td>FG-Conv: Large-Scale LiDAR Point Clouds Understanding Leveraging Feature Correlation Mining  and Geometric-Aware Modeling</td><td>12896</td></tr><tr><td>Exploiting Local Geometry for Feature and Graph Construction for Better 3D Point Cloud  Processing with Graph Neural Networks</td><td>12903</td></tr><tr><td>Elevation Angle Estimation in 2D Acoustic Images Using Pseudo Front View</td><td>12910</td></tr><tr><td>Stereo Object Matching Network</td><td>12918</td></tr><tr><td><strong>Session</strong> ThAT10 : Vision and Perception III</td><td></td></tr><tr><td>Robot Motion Control with Compressive Feedback</td><td>12925</td></tr><tr><td>Action Sequencing Using Visual Permutations</td><td>12931</td></tr><tr><td>MFPN-6D : Real-time One-stage Pose Estimation of Objects on RGB Images</td><td>12939</td></tr><tr><td>A Novel Tactile Feedback System with On-Line Texture Decoding and Direct-Texture-Feedback</td><td>12946</td></tr><tr><td><strong>Session</strong> ThBT10 : Vision and Perception IV</td><td></td></tr><tr><td>Visual Place Recognition Via Local Affine Preserving Matching</td><td>12954</td></tr><tr><td>View-Expansive Microscope System with Real-Time High-Resolution Imaging for Simplified  Microinjection Experiments</td><td>12961</td></tr><tr><td>Leveraging Enhanced Virtual Reality Methods and Environments for Efficient, Intuitive, and  Immersive Teleoperation of Robots</td><td>12967</td></tr><tr><td>End-To-End Multi-Instance Robotic Reaching from Monocular Vision</td><td>12974</td></tr><tr><td><strong>Session</strong> ThAT9 : Vision and Perception V</td><td></td></tr><tr><td>Toward a Unified Framework for Point Set Registration</td><td>12981</td></tr><tr><td>A Heteroscedastic Likelihood Model for Two-Frame Optical Flow</td><td>12988</td></tr><tr><td>Microinjection System to Enable Real-Time 3D Image Presentation through Focal Position  Adjustment</td><td>12996</td></tr><tr><td>Volumetric Propagation Network: Stereo-LiDAR Fusion for Long-Range Depth Estimation</td><td>13003</td></tr><tr><td><strong>Session</strong> WeCT8 : Vision and Perception: 3D Estimation</td><td></td></tr><tr><td>Robust Improvement in 3D Object Landmark Inference for Semantic Mapping</td><td>13011</td></tr><tr><td>YOLOStereo3D: A Step Back to 2D for Efficient Stereo 3D Detection</td><td>13018</td></tr><tr><td>UniFuse: Unidirectional Fusion for 360 Panorama Depth Estimation</td><td>13025</td></tr><tr><td>Depth Estimation under Motion with Single Pair Rolling Shutter Stereo Images</td><td>13033</td></tr><tr><td><strong>Session</strong> ThFT10 : Vision and Perception: Action Recognition I</td><td></td></tr><tr><td>Pose Refinement Graph Convolutional Network for Skeleton-Based Action Recognition</td><td>13041</td></tr><tr><td>Attentional Learn-Able Pooling for Human Activity Recognition</td><td>13049</td></tr><tr><td>Real-Time Instance Detection with Fast Incremental Learning</td><td>13056</td></tr><tr><td>3D3L: Deep Learned 3D Keypoint Detection and Description for LiDARs</td><td>13064</td></tr><tr><td><strong>Session</strong> WeCT1 : Vision and Perception: Action Recognition II</td><td></td></tr><tr><td>Maintaining a Reliable World Model Using Action-Aware Perceptual Anchoring</td><td>13071</td></tr><tr><td>Modeling Affect-Based Intrinsic Rewards for Exploration and Learning</td><td>13078</td></tr><tr><td>A Multi-Level Network for Human Pose Estimation</td><td>13085</td></tr><tr><td>Open-Set Intersection Intention Prediction for Autonomous Driving</td><td>13092</td></tr><tr><td><strong>Session</strong> ThHT1 : Vision and Perception: Applications I</td><td></td></tr><tr><td>LiDAR Few-Shot Domain Adaptation Via Integrated CycleGAN and 3D Object Detector with Joint  Learning Delay</td><td>13099</td></tr><tr><td>Three-Filters-To-Normal: An Accurate and Ultrafast Surface Normal Estimator</td><td>13106</td></tr><tr><td>Device Design and System Integration of a Two-Axis Water-Immersible Micro Scanning Mirror (WIMSM) to Enable Dual-Modal Optical and Acoustic Communication and Ranging for Underwater Vehicles</td><td>13114</td></tr><tr><td>Vanishing Point Aided LiDAR-Visual-Inertial Estimator</td><td>13120</td></tr><tr><td>Session ThIT1 : Vision and Perception: Applications IIFine-Grained Activity Recognition for Assembly Videos</td><td>13127</td></tr><tr><td>Sanjeev; Hager, Gregory Cooperative Visual-Inertial Odometry</td><td>13135</td></tr><tr><td>Vision-Based Self-Assembly for Modular Multirotor Structures</td><td>13142</td></tr><tr><td>Evaluation of a Drone-Based Camera Calibration Approach for Hard-To-Reach Cameras</td><td>13149</td></tr><tr><td><strong>Session</strong> ThJT1 : Vision and Perception: Auto-Calibration</td><td></td></tr><tr><td>Online Photometric Calibration of Automatic Gain Thermal Infrared Cameras</td><td>13156</td></tr><tr><td>A Continuous-Time Approach for 3D Radar to Camera Extrinsic Calibration</td><td>13164</td></tr><tr><td>Learned Camera Gain and Exposure Control for Improved Visual Feature Detection and Matching</td><td>13171</td></tr><tr><td>Auto-Calibration Method Using Stop Signs for Urban Autonomous Driving Applications</td><td>13179</td></tr><tr><td><strong>Session</strong> ThHT2 : Vision and Perception: Autonomous Vehicle Navigation I</td><td></td></tr><tr><td>Learning Robust Driving Policies without Online Exploration</td><td>13186</td></tr><tr><td>SSCNav: Confidence-Aware Semantic Scene Completion for Visual Semantic Navigation</td><td>13194</td></tr><tr><td>Ego-Centric Stereo Navigation Using Stixel World</td><td>13201</td></tr><tr><td>PyTouch: A Machine Learning Library for Touch Processing</td><td>13208</td></tr><tr><td><strong>Session</strong> ThIT2 : Vision and Perception: Autonomous Vehicle Navigation II</td><td></td></tr><tr><td>ViNG: Learning Open-World Navigation with Visual Goals</td><td>13215</td></tr><tr><td>MaAST: Map Attention with Semantic Transformers for Efficient Visual Navigation</td><td>13223</td></tr><tr><td>Samarasekera, Supun; Kumar, Rakesh A Few Shot Adaptation of Visual Navigation Skills to New Observations Using Meta-Learning</td><td>13231</td></tr><tr><td>Hierarchical Cross-Modal Agent for Robotics Vision-And-Language Navigation</td><td>13238</td></tr><tr><td><strong>Session</strong> ThKT1 : Vision and Perception: Autonomous Vehicle Navigation III</td><td></td></tr><tr><td>Efficient and Robust LiDAR-Based End-To-End Navigation</td><td>13247</td></tr><tr><td>Visual Navigation among Humans with Optimal Control As a Supervisor</td><td>13255</td></tr><tr><td>Environmental Hotspot Identification in Limited Time with a UAV Equipped with a Downward-Facing Camera</td><td>13264</td></tr><tr><td>Learning Composable Behavior Embeddings for Long-Horizon Visual Navigation</td><td>13271</td></tr><tr><td><strong>Session</strong> ThET10 : Vision and Perception: Detection and Recognition I</td><td></td></tr><tr><td>VelocityNet: Motion-Driven Feature Aggregation for 3D Object Detection in Point Cloud Sequences</td><td>13279</td></tr><tr><td>Don’t Blindly Trust Your CNN: Towards Competency-Aware Object Detection by Evaluating Novelty  in Open-Ended Environments</td><td>13286</td></tr><tr><td>What My Motion Tells Me about Your Pose: A Self-Supervised Monocular 3D Vehicle Detector</td><td>13293</td></tr><tr><td>Self-Supervised Person Detection in 2D Range Data Using a Calibrated Camera</td><td>13301</td></tr><tr><td><strong>Session</strong> WeBT8 : Vision and Perception: Detection and Recognition II</td><td></td></tr><tr><td>A Cascaded LiDAR-Camera Fusion Network for Road Detection</td><td>13308</td></tr><tr><td>GPR-RCNN: An Algorithm of Subsurface Defect Detection for Airport Runway based on GPR</td><td>13315</td></tr><tr><td>On the Challenges of Open World Recognition under Shifting Visual Domains</td><td>13323</td></tr><tr><td>CentroidReg: A Global-To-Local Framework for Partial Point Cloud Registration</td><td>13331</td></tr><tr><td><strong>Session</strong> ThBT9 : Vision and Perception: Detection and Recognition III</td><td></td></tr><tr><td>Real-Time 3D-Lidar, MMW Radar and GPS/IMU Fusion Based Vehicle Detection and Tracking in  Unstructured Environment</td><td>13339</td></tr><tr><td>Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture  Recognition in Robotic Surgery</td><td>13346</td></tr><tr><td>In Defense of Knowledge Distillation for Task Incremental Learning and Its Application in 3D Object  Detection</td><td>13354</td></tr><tr><td>City-Scale Scene Change Detection Using Point Clouds</td><td>13362</td></tr><tr><td><strong>Session</strong> ThAT8 : Vision and Perception: Detection and Recognition IV</td><td></td></tr><tr><td>Joint Representation of Temporal Image Sequences and Object Motion for Video Object Detection</td><td>13370</td></tr><tr><td>Targetless Multiple Camera-LiDAR Extrinsic Calibration Using Object Pose Estimation</td><td>13377</td></tr><tr><td>Recognition and Prediction of Surgical Actions Based on Online Robotic Tool Detection</td><td>13384</td></tr><tr><td>Target-style-aware Unsupervised Domain Adaptation for Object Detection</td><td>13392</td></tr><tr><td><strong>Session</strong> ThAT1 : Vision and Perception: Detection and Recognition V</td><td></td></tr><tr><td>Adversarially Trained Hierarchical Feature Extractor for Vehicle Re-Identification</td><td>13400</td></tr><tr><td>VIC-Net: Voxelization Information Compensation Network for Point Cloud 3D Object Detection</td><td>13408</td></tr><tr><td>Semantic Reinforced Attention Learning for Visual Place Recognition</td><td>13415</td></tr><tr><td>Towards Efficient Multiview Object Detection with Adaptive Action Prediction</td><td>13423</td></tr><tr><td><strong>Session</strong> ThDT9 : Vision and Perception: Grasping I</td><td></td></tr><tr><td>Binary-LoRAX: Low-Latency Runtime Adaptable XNOR Classifier for Semi-Autonomous Grasping  with Prosthetic Hands</td><td>13430</td></tr><tr><td>Hundhausen, Felix; Hoefer, Julian; Nagaraja, Naveen Shankar; Unger, Christian; Voegel,</td><td></td></tr><tr><td>Hans-Joerg; Becker, Juergen; Asfour, Tamim; Stechele, Walter Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes</td><td>13438</td></tr><tr><td>Residual Squeeze-And-Excitation Network with Multi-Scale Spatial Pyramid Module for Fast  Robotic Grasping Detection</td><td>13445</td></tr><tr><td>End-To-End Trainable Deep Neural Network for Robotic Grasp Detection and Semantic  Segmentation from RGB</td><td>13452</td></tr><tr><td><strong>Session</strong> WeAT8 : Vision and Perception: Grasping II</td><td></td></tr><tr><td>RGB Matters: Learning 7-DoF Grasp Poses on Monocular RGBD Images</td><td>13459</td></tr><tr><td>Hybrid Vision/Force Control for Interaction with the Bottle-Like Object</td><td>13467</td></tr><tr><td>REGNet: REgion-Based Grasp Network for End-To-End Grasp Detection in Point Clouds</td><td>13474</td></tr><tr><td>Visual Servoing of a Cable-Driven Soft Robot Manipulator with Shape Feature</td><td>13481</td></tr><tr><td><strong>Session</strong> ThJT2 : Vision and Perception: Identification and Prediction</td><td></td></tr><tr><td>Efficient Real-Time Inference in Temporal Convolution Networks</td><td>13489</td></tr><tr><td>F-SIOL-310: A Robotic Dataset and Benchmark for Few-Shot Incremental Object Learning</td><td>13496</td></tr><tr><td>Deformable Linear Object Prediction Using Locally Linear Latent Dynamics</td><td>13503</td></tr><tr><td>Visual-Inertial Filtering for Human Walking Quantification</td><td>13510</td></tr><tr><td><strong>Session</strong> ThET9 : Vision and Perception: Image Segmentation I</td><td></td></tr><tr><td>CABiNet: Efficient Context Aggregation Network for Low-Latency Semantic Segmentation</td><td>13517</td></tr><tr><td>Efficient RGB-D Semantic Segmentation for Indoor Scene Analysis</td><td>13525</td></tr><tr><td>Plane Segmentation in Organized Point Clouds Using Flood Fill</td><td>13532</td></tr><tr><td>Semantic Feature Mining for 3D Object Classification and Segmentation</td><td>13539</td></tr><tr><td><strong>Session</strong> WeAT1 : Vision and Perception: Image Segmentation II</td><td></td></tr><tr><td>Discriminative Asymmetric Learning for Efficient Surgical Instrument Parsing</td><td>13546</td></tr><tr><td>One to Many: Adaptive Instrument Segmentation Via Meta Learning and Dynamic Online  Adaptation in Robotic Surgical Video</td><td>13553</td></tr><tr><td>Target-Targeted Domain Adaptation for Unsupervised Semantic Segmentation</td><td>13560</td></tr><tr><td>Point Cloud Segmentation Via Edge-Fused Local Graph Learning</td><td>13567</td></tr><tr><td><strong>Session</strong> ThFT9 : Vision and Perception: Image Segmentation III</td><td></td></tr><tr><td>PlaneSegNet: Fast and Robust Plane Estimation Using a Single-Stage Instance Segmentation  CNN</td><td>13574</td></tr><tr><td>Fast Object Segmentation Learning with Kernel-Based Methods for Robotics</td><td>13581</td></tr><tr><td>Diffuser: Multi-View 2D-to-3D Label Diffusion for Semantic Scene Segmentation</td><td>13589</td></tr><tr><td>A Benchmark for LiDAR-Based Panoptic Segmentation Based on KITTI</td><td>13596</td></tr><tr><td><strong>Session</strong> ThKT2 : Vision and Perception: Learning</td><td></td></tr><tr><td>Object-Centric Video Prediction without Annotation</td><td>13604</td></tr><tr><td>Generalization in Reinforcement Learning by Soft Data Augmentation</td><td>13611</td></tr><tr><td>Test-Time Training for Deformable Multi-Scale Image Registration</td><td>13618</td></tr><tr><td>Multi-GAT: A Graphical Attention-Based Hierarchical Multimodal Representation Learning  Approach for Human Activity Recognition</td><td>13626</td></tr><tr><td><strong>Session</strong> ThAT2 : Vision and Perception: Measurement</td><td></td></tr><tr><td>Learning a Geometric Representation for Data-Efficient Depth Estimation Via Gradient Field and  Contrastive Loss</td><td>13634</td></tr><tr><td>Stereo-Augmented Depth Completion from a Single RGB-LiDAR Image</td><td>13641</td></tr><tr><td>Identifying Reflected Images from Object Detector in Indoor Environment Utilizing Depth  Information</td><td>13648</td></tr><tr><td>PENet: Towards Precise and Efficient Image Guided Depth Completion</td><td>13656</td></tr><tr><td><strong>Session</strong> ThHT3 : Vision and Perception: Modeling</td><td></td></tr><tr><td>Contingencies from Observations: Tractable Contingency Planning with Learned Behavior Models</td><td>13663</td></tr><tr><td>ScrewNet: Category-Independent Articulation Model Estimation from Depth Images Using Screw Theory</td><td>13670</td></tr><tr><td>Visual Perspective Taking for Opponent Behavior Modeling</td><td>13678</td></tr><tr><td>Learning Tactile Models for Factor Graph-Based Estimation</td><td>13686</td></tr><tr><td><strong>Session</strong> ThIT3 : Vision and Perception: Multi-Agents</td><td></td></tr><tr><td>Congestion-Aware Multi-Agent Trajectory Prediction for Collision Avoidance</td><td>13693</td></tr><tr><td>3D Multi-Object Tracking Using Random Finite Set-Based Multiple Measurement Models Filtering (RFS-M^3) for Autonomous Vehicles</td><td>13701</td></tr><tr><td>Joint Object Detection and Multi-Object Tracking with Graph Neural Networks</td><td>13708</td></tr><tr><td>Droidlet: Modular, Heterogenous, Multi-Modal Agents</td><td>13716</td></tr><tr><td>Yuxuan; Drew, Ryan; Elkafrawy, Sara; Tiwari, Anoushka; Hart, Tucker; Williamson, Mary;</td><td></td></tr><tr><td>Gupta, Abhinav; Szlam, Arthur</td><td></td></tr><tr><td><strong>Session</strong> ThBT1 : Vision and Perception: Navigation and Autonomous Driving</td><td></td></tr><tr><td>Robust Navigation for Racing Drones based on Imitation Learning and Modularization</td><td>13724</td></tr><tr><td>Learning Interpretable End-to-End Vision-Based Motion Planning for Autonomous Driving with Optical Flow Distillation</td><td>13731</td></tr><tr><td>Cross-Modal Contrastive Learning of Representations for Navigation Using Lightweight, Low-Cost Millimeter Wave Radar for Adverse Environmental Conditions</td><td>13738</td></tr><tr><td>Task-Driven Deep Image Enhancement Network for Autonomous Driving in Bad Weather</td><td>13746</td></tr><tr><td><strong>Session</strong> ThDT1 : Vision and Perception: Navigation I</td><td></td></tr><tr><td>VINSEval: Evaluation Framework for Unified Testing of Consistency and Robustness of Visual-Inertial Navigation System Algorithms</td><td>13754</td></tr><tr><td>Embodied Visual Navigation with Automatic Curriculum Learning in Real Environments</td><td>13761</td></tr><tr><td>An Event-based Vision Dataset for Visual Navigation Tasks in Agricultural Environments</td><td>13769</td></tr><tr><td>Visual Navigation in Real-World Indoor Environments Using End-To-End Deep Reinforcement  Learning</td><td>13776</td></tr><tr><td><strong>Session</strong> WeBT1 : Vision and Perception: Navigation II</td><td></td></tr><tr><td>A Real-Time Multi-Task Framework for Guidewire Segmentation and Endpoint Localization in  Endovascular Interventions</td><td>13784</td></tr><tr><td>Towards Adjoint Sensing and Acting Schemes and Interleaving Task Planning for Robust Robot Plan</td><td>13791</td></tr><tr><td>Autonomous Multi-View Navigation Via Deep Reinforcement Learning</td><td>13798</td></tr><tr><td>Towards Multi-Modal Perception-Based Navigation: A Deep Reinforcement Learning Method</td><td>13805</td></tr><tr><td><strong>Session</strong> ThJT3 : Vision and Perception: Optimization I</td><td></td></tr><tr><td>VOLDOR-SLAM: For the Times When Feature-Based or Direct Methods Are Not Good Enough</td><td>13813</td></tr><tr><td>ROBIN: A Graph-Theoretic Approach to Reject Outliers in Robust Estimation Using Invariants</td><td>13820</td></tr><tr><td>CLIPPER: A Graph-Theoretic Framework for Robust Data Association</td><td>13828</td></tr><tr><td>Monitoring Fatigue-Induced Changes in Performance During Robot-Mediated Dynamic Movement</td><td>13835</td></tr><tr><td><strong>Session</strong> ThET1 : Vision and Perception: Optimization II</td><td></td></tr><tr><td>Optimizing Keypoint-Based Single-Shot Camera-To-Robot Pose Estimation through Shape  Segmentation</td><td>13843</td></tr><tr><td>Handling Object Symmetries in CNN-Based Pose Estimation</td><td>13850</td></tr><tr><td>Efficient and Robust Orientation Estimation of Strawberries for Fruit Picking Applications</td><td>13857</td></tr><tr><td>Probabilistic Terrain Estimation for Autonomous Off-Road Driving</td><td>13864</td></tr><tr><td><strong>Session</strong> ThKT3 : Vision and Perception: Point Cloud</td><td></td></tr><tr><td>Evaluating Initialization Methods for Discriminative and Fast-Converging HGMM Point Clouds</td><td>13871</td></tr><tr><td>Navigable Space Construction from Sparse Noisy Point Clouds</td><td>13877</td></tr><tr><td>Point Set Voting for Partial Point Cloud Analysis</td><td>13885</td></tr><tr><td>LRGNet: Learnable Region Growing for Class-Agnostic Point Cloud Segmentation</td><td>13893</td></tr><tr><td><strong>Session</strong> ThFT1 : Vision and Perception: Pose Estimation</td><td></td></tr><tr><td>AcinoSet: A 3D Pose Estimation Dataset and Baseline Models for Cheetahs in the Wild</td><td>13901</td></tr><tr><td>PyraPose: Feature Pyramids for Fast and Accurate Object Pose Estimation under Domain Shift</td><td>13909</td></tr><tr><td>Investigations on Output Parameterizations of Neural Networks for Single Shot 6D Object Pose  Estimation</td><td>13916</td></tr><tr><td>L6DNet: Light 6 DoF Network for Robust and Precise Object Pose Estimation with Small Datasets</td><td>13923</td></tr><tr><td><strong>Session</strong> ThHT4 : Vision and Perception: Prediction</td><td></td></tr><tr><td>Double-Prong ConvLSTM for Spatiotemporal Occupancy Prediction in Dynamic Environments</td><td>13931</td></tr><tr><td>Social-STAGE: Spatio-Temporal Multi-Modal Future Trajectory Forecast</td><td>13938</td></tr><tr><td>LaserFlow: Efficient and Probabilistic Object Detection and Motion Forecasting</td><td>13945</td></tr><tr><td>Efficient Map Prediction Via Low-Rank Matrix Completion</td><td>13953</td></tr><tr><td><strong>Session</strong> ThDT2 : Vision and Perception: Rendering</td><td></td></tr><tr><td>Towards In-Field Phenotyping Exploiting Differentiable Rendering with Self-Consistency Loss</td><td>13960</td></tr><tr><td>Multi-View Object Pose Refinement with Differentiable Renderer</td><td>13967</td></tr><tr><td>Efficient Haptic Rendering of Regolith</td><td>13975</td></tr><tr><td>Parameterizable and Jerk-Limited Trajectories with Blending for Robot Motion Planning and  Spherical Cartesian Waypoints</td><td>13982</td></tr><tr><td><strong>Session</strong> ThBT2 : Vision and Perception: Segmentation I</td><td></td></tr><tr><td>PointMoSeg: Sparse Tensor-Based End-To-End Moving-Obstacle Segmentation in 3-D Lidar Point  Clouds for Autonomous Driving</td><td>13989</td></tr><tr><td>Referring Image Segmentation Via Language-Driven Attention</td><td>13997</td></tr><tr><td>GPU-Efficient Dense Convolutional Network for Real-Time Semantic Segmentation</td><td>14004</td></tr><tr><td>Feature Enhanced Projection Network for Zero-Shot Semantic Segmentation</td><td>14011</td></tr><tr><td><strong>Session</strong> ThAT4 : Vision and Perception: Segmentation II</td><td></td></tr><tr><td>A Large-Scale Dataset for Benchmarking Elevator Button Segmentation and Character  Recognition</td><td>14018</td></tr><tr><td>Neighborhood Spatial Aggregation Based Efficient Uncertainty Estimation for Point Cloud Semantic  Segmentation</td><td>14025</td></tr><tr><td>A Two-Stage Unsupervised Approach for Low Light Image Enhancement</td><td>14032</td></tr><tr><td>S3Net: 3D LiDAR Sparse Semantic Segmentation Network</td><td>14040</td></tr><tr><td><strong>Session</strong> ThIT4 : Vision and Perception: Self-Supervised Learning</td><td></td></tr><tr><td>Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor Navigation</td><td>14047</td></tr><tr><td>A Self-Supervised Near-To-Far Approach for Terrain-Adaptive Off-Road Autonomous Driving</td><td>14054</td></tr><tr><td>A Self-Supervised Learning System for Object Detection in Videos Using Random Walks on  Graphs</td><td>14061</td></tr><tr><td>Adversarial Differentiable Data Augmentation for Autonomous Systems</td><td>14069</td></tr><tr><td><strong>Session</strong> ThBT4 : Vision and Perception: Sensing</td><td></td></tr><tr><td>A Tactile Sensing Foot for Single Robot Leg Stabilization</td><td>14076</td></tr><tr><td>High-Resolution 3-Dimensional Contact Deformation Tracking for FingerVision Sensor with Dense  Random Color Pattern</td><td>14083</td></tr><tr><td>Looking Farther in Parametric Scene Parsing with Ground and Aerial Imagery</td><td>14091</td></tr><tr><td>Fast Motion Understanding with Spatiotemporal Neural Networks and Dynamic Vision Sensors</td><td>14098</td></tr><tr><td><strong>Session</strong> ThJT4 : Vision and Perception: Sensor Fusion</td><td></td></tr><tr><td>Fingertip Pulse-Echo Ultrasound and Optoacoustic Dual-Modal and Dual Sensing Mechanisms  Near-Distance Sensor for Ranging and Material Sensing in Robotic Grasping</td><td>14105</td></tr><tr><td>Development of a Perception System for an Autonomous Surface Vehicle Using Monocular  Camera, LIDAR, and Marine RADAR</td><td>14112</td></tr><tr><td>Detecting and Mapping Trees in Unstructured Environments with a Stereo Camera and Pseudo-Lidar</td><td>14120</td></tr><tr><td>Linear Inverse Problem for Depth Completion with RGB Image and Sparse LIDAR Fusion</td><td>14127</td></tr><tr><td><strong>Session</strong> ThKT4 : Vision and Perception: Stastistical Method</td><td></td></tr><tr><td>Out-Of-Distribution Robustness with Deep Recursive Filters</td><td>14134</td></tr><tr><td>ZePHyR: Zero-Shot Pose Hypothesis Rating</td><td>14141</td></tr><tr><td>CARPAL: Confidence-Aware Intent Recognition for Parallel Autonomy</td><td>14149</td></tr><tr><td>A Successive-Elimination Approach to Adaptive Robotic Source Seeking</td><td>14157</td></tr><tr><td><strong>Session</strong> ThET2 : Vision and Perception: Tracking I</td><td></td></tr><tr><td>Tracking 6-DoF Object Motion from Events and Frames</td><td>14171</td></tr><tr><td>Visual Tracking of Deforming Objects Using Physics-Based Models</td><td>14178</td></tr><tr><td>Deep 6-DoF Tracking of Unknown Objects for Reactive Grasping</td><td>14185</td></tr><tr><td>TSDF++: A Multi-Object Formulation for Dynamic Object Tracking and Reconstruction</td><td>14192</td></tr><tr><td><strong>Session</strong> WeCT12 : Vision and Perception: Tracking II</td><td></td></tr><tr><td>Tracking Partially-Occluded Deformable Objects While Enforcing Geometric Constraints</td><td>14199</td></tr><tr><td>Online Recommendation-Based Convolutional Features for Scale-Aware Visual Tracking</td><td>14206</td></tr><tr><td>Exploiting Probabilistic Siamese Visual Tracking with a Conditional Variational Autoencoder</td><td>14213</td></tr><tr><td>Toward Intraoperative Endomicroscopy with a GPU-Accelerated Deformable Video Mosaicking  Algorithm</td><td>14220</td></tr><tr><td><strong>Session</strong> ThAT3 : Vision and Perception: Trajectory Prediction and Tracking</td><td></td></tr><tr><td>Probabilistic 3D Multi-Modal, Multi-Object Tracking for Autonomous Driving</td><td>14227</td></tr><tr><td>AVGCN: Trajectory Prediction Using Graph Convolutional Networks Guided by Human Attention</td><td>14234</td></tr><tr><td>Attentional-GCNN: Adaptive Pedestrian Trajectory Prediction towards Generic Autonomous  Vehicle Use Cases</td><td>14241</td></tr><tr><td>Spatial Graph Regularized Multi-Kernel Subtask Cross-Correlation Tracker</td><td>14248</td></tr><tr><td><strong>Session</strong> ThHT5 : Vision-Based Control</td><td></td></tr><tr><td>Constrained Image-Based Visual Servoing Using Barrier Functions</td><td>14254</td></tr><tr><td>Deep Learning-Based Photoacoustic Visual Servoing: Using Outputs from Raw Sensor Data As  Inputs to a Robot Controller</td><td>14261</td></tr><tr><td>Uncertainty Constrained Differential Dynamic Programming in Belief Space for Vision Based  Robots</td><td>14268</td></tr><tr><td>Analyzing Neural Jacobian Methods in Applications of Visual Servoing and Kinematic Control</td><td>14276</td></tr><tr><td><strong>Session</strong> ThIT5 : Vision-Based Manipulation</td><td></td></tr><tr><td>Reward Machines for Vision-Based Robotic Manipulation</td><td>14284</td></tr><tr><td>What Can I Do Here? Learning New Skills by Imagining Visual Affordances</td><td>14291</td></tr><tr><td>Learning Geometric Reasoning and Control for Long-Horizon Tasks from Visual Input</td><td>14298</td></tr><tr><td>Simulation of Vision-Based Tactile Sensors Using Physics Based Rendering</td><td>14306</td></tr><tr><td><strong>Session</strong> ThFT2 : Visual and Haptic PerceptionMulti-Sensory Guidance and Feedback for Simulation-Based Training in Robot Assisted Surgery: A</td><td></td></tr><tr><td>Preliminary Comparison of Visual, Haptic, and Visuo-Haptic</td><td>14313</td></tr><tr><td>Haptic Teleoperation of Flexible Needles Combining 3D Ultrasound Guidance and Needle Tip  Force Feedback</td><td>14322</td></tr><tr><td>A General Visual-Impedance Framework for Effectively Combining Vision and Force Sensing in  Feature Space</td><td>14330</td></tr><tr><td>Probabilistic Surface Friction Estimation Based on Visual and Haptic Measurements</td><td>14338</td></tr><tr><td><strong>Session</strong> ThDT3 : Visual Learning</td><td></td></tr><tr><td>Learning Camera Performance Models for Active Multi-Camera Visual Teach and Repeat</td><td>14346</td></tr><tr><td>MS-RANAS: Multi-Scale Resource-Aware Neural Architecture Search</td><td>14353</td></tr><tr><td>Vision-Based Mobile Robotics Obstacle Avoidance with Deep Reinforcement Learning</td><td>14360</td></tr><tr><td>A Probabilistic Next Best View Planner for Depth Cameras Based on Deep Learning</td><td>14367</td></tr><tr><td><strong>Session</strong> WeCT16 : Visual Odometry</td><td></td></tr><tr><td>ENCODE: A dEep poiNt Cloud ODometry NEtwork</td><td>14375</td></tr><tr><td>CodeVIO: Visual-Inertial Odometry with Learned Optimizable Dense Depth</td><td>14382</td></tr><tr><td>Lifelong Localization in Semi-Dynamic Environment</td><td>14389</td></tr><tr><td>Deep Online Correction for Monocular Visual Odometry</td><td>14396</td></tr><tr><td>Direct Sparse Stereo Visual-Inertial Global Odometry</td><td>14403</td></tr><tr><td><strong>Session</strong> ThBT3 : Visual Odometry for Localization</td><td></td></tr><tr><td>Learning Optical Flow with R-CNN for Visual Odometry</td><td>14410</td></tr><tr><td>A Normal Distribution Transform-Based Radar Odometry Designed for Scanning and Automotive  Radars</td><td>14417</td></tr><tr><td>Are We Ready for Unmanned Surface Vehicles in Inland Waterways? The USVInland Multisensor  Dataset and Benchmark</td><td>14424</td></tr><tr><td>An Equivariant Filter for Visual Inertial Odometry</td><td>14432</td></tr><tr><td><strong>Session</strong> ThET3 : Visual Servoing</td><td></td></tr><tr><td>Subsequent Keyframe Generation for Visual Servoing</td><td>14439</td></tr><tr><td>Defocus-based Direct Visual Servoing</td><td>14446</td></tr><tr><td>Siame-Se(3): Regression in Se(3) for End-To-End Visual Servoing</td><td>14454</td></tr><tr><td>Human-Piloted Drone Racing: Visual Processing and Control</td><td>14461</td></tr><tr><td><strong>Session</strong> ThAT5 : Visual-Inertial Localization</td><td></td></tr><tr><td>VID-Fusion: Robust Visual-Inertial-Dynamics Odometry for Accurate External Force Estimation</td><td>14469</td></tr><tr><td>Run Your Visual-Inertial Odometry on NVIDIA Jetson: Benchmark Tests on a Micro Aerial Vehicle</td><td>14476</td></tr><tr><td>LIRO: Tightly Coupled Lidar-Inertia-Ranging Odometry</td><td>14484</td></tr><tr><td>Control of a Flexible Continuum Manipulator for Laser Beam Steering</td><td>14491</td></tr><tr><td>Session ThJT5 : Wearable RobotsMacro-Mini Actuation of Pneumatic Pouches for Soft Wearable Haptic Displays</td><td>14499</td></tr><tr><td>Sensing and Control of a Multi-Joint Soft Wearable Robot for Upper-Limb Assistance and Rehabilitation</td><td>14506</td></tr><tr><td>Kinematics-Based Control of an Inflatable Soft Wearable Robot for Assisting the Shoulder of  Industrial Workers</td><td>14515</td></tr><tr><td>Artificial Neural Networks to Solve Forward Kinematics of a Wearable Parallel Robot with Semi-Rigid Links</td><td>14524</td></tr></tbody></table></div>]]></content>
      
      
      
        <tags>
            
            <tag> ICRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IROS2020文章目录</title>
      <link href="/2022/01/03/iros2020-paper-list/"/>
      <url>/2022/01/03/iros2020-paper-list/</url>
      
        <content type="html"><![CDATA[<h1 id="IROS2020-paper-list"><a href="#IROS2020-paper-list" class="headerlink" title="IROS2020-paper-list"></a>IROS2020-paper-list</h1><p>The 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2020) has been held on Oct 25 – Nov 25, not been held in-person. With the continued resurgence of COVID-19 within the State of Nevada, in particular Las Vegas, along with the city’s prohibiting large or even moderately-sized public gatherings, it makes it an impossibility to hold the in-person event as originally planned.</p><p>IROS is one of the largest and most impacting robotics research conferences worldwide. It brings an international community of researchers, educators and practitioners to explore the frontier of science and technology in intelligent robots and systems, and discuss the latest advancements in this fast growing and exciting field.</p><p>IROS 2020 is <strong>free</strong> with access to every Technical Talk, Plenary and Keynote, over 60 Workshops and Tutorials, the Competitions, and includes publishing of accepted papers in the IROS Proceedings and IEEE XPlore.</p><p>This list is edited by <a href="https://github.com/PaoPaoRobot">PaopaoRobot</a>, <a href="http://paopaorobot.org/">泡泡机器人</a>, the Chinese academic nonprofit organization. Recently we will classify these papers by topics. Welcome to follow our github and our WeChat Public Platform Account ( <a href="https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&amp;mid=100000102&amp;idx=1&amp;sn=0a8a831a4f2c18443dbf436ef5d5ff8c&amp;chksm=6c10bf625b6736748c9612879e166e510f1fe301b72ed5c5d7ecdd0f40726c5d757e975f37af&amp;mpshare=1&amp;scene=1&amp;srcid=0530KxSLjUE9I38yLgfO2nVm&amp;pass_ticket=0aB5tcjeTfmcl9u0eSVzN4Ag4tkpM2RjRFH8DG9vylE%3D#rd">paopaorobot_slam</a> ). Of course, you could contact with <a href="https://github.com/yvonshong">Yvon Shong</a>.</p><div class="table-container"><table><thead><tr><th style="text-align:center">download link</th><th style="text-align:left">title</th></tr></thead><tbody><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0018.pdf">0018</a></td><td style="text-align:left">ARAS: Ambiguity-Aware Robust Active SLAM Based on Multi-Hypothesis State and Map Estimations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0025.pdf">0025</a></td><td style="text-align:left">Dynamic Attention-Based Visual Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0031.pdf">0031</a></td><td style="text-align:left">Max Orientation Coverage: Efficient Path Planning to Avoid Collisions in the CNC Milling of 3D Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0039.pdf">0039</a></td><td style="text-align:left">Learning an Uncertainty-Aware Object Detector for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0046.pdf">0046</a></td><td style="text-align:left">Look and Listen: A Multi-Modality Late Fusion Approach to Scene Classification for Autonomous Machines</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0047.pdf">0047</a></td><td style="text-align:left">Variable Stiffness Control with Strict Frequency Domain Constraints for Physical Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0054.pdf">0054</a></td><td style="text-align:left">Proactive Estimation of Occlusions and Scene Coverage for Planning Next Best Views in an Unstructured Representation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0055.pdf">0055</a></td><td style="text-align:left">Static Characteristics of Fire Hose Actuators and Design of a Compliant Pneumatic Rotary Drive for Robotics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0060.pdf">0060</a></td><td style="text-align:left">Domain Transfer for Semantic Segmentation of LiDAR Data Using Deep Neural Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0063.pdf">0063</a></td><td style="text-align:left">LIO-SAM: Tightly-Coupled Lidar Inertial Odometry Via Smoothing and Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0069.pdf">0069</a></td><td style="text-align:left">Roadmap Subsampling for Changing Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0070.pdf">0070</a></td><td style="text-align:left">Sim2Real Transfer for Reinforcement Learning without Dynamics Randomization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0071.pdf">0071</a></td><td style="text-align:left">PresSense: Passive Respiration Sensing Via Ambient WiFi Signals in Noisy Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0072.pdf">0072</a></td><td style="text-align:left">OrcVIO: Object Residual Constrained Visual-Inertial Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0073.pdf">0073</a></td><td style="text-align:left">BioARS: Designing Adaptive and Reconfigurable Bionic Assembly Robotic System with Inchworm Modules</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0074.pdf">0074</a></td><td style="text-align:left">Segmentation-Based 4D Registration of Plants Point Clouds for Phenotyping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0078.pdf">0078</a></td><td style="text-align:left">Self-Supervised Attention Learning for Depth and Ego-Motion Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0079.pdf">0079</a></td><td style="text-align:left">SwarmLab: A MATLAB Drone Swarm Simulator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0082.pdf">0082</a></td><td style="text-align:left">Non-Overlapping RGB-D Camera Network Calibration with Monocular Visual Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0083.pdf">0083</a></td><td style="text-align:left">Adaptive Reliable Shortest Path in Gaussian Process Regulated Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0089.pdf">0089</a></td><td style="text-align:left">Assessment of Soil Strength Using a Robotically Deployed and Retrieved Penetrometer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0092.pdf">0092</a></td><td style="text-align:left">SaD-SLAM: A Visual SLAM Based on Semantic and Depth Information</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0094.pdf">0094</a></td><td style="text-align:left">Zero-Tuning Grinding Process Methodology of Cyber-Physical Robot System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0095.pdf">0095</a></td><td style="text-align:left">ARPDR: An Accurate and Robust Pedestrian Dead Reckoning System for Indoor Localization on Handheld Smartphones</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0096.pdf">0096</a></td><td style="text-align:left">KLIEP-Based Density Ratio Estimation for Semantically Consistent Synthetic to Real Images Adaptation in Urban Traffic Scenes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0097.pdf">0097</a></td><td style="text-align:left">Graph-Based Hierarchical Knowledge Representation for Robot Task Transfer from Virtual to Physical World</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0099.pdf">0099</a></td><td style="text-align:left">An RLS-Based Instantaneous Velocity Estimator for Extended Radar Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0100.pdf">0100</a></td><td style="text-align:left">Informative Path Planning for Gas Distribution Mapping in Cluttered Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0101.pdf">0101</a></td><td style="text-align:left">DSSF-Net: Dual-Task Segmentation and Self-Supervised Fitting Network for End-To-End Lane Mark Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0102.pdf">0102</a></td><td style="text-align:left">Single-Shot Panoptic Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0103.pdf">0103</a></td><td style="text-align:left">Leveraging Stereo-Camera Data for Real-Time Dynamic Obstacle Detection and Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0106.pdf">0106</a></td><td style="text-align:left">Combining Compliance Control, CAD Based Localization, and a Multi-Modal Gripper for Rapid and Robust Programming of Assembly Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0108.pdf">0108</a></td><td style="text-align:left">Model-Free, Vision-Based Object Identification and Contact Force Estimation with a Hyper-Adaptive Robotic Gripper</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0109.pdf">0109</a></td><td style="text-align:left">Human-Robot Interaction in a Shared Augmented Reality Workspace</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0112.pdf">0112</a></td><td style="text-align:left">One-Shot Informed Robotic Visual Search in the Wild</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0119.pdf">0119</a></td><td style="text-align:left">KOVIS: Keypoint-Based Visual Servoing with Zero-Shot Sim-To-Real Transfer for Robotics Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0122.pdf">0122</a></td><td style="text-align:left">Learning Local Planners for Human-Aware Navigation in Indoor Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0123.pdf">0123</a></td><td style="text-align:left">Confidence Guided Stereo 3D Object Detection with Split Depth Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0124.pdf">0124</a></td><td style="text-align:left">Learning Hybrid Object Kinematics for Efficient Hierarchical Planning under Uncertainty</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0128.pdf">0128</a></td><td style="text-align:left">Human-Aware Robot Navigation by Long-Term Movement Prediction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0130.pdf">0130</a></td><td style="text-align:left">A Human-Robot Interface Based on Surface Electroencephalographic Sensors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0132.pdf">0132</a></td><td style="text-align:left">Pit30M: A Benchmark for Global Localization in the Age of Self-Driving Cars</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0135.pdf">0135</a></td><td style="text-align:left">LiTAMIN: LiDAR Based Tracking and MappINg by Stabilized ICP for Geometry Approximation with Normal Distributions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0141.pdf">0141</a></td><td style="text-align:left">Autonomous Obstacle Avoidance for UAV Based on Fusion of Radar and Monocular Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0143.pdf">0143</a></td><td style="text-align:left">Anomaly Detection for Autonomous Guided Vehicles Using Bayesian Surprise</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0144.pdf">0144</a></td><td style="text-align:left">RegionNet: Region-Feature-Enhanced 3D Scene Understanding Network with Dual Spatial-Aware Discriminative Loss</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0146.pdf">0146</a></td><td style="text-align:left">Richer Aggregated Features for Optical Flow Estimation with Edge-Aware Refinement</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0152.pdf">0152</a></td><td style="text-align:left">Quantitative Operator Strategy Comparisons across Human Supervisory Control Scenarios</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0153.pdf">0153</a></td><td style="text-align:left">Multi-Task Control for a Quadruped Robot with Changeable Leg Configuration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0155.pdf">0155</a></td><td style="text-align:left">Assisted Mobile Robot Teleoperation with Intent-Aligned Trajectories Via Biased Incremental Action Sampling</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0157.pdf">0157</a></td><td style="text-align:left">DeepLiDARFlow: A Deep Learning Architecture for Scene Flow Estimation Using Monocular Camera and Sparse LiDAR</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0160.pdf">0160</a></td><td style="text-align:left">Design of an Underactuated Peristaltic Robot on Soft Terrain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0161.pdf">0161</a></td><td style="text-align:left">Accurate, Low-Latency Visual Perception for Autonomous Racing: Challenges, Mechanisms, and Practical Solutions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0162.pdf">0162</a></td><td style="text-align:left">Catch the Ball: Accurate High-Speed Motions for Mobile Manipulators Via Inverse Dynamics Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0164.pdf">0164</a></td><td style="text-align:left">NBVC: A Benchmark for Depth Estimation from Narrow-Baseline Video Clips</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0166.pdf">0166</a></td><td style="text-align:left">On-Plate Localization and Mapping for an Inspection Robot using Ultrasonic Guided Waves: A Proof of Concept</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0170.pdf">0170</a></td><td style="text-align:left">Semantic Graph Based Place Recognition for 3D Point Clouds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0173.pdf">0173</a></td><td style="text-align:left">Barometer-based Tactile Skin for Anthropomorphic Robot Hand</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0176.pdf">0176</a></td><td style="text-align:left">CalibRCNN: Calibrating Camera and LiDAR by Recurrent Convolutional Neural Network and Geometric Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0179.pdf">0179</a></td><td style="text-align:left">Mechanical Design and Preliminary Performance Evaluation of a Passive Arm-Support Exoskeleton</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0184.pdf">0184</a></td><td style="text-align:left">Augmented Reality User Interfaces for Heterogeneous Multirobot Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0187.pdf">0187</a></td><td style="text-align:left">A Robotic Gripper Design and Integrated Solution towards Tunnel Boring Construction Equipment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0191.pdf">0191</a></td><td style="text-align:left">Autonomous RGBD-Based Industrial Staircase Localization from Tracked Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0192.pdf">0192</a></td><td style="text-align:left">Robust MUSIC-Based Sound Source Localization in Reverberant and Echoic Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0193.pdf">0193</a></td><td style="text-align:left">Optimal-Power Configurations for Hover Solutions in Mono-Spinners</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0195.pdf">0195</a></td><td style="text-align:left">Hypothesis-Driven Skill Discovery for Hierarchical Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0196.pdf">0196</a></td><td style="text-align:left">A modified Hybrid Reciprocal Velocity Obstacles approach for multi-robot motion planning without communication</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0198.pdf">0198</a></td><td style="text-align:left">Rapidly Adaptable Legged Robots Via Evolutionary Meta-Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0200.pdf">0200</a></td><td style="text-align:left">Robots Can Defuse High-Intensity Conflict Situations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0201.pdf">0201</a></td><td style="text-align:left">Indoor Scene Recognition in 3D</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0202.pdf">0202</a></td><td style="text-align:left">SolarSLAM: Battery-Free Loop Closure for Indoor Localisation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0204.pdf">0204</a></td><td style="text-align:left">Inner-Approximation of Manipulable and Reachable Regions Using Bilinear Matrix Inequalities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0205.pdf">0205</a></td><td style="text-align:left">SCALE-Net: Scalable Vehicle Trajectory Prediction Network under Random Number of Interacting Vehicles Via Edge-Enhanced Graph Convolutional Neural Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0206.pdf">0206</a></td><td style="text-align:left">Exceeding the Maximum Speed Limit of the Joint Angle for the Redundant Tendon-Driven Structures of Musculoskeletal Humanoids</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0207.pdf">0207</a></td><td style="text-align:left">Tool Shape Optimization through Backpropagation of Neural Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0208.pdf">0208</a></td><td style="text-align:left">PlaNet of the Bayesians: Reconsidering and Improving Deep Planning Network by Incorporating Bayesian Inference</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0209.pdf">0209</a></td><td style="text-align:left">Tell Me What This Is: Few-Shot Incremental Object Learning by a Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0213.pdf">0213</a></td><td style="text-align:left">A Horse Inspired Eight-wheel Unmanned Ground Vehicle with Four-swing Arms</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0219.pdf">0219</a></td><td style="text-align:left">Simultaneous Estimation of Vehicle Position and Data Delays Using Gaussian Process Based Moving Horizon Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0220.pdf">0220</a></td><td style="text-align:left">Globally Optimal Consensus Maximization for Robust Visual Inertial Localization in Point and Line Map</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0223.pdf">0223</a></td><td style="text-align:left">Learning Hierarchical Behavior and Motion Planning for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0224.pdf">0224</a></td><td style="text-align:left">A Bayesian-Based Controller for Snake Robot Locomotion in Unstructured Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0226.pdf">0226</a></td><td style="text-align:left">Personalized Online Learning with Pseudo-Ground Truth</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0228.pdf">0228</a></td><td style="text-align:left">Improving Autonomous Rover Guidance in Round-Trip Missions Using Dynamic Cost Map</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0229.pdf">0229</a></td><td style="text-align:left">An External Stabilization Unit for High-Precision Applications of Robot Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0230.pdf">0230</a></td><td style="text-align:left">Design and Implementation of a Pipeline Inspection Robot with Camera Image Compensation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0231.pdf">0231</a></td><td style="text-align:left">Magnetically Actuated Pick-And-Place Operations of Cellular Micro-Rings for High-Speed Assembly of Micro-Scale Biological Tube</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0233.pdf">0233</a></td><td style="text-align:left">Exploration of Unknown Environments with a Tethered Mobile Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0234.pdf">0234</a></td><td style="text-align:left">Robot-To-Robot Relative Pose Estimation Based on Semidefinite Relaxation Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0235.pdf">0235</a></td><td style="text-align:left">Robust Pedestrian Tracking in Crowd Scenarios Using an Adaptive GMM-Based Framework</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0236.pdf">0236</a></td><td style="text-align:left">Variable In-Hand Manipulations for Tactile-Driven Robot Hand Via CNN-LSTM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0238.pdf">0238</a></td><td style="text-align:left">SMA Actuated Low-Weight Bio-Inspired Claws for Grasping and Perching Using Flapping Wing Aerial Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0240.pdf">0240</a></td><td style="text-align:left">Reconstruction of 3D Flight Trajectories from Ad-Hoc Camera Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0241.pdf">0241</a></td><td style="text-align:left">3D Odor Source Localization Using a Micro Aerial Vehicle: System Design and Performance Evaluation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0244.pdf">0244</a></td><td style="text-align:left">Set-Membership Extrinsic Calibration of a 3D LiDAR and a Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0248.pdf">0248</a></td><td style="text-align:left">BARK: Open Behavior Benchmarking in Multi-Agent Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0249.pdf">0249</a></td><td style="text-align:left">LiDAR Panoptic Segmentation for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0250.pdf">0250</a></td><td style="text-align:left">Learning and Sequencing of Object-Centric Manipulation Skills for Industrial Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0257.pdf">0257</a></td><td style="text-align:left">Ground Texture Based Localization: Do We Need to Detect Keypoints?</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0261.pdf">0261</a></td><td style="text-align:left">Diabolo Orientation Stabilization by Learning Predictive Model for Unstable Unknown-Dynamics Juggling Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0263.pdf">0263</a></td><td style="text-align:left">Sample-Efficient Learning for Industrial Assembly Using Qgraph-Bounded DDPG</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0264.pdf">0264</a></td><td style="text-align:left">ROSflight: A Lean Open-Source Research Autopilot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0265.pdf">0265</a></td><td style="text-align:left">A Model-Based Approach to Acoustic Reflector Localization with a Robotic Platform</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0267.pdf">0267</a></td><td style="text-align:left">Explainable and Efficient Sequential Correlation Network for 3D Single Person Concurrent Activity Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0268.pdf">0268</a></td><td style="text-align:left">Guaranteed Parameter Estimation of Hunt-Crossley Model with Chebyshev Polynomial Approximation for Teleoperation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0272.pdf">0272</a></td><td style="text-align:left">Software Development Framework for Cooperating Robots with High-Level Mission Specification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0277.pdf">0277</a></td><td style="text-align:left">Learning to Collide: An Adaptive Safety-Critical Scenarios Generating Method</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0278.pdf">0278</a></td><td style="text-align:left">No Map, No Problem: A Local Sensing Approach for Navigation in Human-Made Spaces Using Signs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0281.pdf">0281</a></td><td style="text-align:left">A Learning-based Robotic Bin-picking with Flexibly Customizable Grasping Conditions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0284.pdf">0284</a></td><td style="text-align:left">An Augmented Reality Human-Robot Physical Collaboration Interface Design for Shared, Large-Scale, Labour-Intensive Manufacturing Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0287.pdf">0287</a></td><td style="text-align:left">Motion Planning for Heterogeneous Unmanned Systems under Partial Observation from UAV</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0289.pdf">0289</a></td><td style="text-align:left">TTR-Based Reward for Reinforcement Learning with Implicit Model Priors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0290.pdf">0290</a></td><td style="text-align:left">ETRI-Activity3D: A Large-Scale RGB-D Dataset for Robots to Recognize Daily Activities of the Elderly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0292.pdf">0292</a></td><td style="text-align:left">A Flexible Dual-Core Optical Waveguide Sensor for Simultaneous and Continuous Measurement of Contact Force and Position</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0295.pdf">0295</a></td><td style="text-align:left">Multimodal Aggregation Approach for Memory Vision-Voice Indoor Navigation with Meta-Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0297.pdf">0297</a></td><td style="text-align:left">DR^2Track: Towards Real-Time Visual Tracking for UAV Via Distractor Repressed Dynamic Regression</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0301.pdf">0301</a></td><td style="text-align:left">Robust Real-Time Monitoring of Human Task Advancement for Collaborative Robotics Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0304.pdf">0304</a></td><td style="text-align:left">Virtual Reality for Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0309.pdf">0309</a></td><td style="text-align:left">Design of a Linear Gravity Compensator for a Prismatic Joint</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0311.pdf">0311</a></td><td style="text-align:left">Applications of Stretch Reflex for the Upper Limb of Musculoskeletal Humanoids: Protective Behavior, Postural Stability, and Active Induction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0313.pdf">0313</a></td><td style="text-align:left">Practical Verification of Neural Network Enabled State Estimation System for Robotics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0314.pdf">0314</a></td><td style="text-align:left">A Control Scheme for Haptic Inspection and Partial Modification of Kinematic Behaviors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0315.pdf">0315</a></td><td style="text-align:left">Identification of Dynamic Parameters for Rigid Robots Based on Polynomial Approximation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0317.pdf">0317</a></td><td style="text-align:left">SpoxelNet: Spherical Voxel-Based Deep Place Recognition for 3D Point Clouds of Crowded Indoor Spaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0323.pdf">0323</a></td><td style="text-align:left">Multi-Instance Aware Localization for End-To-End Imitation Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0326.pdf">0326</a></td><td style="text-align:left">Cooperative Simultaneous Tracking and Jamming for Disabling a Rogue Drone</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0329.pdf">0329</a></td><td style="text-align:left">Human-Robot Trust Assessment Using Motion Tracking &amp; Galvanic Skin Response</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0330.pdf">0330</a></td><td style="text-align:left">Simultaneous Planning for Item Picking and Placing by Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0334.pdf">0334</a></td><td style="text-align:left">Grasping Detection Network with Uncertainty Estimation for Confidence-Driven Semi-Supervised Domain Adaptation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0335.pdf">0335</a></td><td style="text-align:left">3D Gaze Estimation for Head-Mounted Devices based on Visual Saliency</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0336.pdf">0336</a></td><td style="text-align:left">Learning Hierarchical Acquisition Functions for Bayesian Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0338.pdf">0338</a></td><td style="text-align:left">Reinforcement Learning in Latent Action Sequence Space</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0339.pdf">0339</a></td><td style="text-align:left">Automatic Synthesis of Human Motion from Temporal Logic Specifications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0342.pdf">0342</a></td><td style="text-align:left">UAV-AdNet: Unsupervised Anomaly Detection Using Deep Neural Networks for Aerial Surveillance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0348.pdf">0348</a></td><td style="text-align:left">Unsupervised Domain Adaptation for Transferring Plant Classification Systems to New Field Environments, Crops, and Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0355.pdf">0355</a></td><td style="text-align:left">On-Chip Integration of Ultra-Thin Glass Cantilever for Physical Property Measurement Activated by Femtosecond Laser Impulse</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0356.pdf">0356</a></td><td style="text-align:left">Learning the sense of touch in simulation: a sim-to-real strategy for vision-based tactile sensing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0358.pdf">0358</a></td><td style="text-align:left">Abductive Recognition of Context-Dependent Utterances in Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0359.pdf">0359</a></td><td style="text-align:left">From Points to Planes - Adding Planar Constraints to Monocular SLAM Factor Graphs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0363.pdf">0363</a></td><td style="text-align:left">Enhanced Tracking Wall: A Real-Time Computing Method for Needle Injection on Haptic Simulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0364.pdf">0364</a></td><td style="text-align:left">Occlusion-Robust MVO: Multimotion Estimation through Occlusion Via Motion Closure</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0366.pdf">0366</a></td><td style="text-align:left">Spectral-GANs for High-Resolution 3D Point-Cloud Generation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0368.pdf">0368</a></td><td style="text-align:left">Vision-Based Proprioceptive Sensing: Tip Position Estimation for a Soft Inflatable Bellow Actuator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0369.pdf">0369</a></td><td style="text-align:left">Model Predictive Position and Force Trajectory Tracking Control for Robot-Environment Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0373.pdf">0373</a></td><td style="text-align:left">CoBigICP: Robust and Precise Point Set Registration Using Correntropy Metrics and Bidirectional Correspondence</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0378.pdf">0378</a></td><td style="text-align:left">Walking Human Trajectory Models and Their Application to Humanoid Robot Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0382.pdf">0382</a></td><td style="text-align:left">Plug-And-Play SLAM: A Unified SLAM Architecture for Modularity and Ease of Use</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0383.pdf">0383</a></td><td style="text-align:left">Acquiring Mechanical Knowledge from 3D Point Clouds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0384.pdf">0384</a></td><td style="text-align:left">A Visuo-Haptic Guidance Interface for the Mobile Collaborative Robotic Assistant (MOCA)</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0386.pdf">0386</a></td><td style="text-align:left">Robot Navigation in Crowded Environments Using Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0389.pdf">0389</a></td><td style="text-align:left">Robust Task and Motion Planning for Long-Horizon Problems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0390.pdf">0390</a></td><td style="text-align:left">Tightly-Coupled Fusion of Global Positional Measurements in Optimization-Based Visual-Inertial Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0393.pdf">0393</a></td><td style="text-align:left">LegoBot: Automated Planning for Coordinated Multi-Robot Assembly of LEGO Structures</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0398.pdf">0398</a></td><td style="text-align:left">Progressive Automation of Periodic Tasks on Planar Surfaces of Unknown Pose with Hybrid Force/position Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0400.pdf">0400</a></td><td style="text-align:left">Smart Speaker vs. Social Robot in a Case of Hotel Room</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0403.pdf">0403</a></td><td style="text-align:left">EU Long-Term Dataset with Multiple Sensors for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0404.pdf">0404</a></td><td style="text-align:left">Speed and Memory Efficient Dense RGB-D SLAM in Dynamic Scenes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0405.pdf">0405</a></td><td style="text-align:left">Hand-Object Contact Force Synthesis for Manipulating Objects by Exploiting Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0407.pdf">0407</a></td><td style="text-align:left">Hierarchical Reinforcement Learning Method for Autonomous Vehicle Behavior Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0408.pdf">0408</a></td><td style="text-align:left">Automatic Lane Change Maneuver in Dynamic Environment Using Model Predictive Control Method</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0414.pdf">0414</a></td><td style="text-align:left">LaNoising: A Data-Driven Approach for 903nm ToF LiDAR Performance Modeling under Fog</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0415.pdf">0415</a></td><td style="text-align:left">On Parameter Estimation of Flexible Space Manipulator Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0416.pdf">0416</a></td><td style="text-align:left">The SPIR: An Autonomous Underwater Robot for Bridge Pile Cleaning and Condition Assessment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0417.pdf">0417</a></td><td style="text-align:left">Rapid Autonomous Semantic Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0418.pdf">0418</a></td><td style="text-align:left">Learning Soft Robotic Assembly Strategies from Successful and Failed Demonstrations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0419.pdf">0419</a></td><td style="text-align:left">Mapping Thigh Motion to Knee Motion: Implications for Motion Planning of Active Prosthetic Knees</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0421.pdf">0421</a></td><td style="text-align:left">Comparison between Stationary and Crawling Multi-Arm Robotics for In-Space Assembly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0425.pdf">0425</a></td><td style="text-align:left">Toward Analytical Modeling and Evaluation of Curvature-Dependent Distributed Friction Force in Tendon-Driven Continuum Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0428.pdf">0428</a></td><td style="text-align:left">End-to-end Contextual Perception and Prediction with Interaction Transformer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0432.pdf">0432</a></td><td style="text-align:left">Operational Space Formulation and Inverse Kinematics for an Arm Exoskeleton with Scapula Rotation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0433.pdf">0433</a></td><td style="text-align:left">A Hamilton-Jacobi Formulation for Optimal Coordination of Heterogeneous Multiple Vehicle Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0436.pdf">0436</a></td><td style="text-align:left">Human Gait Phase Recognition Using a Hidden Markov Model Framework</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0443.pdf">0443</a></td><td style="text-align:left">DaVinciNet: Joint Prediction of Motion and Surgical State in Robot-Assisted Surgery</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0455.pdf">0455</a></td><td style="text-align:left">Deep Imitation Learning of Sequential Fabric Smoothing from an Algorithmic Supervisor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0457.pdf">0457</a></td><td style="text-align:left">Visual-Inertial-Wheel Odometry with Online Calibration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0458.pdf">0458</a></td><td style="text-align:left">Lifelong Update of Semantic Maps in Dynamic Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0460.pdf">0460</a></td><td style="text-align:left">Ultra Low-Cost Printable Folding Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0463.pdf">0463</a></td><td style="text-align:left">Deep Keypoint-Based Camera Pose Estimation with Geometric Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0464.pdf">0464</a></td><td style="text-align:left">Generating New Lower Abstract Task Operator Using Grid-TLI</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0471.pdf">0471</a></td><td style="text-align:left">SpCoMapGAN: Spatial Concept Formation-Based Semantic Mapping with Generative Adversarial Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0474.pdf">0474</a></td><td style="text-align:left">Applying Surface Normal Information in Drivable Area and Road Anomaly Detection for Ground Mobile Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0476.pdf">0476</a></td><td style="text-align:left">Few-Shot Relation Learning with Attention for EEG-Based Motor Imagery Classification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0478.pdf">0478</a></td><td style="text-align:left">Robot Sound Interpretation: Combining Sight and Sound in Learning-Based Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0479.pdf">0479</a></td><td style="text-align:left">Development of a Passive Skid for Multicopter Landing on Rough Terrain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0480.pdf">0480</a></td><td style="text-align:left">Touch the Wind: Simultaneous Airflow, Drag and Interaction Sensing on a Multirotor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0486.pdf">0486</a></td><td style="text-align:left">Online Localization with Imprecise Floor Space Maps Using Stochastic Gradient Descent</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0487.pdf">0487</a></td><td style="text-align:left">Wiping 3D-Objects Using Deep Learning Model Based on Image/Force/Joint Information</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0492.pdf">0492</a></td><td style="text-align:left">Fast LTL-Based Flexible Planning for Dual-Arm Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0493.pdf">0493</a></td><td style="text-align:left">Multi-Robot Coordination with Agent-Server Architecture for Autonomous Navigation in Partially Unknown Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0496.pdf">0496</a></td><td style="text-align:left">Perception-Aware Path Planning for UAVs Using Semantic Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0500.pdf">0500</a></td><td style="text-align:left">L2B: Learning to Balance the Safety-Efficiency Trade-Off in Interactive Crowd-Aware Robot Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0504.pdf">0504</a></td><td style="text-align:left">UnRectDepthNet: Self-Supervised Monocular Depth Estimation Using a Generic Framework for Handling Common Camera Distortion Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0505.pdf">0505</a></td><td style="text-align:left">PC-NBV: A Point Cloud Based Deep Network for Efficient Next Best View Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0508.pdf">0508</a></td><td style="text-align:left">Spatio-Temporal Ultrasonic Dataset: Learning Driving from Spatial and Temporal Ultrasonic Cues</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0511.pdf">0511</a></td><td style="text-align:left">Invisible Marker: Automatic Annotation of Segmentation Masks for Object Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0512.pdf">0512</a></td><td style="text-align:left">A Comprehensive Trajectory Planner for a Person-Following ATV</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0513.pdf">0513</a></td><td style="text-align:left">Configuration Space Decomposition for Learning-Based Collision Checking in High-DOF Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0516.pdf">0516</a></td><td style="text-align:left">A Novel Portable Cell Sonoporation Device Based on Open-Source Acoustofluidics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0519.pdf">0519</a></td><td style="text-align:left">A Minimalistic Hyper Flexible Manipulator: Modeling and Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0523.pdf">0523</a></td><td style="text-align:left">A Two-Stage Automatic Latching System for the USVs Charging in Disturbed Berth</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0526.pdf">0526</a></td><td style="text-align:left">The Application of Navigation Technology for the Medical Assistive Devices Based on Aruco Recognition Technology</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0530.pdf">0530</a></td><td style="text-align:left">Physics-Based Dexterous Manipulations with Estimated Hand Poses and Residual Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0532.pdf">0532</a></td><td style="text-align:left">A Time Optimal Reactive Collision Avoidance Method for UAVs Based on a Modified Collision Cone Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0538.pdf">0538</a></td><td style="text-align:left">Computationally Efficient Obstacle Avoidance Trajectory Planner for UAVs Based on Heuristic Angular Search Method</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0544.pdf">0544</a></td><td style="text-align:left">UST: Unifying Spatio-Temporal Context for Trajectory Prediction in Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0552.pdf">0552</a></td><td style="text-align:left">DMLO: Deep Matching LiDAR Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0557.pdf">0557</a></td><td style="text-align:left">Latent Space Roadmap for Visual Action Planning of Deformable and Rigid Object Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0558.pdf">0558</a></td><td style="text-align:left">Learning Visuomotor Policies for Aerial Navigation Using Cross-Modal Representations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0559.pdf">0559</a></td><td style="text-align:left">A Neural Primitive Model with Sensorimotor Coordination for Dynamic Quadruped Locomotion with Malfunction Compensation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0560.pdf">0560</a></td><td style="text-align:left">DenseFusion: Large-Scale Online Dense Pointcloud and DSM Mapping for UAVs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0562.pdf">0562</a></td><td style="text-align:left">A Learning-Driven Framework with Spatial Optimization for Surgical Suture Thread Reconstruction and Autonomous Grasping under Multiple Topologies and Environmental Noises</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0566.pdf">0566</a></td><td style="text-align:left">OceanVoy: A Hybrid Energy Planning System for Autonomous Sailboat</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0567.pdf">0567</a></td><td style="text-align:left">Pattern Analysis and Parameters Optimization of Dynamic Movement Primitives for Learning Unknown Trajectories</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0568.pdf">0568</a></td><td style="text-align:left">Towards Understanding and Inferring the Crowd: Guided Second Order Attention Networks and Re-Identification for Multi-Object Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0572.pdf">0572</a></td><td style="text-align:left">Distributed Near-Optimal Multi-Robots Coordination in Heterogeneous Task Allocation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0573.pdf">0573</a></td><td style="text-align:left">Dynamic Assistance for Human Balancing with Inertia of a Wearable Robotic Appendage</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0575.pdf">0575</a></td><td style="text-align:left">A Real-Time Unscented Kalman Filter on Manifolds for Challenging AUV Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0576.pdf">0576</a></td><td style="text-align:left">Indirect Object-To-Robot Pose Estimation from an External Monocular RGB Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0581.pdf">0581</a></td><td style="text-align:left">A Causal Approach to Tool Affordance Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0583.pdf">0583</a></td><td style="text-align:left">SeqSphereVLAD: Sequence Matching Enhanced Orientation-Invariant Place Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0589.pdf">0589</a></td><td style="text-align:left">Active 6D Multi-Object Pose Estimation in Cluttered Scenarios with Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0592.pdf">0592</a></td><td style="text-align:left">Continuous Tension Validation for Cable-Driven Parallel Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0593.pdf">0593</a></td><td style="text-align:left">Predicting the Human Behaviour in Human-Robot Co-Assemblies: An Approach Based on Suffix Trees</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0596.pdf">0596</a></td><td style="text-align:left">Latent Replay for Real-Time Continual Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0600.pdf">0600</a></td><td style="text-align:left">The Application of a Flexible Leader-Follower Control Algorithm to Different Mobile Autonomous Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0614.pdf">0614</a></td><td style="text-align:left">Examination of Screen-Indicated Methods of Gait Training System with Real-Time Audiovisual Feedback Function of Ground Reaction Force</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0619.pdf">0619</a></td><td style="text-align:left">GOSMatch: Graph-of-Semantics Matching for Detecting Loop Closures in 3D LiDAR Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0620.pdf">0620</a></td><td style="text-align:left">Design, Analysis and Preliminary Validation of a 3-DOF Rotational Inertia Generator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0621.pdf">0621</a></td><td style="text-align:left">Experiments on Whole-Body Control of a Dual-Arm Mobile Robot with the Set-Based Task-Priority Inverse Kinematics Algorithm</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0624.pdf">0624</a></td><td style="text-align:left">UAV Coverage Path Planning under Varying Power Constraints Using Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0625.pdf">0625</a></td><td style="text-align:left">A Model for Optimising the Size of Climbing Robots for Navigating Truss Structures</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0626.pdf">0626</a></td><td style="text-align:left">Reinforcement Learning-Based Hierarchical Control for Path Following of a Salamander-Like Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0629.pdf">0629</a></td><td style="text-align:left">An Obstacle-crossing Strategy Based on the Fast Self-reconfiguration for Modular Sphere Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0631.pdf">0631</a></td><td style="text-align:left">Online Weight-Adaptive Nonlinear Model Predictive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0634.pdf">0634</a></td><td style="text-align:left">FlowControl: Optical Flow Based Visual Servoing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0635.pdf">0635</a></td><td style="text-align:left">Geometrical Interpretation and Detection of Multiple Task Conflicts using a Coordinate Invariant Index</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0638.pdf">0638</a></td><td style="text-align:left">Laser2Vec: Similarity-Based Retrieval for Robotic Perception Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0641.pdf">0641</a></td><td style="text-align:left">Self-Adapting Recurrent Models for Object Pushing from Learning in Simulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0642.pdf">0642</a></td><td style="text-align:left">A Passivity-Based Bilateral Teleoperation Architecture using Distributed Nonlinear Model Predictive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0644.pdf">0644</a></td><td style="text-align:left">A Theory of Fermat Paths for 3D Imaging Sonar Reconstruction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0646.pdf">0646</a></td><td style="text-align:left">Lane Marking Verification for High Definition Map Maintenance Using Crowdsourced Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0652.pdf">0652</a></td><td style="text-align:left">TASC: Teammate Algorithm for Shared Cooperation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0655.pdf">0655</a></td><td style="text-align:left">A Frequency-Dependent Impedance Controller for an Active-Macro/passive-Mini Robotic System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0656.pdf">0656</a></td><td style="text-align:left">Robust and Efficient Post-Processing for Video Object Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0659.pdf">0659</a></td><td style="text-align:left">Topology-Aware Self-Organizing Maps for Robotic Information Gathering</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0660.pdf">0660</a></td><td style="text-align:left">Gaze by Semi-Virtual Robotic Heads: Effects of Eye and Head Motion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0665.pdf">0665</a></td><td style="text-align:left">Using Diverse Neural Networks for Safer Human Pose Estimation: Towards Making Neural Networks Know When They Donï¿t Know</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0668.pdf">0668</a></td><td style="text-align:left">Online Gain Setting Method for Path Tracking Using CMA-ES: Application to Off-Road Mobile Robot Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0669.pdf">0669</a></td><td style="text-align:left">Task Planning with Belief Behavior Trees</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0672.pdf">0672</a></td><td style="text-align:left">Anytime Kinodynamic Motion Planning Using Region-Guided Search</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0674.pdf">0674</a></td><td style="text-align:left">Robust Gait Design Insights from Studying a Compass Gait Biped with Foot Slipping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0675.pdf">0675</a></td><td style="text-align:left">Completeness Seeking Probabilistic Coverage Estimation Using Uncertain State Estimates</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0679.pdf">0679</a></td><td style="text-align:left">IMU-Based Parameter Identification and Position Estimation in Twisted String Actuators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0681.pdf">0681</a></td><td style="text-align:left">Laminar Jamming Flexure Joints for the Development of Variable Stiffness Robot Grippers and Hands</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0682.pdf">0682</a></td><td style="text-align:left">EDAN - an EMG-Controlled Daily Assistant to Help People with Physical Disabilities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0683.pdf">0683</a></td><td style="text-align:left">Residual Pose: A Decoupled Approach for Depth-Based 3D Human Pose Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0685.pdf">0685</a></td><td style="text-align:left">The VCU-RVI Benchmark: Evaluating Visual Inertial Odometry for Indoor Navigation Applications with an RGB-D Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0686.pdf">0686</a></td><td style="text-align:left">Voxel-Based Representation Learning for Place Recognition Based on 3D Point Clouds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0687.pdf">0687</a></td><td style="text-align:left">A POMDP Treatment of Vehicle-Pedestrian Interaction: Implicit Coordination Via Uncertainty-Aware Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0689.pdf">0689</a></td><td style="text-align:left">Analysis and Transfer of Human Movement Manipulability in Industry-Like Activities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0694.pdf">0694</a></td><td style="text-align:left">A Collision-Resilient Aerial Vehicle with Icosahedron Tensegrity Structure</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0695.pdf">0695</a></td><td style="text-align:left">Category-Level 3D Non-Rigid Registration from Single-View RGB Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0697.pdf">0697</a></td><td style="text-align:left">An Implementation of the Adaptive Neuro-Fuzzy Inference System (ANFIS) for Odor Source Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0701.pdf">0701</a></td><td style="text-align:left">Representation and Experience-Based Learning of Explainable Models for Robot Action Execution</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0702.pdf">0702</a></td><td style="text-align:left">Provably Safe Trajectory Optimization in the Presence of Uncertain Convex Obstacles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0704.pdf">0704</a></td><td style="text-align:left">The Marathon 2: A Navigation System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0707.pdf">0707</a></td><td style="text-align:left">Learning State-Dependent Losses for Inverse Dynamics Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0709.pdf">0709</a></td><td style="text-align:left">Learning Your Way without Map or Compass: Panoramic Target Driven Visual Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0710.pdf">0710</a></td><td style="text-align:left">In-Flight Range Optimization of Multicopters Using Multivariable Extremum Seeking with Adaptive Step Size</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0711.pdf">0711</a></td><td style="text-align:left">Inferring Spatial Uncertainty in Object Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0714.pdf">0714</a></td><td style="text-align:left">Deep Depth Estimation from Visual-Inertial SLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0715.pdf">0715</a></td><td style="text-align:left">LAVAPilot: Lightweight UAVTrajectory Planner with Situational Awarenessfor Embedded Autonomy to Track and Locate Radio-Tags</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0716.pdf">0716</a></td><td style="text-align:left">Differential Image Based Robot to MRI Scanner Registration with Active Fiducial Markers for an MRI-Guided Robotic Catheter System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0717.pdf">0717</a></td><td style="text-align:left">Acoustic Collision Detection and Localization for Robot Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0718.pdf">0718</a></td><td style="text-align:left">Regulation of 2D Arm Stability against Unstable, Damping-Defined Environments in Physical Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0719.pdf">0719</a></td><td style="text-align:left">Detecting Usable Planar Regions for Legged Robot Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0720.pdf">0720</a></td><td style="text-align:left">Reinforced Grounded Action Transformation for Sim-To-Real Transfer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0721.pdf">0721</a></td><td style="text-align:left">Monocular Visual Shape Tracking and Servoing for Isometrically Deforming Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0722.pdf">0722</a></td><td style="text-align:left">Probabilistic Multi-Modal Trajectory Prediction with Lane Attention for Autonomous Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0724.pdf">0724</a></td><td style="text-align:left">Improving Disturbance Rejection and Dynamics of Cable Driven Parallel Robots with On-Board Propellers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0728.pdf">0728</a></td><td style="text-align:left">Pi-Map: A Decision-Based Sensor Fusion with Global Optimization for Indoor Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0731.pdf">0731</a></td><td style="text-align:left">Learning the Latent Space of Robot Dynamics for Cutting Interaction Inference</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0732.pdf">0732</a></td><td style="text-align:left">Nonlinear Balance Control of an Unmanned Bicycle: Design and Experiments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0739.pdf">0739</a></td><td style="text-align:left">Heterogeneous Vehicle Routing and Teaming with Gaussian Distributed Energy Uncertainty</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0740.pdf">0740</a></td><td style="text-align:left">Decentralised Self-Organising Maps for Multi-Robot Information Gathering</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0745.pdf">0745</a></td><td style="text-align:left">On a Videoing Control System Based on Object Detection and Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0750.pdf">0750</a></td><td style="text-align:left">Learning-Based Optimization Algorithms Combining Force Control Strategies for Peg-In-Hole Assembly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0751.pdf">0751</a></td><td style="text-align:left">Fingertip Non-Contact Optoacoustic Sensor for Near-Distance Ranging and Thickness Differentiation for Robotic Grasping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0752.pdf">0752</a></td><td style="text-align:left">A Momentum-Based Foot Placement Strategy for Stable Postural Control of Robotic Spring-Mass Running with Point Feet</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0753.pdf">0753</a></td><td style="text-align:left">Distributed Model Predictive Control for UAVs Collaborative Payload Transport</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0754.pdf">0754</a></td><td style="text-align:left">Monocular Camera Localization in Prior LiDAR Maps with 2D-3D Line Correspondences</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0755.pdf">0755</a></td><td style="text-align:left">Cleaning Robot Operation Decision Based on Causal Reasoning and Attribute Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0764.pdf">0764</a></td><td style="text-align:left">A Thermoplastic Elastomer Belt Based Robotic Gripper</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0767.pdf">0767</a></td><td style="text-align:left">Interacting Multiple Model Navigation System for Quadrotor Micro Aerial Vehicles Subject to Rotor Drag</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0772.pdf">0772</a></td><td style="text-align:left">Meta Learning with Differentiable Closed-Form Solver for Fast Video Object Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0774.pdf">0774</a></td><td style="text-align:left">Active Alignment Control-Based LED Communication for Underwater Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0775.pdf">0775</a></td><td style="text-align:left">Semantic Trajectory Planning for Long-Distant Unmanned Aerial Vehicle Navigation in Urban Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0777.pdf">0777</a></td><td style="text-align:left">High-Speed Catching by Multi-Vision Robot Hand</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0778.pdf">0778</a></td><td style="text-align:left">Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning on Graphs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0781.pdf">0781</a></td><td style="text-align:left">Introduction to 7-DoF CoSMo-Arm : High Torque Density Manipulator based on CoSMoA and E-CoSMo</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0782.pdf">0782</a></td><td style="text-align:left">Learning-Based Controller Optimization for Repetitive Robotic Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0784.pdf">0784</a></td><td style="text-align:left">DUI-VIO: Depth Uncertainty Incorporated Visual Inertial Odometrybased on an RGB-D Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0786.pdf">0786</a></td><td style="text-align:left">Wind and the City: Utilizing UAV-Based In-Situ Measurements for Estimating Urban Wind Fields</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0789.pdf">0789</a></td><td style="text-align:left">A Bottom-Up Framework for Construction of Structured Semantic 3D Scene Graph</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0790.pdf">0790</a></td><td style="text-align:left">Bi-Modal Hemispherical Sensors for Dynamic Locomotion and Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0791.pdf">0791</a></td><td style="text-align:left">Underwater Monocular Image Depth Estimation Using Single-Beam Echosounder</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0792.pdf">0792</a></td><td style="text-align:left">TP-TIO: A Robust Thermal-Inertial Odometry with Deep ThermalPoint</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0795.pdf">0795</a></td><td style="text-align:left">Microdrone-Equipped Mobile Crawler Robot System, DIR-3, for High-Step Climbing and High-Place Inspection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0796.pdf">0796</a></td><td style="text-align:left">Risk Vector-based Near miss Obstacle Avoidance for Autonomous Surface Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0797.pdf">0797</a></td><td style="text-align:left">Sampling-Based Search for a Semi-Cooperative Target</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0802.pdf">0802</a></td><td style="text-align:left">Endoscopic Navigation Based on Three-Dimensional Structure Registration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0805.pdf">0805</a></td><td style="text-align:left">Robotic Understanding of Spatial Relationships Using Neural-Logic Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0807.pdf">0807</a></td><td style="text-align:left">Behaviorally Diverse Traffic Simulation via Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0808.pdf">0808</a></td><td style="text-align:left">Cascaded Non-Local Neural Network for Point Cloud Semantic Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0809.pdf">0809</a></td><td style="text-align:left">Fusing Concurrent Orthogonal Wide-Aperture Sonar Images for Dense Underwater 3D Reconstruction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0814.pdf">0814</a></td><td style="text-align:left">Path Planning for Nonholonomic Multiple Mobile Robot System with Applications to Robotic Autonomous Luggage Trolley Collection at Airports</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0823.pdf">0823</a></td><td style="text-align:left">Adaptive Gait Pattern Generation of a Powered Exoskeleton by Iterative Learning of Human Behavior</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0828.pdf">0828</a></td><td style="text-align:left">A Deep Learning Based End-To-End Locomotion Mode Detection Method for Lower Limb Wearable Robot Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0835.pdf">0835</a></td><td style="text-align:left">Leveraging Planar Regularities for Point Line Visual-Inertial Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0837.pdf">0837</a></td><td style="text-align:left">High-Speed Hitting Grasping with Magripper, a Highly Backdrivable Gripper Using Magnetic Gear and Plastic Deformation Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0840.pdf">0840</a></td><td style="text-align:left">A Novel and Controllable Cell-Robot in Real Vascular Network for Target Tumor Therapy</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0844.pdf">0844</a></td><td style="text-align:left">Faster Healthcare Time Series Classification for Boosting Mortality Early Warning System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0845.pdf">0845</a></td><td style="text-align:left">DiPE: Deeper into Photometric Errors for Unsupervised Learning of Depth and Ego-Motion from Monocular Videos</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0849.pdf">0849</a></td><td style="text-align:left">Clothoid-Based Moving Formation Control Using Virtual Structures</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0851.pdf">0851</a></td><td style="text-align:left">Water Based Magnification of Capacitive Proximity Sensors: Water Containers As Passive Human Detectors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0852.pdf">0852</a></td><td style="text-align:left">Adaptive Robot-Assisted Feeding: An Online Learning Framework for Acquiring Previously Unseen Food Items</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0855.pdf">0855</a></td><td style="text-align:left">Remove, Then Revert: Static Point Cloud Map Construction Using Multiresolution Range Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0857.pdf">0857</a></td><td style="text-align:left">FreeBOT: A Freeform Modular Self-Reconfigurable Robot with Arbitrary Connection Point - Design and Implementation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0865.pdf">0865</a></td><td style="text-align:left">A Target Tracking and Positioning Framework for Video Satellites Based on SLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0867.pdf">0867</a></td><td style="text-align:left">360Â° Depth Estimation from Multiple Fisheye Images with Origami Crown Representation of Icosahedron</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0869.pdf">0869</a></td><td style="text-align:left">Augmented Memory for Correlation Filters in Real-Time UAV Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0870.pdf">0870</a></td><td style="text-align:left">Batch Normalization Masked Sparse Autoencoder for Robotic Grasping Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0874.pdf">0874</a></td><td style="text-align:left">ROS-Lite: ROS Framework for NoC-Based Embedded Many-Core Platform</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0876.pdf">0876</a></td><td style="text-align:left">Utilizing Sacrificial Molding for Embedding Motion Controlling Endostructures in Soft Pneumatic Actuators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0879.pdf">0879</a></td><td style="text-align:left">Incorporating Spatial Constraints into a Bayesian Tracking Framework for Improved Localisation in Agricultural Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0888.pdf">0888</a></td><td style="text-align:left">SSP: Single Shot Future Trajectory Prediction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0891.pdf">0891</a></td><td style="text-align:left">Stir to Pour: Efficient Calibration of Liquid Properties for Pouring Actions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0892.pdf">0892</a></td><td style="text-align:left">Drive-Train Design in JAXON3-P and Realization of Jump Motions: Impact Mitigation and Force Control Performance for Dynamic Motions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0895.pdf">0895</a></td><td style="text-align:left">Autonomous Task Planning and Situation Awareness in Robotic Surgery</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0896.pdf">0896</a></td><td style="text-align:left">Subsurface Sampling Robot for Time-Limited Asteroid Exploration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0897.pdf">0897</a></td><td style="text-align:left">A Variable Impedance Control Strategy for Object Manipulation Considering Non-Rigid Grasp</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0898.pdf">0898</a></td><td style="text-align:left">Toward Hierarchical Self-Supervised Monocular Absolute Depth Estimation for Autonomous Driving Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0900.pdf">0900</a></td><td style="text-align:left">Fruit Quality Control by Surface Analysis Using a Bio-Inspired Soft Tactile Sensor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0902.pdf">0902</a></td><td style="text-align:left">AVP-SLAM: Semantic Visual Mapping and Localization for Autonomous Vehicles in the Parking Lot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0904.pdf">0904</a></td><td style="text-align:left">Robust Internal Model Control for Motor Systems Based on Sliding Mode Technique and Extended State Observer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0905.pdf">0905</a></td><td style="text-align:left">Organizing the Internet of Robotic Things: The Effect of Organization Structure on Users’ Evaluation and Compliance Toward IoRT Service Platform</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0907.pdf">0907</a></td><td style="text-align:left">Locomotion Performance of a Configurable Paddle-Wheel Robot Over Dry Sandy Terrain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0908.pdf">0908</a></td><td style="text-align:left">Can I Lift It? Humanoid Robot Reasoning about the Feasibility of Lifting a Heavy Box with Unknown Physical Properties</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0909.pdf">0909</a></td><td style="text-align:left">Adaptability Preserving Domain Decomposition for Stabilizing Sim2Real Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0912.pdf">0912</a></td><td style="text-align:left">Robot-Assisted Ultrasound-Guided Biopsy on MR-Detected Breast Lesions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0913.pdf">0913</a></td><td style="text-align:left">Tactile Event Based Grasping Algorithm Using Memorized Triggers and Mechanoreceptive Sensors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0914.pdf">0914</a></td><td style="text-align:left">An Augmented Reality Interaction Interface for Autonomous Drone</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0919.pdf">0919</a></td><td style="text-align:left">Learning an Overlap-Based Observation Model for 3D LiDAR Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0931.pdf">0931</a></td><td style="text-align:left">Automatic Targetless Extrinsic Calibration of Multiple 3D LiDARs and Radars</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0934.pdf">0934</a></td><td style="text-align:left">HD Map Change Detection with Cross-Domain Deep Metric Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0938.pdf">0938</a></td><td style="text-align:left">Learning Agile Locomotion Via Adversarial Training</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0939.pdf">0939</a></td><td style="text-align:left">Path Planning for Mobile Manipulators under Nonholonomic and Task Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0942.pdf">0942</a></td><td style="text-align:left">Long-Reach Compact Robotic Arm with LMPA Joints for Monitoring of Reactor Interior</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0943.pdf">0943</a></td><td style="text-align:left">The Newer College Dataset Handheld LiDAR, Inertial and Vision with Ground Truth</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0944.pdf">0944</a></td><td style="text-align:left">Automatic Failure Recovery and Re-Initialization for Online UAV Tracking with Joint Scale and Aspect Ratio Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0947.pdf">0947</a></td><td style="text-align:left">Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0948.pdf">0948</a></td><td style="text-align:left">Vision-Based Gesture Recognition in Human-Robot Teams Using Synthetic Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0954.pdf">0954</a></td><td style="text-align:left">Joints-Space Metrics for Automatic Robotic Surgical Gestures Classification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0955.pdf">0955</a></td><td style="text-align:left">Probabilistic Qualitative Localization and Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0956.pdf">0956</a></td><td style="text-align:left">Soft Tissue Simulation Environment to Learn Manipulation Tasks in Autonomous Robotic Surgery</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0960.pdf">0960</a></td><td style="text-align:left">Adaptive Potential Scanning for a Tomographic Tactile Sensor with High Spatio-Temporal Resolution</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0962.pdf">0962</a></td><td style="text-align:left">Modelling Social Interaction between Humans and Service Robots in Large Public Spaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0963.pdf">0963</a></td><td style="text-align:left">A Novel Trajectory Optimization for Affine Systems: Beyond Convex-Concave Procedure</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0970.pdf">0970</a></td><td style="text-align:left">Control of Magnetically-Driven Screws in a Viscoelastic Medium</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0975.pdf">0975</a></td><td style="text-align:left">A Particle Filter Technique for Human Pose Estimation in Case of Occlusion Exploiting Holographic Human Model and Virtualized Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0976.pdf">0976</a></td><td style="text-align:left">Dual-SLAM: A Framework for Robust Single Camera Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0979.pdf">0979</a></td><td style="text-align:left">Point Cloud Completion by Learning Shape Priors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0981.pdf">0981</a></td><td style="text-align:left">Task Planning from Complex Natural Instructions by a Collocating Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0986.pdf">0986</a></td><td style="text-align:left">AutoLay: Benchmarking amodal layout estimation for autonomous driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0987.pdf">0987</a></td><td style="text-align:left">Centroids Triplet Network and Temporally-Consistent Embeddings for In-Situ Object Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0988.pdf">0988</a></td><td style="text-align:left">Accurate Mapping and Planning for Autonomous Racing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0989.pdf">0989</a></td><td style="text-align:left">Optimal Robot Motion Planning in Constrained Workspaces Using Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0991.pdf">0991</a></td><td style="text-align:left">Next-Best-View Planning for Surface Reconstruction of Large-Scale 3D Environments with Multiple UAVs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0994.pdf">0994</a></td><td style="text-align:left">Multi-UAV Coverage Path Planning for the Inspection of Large and Complex Structures</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0995.pdf">0995</a></td><td style="text-align:left">Coordinate-Free Isoline Tracking in Unknown 2-D Scalar Fields</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0998.pdf">0998</a></td><td style="text-align:left">Diagnose Like a Clinician: Third-Order Attention Guided Lesion Amplification Network for WCE Image Classification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/0999.pdf">0999</a></td><td style="text-align:left">Lightweight Multi-Robot Communication Protocols for Information Synchronization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1000.pdf">1000</a></td><td style="text-align:left">Hybrid Aerial-Ground Locomotion with a Single Passive Wheel</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1002.pdf">1002</a></td><td style="text-align:left">Redundancy Resolution under Hard Joint Constraints: A Generalized Approach to Rank Updates</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1005.pdf">1005</a></td><td style="text-align:left">A Mobile Robot Hand-Arm Teleoperation System by Vision and IMU</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1006.pdf">1006</a></td><td style="text-align:left">Standard Deep Generative Models for Density Estimation in Configuration Spaces: A Study of Benefits, Limits and Challenges</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1007.pdf">1007</a></td><td style="text-align:left">Unilateral Constraints for Torque-Based Whole-Body Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1013.pdf">1013</a></td><td style="text-align:left">Distributed Motion Control for Multiple Connected Surface Vessels</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1014.pdf">1014</a></td><td style="text-align:left">Towards Gradient-Based Actuationof Magnetic Soft Robots Using a Six-Coil Electromagnetic System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1015.pdf">1015</a></td><td style="text-align:left">MOZARD: Multi-Modal Localization for Autonomous Vehicles in Urban Outdoor Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1017.pdf">1017</a></td><td style="text-align:left">A Soft Humanoid Hand with In-Finger Visual Perception</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1019.pdf">1019</a></td><td style="text-align:left">Affordance-Based Grasping and Manipulation in Real World Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1020.pdf">1020</a></td><td style="text-align:left">Computing High-Quality Clutter Removal Solutions for Multiple Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1022.pdf">1022</a></td><td style="text-align:left">To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1023.pdf">1023</a></td><td style="text-align:left">Visual Task Progress Estimation with Appearance Invariant Embeddings for Robot Control and Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1025.pdf">1025</a></td><td style="text-align:left">Formalization of Robot Skills with Descriptive and Operational Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1028.pdf">1028</a></td><td style="text-align:left">Video Depth Estimation by Fusing Flow-to-Depth Proposals</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1029.pdf">1029</a></td><td style="text-align:left">Towards Dynamic Transparency: Robust Interaction Force Tracking Using Multi-Sensory Control on an Arm Exoskeleton</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1031.pdf">1031</a></td><td style="text-align:left">Faster Than FAST: GPU-Accelerated Frontend for High-Speed VIO</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1037.pdf">1037</a></td><td style="text-align:left">Accurate and Robust Teach and Repeat Navigation by Visual Place Recognition: A CNN Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1043.pdf">1043</a></td><td style="text-align:left">Aerial Transportation of Unknown Payloads: Adaptive Path Tracking for Quadrotors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1044.pdf">1044</a></td><td style="text-align:left">Design and Modeling of a Parallel Shifted-Routing Cable-Driven Continuum Manipulator for Endometrial Regeneration Surgery</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1045.pdf">1045</a></td><td style="text-align:left">Learning Continuous Object Representations from Point Cloud Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1047.pdf">1047</a></td><td style="text-align:left">Deep Tactile Experience: Estimating Tactile Sensor Output from Depth Sensor Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1049.pdf">1049</a></td><td style="text-align:left">Online Velocity Constraint Adaptation for Safe and Efficient Human-Robot Workspace Sharing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1050.pdf">1050</a></td><td style="text-align:left">Learning Domain Randomization Distributions for Training Robust Locomotion Policies</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1051.pdf">1051</a></td><td style="text-align:left">An Optimized Tilt Mechanism for a New Steady-Hand Eye Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1052.pdf">1052</a></td><td style="text-align:left">Estimating Pedestrian Crossing States Based on Single 2D Body Pose</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1055.pdf">1055</a></td><td style="text-align:left">Hybrid Fluidic Actuation for a Foam-Based Soft Actuator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1057.pdf">1057</a></td><td style="text-align:left">Unsupervised Depth and Confidence Prediction from Monocular Images Using Bayesian Inference</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1060.pdf">1060</a></td><td style="text-align:left">CLOCs: Camera-LiDAR Object Candidates Fusion for 3D Object Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1062.pdf">1062</a></td><td style="text-align:left">Polygonal Perception for Mobile Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1064.pdf">1064</a></td><td style="text-align:left">Relational Graph Learning for Crowd Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1065.pdf">1065</a></td><td style="text-align:left">Learning High-Level Policies for Model Predictive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1066.pdf">1066</a></td><td style="text-align:left">Autonomous Navigation in Complex Environments with Deep Multimodal Fusion Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1071.pdf">1071</a></td><td style="text-align:left">Kinematic Multibody Model Generation of Deformable Linear Objects from Point Clouds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1074.pdf">1074</a></td><td style="text-align:left">Online Dynamic Motion Planning and Control for Wheeled Biped Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1076.pdf">1076</a></td><td style="text-align:left">Bayesian Fusion of Unlabeled Vision and RF Data for Aerial Tracking of Ground Targets</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1077.pdf">1077</a></td><td style="text-align:left">Anatomical Mesh-Based Virtual Fixtures for Surgical Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1078.pdf">1078</a></td><td style="text-align:left">Smart-Inspect: Micro Scale Localization and Classification of Smartphone Glass Defects for Industrial Automation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1079.pdf">1079</a></td><td style="text-align:left">Automated Design and Construction of a Single Incision Laparoscopic System Adapted to the Required Workspace</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1080.pdf">1080</a></td><td style="text-align:left">Dense Decentralized Multi-Robot SLAM Based on Locally Consistent TSDF Submaps</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1081.pdf">1081</a></td><td style="text-align:left">Multiple Trajectory Prediction with Deep Temporal and Spatial Convolutional Neural Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1083.pdf">1083</a></td><td style="text-align:left">Multi-Sparse Gaussian Process: Learning Based Semi-Parametric Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1085.pdf">1085</a></td><td style="text-align:left">Domain Adaptation for Outdoor Robot Traversability Estimation from RGB Data with Safety-Preserving Loss</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1086.pdf">1086</a></td><td style="text-align:left">GndNet: Fast Ground Plane Estimation and Point Cloud Segmentation for Autonomous Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1088.pdf">1088</a></td><td style="text-align:left">A Bio-Inspired Framework for Joint Angle Estimation from Non-Collocated Sensors in Tendon-Driven Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1091.pdf">1091</a></td><td style="text-align:left">Real-Time Spatio-Temporal LiDAR Point Cloud Compression</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1094.pdf">1094</a></td><td style="text-align:left">Solving Large-Scale Stochastic Orienteering Problems with Aggregation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1102.pdf">1102</a></td><td style="text-align:left">An Energy-Based Approach for the Integration of Collaborative Redundant Robots in Restricted Work Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1103.pdf">1103</a></td><td style="text-align:left">Wireless Electronic Skin with Integrated Pressure and Optical Proximity Sensing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1105.pdf">1105</a></td><td style="text-align:left">End-to-End 3D Point Cloud Learning for Registration Task Using Virtual Correspondences</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1108.pdf">1108</a></td><td style="text-align:left">Safe Planning for Self-Driving Via Adaptive Constrained ILQR</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1109.pdf">1109</a></td><td style="text-align:left">Experimental flights of adaptive patterns for cloud exploration with UAVs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1114.pdf">1114</a></td><td style="text-align:left">Learning to Live Life on the Edge: Online Learning for Data-Efficient Tactile Contour Following</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1116.pdf">1116</a></td><td style="text-align:left">Supportive Actions for Manipulation in Human-Robot Coworker Teams</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1118.pdf">1118</a></td><td style="text-align:left">Model-Based Quality-Diversity Search for Efficient Robot Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1119.pdf">1119</a></td><td style="text-align:left">Autonomous Planning for Multiple Aerial Cinematographers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1120.pdf">1120</a></td><td style="text-align:left">Supervised Autoencoder Joint Learning on Heterogeneous Tactile Sensory Data: Improving Material Classification Performance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1121.pdf">1121</a></td><td style="text-align:left">Magnetized Cell-Robot Propelled by Magnetic Field for Cancer Killing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1122.pdf">1122</a></td><td style="text-align:left">Basic Implementation of FPGA-GPU Dual SoC Hybrid Architecture for Low-Latency Multi-DOF Robot Motion Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1123.pdf">1123</a></td><td style="text-align:left">Synchronization of Microphones Based on Rank Minimization of Warped Spectrum for Asynchronous Distributed Recording</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1126.pdf">1126</a></td><td style="text-align:left">Robotic Micromanipulation of Biological Cells with Friction Force-Based Rotation Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1130.pdf">1130</a></td><td style="text-align:left">Multi-Robot Joint Visual-Inertial Localization and 3-D Moving Object Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1132.pdf">1132</a></td><td style="text-align:left">Modeling a Social Placement Cost to Extend Navigation among Movable Obstacles (NAMO) Algorithms</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1134.pdf">1134</a></td><td style="text-align:left">An Earthworm-Like Soft Robot with Integration of Single Pneumatic Actuator and Cellular Structures for Peristaltic Motion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1135.pdf">1135</a></td><td style="text-align:left">IDOL: A Framework for IMU-DVS Odometry Using Lines</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1136.pdf">1136</a></td><td style="text-align:left">This or That: The Effect of Robot’s Deictic Expression on User’s Perception</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1137.pdf">1137</a></td><td style="text-align:left">Modeling and Control of a Hybrid Wheeled Jumping Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1138.pdf">1138</a></td><td style="text-align:left">An In-Pipe Manipulator for Contamination-Less Rehabilitation of Water Distribution Pipes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1140.pdf">1140</a></td><td style="text-align:left">Transferability in an 8-DoF Parallel Robot with a Configurable Platform</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1141.pdf">1141</a></td><td style="text-align:left">Optimizing Dynamic Trajectories for Robustness to Disturbances Using Polytopic Projections</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1142.pdf">1142</a></td><td style="text-align:left">Inter-Robot Range Measurements in Pose Graph Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1145.pdf">1145</a></td><td style="text-align:left">Robots versus Speakers: What Type of Central Smart Home Interface Consumers Prefer?</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1146.pdf">1146</a></td><td style="text-align:left">Reinforcement Co-Learning of Deep and Spiking Neural Networks for Energy-Efficient Mapless Navigation with Neuromorphic Hardware</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1148.pdf">1148</a></td><td style="text-align:left">Scaling Laws for Parallel Motor-Gearbox Arrangements</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1149.pdf">1149</a></td><td style="text-align:left">Passivity Filter for Variable Impedance Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1150.pdf">1150</a></td><td style="text-align:left">Long-Run Multi-Robot Planning under Uncertain Action Durations for Persistent Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1151.pdf">1151</a></td><td style="text-align:left">Template-Based Optimal Robot Design with Application to Passive-Dynamic Underactuated Flapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1155.pdf">1155</a></td><td style="text-align:left">Interactive Movement Primitives: Planning to Push Occluding Pieces for Fruit Picking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1157.pdf">1157</a></td><td style="text-align:left">Modeling Cable-Driven Joint Dynamics and Friction: A Bond-Graph Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1158.pdf">1158</a></td><td style="text-align:left">Verification of System-Wide Safety Properties of ROS Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1159.pdf">1159</a></td><td style="text-align:left">Real-Time Detection of Broccoli Crops in 3D Point Clouds for Autonomous Robotic Harvesting</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1165.pdf">1165</a></td><td style="text-align:left">Understanding Contexts Inside Robot and Human Manipulation Tasks through Vision-Language Model and Ontology System in Video Streams</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1171.pdf">1171</a></td><td style="text-align:left">Representing Spatial Object Relations As Parametric Polar Distribution for Scene Manipulation Based on Verbal Commands</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1172.pdf">1172</a></td><td style="text-align:left">Z-Net: An Anisotropic 3D DCNN for Medical CT Volume Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1176.pdf">1176</a></td><td style="text-align:left">Analysis, Development and Evaluation of Electro-Hydrostatic Technology for Lower Limb Prostheses Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1177.pdf">1177</a></td><td style="text-align:left">Proprioceptive Sensor Fusion for Quadruped Robot State Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1180.pdf">1180</a></td><td style="text-align:left">Model Identification of a Small Omnidirectional Aquatic Surface Vehicle: A Practical Implementation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1183.pdf">1183</a></td><td style="text-align:left">Reducing the Teleoperator’s Cognitive Burden for Complex Contact Tasks Using Affordance Primitives</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1184.pdf">1184</a></td><td style="text-align:left">Point Cloud Based Reinforcement Learning for Sim-To-Real and Partial Observability in Visual Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1189.pdf">1189</a></td><td style="text-align:left">A Novel Inverse Kinematics Method for Upper-Limb Exoskeleton under Joint Coordination Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1190.pdf">1190</a></td><td style="text-align:left">Closing the Loop: Real-Time Perception and Control for Robust Collision Avoidance with Occluded Obstacles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1191.pdf">1191</a></td><td style="text-align:left">Brainless Running: A Quasi-Quadruped Robot with Decentralized Spinal Reflexes by Solely Mechanical Devices</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1193.pdf">1193</a></td><td style="text-align:left">Unsupervised Learning of Dense Optical Flow, Depth and Egomotion with Event-Based Sensors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1195.pdf">1195</a></td><td style="text-align:left">Autonomous Robot Navigation Based on Multi-Camera Perception</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1196.pdf">1196</a></td><td style="text-align:left">Improving Motion Planning for Surgical Robot with Active Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1197.pdf">1197</a></td><td style="text-align:left">Graduated Assignment Graph Matching for Realtime Matching of Image Wireframes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1201.pdf">1201</a></td><td style="text-align:left">Integrating Model Predictive Control and Dynamic Waypoints Generation for Motion Planning in Surgical Scenario</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1203.pdf">1203</a></td><td style="text-align:left">Hierarchical Optimization Control of Redundant Manipulator for Robot-Assisted Minimally Invasive Surgery</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1204.pdf">1204</a></td><td style="text-align:left">Variable Pitch System for the Underwater Explorer Robot UX-1</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1205.pdf">1205</a></td><td style="text-align:left">Real-Time Optimal Control of an Autonomous RC Car with Minimum-Time Maneuvers and a Novel Kineto-Dynamical Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1208.pdf">1208</a></td><td style="text-align:left">PillarFlowNet: A Real-time Deep Multitask Network for LiDAR-based 3D Object Detection and Scene Flow Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1209.pdf">1209</a></td><td style="text-align:left">Intelligent Exploration and Autonomous Navigation in Confined Spaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1211.pdf">1211</a></td><td style="text-align:left">Model Identification of a Soft Robotic Neck</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1216.pdf">1216</a></td><td style="text-align:left">MHYRO: Modular HYbrid RObot for Contact Inspection and Maintenance in Oil&amp;gas Plants</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1218.pdf">1218</a></td><td style="text-align:left">Auditory Feedback Effectiveness for Enabling Safe Sclera Force in Robot-Assisted Vitreoretinal Surgery: A Multi-User Study</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1220.pdf">1220</a></td><td style="text-align:left">Towards Micro Robot Hydrobatics: Vision-based Guidance, Navigation, and Control for Agile Underwater Vehicles in Confined Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1222.pdf">1222</a></td><td style="text-align:left">A Decentralized Framework for Simultaneous Calibration, Localization and Mapping with Multiple LiDARs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1231.pdf">1231</a></td><td style="text-align:left">Real-Time Detection of Distracted Driving Using Dual Cameras</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1232.pdf">1232</a></td><td style="text-align:left">A Biomimetic Tactile Fingerprint Induces Incipient Slip</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1233.pdf">1233</a></td><td style="text-align:left">Model Quality Aware RANSAC: A Robust Camera Motion Estimator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1235.pdf">1235</a></td><td style="text-align:left">Synchrono: A Scalable, Physics-Based Simulation Platform for Testing Groups of Autonomous Vehicles And/or Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1236.pdf">1236</a></td><td style="text-align:left">Cross Scene Prediction via Modeling Dynamic Correlation using Latent Space Shared Auto-Encoders</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1237.pdf">1237</a></td><td style="text-align:left">Towards Vision-Based Impedance Control for the Contact Inspection of Unknown Generically-Shaped Surfaces with a Fully-Actuated UAV</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1238.pdf">1238</a></td><td style="text-align:left">Squash-Box Feasibility Driven Differential Dynamic Programming</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1239.pdf">1239</a></td><td style="text-align:left">SGM-MDE: Semi-Global Optimization for Classification-Based Monocular Depth Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1240.pdf">1240</a></td><td style="text-align:left">Safety Considerations in Deep Control Policies with Safety Barrier Certificates under Uncertainty</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1244.pdf">1244</a></td><td style="text-align:left">Asynchronous Event-Based Line Tracking for Time-To-Contact Maneuvers in UAS</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1245.pdf">1245</a></td><td style="text-align:left">RobotVQA ‘ a Scene-Graph and Deep-Learning-Based Visual Question Answering System for Robot Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1247.pdf">1247</a></td><td style="text-align:left">A Model-Free Solution for Stable Balancing and Locomotion of Floating-Base Legged Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1248.pdf">1248</a></td><td style="text-align:left">Label Efficient Visual Abstractions for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1249.pdf">1249</a></td><td style="text-align:left">Control Interface for Hands-Free Navigation of Standing Mobility Vehicles Based on Upper-Body Natural Movements</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1250.pdf">1250</a></td><td style="text-align:left">Resonating Magnetic Manipulation for 3D Path-Following and Blood Clot Removal Using a Rotating Swimmer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1252.pdf">1252</a></td><td style="text-align:left">Distilling Location Proposals of Unknown Objects through Gaze Information for Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1253.pdf">1253</a></td><td style="text-align:left">Visualization of Intended Assistance for Acceptance of Shared Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1254.pdf">1254</a></td><td style="text-align:left">Learning Object Manipulation with Dexterous Hand-Arm Systems from Human Demonstration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1255.pdf">1255</a></td><td style="text-align:left">Learning Accurate and Human-Like Driving Using Semantic Maps and Attention</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1259.pdf">1259</a></td><td style="text-align:left">Designing Environments Conducive to Interpretable Robot Behavior</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1263.pdf">1263</a></td><td style="text-align:left">Efficiency and Equity are Both Essential: A Generalized Traffic Signal Controller with Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1265.pdf">1265</a></td><td style="text-align:left">Reactive Receding Horizon Planning and Control for Quadrotors with Limited On-Board Sensing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1266.pdf">1266</a></td><td style="text-align:left">SelfieDroneStick: A Natural Interface for Quadcopter Photography</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1275.pdf">1275</a></td><td style="text-align:left">Localization and Force-Feedback with Soft Magnetic Stickers for Precise Robot Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1276.pdf">1276</a></td><td style="text-align:left">Robust Monocular Edge Visual Odometry through Coarse-To-Fine Data Association</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1279.pdf">1279</a></td><td style="text-align:left">TartanAir: A Dataset to Push the Limits of Visual SLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1281.pdf">1281</a></td><td style="text-align:left">An SEM-Based Nanomanipulation System for Multi-Physical Characterization of Single InGaN/GaN Nanowires</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1282.pdf">1282</a></td><td style="text-align:left">Line Walking and Balancing for Legged Robots with Point Feet</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1283.pdf">1283</a></td><td style="text-align:left">Robust Gait Synthesis Combining Constrained Optimization and Imitation Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1284.pdf">1284</a></td><td style="text-align:left">Edge-Based Visual Odometry with Stereo Cameras Using Multiple Oriented Quadtrees</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1285.pdf">1285</a></td><td style="text-align:left">Monocular Localization in HD Maps by Combining Semantic Segmentation and Distance Transform</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1288.pdf">1288</a></td><td style="text-align:left">Optimal Design of a Novel Spherical Scissor Linkage Remote Center of Motion Mechanism for Medical Robotics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1292.pdf">1292</a></td><td style="text-align:left">Adversarial Generation of Informative Trajectories for Dynamics System Identification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1295.pdf">1295</a></td><td style="text-align:left">Robust and Efficient Object Change Detection by Combining Global Semantic Information and Local Geometric Verification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1296.pdf">1296</a></td><td style="text-align:left">Bounded Sub-Optimal Multi-Robot Path Planning Using Satisfiability Modulo Theory (SMT) Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1297.pdf">1297</a></td><td style="text-align:left">Haptic Knowledge Transfer between Heterogeneous Robots Using Kernel Manifold Alignment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1298.pdf">1298</a></td><td style="text-align:left">Competitive Coverage: (Full) Information As a GameChanger</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1299.pdf">1299</a></td><td style="text-align:left">Expressing Diverse Human Driving Behavior with ProbabilisticRewards and Online Inference</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1300.pdf">1300</a></td><td style="text-align:left">Proximal Deterministic Policy Gradient</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1301.pdf">1301</a></td><td style="text-align:left">Generalizing Learned Manipulation Skills in Practice</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1302.pdf">1302</a></td><td style="text-align:left">GR-SLAM: Vision-Based Sensor Fusion SLAM for Ground Robots on Complex Terrain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1304.pdf">1304</a></td><td style="text-align:left">Automatic Gait Pattern Selection for Legged Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1307.pdf">1307</a></td><td style="text-align:left">Learning Vision-Based Physics Intuition Models for Non-Disruptive Object Extraction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1313.pdf">1313</a></td><td style="text-align:left">Lane-Attention: Predicting Vehicles’ Moving Trajectories by Learning Their Attention Over Lanes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1315.pdf">1315</a></td><td style="text-align:left">Robotic Table Tennis with Model-Free Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1317.pdf">1317</a></td><td style="text-align:left">Consistent Covariance Pre-Integration for Invariant Filters with Delayed Measurements</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1319.pdf">1319</a></td><td style="text-align:left">Model-Based Specification of Control Architectures for Compliant Interaction with the Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1321.pdf">1321</a></td><td style="text-align:left">Perception-Aware Path Finding and Following of Snake Robot in Unknown Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1323.pdf">1323</a></td><td style="text-align:left">3D Coating Self-Assembly for Modular Robotic Scaffolds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1326.pdf">1326</a></td><td style="text-align:left">Understanding Dynamic Scenes Using Graph Convolution Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1328.pdf">1328</a></td><td style="text-align:left">Monocular Depth Prediction through Continuous 3D Loss</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1335.pdf">1335</a></td><td style="text-align:left">Peg-In-Hole Using 3D Workpiece Reconstruction and CNN-Based Hole Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1337.pdf">1337</a></td><td style="text-align:left">Crop Height and Plot Estimation for Phenotyping from Unmanned Aerial Vehicles Using 3D LiDAR</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1338.pdf">1338</a></td><td style="text-align:left">Non-linear control under state constraints with validated trajectories for a mobile robot towing a trailer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1340.pdf">1340</a></td><td style="text-align:left">ImitationFlow: Learning Deep Stable Stochastic Dynamic Systems by Normalizing Flows</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1341.pdf">1341</a></td><td style="text-align:left">A Unique Identifier Assignment Method for Distributed Modular Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1344.pdf">1344</a></td><td style="text-align:left">A Framework for Real-Time and Personalisable Human Ergonomics Monitoring</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1346.pdf">1346</a></td><td style="text-align:left">Bio-Inspired Inverted Landing Strategy in a Small Aerial Robot Using Policy Gradient</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1347.pdf">1347</a></td><td style="text-align:left">Walking on TacTip Toes: A Tactile Sensing Foot for Walking Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1350.pdf">1350</a></td><td style="text-align:left">Event-Based PID Controller Fully Realized in Neuromorphic Hardware: A One DoF Study</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1351.pdf">1351</a></td><td style="text-align:left">Modality-Buffet for Real-Time Object Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1352.pdf">1352</a></td><td style="text-align:left">Traffic Control Gesture Recognition for Autonomous Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1353.pdf">1353</a></td><td style="text-align:left">Emergent Adaptive Gait Generation through Hebbian Sensor-Motor Maps by Morphological Probing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1356.pdf">1356</a></td><td style="text-align:left">PnuGrip: An Active Two-Phase Gripper for Dexterous Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1357.pdf">1357</a></td><td style="text-align:left">robo-gym ‘ An Open Source Toolkit for Distributed Deep Reinforcement Learning on Real and Simulated Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1358.pdf">1358</a></td><td style="text-align:left">LIC-Fusion 2.0: LiDAR-Inertial-Camera Odometry with Sliding-Window Plane-Feature Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1359.pdf">1359</a></td><td style="text-align:left">Experimental Evaluation of 3D-LIDAR Camera Extrinsic Calibration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1362.pdf">1362</a></td><td style="text-align:left">Autonomous model-based assessment of mechanical failures of reconfigurable modular robots with a Conjugate Gradient solver</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1363.pdf">1363</a></td><td style="text-align:left">Spiking Neurons Ensemble for Movement Generation in Dynamically Changing Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1365.pdf">1365</a></td><td style="text-align:left">Terrain-Adaptive Planning and Control of Complex Motions for Walking Excavators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1369.pdf">1369</a></td><td style="text-align:left">Gimme Signals: Discriminative Signal Encoding for Multimodal Activity Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1370.pdf">1370</a></td><td style="text-align:left">Goal-Driven Variable Admittance Control for Robot Manual Guidance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1372.pdf">1372</a></td><td style="text-align:left">A Scalable Framework for Robust Vehicle State Estimation with a Fusion of a Low-Cost IMU, the GNSS, Radar, a Camera and Lidar</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1375.pdf">1375</a></td><td style="text-align:left">Joint Feature Selection and Time Optimal Path Parametrization for High Speed Vision-Aided Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1377.pdf">1377</a></td><td style="text-align:left">Multi-Task Deep Learning for Depth-Based Person Perception in Mobile Robotics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1378.pdf">1378</a></td><td style="text-align:left">Online Explanation Generation for Planning Tasks in Human-Robot Teaming</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1381.pdf">1381</a></td><td style="text-align:left">CinemAirSim: A Camera-Realistic Robotics Simulator for  Cinematographic Purposes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1384.pdf">1384</a></td><td style="text-align:left">Real-World Human-Robot Collaborative Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1386.pdf">1386</a></td><td style="text-align:left">Kinodynamic Motion Planning for Multi-Legged Robot Jumping Via Mixed-Integer Convex Program</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1387.pdf">1387</a></td><td style="text-align:left">Who Make Drivers Stop? Towards Driver-Centric Risk Assessment: Risk Object Identification via Causal Inference</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1388.pdf">1388</a></td><td style="text-align:left">Adaptive Partitioning for Coordinated Multi-Agent Perimeter Defense</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1390.pdf">1390</a></td><td style="text-align:left">Tracking Strategy Based on Magnetic Sensors for Microrobot Navigation in the Cochlea</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1391.pdf">1391</a></td><td style="text-align:left">Learning Object Attributes with Category-Free Grounded Language from Deep Featurization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1392.pdf">1392</a></td><td style="text-align:left">First Steps: Latent-Space Control with Semantic Constraints for Quadruped Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1394.pdf">1394</a></td><td style="text-align:left">Self-Reconfiguration Planning of Adaptive Modular Robots with Triangular Structure Based on Extended Binary Trees</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1395.pdf">1395</a></td><td style="text-align:left">Fast Model Predictive Image-Based Visual Servoing for Quadrotors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1396.pdf">1396</a></td><td style="text-align:left">What the HoloLens Maps Is Your Workspace: Fast Mapping and Set-Up of Robot Cells Via Head Mounted Displays and Augmented Reality</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1399.pdf">1399</a></td><td style="text-align:left">6D Pose Estimation for Flexible Production with Small Lot Sizes Based on CAD Models Using Gaussian Process Implicit Surfaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1400.pdf">1400</a></td><td style="text-align:left">Design of a New Electroactive Polymer Based Continuum Actuator for Endoscopic Surgical Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1402.pdf">1402</a></td><td style="text-align:left">Efficient Object Search through Probability-Based Viewpoint Selection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1405.pdf">1405</a></td><td style="text-align:left">A Probabilistic Shared-Control Framework for Mobile Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1409.pdf">1409</a></td><td style="text-align:left">Model Predictive Control for a Tendon-Driven Surgical Robot with Safety Constraints in Kinematics and Dynamics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1411.pdf">1411</a></td><td style="text-align:left">Vision-based Belt Manipulation by Humanoid Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1414.pdf">1414</a></td><td style="text-align:left">3D Localization of a Sound Source Using Mobile Microphone Arrays Referenced by SLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1418.pdf">1418</a></td><td style="text-align:left">Exploit Semantic and Public Prior Information in MonoSLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1422.pdf">1422</a></td><td style="text-align:left">Fast Online Adaptation in Robotics through Meta-Learning Embeddings of Simulated Priors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1425.pdf">1425</a></td><td style="text-align:left">Computational Design of Balanced Open Link Planar Mechanisms with Counterweights from User Sketches</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1427.pdf">1427</a></td><td style="text-align:left">An Underactuated Gripper Using Origami-Folding Inspired Variable Stiffness Flexure Hinges</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1428.pdf">1428</a></td><td style="text-align:left">Frontier Detection and Reachability Analysis for Efficient 2D Graph-SLAM Based Active Exploration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1429.pdf">1429</a></td><td style="text-align:left">Towards the Development of a Robotic Transcatheter Delivery System for Mitral Valve Implant</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1430.pdf">1430</a></td><td style="text-align:left">B-Spline Surfaces for Range-Based Environment Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1431.pdf">1431</a></td><td style="text-align:left">Localizing against Drawn Maps Via Spline-Based Registration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1432.pdf">1432</a></td><td style="text-align:left">Majorization Minimization Methods for Distributed Pose Graph Optimization with Convergence Guarantees</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1433.pdf">1433</a></td><td style="text-align:left">Deep Adversarial Reinforcement Learning for Object Disentangling</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1434.pdf">1434</a></td><td style="text-align:left">Dense Incremental Metric-Semantic Mapping Via Sparse Gaussian Process Regression</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1435.pdf">1435</a></td><td style="text-align:left">Synthesis of Control Barrier Functions Using a Supervised Machine Learning Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1436.pdf">1436</a></td><td style="text-align:left">JRMOT: A Real-Time 3D Multi-Object Tracker and a New Large-Scale Dataset</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1438.pdf">1438</a></td><td style="text-align:left">Slope Handling for Quadruped Robots Using Deep Reinforcement Learning and Toe Trajectory Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1439.pdf">1439</a></td><td style="text-align:left">Realistic and Interactive Robot Gaze</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1440.pdf">1440</a></td><td style="text-align:left">Gaussian Process Gradient Maps for Loop-Closure Detection in Unstructured Planetary Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1442.pdf">1442</a></td><td style="text-align:left">Efficient Multiresolution Scrolling Grid for Stereo Vision-based MAV Obstacle Avoidance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1443.pdf">1443</a></td><td style="text-align:left">Action Sequence Predictions of Vehicles in Urban Environments Using Map and Social Context</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1446.pdf">1446</a></td><td style="text-align:left">Decentralized Nonlinear MPC for Robust Cooperative Manipulation by Heterogeneous Aerial-Ground Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1447.pdf">1447</a></td><td style="text-align:left">Joint-Level Control of the DLR Lightweight Robot SARA</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1452.pdf">1452</a></td><td style="text-align:left">Improving Unimodal Object Recognition with Multimodal Contrastive Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1453.pdf">1453</a></td><td style="text-align:left">Observer-Based Control of Inflatable Robot with Variable Stiffness</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1454.pdf">1454</a></td><td style="text-align:left">Maximizing BCI Human Feedback Using Active Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1457.pdf">1457</a></td><td style="text-align:left">LiDAR Iris for Loop-Closure Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1460.pdf">1460</a></td><td style="text-align:left">Mixed Reality As a Bidirectional Communication Interface for Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1461.pdf">1461</a></td><td style="text-align:left">Visual Monitoring and Servoing of a Cutting Blade During Telerobotic Satellite Servicing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1462.pdf">1462</a></td><td style="text-align:left">Human-Drone Interaction for Aerially Manipulated Drilling Using Haptic Feedback</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1463.pdf">1463</a></td><td style="text-align:left">MAPPER: Multi-Agent Path Planning with Evolutionary Reinforcement Learning in Mixed Dynamic Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1465.pdf">1465</a></td><td style="text-align:left">No-Regret Shannon Entropy Regularized Neural Contextual Bandit Online Learning for Robotic Grasping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1467.pdf">1467</a></td><td style="text-align:left">Learning of Tool Force Adjustment Skills by a Life-Sized Humanoid Using Deep Reinforcement Learning and Active Teaching Request</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1469.pdf">1469</a></td><td style="text-align:left">Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in GPS-Denied Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1471.pdf">1471</a></td><td style="text-align:left">BIT-VO: Visual Odometry at 300 FPS Using Binary Features from the Focal Plane</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1472.pdf">1472</a></td><td style="text-align:left">Using Machine Learning for Material Detection with Capacitive Proximity Sensors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1477.pdf">1477</a></td><td style="text-align:left">Intent-Driven Strategic Tactical Planning for Autonomous SiteInspection Using Cooperative Drones</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1478.pdf">1478</a></td><td style="text-align:left">Physical Human-Robot Interaction with Real Active Surfaces Using Haptic Rendering on Point Clouds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1480.pdf">1480</a></td><td style="text-align:left">End-to-End Autonomous Driving Perception with Sequential Latent Representation Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1482.pdf">1482</a></td><td style="text-align:left">The Robot As Scientist: Using Mental Simulation to Test Causal Hypotheses Extracted from Human Activities in Virtual Reality</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1483.pdf">1483</a></td><td style="text-align:left">Design of a High-Level Teleoperation Interface Resilient to the Effects of Unreliable Robot Autonomy</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1488.pdf">1488</a></td><td style="text-align:left">TactileSGNet: A Spiking Graph Neural Network for Event-Based Tactile Object Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1490.pdf">1490</a></td><td style="text-align:left">A Miniaturised Neuromorphic Tactile Sensor Integrated with an Anthropomorphic Robot Hand</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1493.pdf">1493</a></td><td style="text-align:left">Towards Unsupervised Learning for Instrument Segmentation in Robotic Surgery with Cycle-Consistent Adversarial Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1498.pdf">1498</a></td><td style="text-align:left">Energy-Efficient Motion Planning for Multi-Modal Hybrid Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1499.pdf">1499</a></td><td style="text-align:left">CNN-Based Foothold Selection for Mechanically Adaptive Soft Foot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1503.pdf">1503</a></td><td style="text-align:left">A Topological Approach to Path Planning for a Magnetic Millirobot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1504.pdf">1504</a></td><td style="text-align:left">Autonomous Detection and Assessment with Moving Sensors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1505.pdf">1505</a></td><td style="text-align:left">Compliance Control of Cable-Suspended Aerial Manipulator Using Hierarchical Control Framework</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1507.pdf">1507</a></td><td style="text-align:left">Noncontact Estimation of Stiffness Based on Optical Coherence Elastography under Acoustic Radiation Pressure</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1508.pdf">1508</a></td><td style="text-align:left">Factor Graph Based 3D Multi-Object Tracking in Point Clouds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1512.pdf">1512</a></td><td style="text-align:left">Application of Interacting Models to Estimate the Gait Speed of an Exoskeleton User</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1513.pdf">1513</a></td><td style="text-align:left">An Approach to Reduce Communication for Multi-Agent Mapping Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1514.pdf">1514</a></td><td style="text-align:left">CUHK-AHU Dataset: Promoting Practical Self-Driving Applications in the Complex Airport Logistics, Hill and Urban Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1515.pdf">1515</a></td><td style="text-align:left">Friction Identification in a Pneumatic Gripper</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1519.pdf">1519</a></td><td style="text-align:left">LC-GAN: Image-To-Image Translation Based on Generative Adversarial Network for Endoscopic Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1520.pdf">1520</a></td><td style="text-align:left">Learning Human Navigation Behavior Using Measured Human Trajectories in Crowded Spaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1527.pdf">1527</a></td><td style="text-align:left">Scaling up Multiagent Reinforcement Learning for Robotic Systems: Learn an Adaptive Sparse Communication Graph</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1537.pdf">1537</a></td><td style="text-align:left">Efficient Exploration in Constrained Environments with Goal-Oriented Reference Path</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1538.pdf">1538</a></td><td style="text-align:left">Kalman Filter Based Range Estimation and Clock Synchronization for Ultra Wide Band Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1540.pdf">1540</a></td><td style="text-align:left">Haptic Sequential Monte Carlo Localization for Quadrupedal Locomotion in Vision-Denied Scenarios</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1543.pdf">1543</a></td><td style="text-align:left">Vision Only 3-D Shape Estimation for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1544.pdf">1544</a></td><td style="text-align:left">LLAMA: Design and Control of an Omnidirectional Human Mission Scale Quadrupedal Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1545.pdf">1545</a></td><td style="text-align:left">Variational Filtering with Copula Models for SLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1546.pdf">1546</a></td><td style="text-align:left">Dynamic Parameter Estimation Utilizing Optimized Trajectories</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1551.pdf">1551</a></td><td style="text-align:left">Core-Centered Actuation for Biped Locomotion of Humanoid Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1553.pdf">1553</a></td><td style="text-align:left">Dynamic Stability Control of Inverted-Pendulum-Type Robotic Wheelchair for Going Up and Down Stairs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1560.pdf">1560</a></td><td style="text-align:left">Depth Completion Via Inductive Fusion of Planar LIDAR and Monocular Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1565.pdf">1565</a></td><td style="text-align:left">FlexiVision: Teleporting the Surgeon’s Eyes Via Robotic Flexible Endoscope and Head-Mounted Display</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1566.pdf">1566</a></td><td style="text-align:left">Towards Robust Visual Tracking for Unmanned Aerial Vehicle with Tri-Attentional Correlation Filters</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1568.pdf">1568</a></td><td style="text-align:left">Infusing Reachability-Based Safety into Planning and Control for Multi-Agent Interactions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1569.pdf">1569</a></td><td style="text-align:left">Optimization-Based Hierarchical Motion Planning for Autonomous Racing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1572.pdf">1572</a></td><td style="text-align:left">DR-SPAAM: A Spatial-Attention and Auto-Regressive Model for Person Detection in 2D Range Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1573.pdf">1573</a></td><td style="text-align:left">Functionally Divided Manipulation Synergy for Controlling Multi-Fingered Hands</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1574.pdf">1574</a></td><td style="text-align:left">Solving Cosserat Rod Models Via Collocation and the Magnus Expansion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1576.pdf">1576</a></td><td style="text-align:left">SwingBot: Learning Physical Features from In-Hand Tactile Exploration for Dynamic Swing-Up Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1577.pdf">1577</a></td><td style="text-align:left">Crowdsourced 3D Mapping: A Combined Multi-View Geometry and Self-Supervised Learning Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1579.pdf">1579</a></td><td style="text-align:left">Visuomotor Mechanical Search: Learning to Retrieve Target Objects in Clutter</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1580.pdf">1580</a></td><td style="text-align:left">GRIF Net: Gated Region of Interest Fusion Network for Robust 3D Object Detection from Radar Point Cloud and Monocular Image</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1582.pdf">1582</a></td><td style="text-align:left">Semi-Autonomous Control of Leader-Follower Excavator using Admittance Control for Synchronization and Autonomy with Bifurcation and Stagnation for Human Interface</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1586.pdf">1586</a></td><td style="text-align:left">Active Improvement of Control Policies with Bayesian Gaussian Mixture Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1590.pdf">1590</a></td><td style="text-align:left">PLRC*: A Piecewise Linear Regression Complex for Approximating Optimal Robot Motion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1591.pdf">1591</a></td><td style="text-align:left">Disappearance of Chaotic Attractor of Passive Dynamic Walking by Stretch-Bending Deformation in Basin of Attraction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1593.pdf">1593</a></td><td style="text-align:left">Enabling Robot to Assist Human in Collaborative Assembly Using Convolutional Neural Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1595.pdf">1595</a></td><td style="text-align:left">Estimating Motion Codes from Demonstration Videos</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1598.pdf">1598</a></td><td style="text-align:left">Dynamic Object Tracking and Masking for Visual SLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1599.pdf">1599</a></td><td style="text-align:left">Evaluating the Efficacy of Parallel Elastic Actuators on High-Speed, Variable Stiffness Running</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1600.pdf">1600</a></td><td style="text-align:left">Active Preference Learning Using Maximum Regret</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1602.pdf">1602</a></td><td style="text-align:left">Approximated Dynamic Trait Models for Heterogeneous Multi-Robot Teams</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1603.pdf">1603</a></td><td style="text-align:left">Relevant Region Exploration on General Cost-Maps for Sampling-Based Motion Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1605.pdf">1605</a></td><td style="text-align:left">Self-Supervised Object Tracking with Cycle-Consistent Siamese Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1608.pdf">1608</a></td><td style="text-align:left">Resilient Coverage: Exploring the Local-To-Global Trade-Off</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1611.pdf">1611</a></td><td style="text-align:left">X-Ray: Mechanical Search for an Occluded Object by Minimizing Support of Learned Occupancy Distributions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1613.pdf">1613</a></td><td style="text-align:left">Secure Route Planning Using Dynamic Games with Stopping States</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1619.pdf">1619</a></td><td style="text-align:left">Ospheel: Design of an Omnidirectional Spherical-Sectioned Wheel</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1620.pdf">1620</a></td><td style="text-align:left">SQUIRL: Robust and Efficient Learning from Video Demonstration of Long-Horizon Robotic Manipulation Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1623.pdf">1623</a></td><td style="text-align:left">Depth Estimation from Monocular Images and Sparse Radar Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1629.pdf">1629</a></td><td style="text-align:left">Learning to Switch CNNs with Model Agnostic Meta Learning for Fine Precision Visual Servoing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1630.pdf">1630</a></td><td style="text-align:left">Relative Pose Estimation and Planar Reconstruction Via Superpixel-Driven Multiple Homographies</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1631.pdf">1631</a></td><td style="text-align:left">Crossing the Gap: A Deep Dive into Zero-Shot Sim-to-Real Transfer for Dynamics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1632.pdf">1632</a></td><td style="text-align:left">Rapid Bipedal Gait Optimization in CasADi</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1634.pdf">1634</a></td><td style="text-align:left">Novel Design of a Soft Pump Driven by Super-Coiled Polymer Artificial Muscles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1635.pdf">1635</a></td><td style="text-align:left">Automated Folding of a Deformable Thin Object through Robot Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1639.pdf">1639</a></td><td style="text-align:left">Robot Learning in Mixed Adversarial and Collaborative Settings</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1640.pdf">1640</a></td><td style="text-align:left">Jumping Motion Generation for Humanoid Robot Using Arm Swing Effectively and Changing in Foot Contact Status</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1641.pdf">1641</a></td><td style="text-align:left">Antipodal Robotic Grasping Using Generative Residual Convolutional Neural Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1645.pdf">1645</a></td><td style="text-align:left">Hindsight for Foresight: Unsupervised Structured Dynamics Models from Physical Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1655.pdf">1655</a></td><td style="text-align:left">Resultant Radius of Curvature of Stylet-And-Tube Steerable Needles Based on the Mechanical Properties of the Soft Tissue, and the Needle</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1657.pdf">1657</a></td><td style="text-align:left">Enhanced Transfer Learning for Autonomous Driving with Systematic Accident Simulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1658.pdf">1658</a></td><td style="text-align:left">Observer-Based Disturbance Control for Small-Scale Collaborative Robotics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1659.pdf">1659</a></td><td style="text-align:left">Anticipating Tumor Metastasis by Circulating Tumor Cells Captured by Acoustic Microstreaming</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1660.pdf">1660</a></td><td style="text-align:left">An Untethered Brittle Star-Inspired Soft Robot for Closed-Loop Underwater Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1662.pdf">1662</a></td><td style="text-align:left">What to Do When You Can’t Do It All: Temporal Logic Planning with Soft Temporal Logic Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1663.pdf">1663</a></td><td style="text-align:left">Dynamics and Aerial Attitude Control for Rapid Emergency Deployment of the Agile Ground Robot AGRO</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1665.pdf">1665</a></td><td style="text-align:left">A Framework for Human-Robot Interaction User Studies</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1671.pdf">1671</a></td><td style="text-align:left">A Mixed-Integer Model Predictive Control Approach to Motion Cueing in Immersive Wheelchair Simulator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1674.pdf">1674</a></td><td style="text-align:left">Self-Sensing Soft Tactile Actuator for Fingertip Interface</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1675.pdf">1675</a></td><td style="text-align:left">Trajectory Tracking of a One-Link Flexible Arm Via Iterative Learning Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1677.pdf">1677</a></td><td style="text-align:left">Contextual Policy Search for Micro-Data Robot Motion Learning through Covariate Gaussian Process Latent Variable Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1678.pdf">1678</a></td><td style="text-align:left">A Framework for Online Updates to Safe Sets for Uncertain Dynamics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1680.pdf">1680</a></td><td style="text-align:left">Contact Force Estimation and Regulation of a Position-Controlled Floating Base System without Joint Torque Information</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1685.pdf">1685</a></td><td style="text-align:left">Going Cognitive: A Demonstration of the Utility of Task-General Cognitive Architectures for Adaptive Robotic Task Performance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1686.pdf">1686</a></td><td style="text-align:left">A Fast and Robust Place Recognition Approach for Stereo Visual Odometry Using LiDAR Descriptors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1689.pdf">1689</a></td><td style="text-align:left">Developing Thermal Endoscope for Endoscopic Photothermal Therapy for Peritoneal Dissemination</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1690.pdf">1690</a></td><td style="text-align:left">Collision-Free Distributed Multi-Target Tracking Using Teams of Mobile Robots with Localization Uncertainty</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1692.pdf">1692</a></td><td style="text-align:left">HouseExpo: A Large-Scale 2D Indoor Layout Dataset for Learning-Based Algorithms on Mobile Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1693.pdf">1693</a></td><td style="text-align:left">ReachFlow: An Online Safety Assurance Framework for Waypoint-Following of Self-Driving Cars</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1694.pdf">1694</a></td><td style="text-align:left">An Untethered Soft Cellular Robot with Variable Volume, Friction, and Unit-To-Unit Cohesion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1695.pdf">1695</a></td><td style="text-align:left">Multi-Robot Task Allocation with Time Window and Ordering Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1696.pdf">1696</a></td><td style="text-align:left">A Distributed Scalar Field Mapping Strategy for Mobile Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1698.pdf">1698</a></td><td style="text-align:left">TORM: Fast and Accurate Trajectory Optimization of Redundant Manipulator Given an End-Effector Path</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1703.pdf">1703</a></td><td style="text-align:left">IAN: Multi-Behavior Navigation Planning for Robots in Real, Crowded Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1706.pdf">1706</a></td><td style="text-align:left">Contact Localization Using Velocity Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1707.pdf">1707</a></td><td style="text-align:left">Tensor Action Spaces for Multi-Agent Robot Transfer Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1709.pdf">1709</a></td><td style="text-align:left">Deep Prediction of Swept Volume Geometries: Robots and Resolutions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1710.pdf">1710</a></td><td style="text-align:left">Collaborative Programming of Conditional Robot Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1711.pdf">1711</a></td><td style="text-align:left">A Whisker-Inspired Fin Sensor for Multi-Directional Airflow Sensing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1716.pdf">1716</a></td><td style="text-align:left">Seed: A Segmentation-Based Egocentric 3D Point Cloud Descriptor for Loop Closure Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1719.pdf">1719</a></td><td style="text-align:left">Multi-Fingered Active Grasp Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1720.pdf">1720</a></td><td style="text-align:left">Extended Performance Guarantees for Receding Horizon Search with Terminal Cost</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1721.pdf">1721</a></td><td style="text-align:left">Robot Learning from Demonstration with Tactile Signals for Geometry-Dependent Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1722.pdf">1722</a></td><td style="text-align:left">F-Siamese Tracker: A Frustum-Based Double Siamese Network for 3D Single Object Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1723.pdf">1723</a></td><td style="text-align:left">QSRNet: Estimating Qualitative Spatial Representations from RGB-D Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1724.pdf">1724</a></td><td style="text-align:left">Interactive Planning and Supervised Execution for High-Risk, High-Latency Teleoperation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1725.pdf">1725</a></td><td style="text-align:left">L1-Adaptive MPPI Architecture for Robust and Agile Control of Multirotors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1726.pdf">1726</a></td><td style="text-align:left">Highly Underactuated Radial Gripper for Automated Planar Grasping and Part Fixturing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1727.pdf">1727</a></td><td style="text-align:left">Localization Uncertainty-Driven Adaptive Framework for Controlling Ground Vehicle Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1728.pdf">1728</a></td><td style="text-align:left">Sim-To-Real with Domain Randomization for Tumbling Robot Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1729.pdf">1729</a></td><td style="text-align:left">Robust, Perception Based Control with Quadrotors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1730.pdf">1730</a></td><td style="text-align:left">Analysis of Contact Stability and Contact Safety of a Robotic Intravascular Cardiac Catheter under Blood Flow Disturbances</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1732.pdf">1732</a></td><td style="text-align:left">Real-Time Multi-SLAM System for Agent Localization and 3D Mapping in Dynamic Scenarios</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1733.pdf">1733</a></td><td style="text-align:left">Deep R-Learning for Continual Area Sweeping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1734.pdf">1734</a></td><td style="text-align:left">Fast Uncertainty Estimation for Deep Learning Based Optical Flow</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1735.pdf">1735</a></td><td style="text-align:left">Global Localization Over 2D Floor Plans with Free-Space Density Based on Depth Information</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1736.pdf">1736</a></td><td style="text-align:left">A Multi-Contact Motion Planning and Control Strategy for Physical Interaction Tasks Using a Humanoid Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1737.pdf">1737</a></td><td style="text-align:left">Soft-Bubble Grippers for Robust and Perceptive Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1738.pdf">1738</a></td><td style="text-align:left">Planning for Robust Visibility-Based Pursuit-Evasion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1741.pdf">1741</a></td><td style="text-align:left">Robot Calligraphy Using Pseudospectral Optimal Controlin Conjunction with a Novel Dynamic Brush Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1743.pdf">1743</a></td><td style="text-align:left">Path Planning under MIMO Network Constraints for Throughput Enhancement in Multi-Robot Data Aggregation Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1744.pdf">1744</a></td><td style="text-align:left">Self-Supervised Neural Audio-Visual Sound Source Localization Via Probabilistic Spatial Modeling</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1745.pdf">1745</a></td><td style="text-align:left">Silicone-Based Capacitive E-Skin for Exteroception and Proprioception</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1746.pdf">1746</a></td><td style="text-align:left">SCAN: System for Camera Autonomous Navigation in Robotic-Assisted Surgery</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1749.pdf">1749</a></td><td style="text-align:left">Flight Control of Sliding Arm Quadcopter with Dynamic Structural Parameters</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1750.pdf">1750</a></td><td style="text-align:left">Domain-Adversarial and -Conditional State Space Model for Imitation Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1752.pdf">1752</a></td><td style="text-align:left">MSDPN: Monocular Depth Prediction with Partial Laser Observation Using Multi-Stage Neural Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1753.pdf">1753</a></td><td style="text-align:left">Optimizing Coordinate Choice for Locomotion Systems with Toroidal Shape Spaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1754.pdf">1754</a></td><td style="text-align:left">DeepURL: Deep Pose Estimation Framework for Underwater Relative Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1755.pdf">1755</a></td><td style="text-align:left">Expert-Emulating Excavation Trajectory Planning for Autonomous Robotic Industrial Excavator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1758.pdf">1758</a></td><td style="text-align:left">Soft Microrobotic Transmissions Enable Rapid Ground-Based Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1762.pdf">1762</a></td><td style="text-align:left">Algorithm for Multi-Robot Chance-Constrained Generalized Assignment Problem with Stochastic Resource Consumption</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1763.pdf">1763</a></td><td style="text-align:left">Game-Theoretic Planning for Risk-Aware Interactive Agents</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1765.pdf">1765</a></td><td style="text-align:left">Demonstration of a Novel Phase Lag Controlled Roll Rotation Mechanism Using a Two-DOF Soft Swimming Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1769.pdf">1769</a></td><td style="text-align:left">Learning to Locomote with Artificial Neural-Network and CPG-Based Control in a Soft Snake Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1771.pdf">1771</a></td><td style="text-align:left">HeatNet: Bridging the Day-Night Domain Gap in Semantic Segmentation with Thermal Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1772.pdf">1772</a></td><td style="text-align:left">Building Plannable Representations with Mixed Reality</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1773.pdf">1773</a></td><td style="text-align:left">Parameter Identification for an Uncooperative Captured Satellite with Spinning Reaction Wheels</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1774.pdf">1774</a></td><td style="text-align:left">Design of a Highly-Maneuverable Pneumatic Soft Actuator Driven by Intrinsic SMA Coils (PneuSMA Actuator)</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1779.pdf">1779</a></td><td style="text-align:left">Collision Reaction Through Internal Stress Loading in Cooperative Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1780.pdf">1780</a></td><td style="text-align:left">Pedestrian Motion Tracking by Using Inertial Sensors on the Smartphone</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1781.pdf">1781</a></td><td style="text-align:left">Blind Bin Picking of Small Screws Through In-finger Manipulation With Compliant Robotic Fingers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1782.pdf">1782</a></td><td style="text-align:left">Data-Driven Distributionally Robust Electric Vehicle Balancing for Mobility-On-Demand Systems under Demand and Supply Uncertainties</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1788.pdf">1788</a></td><td style="text-align:left">A Concept of a Miniaturized MR Clutch Utilizing MR Fluid in Squeeze Mode</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1790.pdf">1790</a></td><td style="text-align:left">Enabling Remote Whole-Body Control with 5G Edge Computing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1793.pdf">1793</a></td><td style="text-align:left">3D Printed Bio-Inspired Hair Sensor for Directional Airflow Sensing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1794.pdf">1794</a></td><td style="text-align:left">Learning to Use Adaptive Motion Primitives in Search-Based Motion Planning for Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1795.pdf">1795</a></td><td style="text-align:left">RadarSLAM: Radar Based Large-Scale SLAM in All Weathers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1799.pdf">1799</a></td><td style="text-align:left">Learning Orientation Distributions for Object Pose Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1804.pdf">1804</a></td><td style="text-align:left">Performance Characterization of an Algorithm to Estimate the Search Skill of a Human or Robot Agent</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1807.pdf">1807</a></td><td style="text-align:left">Learning an Optimal Sampling Distribution for Efficient Motion Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1810.pdf">1810</a></td><td style="text-align:left">Autonomous Navigation and Obstacle Avoidance of a Snake Robot with Combined Velocity-Heading Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1811.pdf">1811</a></td><td style="text-align:left">Quadrotor-Enabled Autonomous Parking Occupancy Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1812.pdf">1812</a></td><td style="text-align:left">The Masked Mapper: Masked Metric Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1813.pdf">1813</a></td><td style="text-align:left">Augmenting Control Policies with Motion Planning for Robust and Safe Multi-Robot Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1814.pdf">1814</a></td><td style="text-align:left">Collaborative Semantic Perception and Relative Localization Based on Map Matching</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1816.pdf">1816</a></td><td style="text-align:left">Weakly-Supervised Learning for Multimodal Human Activity Recognition in Human-Robot Collaboration Scenarios</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1817.pdf">1817</a></td><td style="text-align:left">Sim-To-Real Transfer of Bolting Tasks with Tight Tolerance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1818.pdf">1818</a></td><td style="text-align:left">LiDAR Guided Small Obstacle Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1819.pdf">1819</a></td><td style="text-align:left">Towards Transparent Robotic Planningvia Contrastive Explanations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1820.pdf">1820</a></td><td style="text-align:left">Estimation of Object Class and Orientation from Multiple Viewpoints and Relative Camera Orientation Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1821.pdf">1821</a></td><td style="text-align:left">Information Driven Self-Calibration for Lidar-Inertial Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1822.pdf">1822</a></td><td style="text-align:left">Safe and Effective Picking Paths in Clutter given Discrete Distributions of Object Poses</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1823.pdf">1823</a></td><td style="text-align:left">Shape Reconstruction of CCD Camera-Based Soft Tactile Sensors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1824.pdf">1824</a></td><td style="text-align:left">Allocating Limited Sensing Resources to Accurately Map Dynamic Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1825.pdf">1825</a></td><td style="text-align:left">Robust Micro-Particle Manipulation in a Microfluidic Channel Network Using Gravity-Induced Pressure Actuators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1827.pdf">1827</a></td><td style="text-align:left">The Multi-Material Actuator for Variable Stiffness (MAVS): Design, Modeling, and Characterization of a Soft Actuator for Lateral Ankle Support</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1828.pdf">1828</a></td><td style="text-align:left">Dec-PPCPP: A Decentralized Predator—Prey-Based Approach to Adaptive Coverage Path Planning Amid Moving Obstacles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1830.pdf">1830</a></td><td style="text-align:left">Data-Driven Distributed State Estimation and Behavior Modeling in Sensor Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1833.pdf">1833</a></td><td style="text-align:left">Collision Risk Assessment Via Awareness Estimation Toward Robotic Attendant</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1834.pdf">1834</a></td><td style="text-align:left">Leveraging Multiple Environments for Learning and Decision Making: A Dismantling Use Case</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1836.pdf">1836</a></td><td style="text-align:left">Robust Dynamic State Estimation for Lateral Control of an Industrial Tractor Towing Multiple Passive Trailers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1837.pdf">1837</a></td><td style="text-align:left">Output Only Fault Detection and Mitigation of Networks of Autonomous Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1838.pdf">1838</a></td><td style="text-align:left">Markov Decision Processes with Unknown State Feature Values for Safe Exploration using Gaussian Processes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1839.pdf">1839</a></td><td style="text-align:left">Design and Control of SLIDER: An Ultra-Lightweight, Knee-Less, Low-Cost Bipedal Walking Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1840.pdf">1840</a></td><td style="text-align:left">Learning Bayes Filter Models for Tactile Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1841.pdf">1841</a></td><td style="text-align:left">Occlusion Handling for Industrial Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1844.pdf">1844</a></td><td style="text-align:left">Online BayesSim for Combined Simulator Parameter Inference and Policy Improvement</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1846.pdf">1846</a></td><td style="text-align:left">Roboat II: A Novel Autonomous Surface Vessel for Urban Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1847.pdf">1847</a></td><td style="text-align:left">Human Grasp Classification for Reactive Human-To-Robot Handovers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1851.pdf">1851</a></td><td style="text-align:left">Persistent Connected Power Constrained Surveillance with Unmanned Aerial Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1853.pdf">1853</a></td><td style="text-align:left">Designing A Dummy Skin by Evaluating Contacts between A Human Hand and A Robot End Tip</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1854.pdf">1854</a></td><td style="text-align:left">Making Robots Draw a Vivid Portrait in Two Minutes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1856.pdf">1856</a></td><td style="text-align:left">Unified Calibration for Multi-Camera Mult-LiDAR Systems Using a Single Checkerboard</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1857.pdf">1857</a></td><td style="text-align:left">3D Multi-Object Tracking: A Baseline and New Evaluation Metrics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1858.pdf">1858</a></td><td style="text-align:left">Learning Consistency Pursued Correlation Filters for Real-Time UAV Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1860.pdf">1860</a></td><td style="text-align:left">Multi-Robot Containment and Disablement</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1861.pdf">1861</a></td><td style="text-align:left">Snapbot V2: A Reconfigurable Legged Robot with a Camera for Self Configuration Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1862.pdf">1862</a></td><td style="text-align:left">Stable Crawling Policy for Wearable SuperLimbs Attached to a Human with Tuned Impedance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1864.pdf">1864</a></td><td style="text-align:left">Planning on the fast lane: Learning to interact using attention mechanisms in path integral inverse reinforcement learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1867.pdf">1867</a></td><td style="text-align:left">Identification of a Human Hand Kinematics by Measuring and Merging of Nail-Based Finger Motions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1868.pdf">1868</a></td><td style="text-align:left">Tidying Deep Saliency Prediction Architectures</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1872.pdf">1872</a></td><td style="text-align:left">Deep Reinforcement Learning for Industrial Insertion Tasks with Visual Inputs and Natural Rewards</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1873.pdf">1873</a></td><td style="text-align:left">SideGuide: A Large-Scale Sidewalk Dataset for Guiding Impaired People</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1874.pdf">1874</a></td><td style="text-align:left">Autonomous Multi-Robot Assembly of Solar Array Modules: Experimental Analysis and Insights</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1875.pdf">1875</a></td><td style="text-align:left">Learning Transition Models with Time-Delayed Causal Relations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1876.pdf">1876</a></td><td style="text-align:left">Lyapunov-Based Approach to Reactive Step Generation for Push Recovery of Biped Robots Via Hybrid Tracking Control of DCM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1877.pdf">1877</a></td><td style="text-align:left">Versatile 3D Multi-Sensor Fusion for Lightweight 2D Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1878.pdf">1878</a></td><td style="text-align:left">Efficient Trajectory Library Filtering for Quadrotor Flight in Unknown Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1882.pdf">1882</a></td><td style="text-align:left">Towards General Infeasibility Proofs in Motion Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1884.pdf">1884</a></td><td style="text-align:left">PillarFlow: End-To-End Birds-Eye-View Flow Estimation for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1888.pdf">1888</a></td><td style="text-align:left">Self-Supervised Simultaneous Alignment and Change Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1889.pdf">1889</a></td><td style="text-align:left">Multimodal Sensor Fusion with Differentiable Filters</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1890.pdf">1890</a></td><td style="text-align:left">Multi-Object Rearrangement with Monte Carlo Tree Search: A Case Study on Planar Nonprehensile Sorting</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1891.pdf">1891</a></td><td style="text-align:left">A Robust Multi-Stereo Visual-Inertial Odometry Pipeline</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1893.pdf">1893</a></td><td style="text-align:left">Multimodal Material Classification for Robots Using Spectroscopy and High Resolution Texture Imaging</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1895.pdf">1895</a></td><td style="text-align:left">SplitFlyer: a Modular Quadcoptor that Disassembles into Two Flying Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1897.pdf">1897</a></td><td style="text-align:left">Multi-Agent Safe Planning with Gaussian Processes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1898.pdf">1898</a></td><td style="text-align:left">Exponentially Stabilizing and Time-Varying Virtual Constraint Controllers for Dynamic Quadrupedal Bounding</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1899.pdf">1899</a></td><td style="text-align:left">Vision Global Localization with Semantic Segmentation and Interest Feature Points</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1900.pdf">1900</a></td><td style="text-align:left">An Electrocommunication System Using FSK Modulation and Deep Learning Based Demodulation for Underwater Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1901.pdf">1901</a></td><td style="text-align:left">Online System for Dynamic Multi-contact Motion with Impact Force Based on Contact Wrench Estimation and Current-Based Torque Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1902.pdf">1902</a></td><td style="text-align:left">Learning Constraint-Based Planning Models from Demonstrations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1903.pdf">1903</a></td><td style="text-align:left">Autonomous Vehicle Benchmarking Using Unbiased Metrics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1907.pdf">1907</a></td><td style="text-align:left">Ultrasound-Guided Robotic Navigation with Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1908.pdf">1908</a></td><td style="text-align:left">Gait Training Robot with Intermittent Force Application Based on Prediction of Minimum Toe Clearance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1909.pdf">1909</a></td><td style="text-align:left">Design and Implementation of a Haptic Measurement Glove to Create Realistic Human-Telerobot Interactions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1911.pdf">1911</a></td><td style="text-align:left">Risk-Averse MPC via Visual-Inertial Input and Recurrent Networks for Online Collision Avoidance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1912.pdf">1912</a></td><td style="text-align:left">Data Driven Online Multi-Robot Formation Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1913.pdf">1913</a></td><td style="text-align:left">Learning-Based Distributionally Robust Motion Control with Gaussian Processes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1915.pdf">1915</a></td><td style="text-align:left">Multi-Label Long Short-Term Memory for Construction Vehicle Activity Recognition with Imbalanced Supervision</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1916.pdf">1916</a></td><td style="text-align:left">Deep Mixture Density Network for Probabilistic Object Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1917.pdf">1917</a></td><td style="text-align:left">Human Preference-Based Learning for High-Dimensional Optimization of Exoskeleton Walking Gaits</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1919.pdf">1919</a></td><td style="text-align:left">Online Planning in Uncertain and Dynamic Environment in the Presence of Multiple Mobile Vesicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1920.pdf">1920</a></td><td style="text-align:left">Reliable Chattering-Free Simulation of Friction Torque in Joints Presenting High Stiction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1921.pdf">1921</a></td><td style="text-align:left">Generating Minimum-Snap Quadrotor Trajectories Really Fast</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1922.pdf">1922</a></td><td style="text-align:left">Data-Driven Characterization of Human Interaction for Model-based Control of Powered Prostheses</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1925.pdf">1925</a></td><td style="text-align:left">Development of a Maneuverable Un-Tethered Multi-fin Soft Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1928.pdf">1928</a></td><td style="text-align:left">Choosing Classification Thresholds for Mobile Robot Coverage</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1930.pdf">1930</a></td><td style="text-align:left">Accelerating Bi-Directional Sampling-Based Search for Motion Planning of Non-Holonomic Mobile Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1933.pdf">1933</a></td><td style="text-align:left">Online Configuration Selection for Redundant Arrays of Inertial Sensors: Application to Robotic Systems Covered with a Multimodal Artificial Skin</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1934.pdf">1934</a></td><td style="text-align:left">Synchronous Minimum-Time Cooperative Manipulation Using Distributed Model Predictive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1935.pdf">1935</a></td><td style="text-align:left">Robust Force Tracking Impedance Control of an Ultrasonic Motor-Actuated End-Effector in a Soft Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1936.pdf">1936</a></td><td style="text-align:left">Transferring Experience from Simulation to the Real World for Precise Pick-And-Place Tasks in Highly Cluttered Scenes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1937.pdf">1937</a></td><td style="text-align:left">Uncertainty-aware Self-supervised 3D Data Association</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1941.pdf">1941</a></td><td style="text-align:left">Parts-Based Articulated Object Localization in Clutter Using Belief Propagation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1942.pdf">1942</a></td><td style="text-align:left">Low-Viewpoint Forest Depth Dataset for Sparse Rover Swarms</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1943.pdf">1943</a></td><td style="text-align:left">TrueÃdapt: Learning Smooth Online Trajectory Adaptation with Bounded Jerk, Acceleration and Velocity in Joint Space</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1944.pdf">1944</a></td><td style="text-align:left">Simple Means Faster: Real-Time Human Motion Forecasting in Monocular First Person Videos on CPU</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1947.pdf">1947</a></td><td style="text-align:left">H-Infinity-Optimal Tracking Controller for Three-Wheeled Omnidirectional Mobile Robots with Uncertain Dynamics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1950.pdf">1950</a></td><td style="text-align:left">Construction of Multiple Hepatic Lobule like 3D Vascular Networks by Manipulating Magnetic Tweezers toward Tissue Engineering</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1951.pdf">1951</a></td><td style="text-align:left">Generating Alerts to Assist with Task Assignments in Human-Supervised Multi-Robot Teams Operating in Challenging Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1952.pdf">1952</a></td><td style="text-align:left">Stochastic Grounded Action Transformation for Robot Learning in Simulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1955.pdf">1955</a></td><td style="text-align:left">GP-Based Runtime Planning, Learning, and Recovery for Safe UAV Operations under Unforeseen Disturbances</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1956.pdf">1956</a></td><td style="text-align:left">Fast Global Motion Planning for Dynamic Legged Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1960.pdf">1960</a></td><td style="text-align:left">Development of a Pneumatically Driven Growing Sling to Assist Patient Transfer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1961.pdf">1961</a></td><td style="text-align:left">DIAT (Depth-Infrared Image Annotation Transfer) for Training a Depth-Based Pig-Pose Detector</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1962.pdf">1962</a></td><td style="text-align:left">Towards Autonomous Control of Magnetic Suture Needles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1963.pdf">1963</a></td><td style="text-align:left">Interactive Tactile Perception for Classification of Novel Object Instances</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1964.pdf">1964</a></td><td style="text-align:left">DGAZE: Driver Gaze Mapping on Road</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1965.pdf">1965</a></td><td style="text-align:left">PERCH 2.0 : Fast and Accurate GPU-Based Perception Via Search for Object Pose Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1966.pdf">1966</a></td><td style="text-align:left">Experimental Verification of Vibratory Conveyor System Based on Frequency Entrainment of Limit Cycle Walker</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1968.pdf">1968</a></td><td style="text-align:left">Anticipatory Human-Robot Collaboration Via Multi-Objective Trajectory Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1969.pdf">1969</a></td><td style="text-align:left">Se(3)-TrackNet: Data-Driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic Domains</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1971.pdf">1971</a></td><td style="text-align:left">A Study on the Elongation Behaviour of Synthetic Fibre Ropes under Cyclic Loading</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1972.pdf">1972</a></td><td style="text-align:left">Adaptive Kernel Inference for Dense and Sharp Occupancy Grids</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1976.pdf">1976</a></td><td style="text-align:left">Control Framework for a Hybrid-steel Bridge Inspection Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1979.pdf">1979</a></td><td style="text-align:left">DXSLAM: A Robust and Efficient Visual SLAM System with Deep Features</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1981.pdf">1981</a></td><td style="text-align:left">Online Exploration of Tunnel Networks Leveraging Topological CNN-Based World Predictions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1982.pdf">1982</a></td><td style="text-align:left">Learning Visual Policies for Building 3D Shape Categories</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1984.pdf">1984</a></td><td style="text-align:left">On Screw Linear Interpolation for Point-To-Point Path Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1986.pdf">1986</a></td><td style="text-align:left">Diminished Reality for Close Quarters Robotic Telemanipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1987.pdf">1987</a></td><td style="text-align:left">Encoding Formulas As Deep Networks: Reinforcement Learning for Zero-Shot Execution of LTL Formulas</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1988.pdf">1988</a></td><td style="text-align:left">UWB-Based System for UAV Localization in GNSS-Denied Environments: Characterization and Dataset</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1990.pdf">1990</a></td><td style="text-align:left">Feeling the True Force in Haptic Telepresence for Flying Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1991.pdf">1991</a></td><td style="text-align:left">EAO-SLAM: Monocular Semi-Dense Object SLAM Based on Ensemble Data Association</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1992.pdf">1992</a></td><td style="text-align:left">A Probabilistic Model for Planar Sliding of Objects with Unknown Material Properties: Identification and Robust Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1993.pdf">1993</a></td><td style="text-align:left">A Data-Driven Framework for Proactive Intention-Aware Motion Planning of a Robot in a Human Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1994.pdf">1994</a></td><td style="text-align:left">Adaptive Nonlinear Control for Perching of a Bioinspired Ornithopter</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1997.pdf">1997</a></td><td style="text-align:left">Identification of Effective Motion Primitives for Ground Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1998.pdf">1998</a></td><td style="text-align:left">Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics through Adaptive Neural Network Controller</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/1999.pdf">1999</a></td><td style="text-align:left">Safe Path Planning with Multi-Model Risk Level Sets</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2001.pdf">2001</a></td><td style="text-align:left">Nonlinear Model Predictive Control of Hopping Model Using Approximate Step-To-Step Models for Navigation on Complex Terrain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2002.pdf">2002</a></td><td style="text-align:left">Multi-mode Trajectory Optimization for Impact-aware Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2003.pdf">2003</a></td><td style="text-align:left">Tumbling and Hopping Locomotion Control for a Minor Body Exploration Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2008.pdf">2008</a></td><td style="text-align:left">Predictive Runtime Monitoring of Vehicle Models Using Bayesian Estimation and Reachability Analysis</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2010.pdf">2010</a></td><td style="text-align:left">Learning to Take Good Pictures of People with a Robot Photographer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2012.pdf">2012</a></td><td style="text-align:left">Robust Control Synthesis and Verification for Wire-Borne Underactuated Brachiating Robots Using Sum-of-Squares Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2013.pdf">2013</a></td><td style="text-align:left">Fully Convolutional Geometric Features for Category-Level Object Alignment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2014.pdf">2014</a></td><td style="text-align:left">Sequential Motion Planning for Bipedal Somersault Via Flywheel SLIP and Momentum Transmission with Task Space Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2015.pdf">2015</a></td><td style="text-align:left">Learning User-Preferred Mappings for Intuitive Robot Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2022.pdf">2022</a></td><td style="text-align:left">Object-Aware Centroid Voting for Monocular 3D Object Detection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2023.pdf">2023</a></td><td style="text-align:left">Detection-Aware Trajectory Generation for a Drone Cinematographer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2024.pdf">2024</a></td><td style="text-align:left">Scalable Collaborative Manipulation with Distributed Trajectory Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2025.pdf">2025</a></td><td style="text-align:left">D2VO: Monocular Deep Direct Visual Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2027.pdf">2027</a></td><td style="text-align:left">Task-Motion Planning for Safe and Efficient Urban Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2028.pdf">2028</a></td><td style="text-align:left">PaintPath: Defining Path Directionality in Maps for AutonomousGround Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2029.pdf">2029</a></td><td style="text-align:left">Motion Prediction in Visual Object Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2031.pdf">2031</a></td><td style="text-align:left">Inertia-Decoupled Equations for Hardware-In-The-Loop Simulation of an Orbital Robot with External Forces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2034.pdf">2034</a></td><td style="text-align:left">Integrated Benchmarking and Design for Reproducible and Accessible Evaluation of Robotic Agents</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2036.pdf">2036</a></td><td style="text-align:left">Linear Distributed Clustering Algorithm for Modular Robots Based Programmable Matter</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2038.pdf">2038</a></td><td style="text-align:left">A Compliance Control Method Based on Viscoelastic Model for Position-Controlled Humanoid Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2040.pdf">2040</a></td><td style="text-align:left">Optimization-Based Path Planning for Person Following Using Following Field</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2044.pdf">2044</a></td><td style="text-align:left">Design and Experiments with LoCO AUV: A Low Cost Open-Source Autonomous Underwater Vehicle</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2045.pdf">2045</a></td><td style="text-align:left">Robust Ego and Object 6-DoF Motion Estimation and Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2050.pdf">2050</a></td><td style="text-align:left">Risk-Constrained Motion Planning for Robot Locomotion: Formulation and Running Robot Demonstration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2051.pdf">2051</a></td><td style="text-align:left">The Pluggable Distributed Resource Allocator (PDRA): A Middleware for Distributed Computing in Mobile Robotic Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2057.pdf">2057</a></td><td style="text-align:left">Extrinsic and Temporal Calibration of Automotive Radar and 3D LiDAR</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2061.pdf">2061</a></td><td style="text-align:left">Learning Human-Aware Robot Navigation from Physical Interaction Via Inverse Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2062.pdf">2062</a></td><td style="text-align:left">Learning Optimized Human Motion Via Phase Space Analysis</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2064.pdf">2064</a></td><td style="text-align:left">Gain Scheduled Controller Design for Balancing an Autonomous Bicycle</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2068.pdf">2068</a></td><td style="text-align:left">A Bayesian Approach for Gas Source Localization in Large Indoor Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2076.pdf">2076</a></td><td style="text-align:left">Gripping a Kitchen Knife on the Cutting Board</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2078.pdf">2078</a></td><td style="text-align:left">Bayesian Particles on Cyclic Graphs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2079.pdf">2079</a></td><td style="text-align:left">When We First Met: Visual-Inertial Source Localization for Co-Robot Rendezvous</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2080.pdf">2080</a></td><td style="text-align:left">Wet Adhesion of Micro-Patterned Interfaces for Stable Grasping of Deformable Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2081.pdf">2081</a></td><td style="text-align:left">Exploration Strategy Based on Validity of Actions in Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2082.pdf">2082</a></td><td style="text-align:left">A Compact, Cable-Driven, Activatable Soft Wrist with Six Degrees of Freedom for Assembly Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2083.pdf">2083</a></td><td style="text-align:left">MPC-Graph: Feedback Motion Planning Using Sparse Sampling Based Neighborhood Graph</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2084.pdf">2084</a></td><td style="text-align:left">Maintaining Stable Grasps During Highly Dynamic Robot Trajectories</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2086.pdf">2086</a></td><td style="text-align:left">CMetric: A Driving Behavior Measure Using Centrality Functions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2091.pdf">2091</a></td><td style="text-align:left">Collaborative Interaction Models for Optimized Human Robot Teamwork</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2094.pdf">2094</a></td><td style="text-align:left">Decentralized Safe Reactive Planning under TWTL Specifications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2097.pdf">2097</a></td><td style="text-align:left">Pedestrian Intention Prediction for Autonomous Driving Using a Multiple Stakeholder Perspective Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2098.pdf">2098</a></td><td style="text-align:left">KR-Net: A Dependable Visual Kidnap Recovery Network for Indoor Spaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2103.pdf">2103</a></td><td style="text-align:left">MixGAIL: Autonomous Driving Using Demonstrations with Mixed Qualities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2105.pdf">2105</a></td><td style="text-align:left">An Untethered 216-Mg Insect-Sized Jumping Robot with Wireless Power Transmission</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2106.pdf">2106</a></td><td style="text-align:left">Vacuum Driven Auxetic Switching Structure and Its Application on a Gripper and Quadruped</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2107.pdf">2107</a></td><td style="text-align:left">Geomorphological Analysis Using Unpiloted Aircraft Systems, Structure from Motion, and Deep Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2110.pdf">2110</a></td><td style="text-align:left">The Omega Turn: A Biologically-Inspired Turning Strategy for Elongated Limbless Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2111.pdf">2111</a></td><td style="text-align:left">Getting to Know One Another: Calibrating Intent, Capabilities, and Trust for Human-Robot Collaboration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2112.pdf">2112</a></td><td style="text-align:left">Emergence of Swing-to-Stance Transition from Interlocking Mechanism in Horse Hindlimb</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2113.pdf">2113</a></td><td style="text-align:left">Risk-Aware Planning and Assignment for Ground Vehicles Using Uncertain Perception from Aerial Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2114.pdf">2114</a></td><td style="text-align:left">Robots Made from Ice: An Analysis of Manufacturing Techniques</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2116.pdf">2116</a></td><td style="text-align:left">REFORM: Recognizing F-Formations for Social Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2118.pdf">2118</a></td><td style="text-align:left">Balanced Depth Completion between Dense Depth Inference and Sparse Range Measurements Via KISS-GP</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2119.pdf">2119</a></td><td style="text-align:left">Design and Control of SQUEEZE: A Spring-Augmented QUadrotor for intEractions with the Environment to SqueeZE-And-Fly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2121.pdf">2121</a></td><td style="text-align:left">Decentralized Control Schemes for Stable Quadrupedal Locomotion: A Decomposition Approach from Centralized Controllers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2122.pdf">2122</a></td><td style="text-align:left">Real-Time Robot End-Effector Pose Estimation with Deep Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2124.pdf">2124</a></td><td style="text-align:left">Mobile Robot Localization under Non-Gaussian Noise usingCorrentropy Similarity Metric</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2134.pdf">2134</a></td><td style="text-align:left">Dynamic Object Tracking for Self-Driving Cars Using Monocular Camera and LIDAR</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2137.pdf">2137</a></td><td style="text-align:left">A Novel Endoscope Design Using Spiral Technique for Robotic-Assisted Endoscopy Insertion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2138.pdf">2138</a></td><td style="text-align:left">Driving through Ghosts: Behavioral Cloning with False Positives</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2139.pdf">2139</a></td><td style="text-align:left">Ultra-Wideband Aided UAV Positioning Using Incremental Smoothing with Ranges and Multilateration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2141.pdf">2141</a></td><td style="text-align:left">Autonomous Navigation Over Europa Analogue Terrain for an Actively Articulated Wheel-On-Limb Rover</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2144.pdf">2144</a></td><td style="text-align:left">Kinematic Optimization of an Underactuated Anthropomorphic Prosthetic Hand</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2147.pdf">2147</a></td><td style="text-align:left">Material Mapping in Unknown Environments Using Tapping Sound</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2149.pdf">2149</a></td><td style="text-align:left">Optimizing a Continuum Manipulator’s Search Policy through Model-Free Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2150.pdf">2150</a></td><td style="text-align:left">Active Perception for Outdoor Localisation with an Omnidirectional Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2151.pdf">2151</a></td><td style="text-align:left">Biomimetic Control Scheme for Musculoskeletal Humanoids Based on Motor Directional Tuning in the Brain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2155.pdf">2155</a></td><td style="text-align:left">GPU Parallelization of Policy Iteration RRT#</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2158.pdf">2158</a></td><td style="text-align:left">Spatio-Temporal Attention Model for Tactile Texture Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2162.pdf">2162</a></td><td style="text-align:left">Motion Planning for Collision-resilient Mobile Robots in Obstacle-cluttered Unknown Environments with Risk Reward Trade-offs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2164.pdf">2164</a></td><td style="text-align:left">Learning Topological Motion Primitives for Knot Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2166.pdf">2166</a></td><td style="text-align:left">Semantic Segmentation of Underwater Imagery: Dataset and Benchmark</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2168.pdf">2168</a></td><td style="text-align:left">Go-CHART: A Miniature Remotely Accessible Self-Driving Car Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2170.pdf">2170</a></td><td style="text-align:left">Better Together: Online Probabilistic Clique Change Detection in 3D Landmark-Based Maps</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2172.pdf">2172</a></td><td style="text-align:left">A Multigait Stringy Robot with Bi-Stable Soft-Bodied Structures in Multiple Viscous Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2174.pdf">2174</a></td><td style="text-align:left">A Game-Theoretic Strategy-Aware Interaction Algorithm with Validation on Real Traffic Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2175.pdf">2175</a></td><td style="text-align:left">Towards Cooperative Transport of a Suspended Payload Via Two Aerial Robots with Inertial Sensing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2178.pdf">2178</a></td><td style="text-align:left">An Online Training Method for Augmenting MPC with Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2179.pdf">2179</a></td><td style="text-align:left">Affordance-Based Mobile Robot Navigation among Movable Obstacles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2180.pdf">2180</a></td><td style="text-align:left">Robotic Untangling of Herbs and Salads with Parallel Grippers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2185.pdf">2185</a></td><td style="text-align:left">Target Tracking Control of a Wheel-less Snake Robot Based on a Supervised Multi-layered SNN</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2186.pdf">2186</a></td><td style="text-align:left">Probabilistic Semantic Mapping for Urban Autonomous Driving Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2188.pdf">2188</a></td><td style="text-align:left">Cloth Region Segmentation for Robust Grasp Selection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2189.pdf">2189</a></td><td style="text-align:left">Uncertainty Aware Texture Classification and Mapping Using Soft Tactile Sensors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2193.pdf">2193</a></td><td style="text-align:left">Design and Control of Roller Grasper V2 for In-Hand Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2195.pdf">2195</a></td><td style="text-align:left">Navigation on the Line: Traversability Analysis and Path Planning for Extreme-Terrain Rappelling Rovers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2197.pdf">2197</a></td><td style="text-align:left">Navigation-Assistant Path Planning within a MAV Team</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2199.pdf">2199</a></td><td style="text-align:left">Deep Learning-Based Autonomous Scanning Electron Microscope</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2200.pdf">2200</a></td><td style="text-align:left">Multi-Agent Path Planning under Observation Schedule Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2209.pdf">2209</a></td><td style="text-align:left">Deep Inverse Sensor Models as Priors for evidential Occupancy Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2210.pdf">2210</a></td><td style="text-align:left">Quadrupedal Robotic Walking on Sloped Terrains Via Exact Decomposition into Coupled Bipedal Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2214.pdf">2214</a></td><td style="text-align:left">GelTip: A Finger-Shaped Optical Tactile Sensor for Robotic Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2215.pdf">2215</a></td><td style="text-align:left">PufferBot: Actuated Expandable Structures for Aerial Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2221.pdf">2221</a></td><td style="text-align:left">Skill-based Programming Framework for Composable Reactive Robot Behaviors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2222.pdf">2222</a></td><td style="text-align:left">Multiplicative Controller Fusion: Leveraging Algorithmic Priors for Sample-Efficient Reinforcement Learning and Safe Sim-To-Real Transfer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2223.pdf">2223</a></td><td style="text-align:left">Targetless Calibration of LiDAR-IMU System Based on Continuous-Time Batch Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2224.pdf">2224</a></td><td style="text-align:left">A Distributed Range-Only Collision Avoidance Approach for Low-Cost Large-Scale Multi-Robot Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2225.pdf">2225</a></td><td style="text-align:left">Localization Safety Validation for Autonomous Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2227.pdf">2227</a></td><td style="text-align:left">Design and Evaluation of a Perching Hexacopter Drone for Energy Harvesting from Power Lines</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2228.pdf">2228</a></td><td style="text-align:left">From Human to Robot Everyday Activity</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2232.pdf">2232</a></td><td style="text-align:left">Dynamic Legged Manipulation of a Ball through Multi-Contact Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2235.pdf">2235</a></td><td style="text-align:left">A Geometric Perspective on Visual Imitation Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2236.pdf">2236</a></td><td style="text-align:left">Robust Autonomous Navigation of a Small-Scale Quadruped Robot in Real-World Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2240.pdf">2240</a></td><td style="text-align:left">The Personalization of Stiffness for an Ankle-Foot Prosthesis Emulator Using Human-In-The-Loop Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2243.pdf">2243</a></td><td style="text-align:left">Development of Selective Driving Joint Forceps Using Shape Memory Polymer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2246.pdf">2246</a></td><td style="text-align:left">ProxEmo: Gait-Based Emotion Learning andMulti-View Proxemic Fusion for Socially-Aware Robot Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2250.pdf">2250</a></td><td style="text-align:left">Adaptive Dynamic Window Approach for Local Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2253.pdf">2253</a></td><td style="text-align:left">A Tip Mount for Transporting Sensors and Tools Using Soft Growing Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2255.pdf">2255</a></td><td style="text-align:left">With Whom to Communicate: Learning Efficient Communication for Multi-Robot Collision Avoidance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2256.pdf">2256</a></td><td style="text-align:left">PBP-Net: Point Projection and Back-Projection Network for 3D Point Cloud Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2262.pdf">2262</a></td><td style="text-align:left">The Importance of Prior Knowledge in Precise Multimodal Prediction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2264.pdf">2264</a></td><td style="text-align:left">Learning Skills to Patch Plans Based on Inaccurate Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2265.pdf">2265</a></td><td style="text-align:left">Cooperative Control of Mobile Robots with Stackelberg Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2268.pdf">2268</a></td><td style="text-align:left">Design and Experimentation of a Variable Stiffness Bistable Gripper</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2269.pdf">2269</a></td><td style="text-align:left">Expedited Multi-Target Search with Guaranteed Performance Via Multi-Fidelity Gaussian Processes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2270.pdf">2270</a></td><td style="text-align:left">MVLidarNet: Real-Time Multi-Class Scene Understanding for Autonomous Driving Using Multiple Views</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2271.pdf">2271</a></td><td style="text-align:left">Towards RL-Based Hydraulic Excavator Automation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2274.pdf">2274</a></td><td style="text-align:left">Development and Analysis of Digging and Soil Removing Mechanisms for Mole-Bot: Bio-Inspired Mole-Like Drilling Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2275.pdf">2275</a></td><td style="text-align:left">Explore Bravely: Wheeled-Legged Robots Traversing in Unknown Rough Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2276.pdf">2276</a></td><td style="text-align:left">BRM Localization: UAV Localization in GNSS-Denied Environments Based on Matching of Numerical Map and UAV Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2277.pdf">2277</a></td><td style="text-align:left">Minimally Disruptive Connectivity Enhancement for Resilient Multi-Robot Teams</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2278.pdf">2278</a></td><td style="text-align:left">Multi-Modal Pneumatic Actuator for Twisting, Extension, and Bending</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2280.pdf">2280</a></td><td style="text-align:left">Whole-Game Motion Capturing of Team Sports: System Architecture and Integrated Calibration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2281.pdf">2281</a></td><td style="text-align:left">Simultaneous Position-Stiffness Control of Antagonistically Driven Twisted-Coiled Polymer Actuators Using Model Predictive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2282.pdf">2282</a></td><td style="text-align:left">Data-Driven Models with Expert Influence: A Hybrid Approach to Spatiotemporal Process Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2285.pdf">2285</a></td><td style="text-align:left">Meta-Reinforcement Learning for Robotic Industrial Insertion Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2286.pdf">2286</a></td><td style="text-align:left">Stochastic Neural Control Using Raw Pointcloud Data and Building Information Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2287.pdf">2287</a></td><td style="text-align:left">TT-TSDF: Memory-Efficient TSDF with Low-Rank Tensor Train Decomposition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2290.pdf">2290</a></td><td style="text-align:left">HAMLET: A Hierarchical Multimodal Attention-Based Human Activity Recognition Algorithm</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2291.pdf">2291</a></td><td style="text-align:left">Dielecrophoretic Introduction of the Membrane Proteins into the BLM Platforms for the Electrophygiological Analysis Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2292.pdf">2292</a></td><td style="text-align:left">Knuckles That Buckle: Compliant Underactuated Limbs with Joint Hysteresis Enable Minimalist Terrestrial Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2293.pdf">2293</a></td><td style="text-align:left">Path Negotiation for Self-Interested Multirobot Vehicles in Shared Space</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2295.pdf">2295</a></td><td style="text-align:left">Dynamically Constrained Motion Planning Networks for Non-Holonomic Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2297.pdf">2297</a></td><td style="text-align:left">3DMotion-Net: Learning Continuous Flow Function for 3D MotionPrediction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2298.pdf">2298</a></td><td style="text-align:left">Sparse Discrete Communication Learning for Multi-Agent Cooperation through Backpropagation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2301.pdf">2301</a></td><td style="text-align:left">Simultaneous Trajectory Optimization and Force Control with Soft Contact Mechanics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2304.pdf">2304</a></td><td style="text-align:left">GP-SLAM+: Real-Time 3D Lidar SLAM Based on Improved Regionalized Gaussian Process Map Reconstruction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2307.pdf">2307</a></td><td style="text-align:left">Impedance Control of Humanoid Walking on Uneven Terrain with Centroidal Momentum Dynamics Using Quadratic Programming</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2309.pdf">2309</a></td><td style="text-align:left">CAZSL: Zero-Shot Regression for Pushing Models by Generalizing through Context</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2313.pdf">2313</a></td><td style="text-align:left">Objective Functions for Principal Contact Estimation from Motion Based on the Geometrical Singular Condition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2314.pdf">2314</a></td><td style="text-align:left">Autonomous Spot: Long-Range Autonomous Exploration of Extreme Environments with Legged Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2315.pdf">2315</a></td><td style="text-align:left">Fast Texture Classification Using Tactile Neural Coding and Spiking Neural Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2318.pdf">2318</a></td><td style="text-align:left">City-Scale Grid-Topological Hybrid Maps for Autonomous Mobile Robot Navigation in Urban Area</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2324.pdf">2324</a></td><td style="text-align:left">Inspection-On-The-Fly Using Hybrid Physical Interaction Control for Aerial Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2325.pdf">2325</a></td><td style="text-align:left">Real-Time Constrained Nonlinear Model Predictive Control on SO(3) for Dynamic Legged Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2333.pdf">2333</a></td><td style="text-align:left">Telemanipulation with Chopsticks: Analyzing Human Factors in User Demonstrations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2334.pdf">2334</a></td><td style="text-align:left">Three-Dimensional Posture Optimization for Biped Robot Stepping Over Large Ditch Based on a Ducted-Fan Propulsion System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2342.pdf">2342</a></td><td style="text-align:left">STORM: Screw Theory Toolbox for Robot Manipulator and Mechanisms</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2349.pdf">2349</a></td><td style="text-align:left">Development of Deployable Bending Wrist for Minimally Invasive Laparoscopic Endoscope</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2353.pdf">2353</a></td><td style="text-align:left">Predictive Control of Connected Mixed Traffic under Random Communication Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2357.pdf">2357</a></td><td style="text-align:left">Real-time Virtual Coach using LSTM for Assisting Physical Therapists with End-effector-based Robot-assisted Gait Training</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2358.pdf">2358</a></td><td style="text-align:left">Decentralized Deep Reinforcement Learning for a Distributed and Adaptive Locomotion Controller of a Hexapod Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2359.pdf">2359</a></td><td style="text-align:left">Adaptive Informative Sampling with Environment Partitioning for Heterogeneous Multi-Robot Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2362.pdf">2362</a></td><td style="text-align:left">Animated Cassie: A Dynamic Relatable Robotic Character</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2370.pdf">2370</a></td><td style="text-align:left">Steering Magnetic Robots in Two Axes with One Pair of Maxwell Coils</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2443.pdf">2443</a></td><td style="text-align:left">Estimation and Control of Motor Core Temperature with Online Learning of Thermal Model Parameters: Application to Musculoskeletal Humanoids</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2447.pdf">2447</a></td><td style="text-align:left">Design and Modelling of a Minimally Actuated Serial Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2448.pdf">2448</a></td><td style="text-align:left">A Passivity-Shortage Based Control Framework for Teleoperation with Time-Varying Delays</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2450.pdf">2450</a></td><td style="text-align:left">Improved FBG-Based Shape Sensing Methods for Vascular Catheterization Treatment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2455.pdf">2455</a></td><td style="text-align:left">Energy-Efficient Locomotion Generation and Theoretical Analysis of a Quasi-Passive Dynamic Walker</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2459.pdf">2459</a></td><td style="text-align:left">Online Visual Place Recognition Via Saliency Re-Identification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2460.pdf">2460</a></td><td style="text-align:left">2D Laser SLAM with General Features Represented by Implicit Functions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2465.pdf">2465</a></td><td style="text-align:left">Incorporating Object Intrinsic Features within Deep Grasp Affordance Prediction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2467.pdf">2467</a></td><td style="text-align:left">Extremum Seeking Control for Stiffness Auto-Tuning of a Quasi-Passive Ankle Exoskeleton</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2473.pdf">2473</a></td><td style="text-align:left">50 Benchmarks for Anthropomorphic Hand Function-Based Dexterity Classification and Kinematics-Based Hand Design</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2474.pdf">2474</a></td><td style="text-align:left">Risk-Aware Motion Planning for a Limbed Robot with Stochastic Gripping Forces Using Nonlinear Programming</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2477.pdf">2477</a></td><td style="text-align:left">A Flexible Robotic Depalletizing System for Supermarket Logistics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2480.pdf">2480</a></td><td style="text-align:left">Next-Best-Sense: a multi-criteria robotic exploration strategy for RFID tags discovery</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2481.pdf">2481</a></td><td style="text-align:left">3D-Aware Scene Change Captioning from Multiview Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2483.pdf">2483</a></td><td style="text-align:left">AMAE: Adaptive Motion-Agnostic Encoder for Event-Based Object Classification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2485.pdf">2485</a></td><td style="text-align:left">Meta-Learning Deep Visual Words for Fast Video Object Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2487.pdf">2487</a></td><td style="text-align:left">Reactive Semantic Planning in Unexplored Semantic Environments Using Deep Perceptual Feedback</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2490.pdf">2490</a></td><td style="text-align:left">Semantic Localization Considering Uncertainty of Object Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2491.pdf">2491</a></td><td style="text-align:left">Perspective-2-Ellipsoid: Bridging the Gap between Object Detections and 6-DoF Camera Pose</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2494.pdf">2494</a></td><td style="text-align:left">A Point Cloud Registration Pipeline Using Gaussian Process Regression for Bathymetric SLAM</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2495.pdf">2495</a></td><td style="text-align:left">Collaborative Mission Planning for Long-Term Operation Considering Energy Limitations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2496.pdf">2496</a></td><td style="text-align:left">Fast Tennis Swing Motion by Ball Trajectory Prediction and Joint Trajectory Modification in Standalone Humanoid Robot Real-Time System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2497.pdf">2497</a></td><td style="text-align:left">Feedback Whole-Body Control of Wheeled Inverted Pendulum Humanoids Using Operational Space</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2501.pdf">2501</a></td><td style="text-align:left">Intermittent Insertion Control Method with Fine Needle for Adapting Lung Deformation Due to Breathing Motion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2504.pdf">2504</a></td><td style="text-align:left">Object Recognition, Dynamic Contact Simulation, Detection, and Control of the Flexible Musculoskeletal Hand Using a Recurrent Neural Network with Parametric Bias</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2505.pdf">2505</a></td><td style="text-align:left">A Reconfigurable Gripper for Robotic Autonomous Depalletizing in Supermarket Logistics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2506.pdf">2506</a></td><td style="text-align:left">Snatcher: A Highly Mobile Chameleon-Inspired Shooting and Rapidly Retracting Manipulator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2509.pdf">2509</a></td><td style="text-align:left">Hybrid Force-Moment Braking Pulse: A Haptic Illusion to Increase the Perceived Hardness of Virtual Surfaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2512.pdf">2512</a></td><td style="text-align:left">A Multi-Link In-Pipe Inspection Robot Composed of Active and Passive Compliant Joints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2514.pdf">2514</a></td><td style="text-align:left">Learning Scheduling Policies for Multi-Robot Coordination with Graph Attention Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2515.pdf">2515</a></td><td style="text-align:left">Probabilistic Crowd GAN: Multimodal Pedestrian Trajectory Prediction Using a Graph Vehicle-Pedestrian Attention Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2516.pdf">2516</a></td><td style="text-align:left">DiversityGAN: Diversity-Aware Vehicle Motion Prediction Via Latent Semantic Sampling</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2517.pdf">2517</a></td><td style="text-align:left">Experience-Based Prediction of Unknown Environments for Enhanced Belief Space Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2520.pdf">2520</a></td><td style="text-align:left">Forecasting Trajectory and Behavior of Road-Agents Using Spectral Clustering in Graph-LSTMs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2522.pdf">2522</a></td><td style="text-align:left">Efficient Sampling-Based Maximum Entropy Inverse Reinforcement Learning with Application to Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2525.pdf">2525</a></td><td style="text-align:left">Delta Descriptors: Change-Based Place Representation for Robust Visual Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2526.pdf">2526</a></td><td style="text-align:left">The Invariant Rauch-Tung-Striebel Smoother</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2527.pdf">2527</a></td><td style="text-align:left">New Formulation of Mixed-Integer Conic Programming for Globally Optimal Grasp Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2528.pdf">2528</a></td><td style="text-align:left">Probabilistic Approach to Physical Object Disentangling</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2529.pdf">2529</a></td><td style="text-align:left">Drift-Free and Self-Aligned IMU-Based Human Gait Tracking System with Augmented Precision and Robustness</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2531.pdf">2531</a></td><td style="text-align:left">Cross-View Semantic Segmentation for Sensing Surroundings</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2532.pdf">2532</a></td><td style="text-align:left">Deep Context Maps: Agent Trajectory Prediction using Location-specific Latent Maps</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2533.pdf">2533</a></td><td style="text-align:left">Distributed Consistent Multi-Robot Semantic Localization and Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2537.pdf">2537</a></td><td style="text-align:left">Segmenting the Future</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2541.pdf">2541</a></td><td style="text-align:left">Task Priority Matrix at the Acceleration Level: Collision Avoidance under Relaxed Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2542.pdf">2542</a></td><td style="text-align:left">An Algorithm to Design Redundant Manipulators of Optimally Fault-Tolerant Kinematic Structure</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2544.pdf">2544</a></td><td style="text-align:left">Energy Management through Footstep Selection for Bipedal Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2545.pdf">2545</a></td><td style="text-align:left">Exploring the Role of Palm Concavity and Adaptability in Soft Synergistic Robotic Hands</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2546.pdf">2546</a></td><td style="text-align:left">Deep Learning Based Real-Time OCT Image Segmentation and Correction for Robotic Needle Insertion Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2548.pdf">2548</a></td><td style="text-align:left">PrimA6D: Rotational Primitive Reconstruction for Enhanced and Robust 6D Pose Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2549.pdf">2549</a></td><td style="text-align:left">Estimating an Object’s Inertial Parameters by Robotic Pushing: A Data-Driven Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2550.pdf">2550</a></td><td style="text-align:left">A Variable-Structure Robot Hand That Uses the Environment to Achieve General Purpose Grasps</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2552.pdf">2552</a></td><td style="text-align:left">Development of a Spherical 2-DOF Wrist Employing Spatial Parallelogram Structure</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2553.pdf">2553</a></td><td style="text-align:left">Milliscale Features Increase Friction of Soft Skin in Lubricated Contact</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2554.pdf">2554</a></td><td style="text-align:left">Self-supervised Learning for Precise Pick-and-place without Object Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2555.pdf">2555</a></td><td style="text-align:left">The Mag-Gripper: A Soft-Rigid Gripper Augmented with an Electromagnet to Precisely Handle Clothes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2556.pdf">2556</a></td><td style="text-align:left">HDR Reconstruction Based on the Polarization Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2561.pdf">2561</a></td><td style="text-align:left">Seeing through the Occluders: Robust Monocular 6-DOF Object Pose Tracking Via Model-Guided Video Object Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2562.pdf">2562</a></td><td style="text-align:left">Robust Robotic Pouring Using Audition and Haptics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2564.pdf">2564</a></td><td style="text-align:left">Active Vertical Takeoff of an Aquatic UAV</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2565.pdf">2565</a></td><td style="text-align:left">Lightweight High Voltage Generator for Untethered Electroadhesive Perching of Micro Air Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2567.pdf">2567</a></td><td style="text-align:left">Alternating Minimization Based Trajectory Generation for Quadrotor Aggressive Flight</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2570.pdf">2570</a></td><td style="text-align:left">Delicate Fabric Handling Using a Soft Robotic Gripper with Embedded Microneedles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2571.pdf">2571</a></td><td style="text-align:left">SplitFusion: Simultaneous Tracking and Mapping for Non-Rigid Scenes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2572.pdf">2572</a></td><td style="text-align:left">Object-Based Pose Graph for Dynamic Indoor Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2574.pdf">2574</a></td><td style="text-align:left">Asynchronous Adaptive Sampling and Reduced-Order Modeling of Dynamic Processes by Robot Teams Via Intermittently Connected Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2575.pdf">2575</a></td><td style="text-align:left">Multi-UAV Surveillance with Minimum Information Idleness and Latency Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2576.pdf">2576</a></td><td style="text-align:left">An Electrostatic/Gecko-Inspired Adhesives Soft Robotic Gripper</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2577.pdf">2577</a></td><td style="text-align:left">EGAD! an Evolved Grasping Analysis Dataset for Diversity and Reproducibility in Robotic Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2578.pdf">2578</a></td><td style="text-align:left">Deep Gated Multi-Modal Learning: In-hand Object Pose Changes Estimation using Tactile and Image Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2580.pdf">2580</a></td><td style="text-align:left">In-flight Efficient Controller Auto-tuning using a Pair of UAVs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2581.pdf">2581</a></td><td style="text-align:left">Development  and  Evaluation  of  a  Linear  Series  Clutch  Actuator for  Vertical  Joint  Application  with  Static  Balancing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2582.pdf">2582</a></td><td style="text-align:left">Shift-Adaptive Estimation of Joint Angle Using Instrumented Brace With Two Stretch Sensors Based on Gaussian Mixture Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2585.pdf">2585</a></td><td style="text-align:left">Rectangular Pyramid Partitioning Using Integrated Depth Sensors (RAPPIDS): A Fast Planner for Multicopter Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2587.pdf">2587</a></td><td style="text-align:left">Learning Motion Parameterizations of Mobile Pick and Place Actions from Observing Humans in Virtual Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2588.pdf">2588</a></td><td style="text-align:left">Contact-Implicit Trajectory Optimization using an Analytically Solvable Contact Model for Locomotion on Variable Ground</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2589.pdf">2589</a></td><td style="text-align:left">Minor Change, Major Gains: The Effect of Orientation Formulation on Solving Time for Multi-Body Trajectory Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2590.pdf">2590</a></td><td style="text-align:left">Vehicle-In-The-Loop Framework for Testing Long-Term Autonomy in a Heterogeneous Marine Robot Swarm</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2591.pdf">2591</a></td><td style="text-align:left">A Versatile Gripper for Cloth Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2594.pdf">2594</a></td><td style="text-align:left">Task-driven Perception and Manipulation for Constrained Placement of Unknown Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2597.pdf">2597</a></td><td style="text-align:left">Inertial Velocity Estimation for Indoor Navigation through Magnetic Gradient-Based EKF and LSTM Learning Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2598.pdf">2598</a></td><td style="text-align:left">Wireless Soft Actuator Based on Liquid-Gas Phase Transition Controlled by Millimeter-Wave Irradiation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2599.pdf">2599</a></td><td style="text-align:left">C*: Cross-Modal Simultaneous Tracking and Rendering for 6-DoF Monocular Camera Localization Beyond Modalities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2600.pdf">2600</a></td><td style="text-align:left">Accurate estimation of the position and shape of the rolling joint in hyper-redundant manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2601.pdf">2601</a></td><td style="text-align:left">Contact Point Estimation Along Air Tube Based on Acoustic Sensing of Pneumatic System Noise</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2602.pdf">2602</a></td><td style="text-align:left">Footstep Modification Including Step Time and Angular Momentum Under Disturbances on Sparse Footholds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2606.pdf">2606</a></td><td style="text-align:left">Coupled Task-Space Admittance Controller Using Dual Quaternion Logarithmic Mapping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2608.pdf">2608</a></td><td style="text-align:left">A Framework for Recognition and Prediction of Human Motions in Human-Robot Collaboration Using Probabilistic Motion Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2610.pdf">2610</a></td><td style="text-align:left">Swarm Relays: Distributed Self-Healing Ground-And-Air Connectivity Chains</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2611.pdf">2611</a></td><td style="text-align:left">Learning Depth with Very Sparse Supervision</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2614.pdf">2614</a></td><td style="text-align:left">Improving Multirotor Landing Performance on Inclined Surfaces Using Reverse Thrust</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2616.pdf">2616</a></td><td style="text-align:left">A Tendon-Driven Robot Gripper with Passively Switchable Underactuated Surface and Its Physics Simulation Based Parameter Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2618.pdf">2618</a></td><td style="text-align:left">Point Cloud Projective Analysis for Part-based Grasp Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2621.pdf">2621</a></td><td style="text-align:left">The ARCHES Space-Analogue Demonstration Mission: Towards Heterogeneous Teams of Autonomous Robots for Collaborative Scientific Sampling in Planetary Exploration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2624.pdf">2624</a></td><td style="text-align:left">Terrain-Aware Path Planning and Map Update for Mars Sample Return Mission</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2626.pdf">2626</a></td><td style="text-align:left">Modeling and Experimental Verification of a Cable-Constrained Synchronous Rotating Mechanism Considering Friction Effect</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2627.pdf">2627</a></td><td style="text-align:left">MILiMAC: Flexible Catheter with Miniaturized Electromagnets As a Small-Footprint System for Microrobotic Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2628.pdf">2628</a></td><td style="text-align:left">Design, Modeling, and Control of a Coaxially Aligned Steerable (COAST) Guidewire Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2630.pdf">2630</a></td><td style="text-align:left">Subject-Independent sEMG Pattern Recognition by Using a Muscle Source Activation Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2631.pdf">2631</a></td><td style="text-align:left">Optimal Pose Estimation Method for a Multi-Segment, Programmable Bevel-Tip Steerable Needle</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2632.pdf">2632</a></td><td style="text-align:left">Payload Optimization of Surgical Instruments with Rolling Joint Mechanisms</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2634.pdf">2634</a></td><td style="text-align:left">A Supernumerary Robotic Leg Powered by Magnetorheological Actuators to Assist Human Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2636.pdf">2636</a></td><td style="text-align:left">IMU-Based Locomotor Intention Prediction for Real-Time Use in Transfemoral Prostheses</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2639.pdf">2639</a></td><td style="text-align:left">Modeling, Calibration, and Evaluation of a Tendon-Actuated Planar Parallel Continuum Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2641.pdf">2641</a></td><td style="text-align:left">Pauses Provide Effective Control for an Underactuated Oscillating Swimming Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2642.pdf">2642</a></td><td style="text-align:left">Optimal Linearization via Quadratic Programming</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2644.pdf">2644</a></td><td style="text-align:left">Hybrid Systems Differential Dynamic Programming for Whole-Body Motion Planning of Legged Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2647.pdf">2647</a></td><td style="text-align:left">Denoising IMU Gyroscopes with Deep Learning for Open-Loop Attitude Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2648.pdf">2648</a></td><td style="text-align:left">Towards Real-Time Non-Gaussian SLAM for Underdetermined Navigation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2651.pdf">2651</a></td><td style="text-align:left">Comparing Visual Odometry Systems in Actively Deforming Simulated Colon Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2652.pdf">2652</a></td><td style="text-align:left">Variational Inference with Parameter Learning Applied to Vehicle Trajectory Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2653.pdf">2653</a></td><td style="text-align:left">Towards in Situ Backlash Estimation of Continuum Robots Using an Endoscopic Camera</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2654.pdf">2654</a></td><td style="text-align:left">Evolved Neuromorphic Control for High Speed Divergence-Based Landings of MAVs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2655.pdf">2655</a></td><td style="text-align:left">Energy-Based Cooperative Control for Landing Fixed-Wing UAVs on Mobile Platforms under Communication Delays</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2656.pdf">2656</a></td><td style="text-align:left">Staging Energy Sources to Extend Flight Time of a Multirotor UAV</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2657.pdf">2657</a></td><td style="text-align:left">Dense Isometric Non-Rigid Shape-From-Motion Based on Graph Optimization and Edge Selection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2666.pdf">2666</a></td><td style="text-align:left">Multimodal Teleoperation of Heterogeneous Robots within a Construction Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2669.pdf">2669</a></td><td style="text-align:left">A Manipulability Criterion for Magnetic Actuation of Miniature Swimmers with Flexible Flagellum</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2670.pdf">2670</a></td><td style="text-align:left">Towards the Long-Endurance Flight of an Insect-Inspired, Tailless, Two-Winged, Flapping-Wing Flying Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2672.pdf">2672</a></td><td style="text-align:left">Design of the uMAZE Platform and Microrobots for Independent Control and Micromanipulation Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2673.pdf">2673</a></td><td style="text-align:left">GLAS: Global-To-Local Safe Autonomy Synthesis for Multi-Robot Motion Planning with End-To-End Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2674.pdf">2674</a></td><td style="text-align:left">Multi-Robot Coordinated Planning in Confined Environments under Kinematic Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2675.pdf">2675</a></td><td style="text-align:left">Evaluations of response characteristics of on-chip gel actuators for various single cell manipulations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2686.pdf">2686</a></td><td style="text-align:left">Perception-Aware Human-Assisted Navigation of Mobile Robots on Persistent Trajectories</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2687.pdf">2687</a></td><td style="text-align:left">Development of Smartphone-Based Human-Robot Interfaces for Individuals with Disabilities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2688.pdf">2688</a></td><td style="text-align:left">Autonomous and Cooperative Design of the Monitor Positions for a Team of UAVs to Maximize the Quantity and Quality of Detected Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2691.pdf">2691</a></td><td style="text-align:left">Discontinuous and Smooth Depth Completion with Binary Anisotropic Diffusion Tensor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2692.pdf">2692</a></td><td style="text-align:left">Integrating Features Acceleration in Visual Predictive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2693.pdf">2693</a></td><td style="text-align:left">Spatiotemporal Calibration of Camera and 3D Laser Scanner</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2696.pdf">2696</a></td><td style="text-align:left">Towards In-Flight Transfer of Payloads between Multirotors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2699.pdf">2699</a></td><td style="text-align:left">Coverage Path Planning with Track Spacing Adaptation for Autonomous Underwater Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2700.pdf">2700</a></td><td style="text-align:left">Force-Ultrasound Fusion: Bringing Spine Robotic-US to the Next ‘Level’</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2702.pdf">2702</a></td><td style="text-align:left">Ultrasound-Guided Wireless Tubular Robotic Anchoring System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2704.pdf">2704</a></td><td style="text-align:left">Optic Nerve Sheath Fenestration with a Multi-Arm Continuum Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2707.pdf">2707</a></td><td style="text-align:left">Automatic Shape Control of Deformable Wires Based on Model-Free Visual Servoing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2708.pdf">2708</a></td><td style="text-align:left">Image Transformation and CNNs: A Strategy for Encoding Human Locomotor Intent for Autonomous Wearable Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2711.pdf">2711</a></td><td style="text-align:left">An Augmented Reality Spatial Referencing System for Mobile Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2712.pdf">2712</a></td><td style="text-align:left">Proxy-Based Approach for Position Synchronization of Delayed Robot Coupling without Sacrificing Performance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2713.pdf">2713</a></td><td style="text-align:left">A Multi-Channel Reinforcement Learning Framework for Robotic Mirror Therapy</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2714.pdf">2714</a></td><td style="text-align:left">A New Delayless Adaptive Oscillator for Gait Assistance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2715.pdf">2715</a></td><td style="text-align:left">Adaptive Precision-Enhancing Hand Rendering for Wearable Fingertip Tracking Devices</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2717.pdf">2717</a></td><td style="text-align:left">The 6-DoF Implementation of the Energy-Reflection Based Time Domain Passivity Approach with Preservation of Physical Coupling Behavior</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2718.pdf">2718</a></td><td style="text-align:left">Development of Exo-Glove for Measuring 3-Axis Forces Acting on the Human Finger without Obstructing Natural Human-Object Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2720.pdf">2720</a></td><td style="text-align:left">Detection and Control of Air Liquid Interface With an Open-Channel Microfluidic Chip for Circulating Tumor Cells Isolation From Human Whole Blood</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2721.pdf">2721</a></td><td style="text-align:left">Probabilistic End-to-End Vehicle Navigation in Complex Dynamic Environments with Multimodal Sensor Fusion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2722.pdf">2722</a></td><td style="text-align:left">MEDUSA: A Multi-Environment Dual-Robot for Underwater Sample Acquisition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2728.pdf">2728</a></td><td style="text-align:left">Perpendicular Curve-Based Incomplete Orientation Mapping for Teleoperation with DOF Asymmetry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2731.pdf">2731</a></td><td style="text-align:left">A Distributed Pipeline for Scalable, Deconflicted Formation Flying</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2732.pdf">2732</a></td><td style="text-align:left">RILaaS: Robot Inference and Learning As a Service</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2733.pdf">2733</a></td><td style="text-align:left">Pac-Man Is Overkill</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2734.pdf">2734</a></td><td style="text-align:left">Energy Autonomy for Resource-Constrained Multi Robot Missions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2736.pdf">2736</a></td><td style="text-align:left">Stable Flight of a Flapping-Wing Micro Air Vehicle under Wind Disturbance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2737.pdf">2737</a></td><td style="text-align:left">SMALLBug: A 30-mg Crawling Robot Driven by a High-Frequency Flexible SMA Microactuator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2739.pdf">2739</a></td><td style="text-align:left">Knowledge Transfer between Different UAVs for Trajectory Tracking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2740.pdf">2740</a></td><td style="text-align:left">A Morphing Cargo Drone for Safe Flight in Proximity of Humans</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2741.pdf">2741</a></td><td style="text-align:left">Edge Enhanced Implicit Orientation Learning with Geometric Prior for 6D Pose Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2743.pdf">2743</a></td><td style="text-align:left">Development of Hiryu-II: A Long-Reach Articulated Modular Manipulator Driven by Thrusters</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2746.pdf">2746</a></td><td style="text-align:left">Loop-Net: Joint Unsupervised Disparity and Optical Flow Estimation of Stereo Videos with Spatiotemporal Loop Consistency</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2748.pdf">2748</a></td><td style="text-align:left">Real-Time Fusion Network for RGB-D Semantic Segmentation Incorporating Unexpected Obstacle Detection for Road-Driving Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2749.pdf">2749</a></td><td style="text-align:left">Game Theoretic Formation Design for Probabilistic Barrier Coverage</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2750.pdf">2750</a></td><td style="text-align:left">Dual-Arm Control for Enhanced Magnetic Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2751.pdf">2751</a></td><td style="text-align:left">Defensive Escort Teams for Navigation in Crowds Via Multi-Agent Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2753.pdf">2753</a></td><td style="text-align:left">A Novel Coding Architecture for LiDAR Point Cloud Sequence</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2754.pdf">2754</a></td><td style="text-align:left">Time-Relative RTK-GNSS: GNSS Loop Closure in Pose Graph Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2758.pdf">2758</a></td><td style="text-align:left">ROVINS: Robust Omnidirectional Visual Inertial Navigation System</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2759.pdf">2759</a></td><td style="text-align:left">Dynamic and Versatile Humanoid Walking Via Embedding 3D Actuated SLIP Model with Hybrid LIP Based Stepping</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2760.pdf">2760</a></td><td style="text-align:left">Non-Linear Trajectory Optimization for Large Step-Ups: Application to the Humanoid Robot Atlas</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2762.pdf">2762</a></td><td style="text-align:left">SilhoNet-Fisheye: Adaptation of a ROI-Based Object Pose Estimation Network to Monocular Fisheye Images</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2765.pdf">2765</a></td><td style="text-align:left">Boosting Deep Open World Recognition by Clustering</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2768.pdf">2768</a></td><td style="text-align:left">Unsupervised Domain Adaptation through Inter-Modal Rotation for RGB-D Object Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2769.pdf">2769</a></td><td style="text-align:left">ALPHRED: A Multi-Modal Operations Quadruped Robot for Package Delivery Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2771.pdf">2771</a></td><td style="text-align:left">Lio - a Personal Robot Assistant for Human-Robot Interaction and Care Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2772.pdf">2772</a></td><td style="text-align:left">GMMLoc: Structure Consistent Visual Localization with Gaussian Mixture Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2774.pdf">2774</a></td><td style="text-align:left">Building Energy-Cost Maps from Aerial Images and Ground Robot Measurements with Semi-Supervised Deep Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2776.pdf">2776</a></td><td style="text-align:left">Automatic Control Synthesis for Swarm Robots from Formation and Location-Based High-Level Specifications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2777.pdf">2777</a></td><td style="text-align:left">Graph Neural Networks for Decentralized Multi-Robot Path Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2778.pdf">2778</a></td><td style="text-align:left">LineSpyX: A Power Line Inspection Robot Based on Digital Radiography</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2779.pdf">2779</a></td><td style="text-align:left">Improving Visual SLAM in Car-Navigated Urban Environments with Appearance Maps</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2780.pdf">2780</a></td><td style="text-align:left">A Multi-System Chaotic Path Planner for Fast and Unpredictable Online Coverage of Terrains</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2781.pdf">2781</a></td><td style="text-align:left">Collision Avoidance Based on Robust Lexicographic Task Assignment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2782.pdf">2782</a></td><td style="text-align:left">3D Instance Embedding Learning with a Structure-Aware Loss Function for Point Cloud Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2783.pdf">2783</a></td><td style="text-align:left">Improving Tracking through Human-Robot Sensory Augmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2784.pdf">2784</a></td><td style="text-align:left">Generating Reactive Approach Motions towards Allowable Manifolds Using Generalized Trajectories from Demonstrations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2786.pdf">2786</a></td><td style="text-align:left">“Good Robot!”: Efficient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2787.pdf">2787</a></td><td style="text-align:left">An Actor-Based Programming Framework for Swarm Robotic Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2788.pdf">2788</a></td><td style="text-align:left">Multi-Sensor Next-Best-View Planning As Matroid-Constrained Submodular Maximization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2790.pdf">2790</a></td><td style="text-align:left">IDDA: A Large-Scale Multi-Domain Dataset for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2794.pdf">2794</a></td><td style="text-align:left">Perceptive Model Predictive Control for Continuous Mobile Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2795.pdf">2795</a></td><td style="text-align:left">MLOD: Awareness of Extrinsic Perturbation in Multi-LiDAR 3D Object Detection for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2796.pdf">2796</a></td><td style="text-align:left">3D-MiniNet: Learning a 2D Representation from Point Clouds for Fast and Efficient 3D LIDAR Semantic Segmentation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2797.pdf">2797</a></td><td style="text-align:left">Augmented Reality and Robotic-Assistance for Percutaneous Nephrolithotomy</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2798.pdf">2798</a></td><td style="text-align:left">Learning Gait Models with Varying Walking Speeds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2800.pdf">2800</a></td><td style="text-align:left">On the Use of (lockable) Parallel Elasticity in Active Prosthetic Ankles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2801.pdf">2801</a></td><td style="text-align:left">Compliant Control and Compensation for a Compact Cable-Driven Robotic Manipulator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2802.pdf">2802</a></td><td style="text-align:left">Machine Learning Model Comparisons of User Independent &amp; Dependent Intent Recognition Systems for Powered Prostheses</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2804.pdf">2804</a></td><td style="text-align:left">Manipulation Planning Using Object-Centered Predicates and Hierarchical Decomposition of Contextual Actions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2807.pdf">2807</a></td><td style="text-align:left">Grasping in the Wild: Learning 6DoF Closed-Loop Grasping from Low-Cost Demonstrations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2808.pdf">2808</a></td><td style="text-align:left">TLIO: Tight Learned Inertial Odometry</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2813.pdf">2813</a></td><td style="text-align:left">Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2814.pdf">2814</a></td><td style="text-align:left">Persistent Intelligence, Surveillance, and Reconnaissance Using Multiple Autonomous Vehicles with Asynchronous Route Updates</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2815.pdf">2815</a></td><td style="text-align:left">Socially and Contextually Aware Human Motion and Pose Forecasting</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2817.pdf">2817</a></td><td style="text-align:left">A Realistic Simulation Environment for MRI-Based Robust Control of Untethered Magnetic Robots with Intra-Operational Imaging</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2820.pdf">2820</a></td><td style="text-align:left">Minimum Time - Minimum Jerk Optimal Traffic Management for AGVs</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2821.pdf">2821</a></td><td style="text-align:left">Topology-Guided Roadmap Construction with Dynamic Region Sampling</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2822.pdf">2822</a></td><td style="text-align:left">Finite-Horizon LQR Control of Quadrotors on SE_2(3)</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2826.pdf">2826</a></td><td style="text-align:left">Augmenting Visual Place Recognition with Structural Cues</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2827.pdf">2827</a></td><td style="text-align:left">A Control Scheme for Smooth Transition in Physical Human-Robot-Environment between Two Modes: Augmentation and Autonomous</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2828.pdf">2828</a></td><td style="text-align:left">Human Navigation Using Phantom Tactile Sensation Based Vibrotactile Feedback</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2829.pdf">2829</a></td><td style="text-align:left">Applying Force Perturbations Using a Wearable Robotic Neck Brace</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2832.pdf">2832</a></td><td style="text-align:left">Open-Loop Orientation Control Using Dynamic Magnetic Fields</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2833.pdf">2833</a></td><td style="text-align:left">Fluid-Structure Interaction Hydrodynamics Analysis on a Deformed Bionic Flipper with Non-Uniformly Distributed Stiffness</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2834.pdf">2834</a></td><td style="text-align:left">Computational Structure Design of a Bio-inspired Armwing Mechanism</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2836.pdf">2836</a></td><td style="text-align:left">Fully Actuated Body-Mounted Robotic System for MRI-Guided Lower Back Pain Injections: Initial Phantom and Cadaver Studies</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2838.pdf">2838</a></td><td style="text-align:left">Supervised Semi-Autonomous Control for Surgical Robot Based on Bayesian Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2840.pdf">2840</a></td><td style="text-align:left">Improving Low-Level Control of the Exoskeleton Atalante in Single Support by Compensating Joint Flexibility</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2842.pdf">2842</a></td><td style="text-align:left">Multi-Robot Active Sensing and Environmental Model Learning with Distributed Gaussian Process</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2843.pdf">2843</a></td><td style="text-align:left">Mixed-Integer Linear Programming Models for Multi-Robot Non-Adversarial Search</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2845.pdf">2845</a></td><td style="text-align:left">Energetic Passivity Decoding of Human Hip Joint for Physical Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2846.pdf">2846</a></td><td style="text-align:left">sEMG-based Human-in-the-Loop Control of Elbow Assistive Robots for Physical Tasks and Muscle Strength Training</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2847.pdf">2847</a></td><td style="text-align:left">Pneumatic Duplex-Chambered Inchworm Mechanism for Narrow Pipes Driven by Only Two Air Supply Lines</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2848.pdf">2848</a></td><td style="text-align:left">Long-Term Localization with Time Series Map Prediction for Mobile Robots in Dynamic Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2849.pdf">2849</a></td><td style="text-align:left">Inverted and Inclined Climbing Using Capillary Adhesion in a Quadrupedal Insect-Scale Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2850.pdf">2850</a></td><td style="text-align:left">Perceptive Locomotion in Rough Terrain — Online Foothold Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2852.pdf">2852</a></td><td style="text-align:left">CaseCrawler: A Lightweight and Low-Profile Crawling Phone Case Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2853.pdf">2853</a></td><td style="text-align:left">Waste Not, Want Not: Lessons in Rapid Quadrupedal Gait Termination from Thousands of Suboptimal Solutions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2854.pdf">2854</a></td><td style="text-align:left">Learning Force Control for Contact-rich Manipulation Tasks with Rigid Position-controlled Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2856.pdf">2856</a></td><td style="text-align:left">Elastomeric Continuously Variable Transmission Combined with Twisted String Actuator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2860.pdf">2860</a></td><td style="text-align:left">R-Track: Separable Modular Climbing Robot Design for Wall-To-Wall Transition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2861.pdf">2861</a></td><td style="text-align:left">A Soft, Modular, and Bi-Stable Dome Actuator for Programmable Multi-Modal Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2862.pdf">2862</a></td><td style="text-align:left">Robotic Deep Rolling with Iterative Learning Motion and Force Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2867.pdf">2867</a></td><td style="text-align:left">The ASTAR High Speed Amphibious Sprawl Tuned Robot: Design and Experiments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2869.pdf">2869</a></td><td style="text-align:left">Enhancement of Force Exertion Capability of a Mobile Manipulator by Kinematic Reconfiguration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2871.pdf">2871</a></td><td style="text-align:left">Polylidar - Polygons from Triangular Meshes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2872.pdf">2872</a></td><td style="text-align:left">ACMarker: Acoustic Camera-Based Fiducial Marker System in Underwater Environment</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2873.pdf">2873</a></td><td style="text-align:left">Toward Enabling a Hundred Drones to Land in a Minute</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2874.pdf">2874</a></td><td style="text-align:left">TiltDrone: A Fully-Actuated Tilting Quadrotor Platform</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2875.pdf">2875</a></td><td style="text-align:left">Interact with Me: An Exploratory Study on Interaction Factors for Active Physical Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2877.pdf">2877</a></td><td style="text-align:left">Coordinated Appendages Accumulate More Energy to Self-Right on the Ground</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2878.pdf">2878</a></td><td style="text-align:left">Unmanned Aerial Sensor Placement for Cluttered Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2880.pdf">2880</a></td><td style="text-align:left">Asynchronous and Parallel Distributed Pose Graph Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2881.pdf">2881</a></td><td style="text-align:left">Gaussian Process Online Learning with a Sparse Data Stream</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2882.pdf">2882</a></td><td style="text-align:left">Towards Better Surgical Instrument Segmentation in Endoscopic Vision: Multi-Angle Feature Aggregation and Contour Supervision</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2884.pdf">2884</a></td><td style="text-align:left">Development of Dementia Care Training System Based on Augmented Reality and Whole Body Wearable Tactile Sensor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2886.pdf">2886</a></td><td style="text-align:left">Data-Driven Disturbance Observers for Estimating External Forces on Soft Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2888.pdf">2888</a></td><td style="text-align:left">Self-Sensing and Feedback Control for a Twin Coil Spring-Based Flexible Ultrasonic Motor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2891.pdf">2891</a></td><td style="text-align:left">Convergence Analysis of Hybrid Control Systems in the Form of Backward Chained Behavior Trees</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2892.pdf">2892</a></td><td style="text-align:left">FireAnt3D: A 3D Self-Climbing Robot towards Non-Latticed Robotic Self-Assembly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2895.pdf">2895</a></td><td style="text-align:left">Actor-Critic Reinforcement Learning for Control with Stability Guarantee</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2897.pdf">2897</a></td><td style="text-align:left">Matching Color Aerial Images and Underwater Sonar Images using Deep Learning for Underwater Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2898.pdf">2898</a></td><td style="text-align:left">Fail-Safe Flight of a Fully-Actuated Quadcopter in a Single Motor Failure</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2899.pdf">2899</a></td><td style="text-align:left">Improvement in Measurement Area of 3D LiDAR for a Mobile Robot Using a Mirror Mounted on a Manipulator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2901.pdf">2901</a></td><td style="text-align:left">Dynamic Median Consensus for Marine Multi-Robot Systems Using Acoustic Communication</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2906.pdf">2906</a></td><td style="text-align:left">Robust Loop Closure Method for Multi-robot Map Fusion by Integration of Consistency and Data Similarity</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2907.pdf">2907</a></td><td style="text-align:left">ModMan: An Advanced Reconfigurable Manipulator System with Genderless Connector and Automatic Kinematic Modeling Algorithm</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2909.pdf">2909</a></td><td style="text-align:left">Kubits: Solid-State Self-Reconfiguration with Programmable Magnets</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2910.pdf">2910</a></td><td style="text-align:left">Development of a Steep Slope Mobile Robot with Propulsion Adhesion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2911.pdf">2911</a></td><td style="text-align:left">Online Exploration and Coverage Planning in Unknown Obstacle-Cluttered Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2912.pdf">2912</a></td><td style="text-align:left">Optimization-Based Investigation of Bioinspired Variable Gearing of the Distributed Actuation Mechanism to Maximize Velocity and Force</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2913.pdf">2913</a></td><td style="text-align:left">Robotic Episodic Cognitive Learning Inspired by Hippocampal Spatial Cells</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2914.pdf">2914</a></td><td style="text-align:left">A Bio-Inspired Quadruped Robot Exploiting Flexible Shoulder for Stable and Efficient Walking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2916.pdf">2916</a></td><td style="text-align:left">Development of a Running Hexapod Robot with Differentiated Front and Hind Leg Morphology and Functionality</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2919.pdf">2919</a></td><td style="text-align:left">Prediction of Backhoe Loading Motion via the Beta-Process Hidden Markov Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2921.pdf">2921</a></td><td style="text-align:left">Robust RL-Based Map-Less Local Planning: Using 2D Point Clouds as Observations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2924.pdf">2924</a></td><td style="text-align:left">An Ionic Polymer Metal Composite (IPMC)-Driven Linear Peristaltic Microfluidic Pump</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2925.pdf">2925</a></td><td style="text-align:left">Low-Cost Coil-Shaped Optical Fiber Displacement Sensor for a Twisted and Coiled Polymer Fiber Actuator Unit</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2926.pdf">2926</a></td><td style="text-align:left">A Model-Based Sensor Fusion Approach for Force and Shape Estimation in Soft Robotics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2933.pdf">2933</a></td><td style="text-align:left">Design of Fully Soft Actuator with Double-Helix Tendon Routing Path for Twisting Motion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2939.pdf">2939</a></td><td style="text-align:left">VeREFINE: Integrating Object Pose Verification with Physics-Guided Iterative Refinement</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2941.pdf">2941</a></td><td style="text-align:left">A Dexterous Soft Robotic Hand for Delicate In-Hand Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2942.pdf">2942</a></td><td style="text-align:left">Knowledge-Based Grasp Planning Using Dynamic Self-Organizing Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2943.pdf">2943</a></td><td style="text-align:left">Motion Planning for Dual-Arm Manipulation of Elastic Rods</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2945.pdf">2945</a></td><td style="text-align:left">Environment-Aware Grasp Strategy Planning in Clutter for a Variable Stiffness Hand</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2948.pdf">2948</a></td><td style="text-align:left">Online Acquisition of Close-Range Proximity Sensor Models for Precise Object Grasping and Verification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2950.pdf">2950</a></td><td style="text-align:left">Object-Agnostic Dexterous Manipulation of Partially Constrained Trajectories</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2951.pdf">2951</a></td><td style="text-align:left">Describing Physics for Physical Reasoning: Force-Based Sequential Manipulation Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2952.pdf">2952</a></td><td style="text-align:left">Vision and Force Based Autonomous Robotic Coating with Rollers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2953.pdf">2953</a></td><td style="text-align:left">Model-Based Coupling for Co-Simulation of Robotic Contact Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2954.pdf">2954</a></td><td style="text-align:left">ECG: Edge-Aware Point Cloud Completion with Graph Convolution</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2955.pdf">2955</a></td><td style="text-align:left">Don’t Forget the Past: Recurrent Depth Estimation from Monocular Video</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2961.pdf">2961</a></td><td style="text-align:left">AirCapRL: Autonomous Aerial Human Motion Capture Using Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2962.pdf">2962</a></td><td style="text-align:left">Model-Based Reinforcement Learning for Time-Optimal Velocity Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2964.pdf">2964</a></td><td style="text-align:left">Deep Reinforcement Learning for Tactile Robotics: Learning to Type on a Braille Keyboard</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2965.pdf">2965</a></td><td style="text-align:left">Ultra-thin Joint Torque Sensor with Enhanced Sensitivity for Robotic Application</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2967.pdf">2967</a></td><td style="text-align:left">State-Continuity Approximation of Markov Decision Processes Via Finite Element Methods for Autonomous System Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2970.pdf">2970</a></td><td style="text-align:left">BLT Gripper: An Adaptive Gripper with Active Transition Capability between Precise Pinch and Compliant Grasp</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2971.pdf">2971</a></td><td style="text-align:left">Hierarchical Tracking Control with Arbitrary Task Dimensions: Application to Trajectory Tracking on Submanifolds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2972.pdf">2972</a></td><td style="text-align:left">RIDM: Reinforced Inverse Dynamics Modeling for Learning from a Single Observed Demonstration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2975.pdf">2975</a></td><td style="text-align:left">Learning Variable Impedance Control for Contact Sensitive Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2976.pdf">2976</a></td><td style="text-align:left">Person-Directed Pointing Gestures and Inter-Personal Relationship: Expression of Politeness to Friendliness by Android Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2978.pdf">2978</a></td><td style="text-align:left">A Feasibility Study of Culture-Aware Cloud Services for Conversational Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2979.pdf">2979</a></td><td style="text-align:left">Deep Reinforcement Learning for Safe Local Planning of a Ground Vehicle in Unknown Rough Terrain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2984.pdf">2984</a></td><td style="text-align:left">Cluster-Based Penalty Scaling for Robust Pose Graph Optimization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2985.pdf">2985</a></td><td style="text-align:left">Improved Data Association Using Buffered Pose Adjustment for Map-Aided Localization</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2986.pdf">2986</a></td><td style="text-align:left">HDMI-Loc: Exploiting High Definition Map Image for Precise Localization via Bitwise Particle Filter</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2987.pdf">2987</a></td><td style="text-align:left">A Control Barrier Function Approach for Maximizing Performance While Fulfilling to ISO/TS 15066 Regulations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2988.pdf">2988</a></td><td style="text-align:left">Teleoperation and Contact Detection of a Waterjet-Actuated Soft Continuum Manipulator for Low-Cost Gastroscopy</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2990.pdf">2990</a></td><td style="text-align:left">Visual Coverage Path Planning for Urban Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2993.pdf">2993</a></td><td style="text-align:left">Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2995.pdf">2995</a></td><td style="text-align:left">Nonlinear MPC for Collision Avoidance and Control of UAVs with Dynamic Obstacles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2996.pdf">2996</a></td><td style="text-align:left">Non-Gaussian Chance-Constrained Trajectory Planning for Autonomous Vehicles in the Presence of Uncertain Agents</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2998.pdf">2998</a></td><td style="text-align:left">Trajectory Planning Over Regular General Surfaces with Application in Robot-Guided Deposition Printing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/2999.pdf">2999</a></td><td style="text-align:left">An Opportunistic Strategy for Motion Planning in the Presence of Soft Task Constraints</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3002.pdf">3002</a></td><td style="text-align:left">Inverse Kinematics of Redundant Manipulators with Dynamic Bounds on Joint Movements</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3003.pdf">3003</a></td><td style="text-align:left">Human Perception-Optimized Planning for Comfortable VR Based Telepresence</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3004.pdf">3004</a></td><td style="text-align:left">A Disturbance-Aware Trajectory Planning Scheme based on Model Predictive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3006.pdf">3006</a></td><td style="text-align:left">Model-Adaptive High-Speed Collision Detection for Serial-Chain Robot Manipulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3007.pdf">3007</a></td><td style="text-align:left">DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local &amp; Global Collision Avoidance</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3009.pdf">3009</a></td><td style="text-align:left">Quaternion-Based Trajectory Optimization of Human Postures for Inducing Target Muscle Activation Patterns</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3010.pdf">3010</a></td><td style="text-align:left">Fast Sequence Rejection for Multi-Goal Planning with Dubins Vehicle</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3012.pdf">3012</a></td><td style="text-align:left">Combining Speed and Separation Monitoring with Power and Force Limiting for Safe Collaborative Robotics Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3013.pdf">3013</a></td><td style="text-align:left">A Unified NMPC Scheme for MAVs Navigation with 3D Collision Avoidance under Position Uncertainty</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3015.pdf">3015</a></td><td style="text-align:left">Frozone: Freezing-Free, Pedestrian-Friendly Navigation in Human Crowds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3016.pdf">3016</a></td><td style="text-align:left">Modular, Accessible, Sensorized Objects for Evaluating the Grasping and Manipulation Capabilities of Grippers and Hands</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3017.pdf">3017</a></td><td style="text-align:left">Design, Modelling, and Implementation of a 7-DOF Cable-Driven Haptic Device with a Configurable Cable Platform</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3019.pdf">3019</a></td><td style="text-align:left">Asymptotically-Optimal Topological Nearest-Neighbor Filtering</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3020.pdf">3020</a></td><td style="text-align:left">Online Replanning with Human-In-The-Loop for Non-Prehensile Manipulation in Clutter ‘ a Trajectory Optimization Based Approach</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3021.pdf">3021</a></td><td style="text-align:left">Neural Manipulation Planning on Constraint Manifolds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3022.pdf">3022</a></td><td style="text-align:left">Piezoelectric Grippers for Mobile Micromanipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3023.pdf">3023</a></td><td style="text-align:left">Stable In-Grasp Manipulation with a Low-Cost Robot Hand by Using 3-Axis Tactile Sensors with a CNN</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3026.pdf">3026</a></td><td style="text-align:left">Feedback Enhanced Motion Planning for Autonomous Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3027.pdf">3027</a></td><td style="text-align:left">Magnetically Programmable Cuboids for 2D Locomotion and Collaborative Assembly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3030.pdf">3030</a></td><td style="text-align:left">Six-Axis Force/Torque Fingertip Sensor for an Anthropomorphic Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3032.pdf">3032</a></td><td style="text-align:left">Low Latency Trajectory Predictions for Interaction Aware Highway Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3033.pdf">3033</a></td><td style="text-align:left">APPLD: Adaptive Planner Parameter Learning from Demonstration</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3034.pdf">3034</a></td><td style="text-align:left">Precision Assembly of Heavy Objects Suspended with Multiple Cables from a Crane</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3035.pdf">3035</a></td><td style="text-align:left">Explicit Domain Adaptation with Loosely Coupled Samples</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3037.pdf">3037</a></td><td style="text-align:left">Adaptive Aerial Grasping and Perching with Dual Elasticity Combined Suction Cup</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3038.pdf">3038</a></td><td style="text-align:left">Target Search on Road Networks with Range-Constrained UAVs and Ground-Based Mobile Recharging Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3041.pdf">3041</a></td><td style="text-align:left">Simultaneously Learning Corrections and Error Models for Geometry-Based Visual Odometry Methods</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3042.pdf">3042</a></td><td style="text-align:left">Safe Optimal Control under Parametric Uncertainties</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3044.pdf">3044</a></td><td style="text-align:left">Vitruvio: An Open-Source Leg Design Optimization Toolbox for Walking Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3046.pdf">3046</a></td><td style="text-align:left">Alleviating the Burden of Labeling: Sentence Generation by Attention Branch Encoder-Decoder Network</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3050.pdf">3050</a></td><td style="text-align:left">Robot Gaze Behaviors in Human-To-Robot Handovers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3051.pdf">3051</a></td><td style="text-align:left">Self-Attention Based Visual-Tactile Fusion Learning for Predicting Grasp Outcomes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3052.pdf">3052</a></td><td style="text-align:left">Socially Assistive Robots at Work: Making Break-Taking Interventions More Pleasant, Enjoyable, and Engaging</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3053.pdf">3053</a></td><td style="text-align:left">Learn by Observation: Imitation Learning for Drone Patrolling from Videos of a Human Navigator</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3056.pdf">3056</a></td><td style="text-align:left">Lidar Essential Beam Model for Accurate Width Estimation of Thin Poles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3060.pdf">3060</a></td><td style="text-align:left">Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3061.pdf">3061</a></td><td style="text-align:left">Imitation Learning Based on Bilateral Control for Human’Robot Cooperation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3063.pdf">3063</a></td><td style="text-align:left">Autonomous Tissue Retraction in Robotic Assisted Minimally Invasive Surgery - A Feasibilty Study</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3064.pdf">3064</a></td><td style="text-align:left">6-Axis Force/Torque Sensor with a Novel Autonomous Weight Compensating Capability for Robotic Applications</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3066.pdf">3066</a></td><td style="text-align:left">Multi-Fingered Grasp Planning Via Inference in Deep Neural Networks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3067.pdf">3067</a></td><td style="text-align:left">Collision Avoidance in Human-Robot Interaction Using Kinect Vision System Combined with Robot’s Model and Data</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3068.pdf">3068</a></td><td style="text-align:left">Miniaturized robotics: The smallest camera operator bot pays tribute to David Bowie.</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3070.pdf">3070</a></td><td style="text-align:left">Development of Δ-Type Mobile Robot Driven by 3 Standing Wave Type Piezoelectric Ultrasonic Motors</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3072.pdf">3072</a></td><td style="text-align:left">Lyapunov-Stable Orientation Estimator for Humanoid Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3073.pdf">3073</a></td><td style="text-align:left">UFOMap: An Efficient Probabilistic 3D Mapping Framework That Embraces the Unknown</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3074.pdf">3074</a></td><td style="text-align:left">Machine Learning for Active Gravity Compensation in Robotics: Application to Neurological Rehabilitation Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3075.pdf">3075</a></td><td style="text-align:left">Learning robust manipulation tasks involving contact using trajectory parameterized probabilistic principal component analysis</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3076.pdf">3076</a></td><td style="text-align:left">Unsupervised Pedestrian Pose Prediction — A Deep Predictive Coding Network Approach for Autonomous Vehicle Perception</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3077.pdf">3077</a></td><td style="text-align:left">Stable Autonomous Spiral Stair Climbing of Tracked Vehicles Using Wall Reaction Force</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3079.pdf">3079</a></td><td style="text-align:left">TSBP: Tangent Space Belief Propagation for Manifold Learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3080.pdf">3080</a></td><td style="text-align:left">Exploiting Visual-Outer Shape for Tactile-Inner Shape Estimation of Objects Covered with Soft Materials</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3081.pdf">3081</a></td><td style="text-align:left">Heteroscedastic Uncertainty for Robust Generative Latent Dynamics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3082.pdf">3082</a></td><td style="text-align:left">q-VAE for Disentangled Representation Learning and Latent Dynamical Systems</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3083.pdf">3083</a></td><td style="text-align:left">Can a Robot’s Touches Express the Feeling of Kawaii Toward an Object?</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3084.pdf">3084</a></td><td style="text-align:left">Optimisation of Body-ground Contact for Augmenting the Whole-Body Loco-manipulation of Quadruped Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3085.pdf">3085</a></td><td style="text-align:left">Communication Maintenance of Robotic Parasitic Antenna Arrays</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3087.pdf">3087</a></td><td style="text-align:left">Bilateral humanoid teleoperation system using whole-body exoskeleton cockpit TABLIS</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3088.pdf">3088</a></td><td style="text-align:left">Adaptive-Gains Enforcing Constraints in Closed-Loop QP Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3089.pdf">3089</a></td><td style="text-align:left">Multi-Contact Locomotion Planning for Humanoid Robot Based on Sustainable Contact Graph with Local Contact Modification</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3091.pdf">3091</a></td><td style="text-align:left">Self-Assessment of Grasp Affordance Transfer</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3093.pdf">3093</a></td><td style="text-align:left">XBot Real-Time Software Framework for Robotics: From the Developer to the User Perspective</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3094.pdf">3094</a></td><td style="text-align:left">Natural Criteria for Comparison of Pedestrian Flow Forecasting Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3097.pdf">3097</a></td><td style="text-align:left">Lloyd-Based Approach for Robots Navigation in Human-Shared Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3098.pdf">3098</a></td><td style="text-align:left">Flight Path Planning of Solar Powered UAV for Sustainable Communication Relay</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3099.pdf">3099</a></td><td style="text-align:left">RoVaLL: Design and Development of a Multi-Terrain Towed Robot with Variable Lug-Length Wheels</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3102.pdf">3102</a></td><td style="text-align:left">Reconfigurable Soft Flexure Hinges Via Pinched Tubes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3104.pdf">3104</a></td><td style="text-align:left">Rolling Soft Membrane-Driven Tensegrity Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3105.pdf">3105</a></td><td style="text-align:left">Exploiting the Morphology of a Shape Memory Spring as the Active Backbone of a Highly Dexterous Tendril Robot (ATBR)</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3106.pdf">3106</a></td><td style="text-align:left">Retraction Mechanism of Soft Torus Robot with a Hydrostatic Skeleton</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3107.pdf">3107</a></td><td style="text-align:left">Integrated Actuation and Self-Sensing for Twisted-And-Coiled Actuators with Applications to Innervated Soft Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3109.pdf">3109</a></td><td style="text-align:left">Self-Propelled Colonoscopy Robot Using Flexible Paddles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3111.pdf">3111</a></td><td style="text-align:left">Self-Healing Cell Tactile Sensor by Ultraflexible Printed Electrodes</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3113.pdf">3113</a></td><td style="text-align:left">Assured Runtime Monitoring and Planning: Towards Verification of Neural Networks for Safe Autonomous Operations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3114.pdf">3114</a></td><td style="text-align:left">Electromagnetic Actuation of Microrobots in a Simulated Vascular Structure with a Position Estimator Based Motion Controller</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3115.pdf">3115</a></td><td style="text-align:left">Wide Area Exploration System Using Passive-Follower Robots Towed by Multiple Winches</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3117.pdf">3117</a></td><td style="text-align:left">End-To-End Velocity Estimation for Autonomous Racing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3118.pdf">3118</a></td><td style="text-align:left">End-to-end Tactile Feedback Loop: From Soft Sensor Skin over Deep GRU-Autoencoders to Tactile Stimulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3119.pdf">3119</a></td><td style="text-align:left">Parallel Haptic Rendering for Orthopedic Surgery Simulators</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3120.pdf">3120</a></td><td style="text-align:left">Simultaneous 3D Forming and Patterning Method of Realizing Soft IPMC Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3121.pdf">3121</a></td><td style="text-align:left">Visual SLAM with Drift-Free Rotation Estimation in Manhattan World</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3123.pdf">3123</a></td><td style="text-align:left">Structure-SLAM: Low-Drift Monocular SLAM in Indoor Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3124.pdf">3124</a></td><td style="text-align:left">SoftHandler: An Integrated Soft Robotic System for the Handling of Heterogeneous Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3125.pdf">3125</a></td><td style="text-align:left">A Grasping-Centered Analysis for Cloth Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3126.pdf">3126</a></td><td style="text-align:left">Information Correlated Levy Walk Exploration and Distributed Mapping Using a Swarm of Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3127.pdf">3127</a></td><td style="text-align:left">Virtual IR Sensing for Planetary Rovers: Improved Terrain Classification and Thermal Inertia Estimation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3128.pdf">3128</a></td><td style="text-align:left">Definition and Application of Variable Resistance Coefficient for Wheeled Mobile Robots on Deformable Terrain</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3129.pdf">3129</a></td><td style="text-align:left">A Passive pHRI Controller for Assisting the User in Partially Known Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3130.pdf">3130</a></td><td style="text-align:left">On the False Positives and False Negatives of the Jacobian Matrix in Kinematically Redundant Parallel Mechanisms</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3131.pdf">3131</a></td><td style="text-align:left">Gaussians on Riemannian Manifolds: Applications for Robot Learning and Adaptive Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3132.pdf">3132</a></td><td style="text-align:left">Torque-Bounded Admittance Control Realized by a Set-Valued Algebraic Feedback</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3133.pdf">3133</a></td><td style="text-align:left">Decoding Motor Skills of AI and Human Policies: A Study on Humanoid and Human Balance Control</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3134.pdf">3134</a></td><td style="text-align:left">Distributed Control for Cooperative Manipulation With Event-Triggered Communication</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3135.pdf">3135</a></td><td style="text-align:left">Calculating the Support Function of Complex Continuous Surfaces with Applications to Minimum Distance Computation and Optimal Grasp Planning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3136.pdf">3136</a></td><td style="text-align:left">A Routing Framework for Heterogeneous Multi-Robot Teams in Exploration Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3137.pdf">3137</a></td><td style="text-align:left">Continuously Variable Stiffness Mechanism Using Nonuniform Patterns on Coaxial Tubes for Continuum Microsurgical Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3138.pdf">3138</a></td><td style="text-align:left">Achieving Versatile Energy Efficiency With the WANDERER Biped Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3139.pdf">3139</a></td><td style="text-align:left">In Vitro Design Investigation of a Rotating Helical Magnetic Swimmer for Combined 3-D Navigation and Blood Clot Removal</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3151.pdf">3151</a></td><td style="text-align:left">Marker-Based Mapping and Localization for Autonomous Valet Parking</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3152.pdf">3152</a></td><td style="text-align:left">Parameter Optimization for Loop Closure Detection in ClosedÂ Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3153.pdf">3153</a></td><td style="text-align:left">Radar-Camera Sensor Fusion for Joint Object DetectionÂ and Distance Estimation in Autonomous Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3154.pdf">3154</a></td><td style="text-align:left">SalsaNext Fast Uncertainty-aware Semantic SegmentationÂ of LiDAR Point Clouds for Autonomous Driving</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3155.pdf">3155</a></td><td style="text-align:left">SDVTracker Real-Time Multi-Sensor Association and Tracking forÂ Self-Driving Vehicles</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3156.pdf">3156</a></td><td style="text-align:left">Situation Awareness at Autonomous Vehicle Handover - PreliminaryÂ Results of a Quantitative Analysis</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3157.pdf">3157</a></td><td style="text-align:left">Towards Context-Aware Navigation forÂ Long-Term Autonomy in Agricultural Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3158.pdf">3158</a></td><td style="text-align:left">Efficient Sampling in POMDPs with Lipschitz BanditsÂ for Motion Planning in Continuous Spaces</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3159.pdf">3159</a></td><td style="text-align:left">Impact of Traffic Lights on Trajectory Forecasting of Human-drivenÂ Vehicles Near Signalized Intersections</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3161.pdf">3161</a></td><td style="text-align:left">Semantic Grid Map based LiDAR Localization in Highly DynamicÂ Urban Scenarios</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3162.pdf">3162</a></td><td style="text-align:left">Acquiring Mechanical Knowledge from 3D Point Clouds</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3163.pdf">3163</a></td><td style="text-align:left">Representation and Experience-Based Learning of Explainable Models for Robot Action Execution</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3164.pdf">3164</a></td><td style="text-align:left">Emergent Adaptive Gait Generation through Hebbian Sensor-Motor Maps by Morphological Probing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3165.pdf">3165</a></td><td style="text-align:left">Mixed Reality As a Bidirectional Communication Interface for Human-Robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3166.pdf">3166</a></td><td style="text-align:left">The Robot As Scientist: Using Mental Simulation to Test Causal Hypotheses Extracted from Human Activities in Virtual Reality</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3167.pdf">3167</a></td><td style="text-align:left">Graph-Based Hierarchical Knowledge Representation for Robot Task Transfer from Virtual to Physical World</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3168.pdf">3168</a></td><td style="text-align:left">An Optimized Tilt Mechanism for a New Steady-Hand Eye Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3169.pdf">3169</a></td><td style="text-align:left">Optimization-Based Hierarchical Motion Planning for Autonomous Racing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3170.pdf">3170</a></td><td style="text-align:left">SwingBot: Learning Physical Features from In-Hand Tactile Exploration for Dynamic Swing-Up Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3182.pdf">3182</a></td><td style="text-align:left">Learning Visuomotor Policies for Aerial Navigation Using Cross-Modal Representations</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3183.pdf">3183</a></td><td style="text-align:left">Learning Vision-Based Physics Intuition Models for Non-Disruptive Object Extraction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3184.pdf">3184</a></td><td style="text-align:left">Computational Design of Balanced Open Link Planar Mechanisms with Counterweights from User Sketches</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3238.pdf">3238</a></td><td style="text-align:left">Relative Pose Estimation and Planar Reconstruction Via Superpixel-Driven Multiple Homographies</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3239.pdf">3239</a></td><td style="text-align:left">Real-Time Constrained Nonlinear Model Predictive Control on SO(3) for Dynamic Legged Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3240.pdf">3240</a></td><td style="text-align:left">Combining Compliance Control, CAD Based Localization, and a Multi-Modal Gripper for Rapid and Robust Programming of Assembly Tasks</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3241.pdf">3241</a></td><td style="text-align:left">FreeBOT: A Freeform Modular Self-Reconfigurable Robot with Arbitrary Connection Point - Design and Implementation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3242.pdf">3242</a></td><td style="text-align:left">Computational Design of Balanced Open Link Planar Mechanisms with Counterweights from User Sketches</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3243.pdf">3243</a></td><td style="text-align:left">A Tip Mount for Transporting Sensors and Tools Using Soft Growing Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3244.pdf">3244</a></td><td style="text-align:left">Robot Calligraphy Using Pseudospectral Optimal Controlin Conjunction with a Novel Dynamic Brush Model</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3245.pdf">3245</a></td><td style="text-align:left">Diabolo Orientation Stabilization by Learning Predictive Model for Unstable Unknown-Dynamics Juggling Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3246.pdf">3246</a></td><td style="text-align:left">Towards Micro Robot Hydrobatics: Vision-based Guidance, Navigation, and Control for Agile Underwater Vehicles in Confined Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3247.pdf">3247</a></td><td style="text-align:left">Animated Cassie: A Dynamic Relatable Robotic Character</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3248.pdf">3248</a></td><td style="text-align:left">Safety Considerations in Deep Control Policies with Safety Barrier Certificates under Uncertainty</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3249.pdf">3249</a></td><td style="text-align:left">Navigation on the Line: Traversability Analysis and Path Planning for Extreme-Terrain Rappelling Rovers</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3250.pdf">3250</a></td><td style="text-align:left">Autonomous Spot: Long-Range Autonomous Exploration of Extreme Environments with Legged Locomotion</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3251.pdf">3251</a></td><td style="text-align:left">Stable Autonomous Spiral Stair Climbing of Tracked Vehicles Using Wall Reaction Force</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3252.pdf">3252</a></td><td style="text-align:left">Unsupervised Domain Adaptation for Transferring Plant Classification Systems to New Field Environments, Crops, and Robots</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3253.pdf">3253</a></td><td style="text-align:left">DIAT (Depth-Infrared Image Annotation Transfer) for Training a Depth-Based Pig-Pose Detector</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3254.pdf">3254</a></td><td style="text-align:left">Incorporating Spatial Constraints into a Bayesian Tracking Framework for Improved Localisation in Agricultural Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3255.pdf">3255</a></td><td style="text-align:left">Fruit Quality Control by Surface Analysis Using a Bio-Inspired Soft Tactile Sensor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3256.pdf">3256</a></td><td style="text-align:left">Pit30M: A Benchmark for Global Localization in the Age of Self-Driving Cars</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3257.pdf">3257</a></td><td style="text-align:left">OceanVoy: A Hybrid Energy Planning System for Autonomous Sailboat</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3258.pdf">3258</a></td><td style="text-align:left">MHYRO: Modular HYbrid RObot for Contact Inspection and Maintenance in Oil&amp;gas Plants</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3259.pdf">3259</a></td><td style="text-align:left">LLAMA: Design and Control of an Omnidirectional Human Mission Scale Quadrupedal Robot</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3475.pdf">3475</a></td><td style="text-align:left">RGB-D sensing of challenging deformable objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3476.pdf">3476</a></td><td style="text-align:left">Building 3D Deformable Object Models in Partially Observable Robotic Environments</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3477.pdf">3477</a></td><td style="text-align:left">SOMA: A Data-Driven Representation Framework for Semantic Soft Object Manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3478.pdf">3478</a></td><td style="text-align:left">Task-oriented Contact Adjustment in Deformable Objects Manipulation with Non-fixed Contact</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3479.pdf">3479</a></td><td style="text-align:left">Adaptive Shape Servoing of Elastic Rods using Parameterized Regression Features and Auto-Tuning Motion Controls</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3480.pdf">3480</a></td><td style="text-align:left">Automatic Shape Control of Deformable Rods Based on Data-Driven Implicit Sensorimotor Models</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3481.pdf">3481</a></td><td style="text-align:left">Assembly Strategy for Deformable Ring-Shaped Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3482.pdf">3482</a></td><td style="text-align:left">MGSD: Multi-Modal Gaussian Shape Descriptors for Correspondence Matching of Linear and Planar Deformable Objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3494.pdf">3494</a></td><td style="text-align:left">Dual-armed manipulation planning for tethered tools</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3495.pdf">3495</a></td><td style="text-align:left">Prediction of tactile perception from vision on deformable objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3496.pdf">3496</a></td><td style="text-align:left">Shape control of elastoplastic deformable linear objects through reinforcement learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3497.pdf">3497</a></td><td style="text-align:left">Interaction identification through tactile sensing during cloth manipulation using a 3-axis touch sensor</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3498.pdf">3498</a></td><td style="text-align:left">Toward a general framework for 3D deformable object grasping and manipulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3499.pdf">3499</a></td><td style="text-align:left">Experimental multi-camera setup for perception of dynamic objects</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3500.pdf">3500</a></td><td style="text-align:left">Real-time state estimation of deformable objects with dynamical simulation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3601.pdf">3601</a></td><td style="text-align:left">Human-Robot Collaborative Carrying Using Visual and Force Sensing</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3622.pdf">3622</a></td><td style="text-align:left">Toward Detecting Anomalies in Activities for Daily Living with a Mobile Robot Using Plan Recognition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3623.pdf">3623</a></td><td style="text-align:left">Human-Aware Robot Behavior in Healthcare Facilities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3624.pdf">3624</a></td><td style="text-align:left">An Interactive Drink Serving Social Robot: Initial System Implementation</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3625.pdf">3625</a></td><td style="text-align:left">Towards Whole Arm Manipulation for Outpatient Care</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3626.pdf">3626</a></td><td style="text-align:left">Morphological Switching Robots to Support Independent Living for Older Adults</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3627.pdf">3627</a></td><td style="text-align:left">Towards Conversational Interfaces and Visual Memory Representation for Social Robots helping the Elderly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3628.pdf">3628</a></td><td style="text-align:left">On New Research Guidelines for the Deployment of Socially Assistive Robots for Elder Care Amidst the COVID-19 Pandemic</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3629.pdf">3629</a></td><td style="text-align:left">Towards Physical Human-Robot Interaction using Force Support for Nursing Care Bed Activities</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3712.pdf">3712</a></td><td style="text-align:left">Service robot teaching assistant in school class-room</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3713.pdf">3713</a></td><td style="text-align:left">Infant abnormal behavior classification through weakly supervised learning</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3714.pdf">3714</a></td><td style="text-align:left">Amusing Androids: The Argument for Humour in Healthcare Robotics</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3715.pdf">3715</a></td><td style="text-align:left">Towards Explainable Diagnosis of Alzheimer’s</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3716.pdf">3716</a></td><td style="text-align:left">VOTE400(Voide Of The Elderly 400 Hours): A Speech Dataset to Study Voice Interface for Elderly-Care</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3717.pdf">3717</a></td><td style="text-align:left">Toward a Reinforcement Learning Based Framework for Learning Cognitive Empathy in Human-Robot Interactions</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3718.pdf">3718</a></td><td style="text-align:left">Improve identity recognition with occlusion detection-based feature selection</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3719.pdf">3719</a></td><td style="text-align:left">ETRI Activity3D: A Large Scale RGB D Dataset for Robots to Recognize Daily Activities of the Elderly</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3720.pdf">3720</a></td><td style="text-align:left">Deep Emotion Change Detection for Human-robot Interaction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3721.pdf">3721</a></td><td style="text-align:left">Efficiency Analysis of Multi-Head Attention Models for Social Dynamics Prediction</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3722.pdf">3722</a></td><td style="text-align:left">Leveraging Reinforcement Learning for Human Motor Skill Acquisition</td></tr><tr><td style="text-align:center"><a href="https://ras.papercept.net/proceedings/IROS20/3723.pdf">3723</a></td><td style="text-align:left">Efficient Learning of Socially Aware Robot Approaching Behavior Toward Groups via Meta-Reinforcement Learning</td></tr></tbody></table></div>]]></content>
      
      
      
        <tags>
            
            <tag> IROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS state论文(1)</title>
      <link href="/2022/01/03/ps-state-lun-wen-1/"/>
      <url>/2022/01/03/ps-state-lun-wen-1/</url>
      
        <content type="html"><![CDATA[<p>对应文章地址：<a href="https://ieeexplore.ieee.org/document/8258883">Aggressive Flight With Suspended Payloads Using Vision-Based Control | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>绳载负载的四旋翼系统的非线性动力学轨迹执行完全通过<strong>动作捕捉系统</strong>实现，或者将系统限制在<strong>二维空间</strong>或者仅建立四旋翼的闭环控制但是<strong>不建立负载的闭环控制</strong>从而对系统进行简化（这种简化是不可忽视）。</p><p>针对上述问题，本文用向下的摄像机观察负载，利用<strong>扩展卡尔曼滤波器</strong>估计其相对于四旋翼的状态。</p><h2 id="动力学模型与控制设计"><a href="#动力学模型与控制设计" class="headerlink" title="动力学模型与控制设计"></a>动力学模型与控制设计</h2><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gy0rmkb4vsj30un0ecafj.jpg" alt="文中定义的变量与参数"></p><p>动力学模型与控制器与<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load | IEEE Conference Publication | IEEE Xplore</a>一样。</p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1gy0rbmer5ij30nm06f75o.jpg" alt="控制器结构与传感器反馈"></p><h2 id="负载状态估计"><a href="#负载状态估计" class="headerlink" title="负载状态估计"></a>负载状态估计</h2><p>控制器需要精确的负载状态测量。我们使用向下的摄像机检测负载，并使用扩展卡尔曼滤波器(EKF)对测量值进行滤波，得出高频、动态的估计结果。</p><p>无人机的滚动角和俯仰角以及角速度通过无人机上的IMU（惯性测量单元）获得，无人机的偏航角通过Vicon动作捕捉系统获得。对于负载姿态控制环，我们设计了一种EKF来融合IMU和Vicon的偏航角测量结果（无人机的测量结果）与机载相机的图像（负载测量结果），从而估计出<em>p</em>以及其导数。再通过公式（1）结合负载位置$x_L$以及无人机位置$x_Q$以实现有效负载的位置闭环控制。</p>$$-T \mathbf{p}=m_{L}\left(\ddot{\mathbf{x}}_{L}+g \mathbf{e}_{z}^{\mathcal{I}}\right),\mathbf{p}=-\frac{\left(\ddot{\mathbf{x}}_{L}+g \mathbf{e}_{z}^{\mathcal{I}}\right)}{\left\|\ddot{\mathbf{x}}_{L}+g \mathbf{e}_{z}^{\mathcal{I}}\right\|_{2}}, x_Q = x_L− lp \tag{1}$$<p>下图描述了估计出<em>p</em>以及其导数的流程图</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy0rqxchglj315103jwfg.jpg" alt="负载状态估计流程图"></p><h3 id="A-观测器"><a href="#A-观测器" class="headerlink" title="A 观测器"></a>A 观测器</h3><p>本文通过<strong>黑白圆形标记</strong>检测负载<a href="https://ieeexplore.ieee.org/abstract/document/4059340">A Toolbox for Easily Calibrating Omnidirectional Cameras | IEEE Conference Publication | IEEE Xplore</a>。如下图（a）所示。从而可以得到标记的像素位置$x_u  = [u, v]^T$。<strong>该系统具有亚像素精度，对可变光照条件具有鲁棒性，并且需要相对较少的处理时间。</strong></p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gy0rs2thnsj310p0jdwms.jpg" alt="(a)硬件组件 (b)实验架构"></p><h3 id="B-相机模型"><a href="#B-相机模型" class="headerlink" title="B 相机模型"></a>B 相机模型</h3><p>本文利用全向模型来建模相机<a href="https://ieeexplore.ieee.org/abstract/document/4059340">A Toolbox for Easily Calibrating Omnidirectional Cameras | IEEE Conference Publication | IEEE Xplore</a>。像素坐标中标记中心之间的仿射变换$x_u  = [u, v]^T$以及调整过的像素坐标$\mathbf{x}_{u^{\prime}}=\left[u^{\prime}, v^{\prime}\right]^T$,是由于相机传感器错位造成的。摄像机到负载的矢量在摄像机坐标系内为:</p>$$\mathbf{n}^{\mathcal{C}}=\left[\begin{array}{c}n_{x} \\ n_{y} \\ n_{z}\end{array}\right] \approx \lambda\left[\begin{array}{c}u^{\prime} \\ v^{\prime} \\ f\left(u^{\prime}, v^{\prime}\right)\end{array}\right] $$<p>其中因子λ代表了量化的模糊度，将成像函数$f\left(u^{\prime}, v^{\prime}\right)$表示为$ρ :=\sqrt {u^2 + v^2}$的泰勒级数：</p>$$f\left(u^{\prime}, v^{\prime}\right)=f(\rho)=a_{0}+a_{1} \rho+a_{2} \rho^{2}+\ldots+a_{N} \rho^{N}$$<p>其中<em>N</em>为调整得到的，仿射变换和$a_0，…， a_N$是在校准时确定的。从而得到了$\mathbf{n}^{\mathcal{C}}$。</p><h3 id="C-缆绳长度约束"><a href="#C-缆绳长度约束" class="headerlink" title="C 缆绳长度约束"></a>C 缆绳长度约束</h3><p>如下图所示，我们可以得到在缆绳有拉力的假设下存在：</p>$$\mathbf{x}_{L}^{\mathcal{B}}=l \mathbf{p}^{\mathcal{B}}=\mathbf{x}_{C}^{\mathcal{B}}+d \mathbf{R}_{\mathcal{C}}^{\mathcal{B}} \mathbf{n}^{\mathcal{C}} \tag{2}$$$\mathbf{x}_{L}^{\mathcal{B}}$和$\mathbf{x}_{C}^{\mathcal{B}}$分别为机体坐标系下的负载位置和相机位置。$\mathbf{R}_{\mathcal{C}}^{\mathcal{B}}$为相机坐标系到机体坐标系的旋转矩阵。通过$\mathbf{x}_{C}^{\mathcal{B}}$已知，我们可以通过如下公式计算得到*d*，从而通过公式2可以计算得到负载相对于无人机的位置。$$l=\left|\mathbf{x}_{C}^{\mathcal{B}}+d \mathbf{n}^{\mathcal{B}}\right|$$<p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gy0rn217bgj30ly0gj0v8.jpg" alt="四旋翼，有效载荷和机载相机以及惯性坐标系，机体坐标系和相机坐标系。"></p><h3 id="D-基于模型的估计器"><a href="#D-基于模型的估计器" class="headerlink" title="D 基于模型的估计器"></a>D 基于模型的估计器</h3><p>为了进行估计，我们考虑一个具有状态的系统:</p>$$\mathbf{X}=\left[\mathbf{p}^{\top} \dot{\mathbf{p}}^{\top}\right]^{\top}$$<p>其中p以及其导数存在于惯性坐标系中，以及系统输入为</p>$$\mathbf{U}=\left[f\;\boldsymbol{R}\; \boldsymbol{\Omega}^{\top}\right]^{\top}$$<p>我们将过程噪声建模为加性高斯白噪声$N \in {\mathbb{R}^6}$，其均值为零，其标准差为$Q \in {\mathbb{R}^{6,6}}$。得到的过程模型是</p>$$\begin{aligned} \dot{\mathbf{X}} &amp;=\left[\begin{array}{l}\dot{\mathbf{p}} \\ \ddot{\mathbf{p}}\end{array}\right]=\mathbf{f}(\mathbf{X}, \mathbf{U}, \mathbf{N}), \quad \mathbf{N} \sim \mathcal{N}(0, \mathbf{Q}), \\ &amp;=\left[\begin{array}{c}\dot{\mathbf{p}} \\ \frac{1}{m_{Q} l} \mathbf{p} \times\left(\mathbf{p} \times f \mathbf{R e}_{3}\right)-(\dot{\mathbf{p}} \cdot \dot{\mathbf{p}}) \mathbf{p}\end{array}\right]+\mathbf{N} . \end{aligned} \tag{3}$$<p>已经在本文的A到C节中获得了机体坐标系中负载位置$\mathbf{x}_{L}^{\mathcal{B}}$以及其对应的数值离散时间导数${\mathbf{\dot x}}_L^\mathcal{B}$。其对应的测量模型为：</p>$$\begin{aligned} \mathbf{Z} &amp;=\left[\begin{array}{l}\mathbf{x}_{L}^{B} \\ \dot{\mathbf{x}}_{L}^{B}\end{array}\right]=\mathbf{g}(\mathbf{X}, \mathbf{U}, \mathbf{V}), \quad \mathbf{V} \sim \mathcal{N}(0, \mathbf{S}), \\ &amp;=\left[\begin{array}{c}\mathbf{R}^{\top} l \mathbf{p} \\ l\left(\mathbf{R}^{\top} \dot{\mathbf{p}}-\boldsymbol{\Omega} \times\left(\mathbf{R}^{\top} \mathbf{p}\right)\right)\end{array}\right]+\mathbf{V} . \end{aligned} \tag{4}$$<p>其中加性高斯白噪声为$V \in {\mathbb{R}^6}$，其均值为零，其标准差为$S \in {\mathbb{R}^{6,6}}$。</p><p><strong>从而有公式（3）和（4）构成了标准卡尔曼滤波器中的考虑高斯白噪声的非线性系统。</strong></p><p>注意，我们也用无坐标的方式表示EKF。当相机测量频率较低时，EKF利用动态模型估计IMU测量速率较高时的状态。当收到新的IMU测量数据时，我们会使用最新的控制输入和偏航j角测量数据进行流程更新。当接收到新的原始图像时，我们缓存当前状态估计以及之后的IMU、Vicon偏航角测量值、控制输入。在$\mathbf{x}_{L}^{\mathcal{B}}$和其导数被计算后，我们对第一个被缓存的状态估计进行测量更新，并重新计算过程更新，以考虑图像处理延迟。</p><blockquote><p><a href="https://blog.csdn.net/gangdanerya/article/details/105105611"> 扩展卡尔曼滤波（EKF）算法详细推导及仿真（Matlab)</a></p></blockquote><h2 id="轨迹生成"><a href="#轨迹生成" class="headerlink" title="轨迹生成"></a>轨迹生成</h2><p>我们通过优化负载轨迹$\mathbf{x}_{L, \text { des }} \in \mathbb{R}^{3}$来规划系统的轨迹。为了实现动态可行性，轨迹必须至少具有6阶段可微性以及5次函数，输入中出现的最高导数为$x^{(6)}_L$(输入M（四旋翼在固定机体坐标系中的力矩矢量）为负载位置的6阶导数)，对应的成本函数为：</p>$$\mathbf{x}_{L, \text { des }}=\arg \min _{\mathbf{x}_{L}} \int_{0}^{t_{m}}\left\|\mathbf{x}_{L}^{(6)}\right\|_{2}^{2} d t \tag{5}$$<p>欧拉-拉格朗日条件得到以下条件:</p>$$x^{(12)}_L= 0$$ <p>它的解是一个11阶多项式。因此，最优负载轨迹采用分段多项式的形式:</p>$$\mathbf{x}_{L, d e s}=\left\{\begin{array}{cc}\mathbf{x}_{L, d e s, 1}=\sum_{i=0}^{11} c_{i, 0} t^{i} &amp; t_{0} \leq t \leq t_{1} \\\mathbf{x}_{L, d e s, 2}=\sum_{i=0}^{11} c_{i, 1} t^{i} &amp; t_{1}<t \leq="" t_{2}="" \\="" \ldots="" &="" \mathbf{x}_{l,="" d="" e="" s,="" m}="\sum_{i=0}^{11}" c_{i,="" m-1}="" t^{i}="" t_{m-1}<t="" t_{m},="" \end{array}\right.$$="" <p="">其中 $\mathcal{T}=\left\{t_{0}, \ldots, t_{m}\right\}$ 为事先决定的中断时间， $\mathbf{x}_{L, \text { des }}$ 为向量函数。 考虑到决策向量<p></p>$\mathbf{c}=\left[\begin{array}{lllll}c_{0,0} &amp; c_{1,0} &amp; c_{2,0} &amp; \ldots &amp; c_{N, m-1}\end{array}\right]^{\top}$<p>公式(5) 是关于c的正定二次函数，为了实现动力学可行性，我们施加连续性约束:</p>$$\mathbf{x}_{L, d e s, j}^{(k)}\left(t_{j}\right)=\mathbf{x}_{L, d e s, j+1}^{(k)}\left(t_{j}\right) \forall j \in[0,5], k \in[1, m-1] .\tag{6}$$<p>为了确保系统开始和结束于悬停，我们强制:</p>$$\mathbf{x}_{L, d e s}^{(k)}\left(t_{j}\right)=\mathbf{0} \forall j \in\{0, m\}, k \in[1,5] \text {. } \tag{7}$$<p>注意到上式中对应与状态的平坦微分$\mathbf{p}= -\mathbf{e}_{z}^{\mathcal{T}}, \mathbf{R}=\mathcal{I}, \dot{\mathbf{p}}=\Omega=0$。最终我们确定需要穿过的路径点$x_{L,j}$为</p>$$\mathbf{x}_{L, d e s}\left(t_{j}\right)=\mathbf{x}_{L, j} \forall j \in[0, m] \tag{8}$$<p>上述约束（6-8）对于<em>c</em>是线性的。利用式(5)和式(6)-(8)，我们得到了一个二次规划问题(QP)，可以用商业优化软件进行求解。</p><p>有一种可能性，优化轨迹违反了我们的系统中的缆绳是拉紧的假设。由公式(1)得到，保证${\ddot x_L}{e_z} &gt; {\rm{ - }}g$就可以使T &gt;0。为了保证缆绳是拉紧的假设，我们首先通过求解初始T的QP问题来求得所需的轨迹系数。然后，我们通过选择αT来调整轨迹中断时间，使${\ddot x_L}{e_z} &gt; {\rm{ - }}g$。</p><blockquote><p><a href="https://ieeexplore.ieee.org/document/5980409">Minimum snap trajectory generation and control for quadrotors | IEEE Conference Publication | IEEE Xplore</a>证明了中断时间T是可以调整但是不影响轨迹路线的（Nondimensionalization无量钢化）。</p></blockquote><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>无人机总质量为835 g，负载质量为88 g，缆绳长度为0.4 ~ 0.7 m。</p></t>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
            <tag> 负载状态 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS论文（5）</title>
      <link href="/2022/01/02/ps-lun-wen-5/"/>
      <url>/2022/01/02/ps-lun-wen-5/</url>
      
        <content type="html"><![CDATA[<p>文章地址：<a href="https://ieeexplore.ieee.org/document/6631275">Trajectory generation and control of a quadrotor with a cable-suspended load - A differentially-flat hybrid system | IEEE Conference Publication | IEEE Xplore</a>+<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load | IEEE Conference Publication | IEEE Xplore</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>考虑了一种具有8自由度并且存在4自由度欠驱动的绳载负载的四旋翼飞行器，将其建立为微分平坦混合动力系统。利用平坦特性，提出了一种轨迹生成方法，该方法能够找到具有各种约束的标称轨迹，这些轨迹不仅能在需要时产生最小的载荷摆动，而且还能在动态敏捷运动中引起较大的负载摆动。本文提出了一种控制器设计，专门用于平面情况下的系统，使其跟踪四旋翼姿态，负载姿态或负载位置。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>希望无人机最小化负载摆动的需求是显然易见的，但是我们也希望能使负载也能产生较大的负载摆动。</p><p>即针对如下两种情况：</p><p>a）为了使无人机携带绳载负载进入/退出窄口(如窗户)，载荷需要动态摆动进入窄口，从而使在正确的时间点，缆绳的张力为零，使得无人机能够在缆绳的张力重新出现之前在负载经历自由落体时穿过窗户。</p><p>b）为了使无人机能够在严格的天花板高度限制下飞行时运输悬浮载荷，且避免雷达探测或在室内飞行时，需要载荷的动态运动，以避免地面上的大型障碍物。</p><p>需要实现绳载负载的无人机系统的如下功能：实现具有大振荡相位的负载轨迹，以及在有限的持续时间内，当缆绳中的张力趋于零时，并使用适当设计的反馈控制器跟踪轨迹。</p><h2 id="动力学模型"><a href="#动力学模型" class="headerlink" title="动力学模型"></a>动力学模型</h2><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gxzjir4np1j30n90ebta7.jpg" alt="图1.(a)绳载负载的无人机在3d空间的表现(b)绳载负载的无人机在2d平面的表现"></p><p><img src="https://tva3.sinaimg.cn/large/007mx13gly1gxzjpcev2uj30ie0gln29.jpg" alt="本文中定义的参数"></p><h3 id="非零张力的动力学模型"><a href="#非零张力的动力学模型" class="headerlink" title="非零张力的动力学模型"></a>非零张力的动力学模型</h3><p>如图1（a）四旋翼位置 $x_Q$ 和负载位置 $x_L$ 由如下公式联系，其中<em>L</em>为绳长，<em>p</em>为四旋翼指向负载的单位向量</p> $$x_Q=x_L-Lp\tag{1}$$ <p>四旋翼在绳载负载作用下的动力学方程为:</p> $$\dot{x}_{L}=v_{L}$$  $$\left(m_{Q}+m_{L}\right)\left(\dot{v}_{L}+g e_{3}\right)=\left(p \cdot f R e_{3}-m_{Q} L(\dot{p} \cdot \dot{p})\right) p$$  $$\dot{p}=\omega \times p$$  $$m_{Q} L \dot{\omega}=-p \times f R e_{3}$$  $$\dot{R}=R \hat{\Omega}$$  $$J_{Q} \dot{\Omega}+\Omega \times J_{Q} \Omega=M .\tag{2}$$ <p>为建立混合模型，上述动力学可以表示为标准形式$\dot{X}_{1}=f_{1}\left(X_{1}\right)+g_{1}\left(X_{1}\right) u$ ，其中$X_{1}=\left\{x_{L}, q, R, v_{L}, \omega, \Omega\right\}$  为状态，$u=\{f, M\}$  为系统的输入</p><p>注1:四旋翼姿态动力学分别与负载姿态和位置动力学解耦，而负载姿态动力学与负载位置动力学解耦。重力不影响负载姿态动力学。</p><p>注2：载荷姿态动力学(8)也可以直接写成载荷姿态 $p∈S^2$ ，其导数被表示为:</p>$m_{Q} L \ddot{p}+m_{Q} L(\dot{p} \cdot \dot{p}) p=p \times\left(p \times f \operatorname{Re}_{3}\right)$ <h3 id="零张力的动力学模型"><a href="#零张力的动力学模型" class="headerlink" title="零张力的动力学模型"></a>零张力的动力学模型</h3><p>四旋翼和负载作为独立的系统，负载呈自由落体状态。（两个系统都是微分平坦的）对应的动力学模型为</p> $$\dot{x}_{L}=v_{L}$$  $$m_{L}\left(\dot{v}_{L}+g e_{3}\right)=0$$ , $$\dot{x}_{Q}=v_{Q}$$ , $$m_{Q}\left(\dot{v}_{Q}+g e_{3}\right)=f R e_{3}$$ , $$\dot{R}=R \hat{\Omega}$$ , $$J_{Q} \dot{\Omega}+\Omega \times J_{Q} \Omega=M .\tag{3}$$ <p>为建立混合模型，上述动力学可以表示为标准形式$\dot{X}_{2}=f_{2}\left(X_{1}\right)+g_{2}\left(X_{2}\right) u$ ，其中$X_{2}=\left\{x_{L}, q, R, v_{L}, \omega, \Omega\right\}$  为状态，$u=\{f, M\}$  为系统的输入</p><h3 id="专门针对平面的动力学模型"><a href="#专门针对平面的动力学模型" class="headerlink" title="专门针对平面的动力学模型"></a>专门针对平面的动力学模型</h3><p>如图1（b）， $φ_L$ 为负载的滚转角， $φ_Q$ 为四旋翼的滚转角，<em>p</em>和旋转矩阵<em>R</em>定义如下</p> $$p=\left[\begin{array}{c}\sin \left(\phi_{L}\right) \\ -\cos \left(\phi_{L}\right)\end{array}\right], \quad R=\left[\begin{array}{cc}\cos \left(\phi_{Q}\right) &amp; -\sin \left(\phi_{Q}\right) \\ \sin \left(\phi_{Q}\right) &amp; \cos \left(\phi_{Q}\right)\end{array}\right] \tag{3}$$ <p>由公式（2）得到的平面动力学方程为：</p> $$\left(m_{Q}+m_{L}\right)\left(\dot{v}_{L}+g e_{3}\right)=\left(f \cos \left(\phi_{Q}-\phi_{L}\right)-m_{Q} l \dot{\phi}_{L}^{2}\right) p$$  $$m_{Q} l \ddot{\phi}_{L}=\sin \left(\phi_{Q}-\phi_{L}\right)$$  $$J_{Q} \ddot{\phi}_{Q}=M$$ <h2 id="微分平坦性"><a href="#微分平坦性" class="headerlink" title="微分平坦性"></a>微分平坦性</h2><blockquote><p>如果存在一组平坦输出，系统的状态和输入可以表示为平坦输出及其高阶导数的平滑函数，则系统是微分平坦的。</p></blockquote><p>本文采用微分平面度法对四旋翼系统进行了动态轨迹规划，本文证明了具有缆索悬挂负载的四旋翼是微分平坦的，而且它是一个定义如下的微分平坦混合系统。</p> $$\Sigma: \begin{cases}\dot{x}_{1}=f_{1}\left(x_{1}\right)+g_{1}\left(x_{1}\right) u_{1}, &amp; x_{1} \notin \mathcal{S}_{1} \\ x_{2}^{+}=\Delta_{1}\left(x_{1}^{-}\right), &amp; x_{1}^{-} \in \mathcal{S}_{1} \\ \dot{x}_{2}=f_{2}\left(x_{2}\right)+g_{2}\left(x_{2}\right) u_{2}, &amp; x_{2} \notin \mathcal{S}_{2} \\ x_{1}^{+}=\Delta_{2}\left(x_{2}^{-}\right), &amp; x_{2}^{-} \in \mathcal{S}_{2},\end{cases} \tag{4}$$ <p>假设 $x_1,  x_2$ 的动力学是微分平坦的，分别有一个平坦的输出 $y_1,y_2$ 。输出 $y_2$ 的过渡后值是平坦输出 $y_1 $ 的过渡前值及其高阶导数的函数，则系统Σ是微分平坦混合系统。</p><p>为了表明由四旋翼和缆索悬挂载荷组成的系统是微分平坦的，我们将看由Newton-Euler推导出的动力学运动方程，从而系统的内部约束力（对应于缆索中的张力）被引入了。如图1a，运动方程可以写成公式（5）， <em>T</em>为缆绳的张力。</p> $$m_{Q} \ddot{x}_{Q}=f R e_{3}-m_{Q} g e_{3}+T p$$  $$J \dot{\Omega}+\Omega \times J \Omega=M$$  $$m_{L} \ddot{x}_{L}=-T p-m_{L} g e_{3}\tag{5}$$ <p>定理1： $y_1 = (x_L,ψ)$ 是上述系统的平坦输出，其中 $ψ∈R$ 是四旋翼飞行器的偏航角。</p><p>证明：由公式（5）可以得到单位向量<em>p</em>，从而由公式（1）可以得到四旋翼无人机的位置 $x_Q$ 。而 $(x_Q,ψ)$ 为四旋翼无人机的平坦输出，则 $y_1 = (x_L,ψ)$ 是上述系统的平坦输出。<em>（仅当缆绳绷紧时成立，拉力为零时不成立）</em></p><p>注2:输入M（四旋翼在固定机体坐标系中的力矩矢量）由负载位置的6阶导数求得。</p><h2 id="控制器设计（Geometric-control-and-differential-flatness-of-a-quadrotor-UAV-with-a-cable-suspended-load）"><a href="#控制器设计（Geometric-control-and-differential-flatness-of-a-quadrotor-UAV-with-a-cable-suspended-load）" class="headerlink" title="控制器设计（Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load）"></a>控制器设计（Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load）</h2><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gy0omg7ig2j30lq0guafj.jpg" alt="Geometric...文章中符号的定义"></p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1gy0onuqse8j30n407fq4r.jpg" alt="用于跟踪负载位置的控制器结构"></p><p>控制器中的误差项的定义如下</p>$$\begin{aligned} e_{R} &amp;=\frac{1}{2}\left(R_{d}^{T} R-R^{T} R_{d}\right)^{\vee} \\ e_{\Omega} &amp;=\Omega-R^{T} R_{d} \Omega_{d} \end{aligned}$$$$\begin{aligned} e_{q} &amp;=\hat{q}^{2} q_{d} \\ e_{\dot{q}} &amp;=\dot{q}-\left(q_{d} \times \dot{q}_{d}\right) \times q \end{aligned}$$$$e_{x}=x-x_{d}$$$$e_{v}=v-v_{d}$$<p>四旋翼力矩定义如下：</p>$$\begin{aligned} M=&amp;-\frac{1}{\epsilon^{2}} k_{R} e_{R}-\frac{1}{\epsilon} k_{\Omega} e_{\Omega}+\Omega \times J_{Q} \Omega \\ &amp;-J_{Q}\left(\hat{\Omega} R^{T} R_{d} \Omega_{d}-R^{T} R_{d} \dot{\Omega}_{d}\right) \end{aligned}$$<p>四旋翼的姿态定义如下</p>$$R_{c}:=\left[b_{1_{c}} ; b_{3_{c}} \times b_{1_{c}} ; b_{3_{c}}\right], \quad \hat{\Omega}_{c}=R_{c}^{T} \dot{R}_{c}$$$$b_{3_{c}}=\frac{F}{\|F\|},$$<p>其中，</p>$$F=F_{n}-F_{p d}-F_{f f},$$$$\begin{array}{r}F_{n}=-\left(q_{d} \cdot q\right) q \\F_{p d}=-k_{q} e_{q}-k_{\omega} e_{\dot{q}} \\F_{f f}=m_{Q} l\left\langle q, q_{d} \times \dot{q}_{d}\right\rangle(q \times \dot{q})+m_{Q} l\left(q_{d} \times \ddot{q}_{d}\right) \times q .\end{array}$$$$b_{1_{c}}=-\frac{1}{\left\|b_{3_{c}} \times b_{1_{d}}\right\|}\left(b_{3_{c}} \times\left(b_{3_{c}} \times b_{1_{d}}\right)\right) .$$$$f=F \cdot R e_{3},$$<p>负载的姿态定义如下：</p>$$q_{c}=-\frac{A}{\|A\|}$$$$A=-k_{x} e_{x}-k_{v} e_{v}+\left(m_{Q}+m_{L}\right)\left(\ddot{x}_{L}^{d}+g e_{3}\right)+m_{Q} l(\dot{q} \cdot \dot{q}) q,$$<h2 id="控制器设计（Trajectory-Generation-and-Control-of-a-Quadrotor-with-a-Cable-Suspended-Load–-A-Differentially-Flat-Hybrid-System）"><a href="#控制器设计（Trajectory-Generation-and-Control-of-a-Quadrotor-with-a-Cable-Suspended-Load–-A-Differentially-Flat-Hybrid-System）" class="headerlink" title="控制器设计（Trajectory Generation and Control of a Quadrotor with a Cable-Suspended Load– A Differentially-Flat Hybrid System）"></a>控制器设计（Trajectory Generation and Control of a Quadrotor with a Cable-Suspended Load– A Differentially-Flat Hybrid System）</h2><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gxznhn7qvbj30yd08kwgy.jpg" alt="用于跟踪负载位置的控制器结构"></p><p>上述控制器可以跟踪(a) 无人机姿态,(b)负载姿态,或(c)负载位置</p><p>四旋翼力矩定义如下：</p> $$M=J_{Q}\left(-k_{p}^{Q} e_{Q}-k_{d}^{Q} \dot{e}_{Q}+\ddot{\phi}_{Q}^{d}\right)$$ <p>其中， $e_Q =φ_Q−φ^d_Q$ 为跟踪期望的四旋翼姿态的误差。</p><p>四旋翼姿态定义如下：</p> $$\phi_{Q}^{c}:=\phi_{L}+\sin ^{-1}\left(-k_{p}^{L} e_{L}-k_{d}^{L} \dot{e}_{L}+\frac{\ddot{\phi}_{L}^{d} m_{Q} l}{f}\right)$$ <p>其中， $e_L =φ_L−φ^d_L$ 为跟踪期望负载姿态的误差。</p><p>四旋翼推力和期望负载姿态定义如下：</p> $$f=(A+B) \cdot R e_{3}$$  $$p_{d}=-\frac{A}{\|A\|} \Longrightarrow \phi_{L}^{d}=\tan ^{-1}\left(\frac{-A_{1}}{A_{2}}\right)$$ <p>其中，A，B定义如下， $A_1,A_2$ 为A的分量。</p> $$\begin{aligned} A &amp;=-k_{p}^{x} e_{x}-k_{d}^{x} \dot{e}_{x}+m_{L} \ddot{x}_{L}^{d}+m_{L} g e_{3} \\ B &amp;=m_{Q} \ddot{x}_{Q}^{d}+m_{Q} g e_{3} \\ &amp;=m_{L} \ddot{x}_{L}^{d}-m_{Q} l \ddot{p}^{d}+m_{Q} g e_{3} \end{aligned}$$ <p>其中 $e_{x}=x_{L}-x_{L}^{d}, e_{v}=\dot{e}_{x}$ 为跟踪期望的负载位置的误差。</p><blockquote><p>可以看出Trajectory …的控制器只是把Geometric…中的用旋转矩阵以及角速度表示的四旋翼姿态用更简单更直接的四旋翼姿态角表示，更方面在实际的控制器设计中实现。</p></blockquote><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>我们首先讨论了轨迹生成，然后介绍了反馈控制跟踪的结果（见原文）。</p><p>我们选择一个合适的基函数将每个平坦输出参数化为时间的函数。在初始状态和最终状态的约束下，求解基多项式的系数以最小化负载位置的六阶导数。将负载位置的六阶导数最小化，确保四旋翼的快速运动最小。即我们需要对如下公式求解：</p> $$\min \int_{t_{0}}^{t_{1}}\left\|\frac{d^{k} x_{i}}{d t^{k}}\right\|^{2} d t$$ <p>其中$x_{i}(t)=\Sigma_{j=0}^{n} c_{i, j} \beta_{j}(t)$是参数化的平面输出。而$\beta_{j}(t)$</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gy092gqe2ej308o0c9q6k.jpg" alt="四旋翼与负载配备了Vicon标记，以便能够感知它们的位置和姿态以进行反馈控制。缆绳长度1m，负载90gm。"></p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS论文(4)</title>
      <link href="/2021/11/17/ps-lun-wen-4/"/>
      <url>/2021/11/17/ps-lun-wen-4/</url>
      
        <content type="html"><![CDATA[<p>文章地址：<a href="https://ieeexplore.ieee.org/abstract/document/7946750">Dynamics and control of a quadrotor with a cable suspended payload | IEEE Conference Publication | IEEE Xplore</a></p><p>本文为PS论文笔记(3)中的动力学基础。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>研究了绳载负载的四旋翼飞行器的动力学与控制问题。</p><p>系绳点偏离四旋翼飞行器质心的负载称为偏离中心的悬挂负载。利用 Kane方法的矩阵形式，得到了运动方程。该系统被分解为旋转子系统和平动子系统。通过利用系统的部分线性化，开发了一种非线性控制器来实现四旋翼的镇定。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>大多数控制器设计仍然局限于系绳点与四旋翼质心重合的构型。我们将该配置表示为居中有效负载配置。在本文中，偏心配置是指系绳点远离质心的情况。对于某些四旋翼无人机，负载配置在质心在机械上是不可行的，因为质心可能位于无人机内部。从而将系绳点固定质心上是非常困难的，此外，精确的坐标测量是困难的，因此一个偏离中心的系绳点是不可避免的。然而，对于偏心系绳构型的非线性控制器的研究还不够全面。主要难点在于偏离中心的载荷运动与四旋翼的旋转运动耦合，使得建模和控制难以推导。针对现有控制器的不足之处，研究了四旋翼飞行器偏心悬索载荷的动力学和控制问题。</p><p>本文的贡献在于两部分:利用Kane方法对偏置无人机有效载荷系统进行建模，利用模型分解进行非线性控制设计。</p><p>常用的拉格朗日方法是对无人机负载系统进行建模的常用方法。在偏心系绳构型下，载荷运动与四旋翼旋转耦合，载荷的动能包含四旋翼平动速度、旋转速度和载荷摆动速度，这使得拉格朗日法存在复杂性的后续微分。另一方面，利用偏导速度概念和D’Alembert’s原理发展的kane方法避免了对约束方程和系统拉格朗日函数的二阶微分，因此可以在没有符号计算工具箱的情况下用于推导动力学方程的显式形式。最后，凯恩方法的本质是外力和D’Alembert’s惯性力的力平衡在由偏导速度矩阵零空间上的投影，这给我们提供了一种简洁的使用矩阵形式的kane方法来建模存在偏心负载的绳载负载的四旋翼系统的。</p><p>在<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load | kumar</a>、<a href="https://ieeexplore.ieee.org/abstract/document/5717652">Geometric tracking control of a quadrotor UAV on SE(3) |</a>的基础上，提出了一种姿态稳定控制方法，通过改变四旋翼升力矢量的方向来控制其平动和载荷运动。</p><h2 id="2-具有偏心绳载负载的四旋翼飞行器动力学模型"><a href="#2-具有偏心绳载负载的四旋翼飞行器动力学模型" class="headerlink" title="2 具有偏心绳载负载的四旋翼飞行器动力学模型"></a>2 具有偏心绳载负载的四旋翼飞行器动力学模型</h2><h3 id="A-矩阵形式的kane方程"><a href="#A-矩阵形式的kane方程" class="headerlink" title="A 矩阵形式的kane方程"></a>A 矩阵形式的kane方程</h3><p>kane法见<a href="https://www.lukesy.net/docs/self-study/kane-dynamics/">Dynamics Theory and Applications – Thomas Kane and David Levinson | Luke Sy, PhD Candidate</a>。</p><p>本文中的变量见表1</p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1gwij3z2l3gj30gz0im0wq.jpg" alt=""></p><p>表1</p><div class="table-container"><table><thead><tr><th><em>V</em></th><th>机体坐标系</th></tr></thead><tbody><tr><td><em>I</em></td><td>惯性坐标系</td></tr><tr><td>${R_{vi}}$</td><td>由惯性坐标系转换为机体坐标系的旋转矩阵</td></tr><tr><td>$m_q$</td><td>四旋翼质量</td></tr><tr><td><em>m</em></td><td>负载质量</td></tr><tr><td>$J_v$(3维实矩阵)</td><td>四旋翼转动惯量</td></tr><tr><td><em>L</em></td><td>缆绳长度</td></tr><tr><td>$g_i$</td><td>惯性坐标系下的重力加速度</td></tr><tr><td>$r_v^{tv}$(长度为3的实向量)</td><td>系绳点相对于四旋翼质心的偏移量</td></tr><tr><td>$r_v^{pv}$(长度为3的实向量)</td><td>负载在机体坐标系中的位置</td></tr><tr><td>$v_v^{pv}$(长度为3的实向量)</td><td>负载在机体坐标系中的速度</td></tr><tr><td>${r_p} = {\left[ {\matrix{   {r_{v,1}^{pv}} &amp; {r_{v,2}^{pv}}  } } \right]^T}$</td><td>负载在机体坐标系中的位置的X Y分量</td></tr><tr><td>${v_p} = {\left[ {\matrix{   {v_{v,1}^{pv}} &amp; {v_{v,2}^{pv}}  } } \right]^T}$</td><td>负载在机体坐标系中的速度的X Y分量</td></tr><tr><td>$r_v^{vi}$</td><td>四旋翼在机体坐标系中的位置</td></tr><tr><td>$v_v^{vi}$</td><td>四旋翼在惯性坐标系中的平动速度</td></tr><tr><td>$\omega _v^{vi}$$</td><td>四旋翼在机体坐标系中的角速度</td></tr><tr><td>${f_v}$</td><td>在机体坐标系螺旋桨生成的力</td></tr><tr><td>${x_i}$</td><td>四旋翼在惯性坐标系中的位置</td></tr><tr><td><script type="math/tex">{M_v}</script></td><td>在机体坐标系螺旋桨生成的力矩</td></tr></tbody></table></div><p>基于<a href="https://www.lukesy.net/docs/self-study/kane-dynamics/">Dynamics Theory and Applications – Thomas Kane and David Levinson | Luke Sy, PhD Candidate</a>，<a href="https://arc.aiaa.org/doi/abs/10.2514/6.2013-4649">Implementation of Kane’s Method for a Spacecraft Composed of Multiple Rigid Bodies | aiaa.org</a>，kane的运动方程可以通过引入局部速度矩阵<em>U</em>。注意，对于具有独立坐标的刚体系统，我们可以赋予广义速度来完全描述系统的运动。对于一个有外部力和D’Alembert’s惯性力的系统，kane方法是由以下虚功原理推导出来的:</p>$$\sum\limits_{k = 1}^N {({{\vec F}_k} + \vec F_k^*) \cdot {{\partial {{\vec v}_k}} \over {\partial {u_r}}} = 0,(r = 1,2,3,...m)} \tag{1}$$<p>其中${{\vec F}_k},\vec F_k^*$,分别为外部力和D’Alembert’s惯性力；${{{\vec v}_k}}$是对应惯性力的速度；${{u_r}}$是广义速度。</p>${{\vec F}_k},\vec F_k^*,{{{\vec v}_k}}$都在惯性坐标系中表示，我们可以得到基于虚功原理的坐标形式：$$\sum\limits_{k = 1}^N {{{\left( {{{\partial {v_{k,i}}} \over {\partial u_r^T}}} \right)}^T}({F_{k,i}} + F_{k,i}^*) = 0,(r = 1,2,3,...m)} \tag{2}$$<p>其中偏导速度项${{{\partial {v_{k,i}}} \over {\partial u_r^T}}}$为一个矩阵；其下标<em>i</em>表示惯性坐标系。以矢量形式，上面的公式可以转换为：</p>$$\eqalign{  &amp; \left[ {\matrix{   {{{\left( {{{\partial {v_{1,i}}} \over {\partial u_r^T}}} \right)}^T}} &amp; {...} &amp; {{{\left( {{{\partial {v_{n,i}}} \over {\partial u_r^T}}} \right)}^T}}  \cr  } } \right]\left[ {\matrix{   {{F_{1,i}} + F_{1,i}^*}  \cr    {...}  \cr    {{F_{n,i}} + F_{n,i}^*}  \cr  } } \right]  \cr   &amp;  = U_r^T({F_i} + F_i^*) = 0,(r = 1,2,3,...m) \cr} \tag{3}$$<p>其中$U_r^T$是一个其中每个元素都是矩阵的块矩阵。对于由<em>n</em>对 D’Alembert’s惯性力、外力和广义速度组成的系统，我们可以得到矩阵形式的运动方程：</p>$${U^T}({F_i} + F_i^*) = 0 \tag{4}$$<p>其中：</p>$$\eqalign{  &amp; U = \left[ {\matrix{   {{U_1}} &amp; {{U_2}} &amp; {...} &amp; {{U_m}}  \cr } } \right]  \cr   &amp; {F_i} = \left[ {\matrix{   {F_{1,i}^T} &amp; {...} &amp; {F_{n,i}^T}  \cr } } \right],F_i^* = \left[ {\matrix{   {F_{1,i}^{*,T}} &amp; {...} &amp; {F_{n,i}^{*,T}}  \cr  } } \right] \cr} \tag{5}$$<p>公式(4)表明运动方程是力平衡在偏导速度矩阵零空间上的投影。根据文献<a href="https://www.lukesy.net/docs/self-study/kane-dynamics/">Dynamics Theory and Applications – Thomas Kane and David Levinson | Luke Sy, PhD Candidate</a>，刚体<em>k</em>的D’Alembert’s惯性力为:</p>$$\eqalign{  &amp; F_{k,i}^* =  - {m_k}{{\dot v}_{k,i}},  \cr   &amp; M_{k,i}^* =  - {{\dot h}_{k,i}} =  - {R_{ib,k}}({J_{k,b}}\dot \omega _b^{k,i} + \omega _b^{k,i \wedge }{J_{k,b}}\dot \omega _b^{k,i}) \cr} \tag{6}$$<p>其中，$F_{k,i}^*，M_{k,i}^*$为 D’Alembert’s惯性力和惯性力矩；注意，在凯恩的运动方程中，表达惯性力矩的方式与惯性力是一样的。将系统第<em>k</em>个分量从机体坐标系转换到惯性坐标系的旋转矩阵为${R_{ib,k}}$。${J_{k,b}}$为第<em>k</em>个分量的转动惯量。∧的映射如下：</p>$${\phi ^ \wedge }: = \left[ {\matrix{   0 &amp; { - {\phi _3}} &amp; {{\phi _2}}  \cr    {{\phi _3}} &amp; 0 &amp; { - {\phi _1}}  \cr    { - {\phi _2}} &amp; {{\phi _1}} &amp; 0  \cr } } \right] ,\phi  \in {\mathbb{R}^{3}} \tag{7}$$<p>在本文中，<strong>∧</strong>等价于叉积矩阵算子 <strong>×</strong>。<strong>∧</strong>的逆映射算子定义为<strong>∨</strong>。</p><h3 id="B-绳载负载的四旋翼系统动力学模型"><a href="#B-绳载负载的四旋翼系统动力学模型" class="headerlink" title="B 绳载负载的四旋翼系统动力学模型"></a>B 绳载负载的四旋翼系统动力学模型</h3><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gwih6asu0yj30g50fhgox.jpg" alt="坐标系定义" style="zoom:80%;"></p><p>偏心绳载负载的四旋翼系统结构如图1所示，其中参数定义见表一。由图一，可以得到如下的运动学关系：</p>$$r_i^{pi} = r_i^{vi} + {R_{iv}}(r_v^{tv} + r_v^{pv}) \tag{8}$$<p>对于绳载负载的四旋翼系统，我们使用如下的广义速度<em>u</em>：</p>$$u = {\left[ {v_p^T,v_v^{vi,T},\omega _v^{vi,T}} \right]^T} \tag{9}$$<p>通过对(8)微分，得到了惯性坐标系中负载的速度和加速度以及四旋翼的速度：</p>$$\eqalign{  &amp; v_i^{pi} = {R_{iv}}(v_i^{vi} + B{v_p} + A\omega _v^{pv})  \cr   &amp; v_i^{vi} = {R_{iv}}v_v^{vi}  \cr   &amp; \omega _i^{vi} = {R_{iv}}\omega _v^{vi} \cr} \tag{10}$$<p>定义以下负载的诱导交叉项：</p>$$\eqalign{  &amp; {{\dot R}_{iv}} = {R_{iv}}\omega _v^{vi, \wedge }  \cr   &amp; A =  - {(r_v^{tv} + r_v^{pv})^ \wedge };B = \left[ {\matrix{   {{1_{2 \times 2}}}  \cr    { - {{r_p^T} \over {\sqrt {{L^2} - r_p^T{r_p}} }}}  \cr  } } \right] \cr} \tag{11}$$<p>根据(4),其偏导速度矩阵如下所示：</p>$${U^T} = \left[ {\matrix{   {{B^T}{R_{vi}}} &amp; 0 &amp; 0  \cr    {{R_{vi}}} &amp; {{R_{vi}}} &amp; 0  \cr    {A{R_{vi}}} &amp; 0 &amp; {{R_{vi}}}  \cr  } } \right] \tag{12}$$<p>对(10)微分得到四旋翼和负载的加速度以及角动量的变化率$\dot h_i^{vi}$如下：</p>$$\eqalign{  &amp; \dot v_i^{pi} = {R_{iv}}(\dot v_i^{vi} + B{{\dot v}_p} + A\dot \omega _v^{pv} + R)  \cr   &amp; \dot v_i^{vi} = {R_{iv}}(\dot v_v^{vi}{\rm{ + }}P){\rm{ }} \cr   &amp; \dot h_i^{vi} = {R_{iv}}({J_v}\dot \omega _v^{vi} + Q) \cr} \tag{13}$$<p>定义了下列速度诱导力的量为：</p>$$\eqalign{  &amp; P = {(\omega _v^{vi})^ \wedge }v_v^{vi}  \cr   &amp; Q = {(\omega _v^{vi})^ \wedge }{J_v}\omega _v^{vi}  \cr   &amp; R = {(\omega _v^{vi})^ \wedge }(v_v^{vi} + A\omega _v^{vi} + 2B{v_p}) + \dot B{v_p} \cr} \tag{14}$$<p>D’Alembert’s惯性力与外力的平衡可以用以下形式表示:</p>$$F_i^* =  - \left[ {\matrix{   {m{R_{iv}}B} &amp; {m{R_{iv}}} &amp; {m{R_{iv}}A}  \cr    0 &amp; {{m_q}{R_{iv}}} &amp; 0  \cr    0 &amp; 0 &amp; {{R_{iv}}{J_V}}  \cr } } \right]\dot u - \left[ {\matrix{   {m{R_{iv}}R}  \cr    {{m_q}{R_{iv}}P}  \cr    {{R_{iv}}Q}  \cr } } \right] \tag{15}$$$${F_i} = {\left[ {\matrix{   {m{g_i}} &amp; {{m_q}{g_i}} &amp; 0  \cr } } \right]^T} + {\left[ {\matrix{   0 &amp; {{F_i}} &amp; {{M_i}}  \cr  } } \right]^T} \tag{16}$$<p>根据(4)，力平衡的投影为kane运动方程:</p>$$\eqalign{  &amp; \left[ {\matrix{   {m{B^T}B} &amp; {m{B^T}} &amp; {m{B^T}A}  \cr    {mB} &amp; {({m_q} + m)1} &amp; {mA}  \cr    {m{A^T}B} &amp; {m{A^T}} &amp; {{J_v} + m{A^T}A}  \cr  } } \right]\left[ {\matrix{   {{{\dot v}_p}}  \cr    {\dot v_v^{vi}}  \cr    {\dot \omega _v^{vi}}  \cr  } } \right] =   \cr   &amp; \left[ {\matrix{   {m{B^T}}  \cr    {({m_q} + m)1}  \cr    {m{A^T}}  \cr } } \right]{R_{vi}}g + \left[ {\matrix{   {m{B^T}R}  \cr    { - {m_q}P - mR}  \cr    { - m{A^T}R - Q}  \cr } } \right] + \left[ {\matrix{   {{0_{4 \times 1}}}  \cr    {{f_v}}  \cr    {{M_v}}  \cr } } \right] \cr} \tag{17}$$<h2 id="3-控制设计"><a href="#3-控制设计" class="headerlink" title="3 控制设计"></a>3 控制设计</h2><h3 id="A-分解姿态运动"><a href="#A-分解姿态运动" class="headerlink" title="A 分解姿态运动"></a>A 分解姿态运动</h3><p>对于一个正定矩阵<em>C</em>，我们有如下的LDU分解：</p>$$C{\rm{ = }}\left[ {\matrix{   A &amp; {{B^T}}  \cr    B &amp; D  \cr } } \right]{\rm{ = }}\left[ {\matrix{   1 &amp; 0  \cr    {B{A^{ - 1}}} &amp; 1  \cr } } \right]\left[ {\matrix{   A &amp; 0  \cr    0 &amp; S  \cr } } \right]\left[ {\matrix{   1 &amp; {{A^{ - 1}}{B^T}}  \cr    0 &amp; 1  \cr } } \right] \tag{18}$$<p>其中<em>L</em>和<em>U</em>是上三角形矩阵和下三角矩阵；<em>D</em>为一个对角矩阵，其中$S = D - B{A^{ - 1}}{B^T}$。利用LDU分解，可以将姿态运动与系统其他部分解耦。我们按以下方式划分质量矩阵：</p>$$\eqalign{  &amp; A = \left[ {\matrix{   {m{B^T}B} &amp; {m{B^T}}  \cr    {m{B^T}} &amp; {({m_q} + m)1}  \cr } } \right];B = [\matrix{   {m{A^T}B} &amp; {m{A^T}}  \cr  } ]  \cr   &amp; D = {J_v}{\rm{ + }}m{A^T}A;S = D - B{A^{ - 1}}{B^T} \cr} \tag{19}$$<p>解耦后的姿态动力学方程为:</p>$$\eqalign{  &amp; \dot \omega _v^{vi} = \tau  = {S^{ - 1}}( - B{A^{ - 1}}{h_1} + {h_2} + {M_v})  \cr   &amp; {h_1} = \left[ {\matrix{   {m{B^T}}  \cr    {({m_q} + m)1}  \cr } } \right]{R_{vi}}{g_i} + \left[ {\matrix{   { - m{B^T}R}  \cr    { - {m_q}P - mR}  \cr } } \right] + \left[ {\matrix{   {{0_{4 \times 1}}}  \cr    {{f_v}}  \cr } } \right]  \cr   &amp; {h_2} = m{A^T}{R_{vi}}{g_i} - m{A^T}R - Q \cr}  \tag{20}$$<p>由上式可知，姿态运动是完全驱动的。定义饱和函数如下:</p>$$sat(x,{x_0}) = \left\{ \matrix{  {x_0},{x_0} &lt; x \hfill \cr   x, - {x_0} \le x \le {x_0},{x_0} &gt; 0 \hfill \cr {x_0},x &lt;  - {x_0} \hfill \cr}  \right. \tag{21}$$<p>如果<em>x</em>是一个向量，那么饱和函数适用于每个元素。如果$x_0$为∞，则表示该通道没有限制。</p><p>在文献<a href="https://ieeexplore.ieee.org/abstract/document/5717652">Geometric tracking control of a quadrotor UAV on SE(3) </a>、<a href="https://ieeexplore.ieee.org/document/6315143">Nonlinear robust tracking control of a quadrotor UAV on SE(3)</a>的基础上，我们得到以下控制律:</p>$$\eqalign{  &amp; \tau  =  - {K_\Omega }\omega _v^{vi} - sat({K_R}{e_R},{x_{R,0}});{x_{R,0}} = {\left[ {\infty ,\infty ,0.1} \right]^T}  \cr   &amp; {e_R} = {1 \over 2}{(R_{vi,c}^T{R_{vi}} - R_{vi}^T{R_{vi,c}})^ \vee } \cr} \tag{22}$$<p>其中，$R_{vi,c}$为期望的姿态，期望角速度为$\omega _{v,c}^{vi} = 0$；$K_Ω$和$K_R$为正定矩阵。该限制适用于偏航角通道，以防止大偏航角引起的负载大幅度摆动的影响。</p><h3 id="B-平移运动控制设计"><a href="#B-平移运动控制设计" class="headerlink" title="B 平移运动控制设计"></a>B 平移运动控制设计</h3><p>基于姿态指令控制器，在文献<a href="https://ieeexplore.ieee.org/abstract/document/5717652">Geometric tracking control of a quadrotor UAV on SE(3) </a>、<a href="https://ieeexplore.ieee.org/document/6315143">Nonlinear robust tracking control of a quadrotor UAV on SE(3)</a>的基础上设计了四旋翼飞行器的平移运动控制器,定义位置和速度误差为:</p>$${e_x} = {x_i} - {x_{i,d}};{e_v} = v_v^{vi} - v_{v,d}^{vi} \tag{23}$$<p>四旋翼的速度是通将倾斜控制的升力矢量控制在期望的方向实现的。然后将位置控制器定义为</p>$$\eqalign{  &amp; v_{v,d}^{vi} =  - {k_x}{e_x};{R_{vi,c}} = 1 + {k_v}{\left[ {\matrix{   {sat({e_{v,y}},{v_0})}  \cr    { - sat({e_{v,x}},{v_0})}  \cr    0  \cr  } } \right]^ \wedge }  \cr   &amp; {f_v} = {f_{v,e}} - {k_v}({m_q} + m)sat({e_{v,z}},{v_1}) \cr} \tag{24}$$<p>通过在饱和函数中设置足够小的限制$v_0$，可以认为矩阵近似于SO(3)。${f_{v,e}}$即为四旋翼和有效载荷悬停时的纵倾力。由于姿态控制将使四旋翼飞行器最终达到接近$R_{vi}=1$的姿态，因此由$v_0$产生的小倾角使得$v_{v,d}^{vi} \approx v_{i,d}^{vi}$。因此，速度控制信号$v_{v,d}^{vi} =  - {k_x}{e_x}$可以将四旋翼飞行器带到目标位置。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS论文(3)</title>
      <link href="/2021/11/15/ps-lun-wen-3/"/>
      <url>/2021/11/15/ps-lun-wen-3/</url>
      
        <content type="html"><![CDATA[<p>文章地址：<a href="https://ieeexplore.ieee.org/document/8672929">Path-Following Control of A Quadrotor UAV With A Cable-Suspended Payload Under Wind Disturbances | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p>文章代码地址：<a href="https://github.com/LonghaoQian/Single-Drone-Payload-Simulink">LonghaoQian/Single-Drone-Payload-Simulink: Paper, Simulink Model, and Technical Clarifications (github.com)</a></p><p>符号介绍：符号头顶~表示误差，而符号头顶^表示估计值。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>提出了一种基于不确定性和干扰估计(uncertainty and disturbance estimator,UDE)的绳载负载的四旋翼路径跟踪控制器。四旋翼飞行器和负载受到未知的风扰动。</p><p>控制器采用级联结构。针对外环，<u>提出了一种基于UDE的平动控制器</u>。控制器使沿给定路径的四旋翼渐近稳定，并用低通滤波器估计集总扰动。对于内环，采用姿态跟踪控制器控制升力矢量的方向，使实际升力能够渐近地跟随平动控制器产生的参考力。</p><p>利用<a href="?">约简定理</a>证明了带有平动控制器和姿态跟踪控制器的系统是渐近稳定的。借助<a href="?">约简定理</a>，平动控制和姿态控制的设计可以解耦，保证了无需重新进行稳定性分析而实现不同姿态控制器的灵活性。</p><p>仿真结果表明，所设计的控制律可以使四旋翼在不同的风力干扰下稳定在期望路径上。</p><p>重点：reduction theorem<a href="?">约简定理</a>, uncertainty and disturbance estimator(UDE)(不确定性和干扰估计).</p><h2 id="1-相关工作"><a href="#1-相关工作" class="headerlink" title="1 相关工作"></a>1 相关工作</h2><h3 id="A-绳载负载的四旋翼系统控制"><a href="#A-绳载负载的四旋翼系统控制" class="headerlink" title="A 绳载负载的四旋翼系统控制"></a>A 绳载负载的四旋翼系统控制</h3><p>由于四旋翼的升力矢量沿固定架的z轴方向固定，因此四旋翼螺旋桨通常只能通过将飞行器倾斜到参考方向来控制平动运动。同时，缆索和负载形成了一个不受控制的摆系统。因此，整个系统是欠驱动的，给控制设计带来许多挑战。对于这类系统，通常首先确定一个平动外环控制器，然后使用一个姿态跟踪控制器来渐近指向四自由度参考姿态。这种方法称为级联设计技术。</p><p>kumar组的文章<a href="https://ieeexplore.ieee.org/document/6631275">Trajectory generation and control of a quadrotor with a cable-suspended load - A differentially-flat hybrid system</a>、<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load </a>利用非线性级联控制设计完成了绳载负载的四旋翼飞行器轨迹跟踪控制的关键工作。<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load </a>中的控制器首先驱动绳索到一个参考方向，以便绳索可以提供正确的力来操纵负载的运动，而实际升力的控制就是对四旋翼的扭矩控制。</p><p>由于<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load </a>中的控制律需要负载的位置和速度信息，<a href="https://ieeexplore.ieee.org/document/8258883">Aggressive Flight With Suspended Payloads Using Vision-Based Control </a>提出了一种基于估计的控制器，使<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load </a>中的控制器更适合实际应用。</p><p><a href="https://ieeexplore.ieee.org/document/7129434">Adaptive controller design for generic quadrotor aircraft platform subject to slung load</a>提出了一种回顾性成本自适应控制来处理负载质量导致系统的不稳定摆动问题。<a href="https://link.springer.com/article/10.1007/s12555-014-0304-0">Geometric control of a quadrotor UAV transporting a payload connected via flexible cable</a>提出了一种在固定扰动下来控制绳载负载无人机的方法。<a href="https://ieeexplore.ieee.org/abstract/document/7946750">Dynamics and control of a quadrotor with a cable suspended payload|作者之前的文章</a>提出了一种部分反馈线性化控制律来处理偏离中心的绳载负载。最近，<a href="https://ieeexplore.ieee.org/document/8038248">Nonlinear Hierarchical Control for Unmanned Quadrotor Transportation Systems </a>提出了一种无负载运动反馈的控制器，以促进位置稳定。</p><h3 id="B-风扰动下的绳载负载的四旋翼系统控制"><a href="#B-风扰动下的绳载负载的四旋翼系统控制" class="headerlink" title="B 风扰动下的绳载负载的四旋翼系统控制"></a>B 风扰动下的绳载负载的四旋翼系统控制</h3><h4 id="1-风干扰处理和系统信息获取方法"><a href="#1-风干扰处理和系统信息获取方法" class="headerlink" title="1)风干扰处理和系统信息获取方法"></a>1)风干扰处理和系统信息获取方法</h4><p>由空气阻力引起的风扰是影响系统性能的主要外力，因此在精确运输任务的控制设计中必须考虑风扰。如<a href="https://ieeexplore.ieee.org/abstract/document/8243819">Stabilization of quadrotor with air drag based on controlled Lagrangians method</a>和<a href="https://www.researchgate.net/publication/319031991_Improving_quadrotor_trajectory_tracking_by_compensating_for_aerodynamic_effects">Improving quadrotor trajectory tracking by compensating for aerodynamic effects </a>所提出的，虽然对不规则四旋翼飞行器的阻力建模比较复杂，但在低速时将阻力近似为空速的线性函数是一种合理的简化方法。由于一个物体的空速是它的惯性速度和相对于地面的风速之和,我们可以将总的风扰动解耦为由物体惯性速度引起的巡航阻力和由风速引起的风力之和。</p><p>四旋翼飞行器的空速可以是相对于机身固定框架的任何方向，因此需要额外的风传感器来提供各个方向的空速准确读数，这增加了成本和系统复杂性。对于带有强大电机的四旋翼飞行器，螺旋桨涡旋很强烈，会影响传感器读数。因此，本文没有使用风传感器。</p><p>四旋翼运动由惯性测量单元和GPS测量。</p><p>有效载荷的摆动运动可以通过像<a href="https://ieeexplore.ieee.org/document/8258883">Aggressive Flight With Suspended Payloads Using Vision-Based Control </a>中提出的那样的摄像系统来测量。</p><p>风场的完全速度分布是复杂的。然而，一个变化的风场可以看作是一个恒定的风速加上一个零平均时变阵风。在许多出版的著作中，一个合理的做法是将阵风视为其平均值，即0，并以恒定风速或恒定阻力近似风场。<a href="https://ieeexplore.ieee.org/document/5674091">Adaptive Position Tracking of VTOL UAVs</a>在模拟或实验环境下中测试了该控制器在变化风场中的性能，且对风扰动的估计和补偿进行了研究。</p><h4 id="2-控制器比较"><a href="#2-控制器比较" class="headerlink" title="2)控制器比较"></a>2)控制器比较</h4><h5 id="其他控制器："><a href="#其他控制器：" class="headerlink" title="其他控制器："></a>其他控制器：</h5><p>自适应控制是处理恒源扰动(<a href="https://ieeexplore.ieee.org/document/5674091">Adaptive Position Tracking of VTOL UAVs</a>)和未知系统参数(<a href="https://ieeexplore.ieee.org/document/7040352">Adaptive control of a quadrotor UAV transporting a cable-suspended load with unknown mass</a>)的主要方法。<a href="https://ieeexplore.ieee.org/document/7525403">Nonlinear robust control of a quadrotor UAV for load transportation with swing improvement</a>提出了一种结合李雅普诺夫再设计方法的非线性H∞控制器，实现无负载摆动的路径跟踪。<a href="https://ieeexplore.ieee.org/document/8062614">Computational geometric identification for quadrotor dynamics in wind fields</a>介绍了扑翼效应以及估算风场的计算方法。<u>自适应控制的缺点</u>：自适应控制适合处理常数未知参数，但会给系统带来较大的波动。该自适应律在未知参数为常数的假设下是有效的，因此在风力变化情况下自适应控制的鲁棒性有限。</p><h5 id="本文采用的控制器"><a href="#本文采用的控制器" class="headerlink" title="本文采用的控制器"></a>本文采用的控制器</h5><p>不确定性和干扰估计器(UDE)提供了一种替代的方法来设计作为真实干扰过滤结果的估计器。(<a href="https://asmedigitalcollection.asme.org/dynamicsystems/article/134/2/024501/455886/Control-of-Uncertain-Nonlinear-Systems-Using-an">Control of Uncertain Nonlinear Systems Using an Uncertainty and Disturbance Estimator</a>、<a href="https://www.researchgate.net/publication/281292688_A_comparative_study_of_robust_attitude_synchronization_controllers_for_multiple_3-DOF_helicopters">A comparative study of robust attitude synchronization controllers for multiple 3-DOF helicopters</a>)与计算方法和H∞控制相比，UDE计算能力更小，性能限制更小。通过在系统动力学中引入稳定的线性滤波器，我们可以得到只有状态反馈的估计律。此外，UDE可以同时捕获扰动的常数分量和低频分量，使其在处理时变扰动时比自适应控制更具有鲁棒性。</p><h4 id="3-本文主要工作"><a href="#3-本文主要工作" class="headerlink" title="3)本文主要工作"></a>3)本文主要工作</h4><p>本文采用级联设计方法，提出了一种基于UDE的在风干扰下绳载负载的四旋翼无人机轨迹跟踪控制器。系统的运动学方程取自 <a href="https://ieeexplore.ieee.org/abstract/document/7946750">Dynamics and control of a quadrotor with a cable suspended payload(作者之前的文章) </a>。缆索系在四旋翼的质心(the center of mass ,CM)上，这样就不需要考虑之前在<a href="https://ieeexplore.ieee.org/document/6760219">Geometric control and differential flatness of a quadrotor UAV with a cable-suspended load </a>和<a href="https://ieeexplore.ieee.org/document/8038248">Nonlinear Hierarchical Control for Unmanned Quadrotor Transportation Systems </a>中指出的姿态与平动动力学之间的耦合。即使系绳点与CM有轻微的偏移，当四旋翼角加速度较小时(<a href="https://www.hindawi.com/journals/jat/2018/1467040/">A Load Transportation Nonlinear Control Strategy Using a Tilt-Rotor UAV</a>)，该模型是合理的。我们将这个问题表述为沿着一组接近曲线路径的相互连接的直线的路径跟踪任务，以获得一个简化和实用的控制律用于工程实施。</p><p>本文主要创新包括以下内容:</p><ol><li>提出了一种新的渐近稳定(Asymptotically Stable,AS)的基于 UDE的平动控制律，该平动控制器可以同时消除巡航阻力和风力的影响。此外，在可以忽略巡航阻力的接近悬停状态的情况下，闭环系统几乎是全局渐近稳定的（almost globally asymptotically stable，AGAS）。</li><li>使用了<a href="https://www.sciencedirect.com/science/article/pii/S0005109812004748">Reduction theorems for stability of closed sets with application to backstepping control design</a>中的约简定理。通常情况下，在添加姿态跟踪控制器以方便平动控制器后，需要一个扩展的李雅普诺夫函数来表示整个系统的稳定性。在约简定理的帮助下，我们在不需要新的李雅普诺夫函数的情况下保证了稳定性，并对平动控制器的设计和姿态跟踪控制器的选择进行了解耦，为以后的修改提供了更多的空间。</li></ol><h2 id="2-预设"><a href="#2-预设" class="headerlink" title="2 预设"></a>2 预设</h2><p>( $: = , \buildrel \Delta \over = , = $表示“定义为”、“设为”)</p><p>将 $1$和 $0$表示为单位矩阵和在较大的块矩阵中具有适当大小的零矩阵。</p> $\left\| v \right\| = \sqrt {{v^T}v} $为向量 $v \in {\mathbb{R}^{n \times 1}}$。对于 $\phi  \in {\mathbb{R}^{3 \times 1}} = {\left[ {\begin{array}{*{20}{c}}  {{\phi _1}}&amp;{{\phi _2}}&amp;{{\phi _3}} \end{array}} \right]^T}$，可 ${\phi ^ \times } = {\phi ^ \wedge } \in {\mathbb{R}^{3 \times 3}}$被定义为： $${\phi ^ \times }: = \left[ {\matrix{   0 &amp; { - {\phi _3}} &amp; {{\phi _2}}  \cr    {{\phi _3}} &amp; 0 &amp; { - {\phi _1}}  \cr    { - {\phi _2}} &amp; {{\phi _1}} &amp; 0  \cr } } \right] \tag{1}$$<p>反之亦然，给定一个斜对称矩阵 $M =  - {M^T} \in {\mathbb{R}^{3 \times 3}}$。</p><p>我们定义 ${M^ \vee } = {\left[ {\matrix{   {{M_{32}}} &amp; {{M_{13}}} &amp; {{M_{21}}}  \cr } } \right]^T}$。</p><p>坐标系A下的坐标 ${\vec x}$被定义为 ${x_A} \in {\mathbb{R}^{3 \times 1}}$。</p><p>坐标系A和坐标系B之间的旋转矩阵被定义为 ${R_{AB}} \in SO(3)$。</p><p>对于向量 ${\vec x}$，有 ${x_A} = {R_{AB}}{x_B}$。</p><p>我们也定义两个特殊函数 $\pi (x):{\mathbb{R}^{n \times 1}} \to \mathbb{R},h(x):{\mathbb{R}^{n \times 1}} \to {\mathbb{R}^{n \times 1}}$：</p> $$\pi (x): = \sqrt {c + {x^T}x}  - \sqrt c ;h(x): = {{d\pi (x)} \over {dx}} = x/\sqrt {c + {x^T}x} \tag{2}$$<p>其中，<em>c</em> &gt; 0； $\pi (x)$是正定且径向无界(<a href="https://handwiki.org/wiki/Radially_unbounded_function">Radially unbounded function</a>)的； $0 \le \left\| {h(x)} \right\| \le 1$； ${B_\delta }(\Gamma )$为以集合Γ中心，半径为 $\delta $的邻域。</p><h2 id="3-问题公式化"><a href="#3-问题公式化" class="headerlink" title="3 问题公式化"></a>3 问题公式化</h2><h3 id="A-坐标系定义和系统状态"><a href="#A-坐标系定义和系统状态" class="headerlink" title="A 坐标系定义和系统状态"></a>A 坐标系定义和系统状态</h3><p>在图1中需要注意， ${d_q}$和 ${d_p}$分别为四旋翼和负载所受到的巡航阻力和风力之和。</p><p>如图1所示，坐标系I为惯性坐标系。坐标系B为四旋翼的机体坐标系。 ${X_\Sigma }{\rm{ = \{ }}{X_{{\rm{tran}}}},{X_{{\rm{rot}}}}{\rm{\} }}$表示系统状态：</p> $${X_{{\rm{tran}}}} = \{ {v_q},{v_p},x,r\} ,{X_{rot}} = \{ \omega ,{R_{IB}}\} ,v = \left[ {\matrix{   {{v_p}}  \cr    {{v_q}}  \cr  } } \right] \tag{3}$$<p>其中， ${v_p},x$是四旋翼在惯性坐标系下的速度和位置；<em>L</em>表示系绳点指向负载的向量， $\left\| L \right\| = l$。<em>r</em>是<em>L</em>的水平投影，所以<em>L</em>是关于<em>r</em>如式(4)所示的函数。 ${v_p}: = \dot r$为负载的水平速度。 $\omega $为机体坐标系B相对于惯性坐标系I的角速度，在机体坐标系中表述。 ${R_{IB}}$为机体坐标系B到惯性坐标系I的旋转矩阵。</p> $$L = \left[ {\matrix{   r  \cr    {\sqrt {{l^2} - {r^T}r} }  \cr } } \right],\dot L = B{v_p},B = \left[ {\matrix{   1  \cr    { - {{{r^T}} \over {\sqrt {{l^2} - {r^T}r} }}}  \cr } } \right] \tag{4}$$<p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gwgy6nw7qrj312h0u0k49.jpg" alt="绳载负载的四旋翼系统" style="zoom: 50%;"></p><h3 id="B-系统模型"><a href="#B-系统模型" class="headerlink" title="B 系统模型"></a>B 系统模型</h3><p>根据<a href="https://ieeexplore.ieee.org/abstract/document/7946750">Dynamics and control of a quadrotor with a cable suspended payload|作者之前的文章</a>，可以得到当将系绳点放在四旋翼质心时的系统模型为：</p> $$\eqalign{  &amp; {\Sigma _1}:\left\{ \matrix{  M\dot v + Cv = H(G + {d_c} + {d_w} + F) \hfill \cr   \dot x = {v_q} \hfill \cr   \dot r = {v_p} \hfill \cr}  \right.  \cr   &amp; {\Sigma _2}:\left\{ \matrix{  J\dot \omega  + {\omega ^ \times }J\omega  = \tau  \hfill \cr   {{\dot R}_{IB}} = {R_{IB}}{\omega ^ \times } \hfill \cr}  \right. \cr} \tag{5}$$ ${\Sigma _1}$含有驱动力*F*和重力*G*(在惯性坐标系I下定义)的平动子系统，在； ${d_c},{d_w}$(在惯性坐标系I下定义)分别为巡航阻力和风力扰动 。 ${\Sigma _2}$为姿态子系统，其包括由机体坐标系B中的螺旋桨产生的力矩 $\tau $。整体的系统由 $\Sigma : = \{ {\Sigma _1},{\Sigma _2}\} $定义。其中，M和C分别表示惯性矩阵和Coriolis矩阵： $$M = \left[ {\matrix{   {{m_p}{B^T}B} &amp; {{m_p}{B^T}}  \cr    {{m_p}B} &amp; {({m_q} + {m_p})1}  \cr } } \right],C = \left[ {\matrix{   {{m_p}{B^T}\dot B} &amp; 0  \cr    {{m_p}\dot B} &amp; 0  \cr  } } \right] \tag{6}$$ $$H = \left[ {\matrix{   {{B^T}} &amp; 0  \cr    1 &amp; 1  \cr } } \right],G = \left[ {\matrix{   {{m_p}{g_I}}  \cr    {{m_q}{g_I}}  \cr } } \right],F = \left[ {\matrix{   0  \cr    {{F_L}}  \cr } } \right] \tag{7}$$ ${m_p}$、 ${m_q}$分别为负载、四旋翼的质量； $J \in {\mathbb{R}^{3 \times 3}}$为四旋翼的转动惯量； ${e_3} = {\left[ {\matrix{   0 &amp; 0 &amp; 1  \cr  } } \right]^T}$；${g_I}$是在惯性坐标系*I*中表示的重力加速度; ${F_L}$是四旋翼螺旋桨在惯性坐标系中产生的升力。 ${F_L}$在四旋翼中被定义为： ${F_L} =  - f{R_{IB}}{e_3} \tag{8}$<p>其中 $f$为四旋翼螺旋桨产生的升力大小。</p><p>需要注意公式(3)中的 ${X_{tran}}$是定义在惯性坐标系<em>I</em>中，而该平动状态在<a href="https://ieeexplore.ieee.org/abstract/document/7946750">Dynamics and control of a quadrotor with a cable suspended payload|作者之前的文章</a>中是定义在机体坐标系<em>B</em>。因此，为了得到公式(5)中的 ${\Sigma _2}$，需要使用一个坐标变换。</p> $${d_c} = \left[ {\matrix{   { - {\lambda _p}({v_q} + B{v_p})}  \cr    { - {\lambda _q}{v_q}}  \cr } } \right],{d_w} = \left[ {\matrix{   {{\lambda _p}v_w}  \cr    {{\lambda _q}v_w}  \cr  } } \right] = \left[ {\matrix{   {{W_p}}  \cr    {{W_q}}  \cr  } } \right],{d_c} + {d_w} = \left[ {\matrix{   {{d_p}}  \cr    {{d_q}}  \cr  } } \right]$$<p>如图1所示， ${{v_q} + B{v_p}}$和 ${{v_q}}$分别为负载的速度和四旋翼的速度；所以， ${d_c}$是基于线性阻力假设的巡航阻力的近似值。 ${\lambda _p} \ge 0,{\lambda _q} \ge 0$为未知阻力系数。 ${d_w}$由未知风速 ${v_w}$引起的未知恒定风力。由于阻力是空速的线性函数，我们可以把总风力写成的 ${d_c}$与 ${d_w}$的线性和。</p><p>假设<script type="math/tex">{W_p},{W_q},{\lambda _p},{\lambda _q}</script>的上界已知：</p> $$\left\| {{W_p}} \right\| \le {W_{p,0}},{\left\| W \right\|_q} \le {W_{q,0}},\left\| {{\lambda _p}} \right\| \le {\lambda _{p,o}},\left\| {{\lambda _q}} \right\| \le {\lambda _{q,0}} \tag{10}$$<h3 id="C-路径跟随控制问题"><a href="#C-路径跟随控制问题" class="headerlink" title="C 路径跟随控制问题"></a>C 路径跟随控制问题</h3><p>其路径 $\mathbb{P}{\text{ = \{ }}P{\text{,}}n{\text{,}}v{\text{\} ,i = 1,2,3,}}...{\text{,}}N$为如图1所示的曲线的分段线性近似。第<em>i</em>段的起始点和方向被定义为 ${P_i} \in {\mathbb{R}^{3 \times 1}},{n_i} \in {\mathbb{R}^{3 \times 1}}(n_i^T{n_i} = 1)$。第<em>i</em>段的参考速度被定义为 ${v_i} \in \mathbb{R}$。 ${v_i} \in \mathbb{R}$的符号表示参考运动的方向。 ${v_{d,i}} = {v_i}{n_i}$。第<em>i</em>段的位置误差和速度误差被定义为：</p> ${e_{x,i}} = (1 - {n_i}n_i^T)(x - {P_i}),{e_{v,i}} = {v_q} - {v_{d.i}},v_{d,i}^T{e_{x,i}} = 0 \tag{11}$<p>注意 ${e_{x,i}}$是如图1所示的路径偏移，当四旋翼到达下一个路径点的邻域时，一个控制逻辑将参考路径切换到下一个路径。在风和阻力的作用下，当四旋翼以参考速度巡航时，缆索的摆角是非零的。这是负载的平衡位置 $r_{d,i}$，本文将在下一节描述。使得 $\tilde r = r - {r_{d,i}}$成为负载的位置误差。使 ${{\tilde X}_{{\text{tran}}}} = \{ {e_{v,i}},{v_p},{e_{x,i}},\tilde r\} $为 ${\sum _1}$的误差。 $\tilde X_{tran}^* = \{ 0,0,0,0\} $为 ${\sum _1}$的平衡状态。使得 $\lambda  = {\lambda _q} + {\lambda _p},W = {W_p} + {W_q} - \lambda {v_{d,i}}$作为集总常数未知扰动(集总扰动)。我们也定义 $\hat W,\tilde W = \hat W - W$为<em>W</em>的估计和预测误差。</p><p>路径跟踪问题定义如下:考虑系统 ${\sum}$以及参考路径 $\mathbb{P}$，我们设计如下反馈形式</p> $z = \phi ({X_{{\text{tran}}}}),f = {\eta _1}({X_{{\text{tran}}}},z),\tau  = {\eta _1}({X_\sum },z) \tag{12}$<p>其中 $z \in {\mathbb{R}^{3 \times 1}}$，使得 ${z^{\text{*}}},\{ {z^*},\tilde X_{tran}^*\} $渐近稳定。</p><h2 id="4-控制架构"><a href="#4-控制架构" class="headerlink" title="4 控制架构"></a>4 控制架构</h2><p>我们通过假设 $F_{L,d}$而不是 $F_{L}$作为系统 ${\sum _1}$的驱动力设计了一个稳定的 $F_{L,d}$。其次，一种姿态跟踪控制器被设计来驱动 $ - {R_{IB}}{e_3}$来追踪参考速度以使 $F_{L}$渐近 $F_{L,d}$。</p><h3 id="A-巡航状态"><a href="#A-巡航状态" class="headerlink" title="A 巡航状态"></a>A 巡航状态</h3><p>在巡航状态下，巡航阻力和风力都会影响系统 ${\sum _1}$。使 ${u^T} = {\left[ {\matrix{   {v_p^T} &amp; {e_{v,i}^T}  \cr } } \right]^T}$为速度的误差。使得 $K = \left\| {{W_p} - {\lambda _p}{v_{d,i}} + {m_p}{g_I}} \right\|$。 ${\sum _1}$处于平衡状态，缆绳提供了 ${{W_p} - {\lambda _p}{v_{d,i}} + {m_p}{g_I}}$的力去平衡负载，所以摆动偏移 $r_{d,i}$为：</p> $${r_{d,i}} = l({W_{p,xy}} - {\lambda _p}{v_{d,i,xy}})/K \tag{13}$$<p>第<em>i</em>段路径段的缆索矢量L的平衡状态 $L_{d,i}$，其被定义为</p> $${L_{d,i}} = \left[ {\matrix{   {{r_{d,i}}}  \cr    {\sqrt {{l^2} - r_{d,i}^2} }  \cr } } \right] = {{l({W_{p,xy}} - {\lambda _p}{v_{d,i,xy}} + {m_p}{g_I})} \over K}  \tag{14}$$<p>以确保缆绳在平衡状态时不松弛，我们需要 ${{W_p} - {\lambda _p}{v_{d,i}} + {m_p}{g_I}}&gt;0$。李亚普洛夫函数 ${V_{{\sum _1},c}}$可以被选择为：</p> $${V_{{\sum _1},c}} = {1 \over 2}{u^T}Mu{\rm{ + }}K(l - L_{d,i}^TL/l) + {k_e}\pi ({e_{x,i}}) + {{{{\tilde W}^T}\tilde W} \over {2{k_1}}} \tag{15}$$<p>其中 $k_1&gt;0$且 $k_e&gt;0$，而 $L \in SO(2)$(二维旋转矩阵)和 $\pi ({e_{x,i}})$是径向无界的(<a href="https://handwiki.org/wiki/Radially_unbounded_function">Radially unbounded function</a>)， ${V_{{\sum _{1,c}}}}$是相关 ${{\tilde X}_{tran}}$正定的，对于除了 ${\tilde r}$的其他的误差是径向无界的。这就已经足够了，因为 $\tilde r \in {\rm{\{ }}r:\left\| r \right\| \le {\rm{2}}l{\rm{\} }}$。所以整体的函数也是径向无界的。</p><p>联合式(5)和(11)，我们可以得到 ${V_{{\sum _{1,c}}}}$的时间微分(<u>需要推导</u>, ${u^T} = {\left[ {\matrix{   {v_p^T} &amp; {e_{v,i}^T}  \cr } } \right]^T}$为速度的误差。)：</p> $$\begin{aligned} \dot{V}_{\Sigma_{1}, c} &amp;=e_{v, i}^{T}\left(F_{L, d}+\left(m_{p}+m_{q}\right) g_{I}-\lambda e_{v, i}\right.\\ &amp;\left.-\lambda_{p} \boldsymbol{B} v_{p}+\hat{W}-\tilde{W}\right)+k_{e} h\left(e_{x, i}\right)^{T}\left(v_{q}-v_{d, i}\right)+\frac{1}{k_{1}} \tilde{W}^{T} \dot{\hat{W}} \\ &amp;+v_{p}^{T} \boldsymbol{B}^{T}\left(m_{p} g_{I}-\lambda_{p}\left(v_{q}+\boldsymbol{B} v_{p}\right)+W_{p}\right)-K v_{p}^{T} \boldsymbol{B}^{T} L_{d, i} / l \end{aligned} \tag{16}$$<p>注意我们将 $F_{L,d}$而不是 $F_{L}$视为驱动力， ${L_{d,i}}$是李雅普诺夫函数中的一个数学术语而不是在控制律中使用的,所以我们使用  ${W_p}$和 $\lambda_p$ 。</p><p>由公式(14),我们推导如下公式：</p> $$v^T_pB^T(m_pg_I-\lambda_p(v_q+Bv_p)+W_p-KL_{d,i}/l)=-\lambda_pv^T_pB^TBv_p-\lambda_pv^T_pB^Te_{v,i} \tag{17}$$<p>根据UDE参考文献<a href="https://asmedigitalcollection.asme.org/dynamicsystems/article/134/2/024501/455886/Control-of-Uncertain-Nonlinear-Systems-Using-an">Control of Uncertain Nonlinear Systems Using an Uncertainty and Disturbance Estimator</a>，我们选择不确定性估计器的动态作为集总扰动的一阶滤波结果：</p> $$\lambda_W \dot{\hat W}+\hat W=W-\lambda e_{v,i}-\lambda_pBv_p \tag{18}$$<p>其中<script type="math/tex">\lambda_W>0</script>,注意公式(18)是我们需要 $\hat W$实现的动力学。我们再给出 $F_{L,d}$的表达式：</p> $$F_{L,d}=-(m_p+m_q)g_I-k_eh(e_{x,i})-k_vh(e_{v,i})-\hat{W} \tag{19}$$<p>其中 $k_e&gt;0$和 $k_v&gt;0$。将式(18)和式(19)插入式(5)中的系统动力学中，得到实际的估计器(计算的是(5)第二行)：</p> $$m_{p} \boldsymbol{B} \dot{v}_{p}+m_{p} \dot{\boldsymbol{B}} v_{p}+\left(m_{q}+m_{p}\right) \dot{v}_{q}=\left(m_{p}+m_{q}\right) g_{I}+F_{L, d}+W_{p}+W_{q}-\lambda_{p}\left(v_{q}+\boldsymbol{B} v_{p}\right)-\lambda_{q} v_{q} \tag{20}$$<p>因为 $W = {W_p} + {W_q} - \lambda {v_{d,i}}$，我们以如下的方法来计算估计律：</p> $$\begin{aligned} \lambda_{W} \dot{\hat{W}}+\hat{W}=&amp; W_{p}+W_{q}-\lambda_{q} v_{q}-\lambda_{p} v_{q}-\lambda_{p} \boldsymbol{B} v_{p} \\=&amp; m_{p} \boldsymbol{B} \dot{v}_{p}+\left(m_{q}+m_{p}\right) \dot{v}_{q}+k_{e} h\left(e_{x, i}\right) \\ &amp;+\hat{W}+m_{p} \dot{\boldsymbol{B}} v_{p}+k_{v} h\left(e_{v, i}\right) \end{aligned}  \tag{21}$$<p>因此，实际估计器提供的 $\hat{W}$如下：</p> $$\begin{aligned} \hat{W}(t)=\frac{1}{\lambda_{W}} &amp;\left(\left.m_{p} \boldsymbol{B} v_{p}\right|_{0} ^{t}+\left.\left(m_{q}+m_{p}\right) v_{q}\right|_{0} ^{t}\right.\\ &amp;\left.+\int_{0}^{t} k_{v} h\left(e_{v, i}\right)+k_{e} h\left(e_{x, i}\right) d t\right) \end{aligned} \tag{22}$$<p>式(21)是将(18)代入(5)得到的，(22)是(21)的直接解。式(22)利用系统的速度信息和路径误差构造 $\hat W$。由(18)和(19)可知，李雅普诺夫函数的时间导数为</p> $$\begin{aligned} \dot{V}_{\Sigma_{1}}=&amp;-\lambda_{p} v_{p}^{T} \boldsymbol{B}^{T} \boldsymbol{B} v_{p}-2 \lambda_{p} v_{p}^{T} \boldsymbol{B}^{T} e_{v, i}-e_{v, i}^{T} k_{v} h\left(e_{v, i}\right) \\ &amp;-\lambda e_{v, i}^{T} e_{v, i}-e_{v, i}^{T} \tilde{W}-\frac{1}{k_{1} \lambda_{W}} \tilde{W}^{T} \tilde{W} \\ &amp;-\frac{\lambda}{k_{1} \lambda_{W}} \tilde{W}^{T} e_{v, i}-\frac{\lambda_{p}}{k_{1} \lambda_{W}} \tilde{W}^{T} \boldsymbol{B} v_{p} \\ \leq &amp;-z^{T} \boldsymbol{A} z-k_{v} e_{v, i}^{T} h\left(e_{v, i}\right)-e_{v, i}^{T} \tilde{W}-\frac{1}{2 k_{1} \lambda_{W}} \tilde{W}^{T} \tilde{W} \\ &amp;-\delta_{p} \lambda_{p}\left\|\boldsymbol{B} v_{p}\right\|^{2}-\delta \lambda\left\|e_{v, i}\right\|^{2}-\frac{1}{2 k_{1} \lambda_{W}}\|\tilde{W}\|^{2} \\ &amp;+\frac{\lambda}{k_{1} \lambda_{W}}\|\tilde{W}\|\left\|e_{v, i}\right\|+\frac{\lambda_{p}}{k_{1} \lambda_{W}}\|\tilde{W}\|\left\|\boldsymbol{B} v_{p}\right\| \\=&amp;-z^{T} \boldsymbol{A} z-y^{T} \boldsymbol{D} y-\zeta^{T} \boldsymbol{H}_{1} \zeta-\eta^{T} \boldsymbol{H}_{2} \eta \end{aligned} \tag{23}$$<p>其中，  $z^{T}=\left[\left\|\boldsymbol{B} v_{p}\right\|,\left\|e_{v, i}\right\|\right], \quad y^{T}=\left[\left\|e_{v, i}\right\|,\|\tilde{W}\|\right], \quad \zeta^{T}=\left[\left\|e_{v, i} \mid\right\|,\|\tilde{W}\|\right]^{T}$ 2, {% raw%} $\eta^{T}=\left[\left\|\boldsymbol{B} v_{p}\right\|,\|\tilde{W}\|\right]^{T} . \delta&gt;0${% endraw%} 且 {% raw%} $\delta_{p}&gt;0${% endraw%} 。矩阵1 $\boldsymbol{A} \in \mathbb{R}^{2 \times 2}, \boldsymbol{D} \in \mathbb{R}^{2 \times 2}, \boldsymbol{H}_{1} \in \mathbb{R}^{2 \times 2}$,  $\boldsymbol{H}_{2} \in$ $\mathbb{R}^{2 \times 2}$ 被定义如下：</p> $\begin{aligned}\boldsymbol{A} &amp;=\left[\begin{array}{cc}\lambda_{p}\left(1-\delta_{p}\right) &amp; -\lambda_{p} \\-\lambda_{p} &amp; \lambda(1-\delta)\end{array}\right] \\\boldsymbol{D} &amp;=\left[\begin{array}{ll}\frac{k_{v}}{\sqrt{\| e_{v} i} \|^{2}+c} &amp; -1 / 2 \\-1 / 2 &amp; \frac{1}{2 k_{1} \lambda_{W}}\end{array}\right] \\\boldsymbol{H}_{1} &amp;=\left[\begin{array}{cc}\delta \lambda &amp; -\frac{\lambda}{2 k_{1} \lambda_{W}} \\-\frac{\lambda}{2 k_{1} \lambda_{W}} &amp; \frac{\delta}{2 k_{1}\left(\delta+\delta_{p}\right) \lambda_{W}}\end{array}\right] \\\boldsymbol{H}_{2} &amp;=\left[\begin{array}{cc}\delta_{p} \lambda_{p} &amp; -\frac{\lambda_{p}}{2 k_{1} \lambda_{W}} \\-\frac{\lambda_{p}}{2 k_{1} \lambda_{W}} &amp; \frac{\delta_{p}}{2 k_{1}\left(\delta+\delta_{p}\right) \lambda_{W}}\end{array}\right] \\\end{aligned} \tag{24}$$$\begin{aligned}\operatorname{det}(\boldsymbol{A})=&amp; \lambda_{p} \lambda\left(1-\delta_{p}\right)(1-\delta)-\lambda_{p}^{2}&gt;0 \\&amp; \rightarrow 1&gt;\left(1-\delta_{p}\right)(1-\delta)&gt;\lambda_{p} / \lambda\end{aligned} \tag{25}$$<p>因为 ${\lambda _p}/\lambda  &lt; 1$，总会有一套解决方案去设计 $\delta ,{\delta _p}$使得det(<em>A</em>)&gt;0。如果我们选择 $k_1&gt;max(\lambda_p/\delta_p^2,\lambda/\delta^2)(\delta+\delta_p)/(2\lambda_W)$，我们得到：</p> $$\begin{aligned} \frac{\delta^{2} \lambda}{2 k_{1}\left(\delta+\delta_{p}\right) \lambda_{W}} &amp;&gt;\frac{\lambda^{2}}{4 k_{1}^{2} \lambda_{W}^{2}} \rightarrow \frac{2 \delta^{2}}{\lambda\left(\delta+\delta_{p}\right)}&gt;\frac{1}{k_{1} \lambda_{W}} \\ \frac{\delta_{p}^{2} \lambda_{p}}{2 k_{1}\left(\delta+\delta_{p}\right) \lambda_{W}} &amp;&gt;\frac{\lambda_{p}^{2}}{4 k_{1}^{2} \lambda_{W}^{2}} \rightarrow \frac{2 \delta_{p}^{2}}{\lambda_{p}\left(\delta+\delta_{p}\right)}&gt;\frac{1}{k_{1} \lambda_{W}}  \end{aligned} \tag{26}$$<p>因为 $\det ({H_1}) &gt; 0$和 $\det ({H_2}) &gt; 0$， $\delta$和 $\delta_p$的存在意味着在适当的 $k_1 $使得稳定是可能的。速度误差必须在这个范围内以至于 $\det (D) &gt; 0$：</p> $$\left\| {{e_{v,i}}} \right\| &lt; \sqrt {(4k_v^2)/(k_1^2\lambda _W^2) - c} \tag{27}$$<p>因此，只要速度误差在极限之内，$\dot{V}$是负半定的。</p><p>对于式(5)和式(19)(还有20)，我们应用 LaSalle’s不变原理(<a href="https://zhuanlan.zhihu.com/p/31925435">La Salle不变集原理与渐近稳定)</a>)为</p> $$\dot{V}_{\Sigma_{1}}=0 \Rightarrow e_{v, i}=0, v_{p}=0 \Rightarrow \dot{v}_{q}=0, \dot{v}_{p}=0\Rightarrow\left[\begin{array}{c}\boldsymbol{B}^{T}\left(m_{p} g_{I}-\lambda_{p} v_{d}+W_{q}\right) \\ -\lambda_{q} v_{q}-\lambda_{p} v_{q}+W_{p}+W_{q}-k_{e} h\left(e_{x, i}\right)-\hat{W}\end{array}\right]=\mathbf{0}\tag{28}$$ <p>（上面第一行好像是 ${B}^{T}\left(m_{p} g_{I}-\lambda_{p} v_{d}+W_{p}\right)$ ,不然后面有点不对）</p><p>对于第一行和公式(14)，我们有</p> $$\boldsymbol{B}^{T}\left(m_{p} g_{I}-\lambda_{p} v_{d}+W_{q}\right)=0 \rightarrow r=r_{d, i} \rightarrow v_{p}=0 \tag{29}$$<p>即使 $\lambda_p、\lambda_q$为零，这意味着当阻尼很小时，负载仍然会稳定下来。</p><p>通过结合第二行和式(18)中 $\hat W$的动力学，我们得到</p> $$\tilde{W}=-k_{e} h\left(e_{x, i}\right) \rightarrow \lambda_{W} d h\left(e_{x, i}\right) / d t+h\left(e_{x, i}\right)=0 \tag{30}$$<p>所以 $h(e_{x,i})$和 $\tilde W$的动力学为稳定的一阶系统，所以当 $t\rightarrow \infty$时 $h(e_{x,i}) \rightarrow 0$且 $\tilde W \rightarrow 0$。因此， $\sum_1 $在式(19)中的控制力。</p><h3 id="B-接近悬停状态"><a href="#B-接近悬停状态" class="headerlink" title="B 接近悬停状态"></a>B 接近悬停状态</h3><p>有很多四旋翼飞行器悬停或低速飞行的情况，比如负载装载和卸载阶段。因此，通过设置 $\lambda= 0$， $\delta_p= 0$， $\delta= 0$, $A=0$,  $H_1=0$, $ h_2 =0$，我们可以忽略巡航阻力，只保留风力。根据式(18),其预测误差 $\tilde W$可以被简化为如下公式:</p> $$\lambda_W\dot{\tilde W}-\tilde W=0 \tag{31}$$<p>(是不是应该修改为 $\lambda_W\dot{\tilde W}+\tilde W=0 $。)</p>$$\dot{V}_{\Sigma_{1}} \leq-y^{T}\left[\begin{array}{cc}\frac{k_{v}}{\sqrt{\left\|e_{v}, i\right\|^{2}+c}} &amp; -1 / 2 \\ -1 / 2 &amp; \frac{1}{k_{1} \lambda_{W}}\end{array}\right] y=-y^{T} \hat{\boldsymbol{D}} y \tag{32}$$<p>当 $\left\| {{e_{v,i}}} \right\| &lt; \sqrt {(4k_v^2)/(k_1^2\lambda _W^2) - c}$时， $\det (\hat D)&gt;0$，则 $\dot V_{\sum_1}&lt;0$。，如果 $\left\| {{e_{v,i}}} \right\| \ge \sqrt {(4k_v^2)/(k_1^2\lambda _W^2) - c} {\rm{ }}$，李亚普诺夫函数的导数为：</p> $$\dot{V}_{\Sigma_{1}}=-e_{v, i}^{T}\left(k_{v} h\left(e_{v, i}\right)+\tilde{W}\right)-\frac{1}{k_{1} \lambda_{W}} \tilde{W}^{T} \tilde{W} \tag{33}$$<p>以初始状态为0的 $\hat {W}$，存在一个时间区间 $0&lt;{t_1}&lt;\infty$，对于 $\forall t &gt; {t_1}$， $\left\| {\tilde W} \right\| &lt; {k_v}h({e_{v,i}})$。因此，在 $t_1 $之后， $\dot V_{\sum_1}$半负定。通过使用(28)-(30)中的LaSalle不变性原理进行类似的程序，我们可以发现使用式(19)和式(22)中的控制率和估计规律的系统 $\sum_1 $是全局渐近稳定的。</p><h3 id="C-姿态提取地图"><a href="#C-姿态提取地图" class="headerlink" title="C 姿态提取地图"></a>C 姿态提取地图</h3><p>从式(19)中获得所需升力 $F_{L,d}$后，将其转化为姿态指令，使姿态跟踪器渐近地驱动四旋翼提供所需升力。由式(8)可以得到四旋翼的幅值和参考方向如下：</p> $$f = \left\| {{F_{L,d}}} \right\|,{n_z} =  - {F_{L,d}}/f \tag{34}$$<p>对于四旋翼， $n_z=[n_{z,1},n_{z,2},n_{z,3}]^T$是用惯性坐标系<em>I</em>表示的机体坐标系的<em>z</em>轴，即 $n_z=R_{IB}e_3$。x轴和y轴记作 $n_x,n_y$。根据围绕着 $n_z$的给定偏航角 $\psi $， $R_{IB,d}$按下列公式给出:</p> $$\eqalign{  &amp; {n_x} = {\left[ {\matrix{   {\cos \psi } \hfill &amp; {\sin \psi } \hfill &amp; { - \left( {\cos \psi {n_{z,1}} + \sin \psi {n_{z,2}}} \right)/{n_{z,3}}} \hfill  \cr } } \right]^T}  \cr   &amp; {n_y} = n_z^ \times {n_x}/\left\| {n_z^ \times {n_x}} \right\|,{R_{IB,d}} = \left[ {\matrix{   {{n_x}/\left\| {{n_x}} \right\|} \hfill &amp; {{n_y}} \hfill &amp; {{n_z}} \hfill  \cr } } \right] \cr} \tag{35}$$<p>给出 ${n_x}$一个合适的解， $F_{L,d}$的<em>z</em>分量不得为零。由式(19)，我们需要 $e_3^TF_L$总为负数：</p> $$e_{3}^{T} F_{L, d} \leq-\left(m_{p}+m_{q}\right) g+k_{e}+k_{v}+\left|e_{3}^{T} \hat{W}\right|&lt;0\Rightarrow\left|e_{3}^{T} \hat{W}\right|&lt;\left(m_{p}+m_{q}\right) g-k_{e}-k_{v} \tag{36}$$<p>对于(22)中初值为零的估计器，我们首先需要集总不确定量<em>W</em>被 $({m_p} + {m_q})g - {k_e} - {k_v} &gt; {e_W} &gt; \left| {e_W^TW} \right|$限制有界。根据公式(18),我们得到了频域的估计器动力学:</p> $$e_{3}^{T} \tilde{W}(s)=-\frac{1}{\lambda_{W} s+1} e_{3}^{T}\left(\lambda_{p} \boldsymbol{B} v_{p}+\lambda e_{v, i}\right)(s)\tag{37}$$<p>在巡航状态下，由于估计器是一个具有单位直流增益的低通滤波器，所以 $e_{3}^{T}\left(\lambda_{p} \boldsymbol{B} v_{p}+\lambda e_{v, i}\right)$ 应该是有界的。</p> $$\left|e_{3}^{T}\left(\lambda_{p} \boldsymbol{B} v_{p}+\lambda e_{v, i}\right)\right|&lt;\epsilon_{W}-\left|e_{3}^{T} W\right| \tag{38}$$<p>在接近悬停状态时，估计误差是一个稳定的一阶系统。因此，从(18)和(22)中，我们得到 $|e^T_3\hat W|&lt;|e^T_3 W|,∀t  &gt;0$。此外， $|e^T_3\hat W|$将具有与 $|e^T_3 W|$相同的符号。因此在悬停情况下，我们只需要 $({m_p} + {m_q})g - {k_e} - {k_v} &gt; {\epsilon_W} &gt; \left| {e_3^TW} \right|$。综上所述，我们需要 $\left|e_{3}^{T}\left(\lambda_{p} \boldsymbol{B} v_{p}+\lambda e_{v, i}\right)\right|&lt;\epsilon_{W}-\left|e_{3}^{T} W\right| \tag{38}$和 $({m_p} + {m_q})g - {k_e} - {k_v} &gt; {\epsilon_W} &gt; \left| {e_3^TW} \right|$来保证系统不会移动到(35)中姿态提取图的奇异点附近。</p><h3 id="D-姿态追踪控制"><a href="#D-姿态追踪控制" class="headerlink" title="D 姿态追踪控制"></a>D 姿态追踪控制</h3><p>使 ${\omega _d}$成为期望角速度，而 ${\tilde X_{rot}} = \{ \tilde \omega , \tilde {R} \}$成为 $\sum_2$的状态误差。一旦参考姿态 $R_{IB,d}$，参考角速度 ${\omega _d}$，参考角加速度 $\dot{\omega _d}$给定，一个几乎全局渐近稳定的如<a href="https://ieeexplore.ieee.org/document/6748916">A Class of Position Controllers for Underactuated VTOL Vehicles | IEEE Journals &amp; Magazine</a>中所建议的无奇点的姿态追踪器被使用：</p> $\begin{aligned} \tau=&amp;-k_{\omega} \tilde{\omega}-k_{R} e_{R} \\ &amp;-\tilde{\omega}^{\times} J \tilde{\omega}+\omega^{\times} J \omega-J\left(\tilde{\omega}^{\times} \tilde{R}^{T} \omega_{d}-\tilde{R}^{T} \dot{\omega}_{d}\right) \end{aligned} \tag{39}$<p>其中 $e_R=\sum_{i=1}^3e_i^{\times}\tilde Re_i,\tilde R=R_{IB,d}^TR_{IB},\omega_d=(R_{IB,d}^T\dot R_{IB,d})^\vee $，而 $\tilde \omega=\omega-\tilde R^T\omega_d$。 $\dot R_{IB,d}$和 $\dot \omega_d$沿用(5)中的系统动力学由(35)中地图的时间导数得到。在实际四旋翼飞行器的实现中，可以用数值微分来简化控制器。</p><h2 id="5-整个系统的稳定性"><a href="#5-整个系统的稳定性" class="headerlink" title="5 整个系统的稳定性"></a>5 整个系统的稳定性</h2><p>定理1：对于系统 $\sum$和一条路径 ${\Bbb P}$，如果存在 $({m_p} + {m_q})g - {k_e} - {k_v} &gt; {\epsilon_W} &gt; \left| {e_3^TW} \right|$和 $e_3^T(W_P-\lambda_pv_{d,i})+m_pg&gt;0$，在(19)、(22)、(39)的控制和估算规律下，其平衡态 $\tilde X^*$是渐近稳定的。更进一步，如果 $\lambda=0$， $\tilde X^*$是几乎全局渐近稳定的。</p><p>以下是定理1的要点：</p><p>1)引力的估计域 $\chi_{\sum_c} $在本节A中被给出。</p><p>2) $({m_p} + {m_q})g - {k_e} - {k_v} &gt; {\epsilon_W} &gt; \left| {e_3^TW} \right|$和 $e_3^T(W_P-\lambda_pv_{d,i})+m_pg&gt;0$意味着四旋翼飞行器不能在缆绳松弛的情况下对螺旋桨产生负推力并操纵有效载荷。</p><p>3)如果系统从 $\chi_{\sum_c} $启动或者处于接近悬停状态，Lyapunov函数将单调减小，这意味着所有状态和误差都是有界的，因此由(19)和(18)可知，控制力 $F_L$必然是有界的。</p><p>因此，所有加速度和 $F_L$的变化率均有界，因此 $\tau $是有界的。因此，如果需要系统稳定在风场中，我们可以通过 $W_{p,0},W_{q,0},\lambda_{q,0},\lambda_p,\lambda_{p,0}$估计控制律所需的最大推力。</p><p>约简定理是稳定性分析中的关键工具。由于约简定理的证明较为复杂，本文不作说明。关于约简定理、集稳定性和吸引性的详细信息请参见:<a href="https://www.sciencedirect.com/science/article/pii/S0005109812004748">Reduction theorems for stability of closed sets with application to backstepping control design - 定义1和3-5</a>。约简定理表述如下：</p><p>定理2：<a href="https://www.sciencedirect.com/science/article/pii/S0005109812004748">Reduction theorems for stability of closed sets with application to backstepping control design -定理6稳定性</a>:使 ${\Gamma _1} \subset {\Gamma _2}$是 $\chi $的两个闭正不变量子集。如果满足以下条件，则 ${\Gamma _1} $是稳定的。</p><p>1) ${\Gamma _1}$是相对于 ${\Gamma _2}$渐近稳定的</p><p>2) ${\Gamma _2}$在 ${\Gamma _1}$附近是局部稳定的 </p><p>3)如果 ${\Gamma _1}$是无界的，则 $\sum_0$是在 ${\Gamma _1}$附近局部一致有界的</p><p>定理3：<a href="https://www.sciencedirect.com/science/article/pii/S0005109812004748">Reduction theorems for stability of closed sets with application to backstepping control design -定理10渐近稳定性</a>:使 ${\Gamma _1} \subset {\Gamma _2}$是 $\chi $的两个闭正不变量子集。如果满足以下条件，则 ${\Gamma _1} $是(全局)渐近稳定的。</p><p>1) ${\Gamma _1}$是相对于 ${\Gamma _2}$(全局)渐近稳定的</p><p>2) ${\Gamma _2}$在 ${\Gamma _1}$附近是局部稳定的 </p><p>3) ${\Gamma _2}$在 ${\Gamma _1}$附近是局部吸引的( ${\Gamma _2}$是全局吸引的)</p><p>4)如果 ${\Gamma _1}$是无界的，则 $\sum_0$是在 ${\Gamma _1}$附近局部一致有界的</p><p>5)( $\sum_0$的所有轨迹都是有界的)</p><p>上述定理中的条件(1)-(3)是必要的。如果满足括号中的条件，则稳定性是全局的。</p> $$\Sigma_{e}:\left\{\begin{array}{l}\boldsymbol{M} \dot{u}+\boldsymbol{C} u=H\left(G+d_{c}+d_{w}+F\right) \\ \dot{e}_{x, i}=v_{q}-n_{i} n_{i}^{2} v_{q} \\ \dot{\tilde{r}}=v_{p} \\ \lambda_{W} \dot{\tilde{W}}=-\tilde{W}-\lambda e_{v, i}-\lambda_{p} \boldsymbol{B} v_{p} \\ \Sigma_{2}\end{array}\right.\tag{40}$$<p>其中 $u^T=[v^T_p\;e_{v,i}^T]$而 $\tilde W=\hat W-W$。对于在式(19)、(35)、(39)的控制下的 $\sum_e$，我们定义 $\tilde X=\{W,\tilde X_{tran},\tilde X_{rot}\}$。 $\sum_e$的平衡状态为 $\tilde X^*=\{{0,0,0,0,0,0,1}\}$。定义集合 ${\Gamma _1}=\{\tilde X^*\}$和 ${\Gamma _2}=\{\tilde X:\tilde R=1,\tilde \omega=0 \}$。因为 $\tilde X^*$为 $\sum_e$的平衡状态  $\forall \tilde X \in {\Gamma _1}$，所以从(19)中的控制力表示为 $F_{L,d}=-(m_p+m_q)g_I-W$，而且 $F_{L,d}$保存不变。基于(35)中的姿态提取图，因为 $\dot {\tilde R}=0,\omega_d=0$，所以 $ \tilde R=1,\dot {\tilde R}=0,\tilde {\omega_d}=0$。因此， $\tilde X \in {\Gamma _2},{\Gamma _1}\subset{\Gamma _2}$。由于 $\Gamma_1,\Gamma_2$是平衡状态，根据定义，它们是正不变的。而且，很明显 $\Gamma_1 $为有界的，因为它只包含一个平衡点。我们使用 $\phi([0,t],\tilde X_0) $表示给定初始状态 $\tilde X_0$的 $\sum_e$，我们定义 $\rho  =  - {R_{IB}}{e_3}\left\| {{F_{L,{\text{d}}}}} \right\| - {F_{L,{\text{d}}}}$为期望升力和实际升力的误差。</p><h3 id="A-整个系统的稳定性-巡航状态"><a href="#A-整个系统的稳定性-巡航状态" class="headerlink" title="A 整个系统的稳定性:巡航状态"></a>A 整个系统的稳定性:巡航状态</h3><p>在巡航状态中，我们希望证明 $\tilde X=\tilde X^*$在(19),(35)和(39)的控制下是局部渐近稳定的。在(19)中控制期望力 $F_{L,d}$作用下， $\Gamma_1 $相对于 $\Gamma_2$是渐近稳定的。因为在式(39)中的姿态追踪器是几乎全局渐近稳定，其保证了对于 $\forall\epsilon&gt;0$，都存在 $\delta &gt;0 $，例如 $\forall {\tilde X_0} \in {B_\delta }({\Gamma _1}),\phi ([0,t],{\tilde X_0}) \subset {B_\epsilon{}}({\Gamma _1})$。此外，假设扰动是有界的，例如 $({m_p} + {m_q})g - {k_e} - {k_v} &gt; {\epsilon_W} &gt; \left| {e_3^TW} \right|$和 $e_3^T(W_P-\lambda_pv_{d,i})+m_pg&gt;0$，我们可以选择足够小的 $\delta $以至于 $\forall {\tilde X_0} \in {B_\delta }({\Gamma _1})$，(27)和(38)都是满足的。因此， $\forall {\tilde X_0} \in {B_\delta }({\Gamma _1})$，姿态提取图不会达到奇异点。因此 ${\Gamma _2}$在 ${\Gamma _1}$附近是局部稳定的 。基于定理2，我们可以得到 ${\Gamma _1}$是稳定的。 ${\sum _e}$中所有轨道开始于 ${B_\delta }({\Gamma _1})$都停留在 ${B_\delta }({\Gamma _\epsilon})$内，因此姿态提取图将给出一个合适的解。由于 ${\sum _e}$开始于 ${B_\delta }({\Gamma _1})$的所有解都不会碰到姿态提取图的奇异点，因此姿态控制保证 ${\sum _e}$具有局部吸引力。最后，根据定理3， $\tilde X=\tilde X^*$是对于 ${\sum _e}$是全局渐近稳定的。此外，基于公式(19)，升力是有界的。即， $0<f<f_0$。< p=""> ${\Gamma _1}$的引力域的估计可以通过如下方法得到:使 ${D_{{\mathop{\rm tran}\nolimits} }} = \{ \widetilde {\bf{X}}:\left\| {{e_{v,i}}} \right\| \le \sqrt {{{4k_2^2} \over {k_1^2\lambda _W^2}} - c  }-\epsilon ,\left| {e_3^T\left( {{\lambda _p}B{v_p} + \lambda {e_v},i} \right)} \right| &lt; {\epsilon_W} - \left| {e_3^TW} \right|\} , \epsilon&gt; 0\}$。我们有一个吸引域(系统渐近稳定的区域)  $\chi_{\operatorname{tran}}=\left\{\tilde{\boldsymbol{X}}: V_{\Sigma_{1}} \leq V_{\Sigma_{1}}^{\star}\right\}$, 其中  $V_{\Sigma_{1}}^{\star}= \inf _{\tilde{\boldsymbol{X}} \in \partial D_{\text {tran }}} V_{\Sigma_{1}}(\tilde{\boldsymbol{X}})$。因为 $V_{\Sigma_{1}}$ 是径向无界的, 所以 $\chi_{\operatorname{tran}}$是紧集[什么是紧集(compact set)](https://zhuanlan.zhihu.com/p/403213165)。定义 $c_{0}$ 为  $c_{0}=\max \left\|e_{v, i}\right\|$ 对于  $e_{v, i} \in \chi_{\operatorname{tran}}$。因为 $\|\rho\|=0$表示姿态跟踪器的平衡，所以存在一个状态追踪器的吸引域  $\chi_{\text {rot }}$，即  $\forall \tilde{\boldsymbol{X}} \in \chi_{\text {rot }},\|\rho(\tilde{\boldsymbol{X}})\|&lt;\left(k_{v} / \sqrt{c_{0}^{2}+c}-k_{1} \lambda_{W}\right) c_{0} / 2$。当 $F_{L}$为控制力时， $\dot{V}_{\Sigma_{1}}$为：$$\dot{V}_{\Sigma_{1}} \leq-z^{T} \boldsymbol{A} z-y^{T} \boldsymbol{D} y-\zeta^{T} \boldsymbol{H}_{1} \zeta-\eta^{T} \boldsymbol{H}_{2} \eta+\left\| {{e_{v,i}}} \right\|\left\| \rho  \right\| \tag{41}$$</f<f_0$。<></p><p>因为 $t \rightarrow \infty $时 $\|\rho\| \rightarrow 0$，当  $\tilde{\boldsymbol{X}}_{0} \in \chi_{\text {tran }}$ ， $\dot{V}_{\Sigma_{1}}&lt;0$ 。   $\Sigma_{1}$是稳定的. 基于上述的稳定性分析, 当 $\Sigma_{1}$ 是稳定时,  $\Sigma$ 为渐近稳定。 <u>因此，整个系统的吸引域是  $\chi_{\Sigma_{e}}=\chi_{\operatorname{tran}} \cap \chi_{\text {rot }} $。 $ \chi_{\Sigma_{e}}$ 很难以计算得到，实际实现条件有限，需要通过仿真和飞行试验来确定实际边界。</u></p><h3 id="B-整个系统的稳定性-接近悬停状态"><a href="#B-整个系统的稳定性-接近悬停状态" class="headerlink" title="B 整个系统的稳定性:接近悬停状态"></a>B 整个系统的稳定性:接近悬停状态</h3><p>在接近悬停状态中，我们希望证明 $\tilde X=\tilde X^*$几乎全局渐近稳定的。我们进行了如<a href="https://ieeexplore.ieee.org/document/6748916">A Class of Position Controllers for Underactuated VTOL Vehicles | IEEE Journals &amp; Magazine</a>所示类似的分析。根据(19)和(18)，在 $\hat W$的初始条件为零时， $F_L$总是有界的。只要 $({m_p} + {m_q})g - {k_e} - {k_v} &gt; {\epsilon_W} &gt; \left| {e_3^TW} \right|$和 $e_3^T(W_P-\lambda_pv_{d,i})+m_pg&gt;0$，姿态提取图总是能给出一个合适的解。在系统无限制逃逸时间的情况下，姿态跟踪律保证了 $\Gamma_1 $为几乎渐近稳定的。如果缆绳不是松弛的，那么平移系统可以看作是在杆的两端各有两个点的刚性体。使 $v_c=(m_p(Bv_p+v_q)+(m_q+m_p))/(m_p+m_q)$， $\omega_c$为杆的质心的平动速度和角速度。注意 $\omega_c$是缆绳的转速，所以ω总是垂直于缆绳。因为$R_{IB}$有单位范数且通过控制设计使 $||F_L||&lt;\infty，(m_p+m_q)g_I+F_d+\rho+W$有界，绳载负载的四旋翼系统的合力和合力矩有界。因此， $\dot v_c$和 $\dot \omega_c$是有界的。对于 $\forall t &gt; 0$， $v_c$和 $ \omega_c$被定义为：</p> $$v_{q}=-\omega_{c}^{\times} \frac{m_{p}}{m_{p}+m_{q}} L+v_{c}, \boldsymbol{B} v_{p}=\omega_{c}^{\times} \frac{m_{q}}{m_{p}+m_{q}} L+v_{c} \tag{42}$$<p>对于(42), $v_{q},\boldsymbol{B} v_{p}$被定义在 $\forall t &gt; 0$上。因此， $\Lambda={Bv_p,v_q,e_i,\hat W}$被定义为 $\forall t &gt; 0$上。  $\omega_{d}$ 被  $\left\{\boldsymbol{\Lambda}, R_{I B}\right\}$决定。因为  $R_{I B} \in S O(3)$ 而 $S O(3)$  是紧集， $\omega_{d}$ 被定义在 $\forall t &gt; 0$上。因为  $\tilde{\boldsymbol{X}}_{\text {rot }}$ 对于姿态追踪控制器是几乎全局渐近稳定的，所以$\tilde{\omega}$是有界的。因为  $\tilde{\omega}$ 被定义为  $\tilde{\omega}=\omega-\tilde{R}^{T} \omega_{d}$， 所以 对于 $\forall t \geq 0$， $\omega$​是有界的。因此，闭环系统有无限制的逃逸时间。使 $\boldsymbol{\Phi}$ 作为  $\Gamma_{2} $的吸引域。 然后,  $\Gamma_{2}$ 相对于  $\Phi$是几乎全局渐近稳定，从而有 $\rho(t) \rightarrow 0$。 对于悬停状态，我们有当 $t \rightarrow \infty$,  $\tilde{W} \rightarrow 0$。所以存在一个时间实例$t_{0}&lt;\infty$, 有对于  $1 / 2 k_{v}&gt;c_{0}&gt;0,\|\rho(t)+\tilde{W}\|<c_{0} $="" 。基于="" (32),="" 我们得到如下式：<="" p=""> $$\dot{V}_{\Sigma_{1}} \leq-\frac{k_{v}\left\|e_{v, i}\right\|^{2}}{\sqrt{\left\|e_{v, i}\right\|^{2}+c}}+\left\|e_{v, i}\right\| c_{0}-\frac{1}{k_{1} \lambda_{W}} \tilde{W}^{T} \tilde{W} \tag{43}$$</c_{0}></p><p>如果 $\left\|e_{v, i}\right\|&gt;c_{0} \sqrt{c /\left(k_{v}^{2}-c_{0}^{2}\right)}$,  $\dot{V}&lt;0$。因为  $\Lambda$ 被定义在 $\forall t \geq 0, \Lambda$ 是有界的。 因为  $\omega_{d}$ 是关于  $\left\{\boldsymbol{\Lambda}, R_{I B}\right\}$的光滑函数, 而  $R_{I B} \in S O(3)$，所以 $ \omega_{d}$ 是有界的。最后，  $\tilde{\omega}_{d}$ 有界意味着  $\omega$ 有界。所以  $\Sigma_{2}$的所有解都有界，所以根据定理3， $ \tilde{\boldsymbol{X}}=\tilde{\boldsymbol{X}}^{\star}$ 为几乎全局渐近稳定。</p><h2 id="6-仿真简介"><a href="#6-仿真简介" class="headerlink" title="6 仿真简介"></a>6 仿真简介</h2><p>为了演示控制器的能力，在仿真中执行了一个路径跟踪任务。其中 $m_q=2(kg),m_p=2(kg)$。将路径分为三段（A,B,C），在A区域(恒定扰动)，在原常量风扰动上增加变化的风力扰动。在B区域(时变风扰动)，风扰动为常量。在C区域(阵风扰动)，在时间段65s-67s中，在原常量风扰动上增加常量风力扰动。</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS论文(2)</title>
      <link href="/2021/11/12/ps-lun-wen-2/"/>
      <url>/2021/11/12/ps-lun-wen-2/</url>
      
        <content type="html"><![CDATA[<p>论文地址：<a href="https://rss2017.lids.mit.edu/static/papers/31.pdf">Fast Trajectory Optimization for Agile Quadrotor Maneuvers with a Cable-Suspended Payload</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出了一种新型的绳载负载的四旋翼系统的动力学模型和快速轨迹优化算法，贡献如下：</p><ol><li>提出一个定义新型的悬挂负载行为的公式。其被建模为连接到四旋翼与两个转动关节和一个移动关节的组合，上述关节都是被动的。与当前的工作不同，我们不需要根据缆绳张力使用混合模式来确定模型。</li><li>提出了一种基于上述系统模型的快速轨迹优化算法。我们所提出的模型使我们能够将轨迹优化问题作为一个带互补约束的数学程序(MPCC， Mathematical Program with Complementarity Constraints)。在这个框架中，系统的期望行为(例如，避障)可以很容易地表述出来。</li></ol><p>提出的框架的具体优势</p><ol><li>在速度方面优于最先进的技术，而不限制轨道的复杂性;</li><li>提供参数化不同任务的简单方法;</li><li>根据系统动力学和控制输入边界，保证轨迹的可行性。</li></ol><p>实验简述：</p><p>本文所提出的方法在计算速度方面优于目前的技术水平，并且在系统动力学和控制输入饱和方面保证了轨迹的可行性，同时使用更少的优化参数。</p><p>我们在一个真实的四旋翼飞行器上实验验证了我们的方法，表明我们的方法适用于各种任务，如飞行通过理想的航路点，同时避免障碍物，或向理想的目标投掷有效载荷。</p><p>据我们所知，这是第一次在绳载负载的四旋翼飞行器上实现了基于系统动力学的三维灵活运动，如图1所示。</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gwdb7xsotnj30ew06zgoo.jpg" alt="我们的四旋翼飞行轨迹通过多个航路点，同时通过缆索悬挂运输负载。"></p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><h3 id="A-动机"><a href="#A-动机" class="headerlink" title="A 动机"></a>A 动机</h3><p>部分或完全驱动的操作器已经被用于空中操纵，可以将它们安装在四旋翼上进行操作。虽然这种解决方案适用于精细操作和与环境的交互，但它有一些缺点(例如，能源损耗、整体平台的大小、额外的惯性)，降低了无人机的灵活性。相反，通过绳载负荷的方式显著降低了系统的机械复杂性和重量，并且不需要额外的驱动，因此所需的能量最小。与驱动机械臂方法相比，绳载系统在系统动力学建模和参数化特定行为以完成预期任务方面引入了各种挑战。</p><p>缆绳张力的变化极大地改变了动力学描述，因为载荷可以通过缆绳将力传递给车辆，这取决于缆绳是否绷紧。通常引入一种混合动力学模型来处理系统的变化结构，根据拉索张力的不同有不同的数学描述(也称为模式)。这为系统提供了准确的描述，但使轨迹优化难以求解。实际上，混合优化会使用非常昂贵的计算性能，并且需要通过轨迹预先确定所需的模式序列。此外，这种公式通常会导致在为关键的安全功能(如缆绳缠绕)指定凸约束时遇到困难，并需要复杂的特定任务参数调整。此外，考虑工作空间，如在一组约束条件下考虑障碍物是困难的，并给轨迹优化带来额外的挑战。</p><h3 id="B-相关工作"><a href="#B-相关工作" class="headerlink" title="B 相关工作"></a>B 相关工作</h3><p>针对无人机绳载负荷的最新技术大致可分为两种方法:</p><ol><li>跟踪负载期望轨迹的反馈控制。(对象是负载位置)</li><li>绳载负荷的四旋翼飞行器的轨迹规划。(对象是四旋翼位置)</li></ol><p>本文主要使用的是第二种方法。</p><p>一种可能的解决方案是使运输载荷的摆动行为最小化。减少有效载荷的摆动会导致次优结果，因为它没有能量效率(四旋翼必须抵消有效载荷的摆动运动)，而且它没有利用系统动力学，阻止了高速敏捷的运动。</p><p>利用系统摆动动力学的敏捷导航轨迹规划也已进行了研究。虽然已经取得了令人印象深刻的成果，但仍有一些挑战尚未解决。已经提出了快速的轨迹计算方法，但往往不采用最优准则，不允许系统通过轨迹的行为约束或表示手动计算的系统状态硬约束。诸如航路点导航或避障等任务通常需要大量的参数，这些参数必须由专家操作人员手工调整，并显著影响系统的性能和所需的计算时间(例如，为每个障碍引入一个整数变量会成倍地增加问题的复杂性)。混合模式通常需要事先确定准确的模式序列。这迫使优化器沿着可能不是最优的单模态序列限制运动，并需要耗时的优化才能达到令人满意的结果。保证闭环系统性能的一个关键方面是计算轨迹的可行性。<a href="https://ieeexplore.ieee.org/document/5980409">微分平坦度</a>常被用来规划平滑的多项式轨迹，使基于系统输入的成本函数最小化，但不保证电机输入饱和。最后，其目前工作实验结构结果仅在仿真中显示，或在现实世界中仅限于二维运动的实验中显示。(参考文献<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6631275&amp;tag=1">Trajectory generation and control of a quadrotor with a cable-suspended load-a differentially-flat hybrid system</a>；<a href="https://ieeexplore.ieee.org/document/7139492">Mixed Integer Quadratic Program trajectory generation for a quadrotor with a cable-suspended payload </a>；<a href="https://ieeexplore.ieee.org/document/7171008">Lift of a cable-suspended load by a quadrotor: A hybrid system approach</a>；<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.713.8121"> Unified Motion Control for Dynamic Quadrotor Maneuvers Demonstrated on Slung Load and Rotor Failure Tasks </a>)</p><h2 id="2-问题公式化"><a href="#2-问题公式化" class="headerlink" title="2 问题公式化"></a>2 问题公式化</h2><h3 id="A-系统动力学的公式"><a href="#A-系统动力学的公式" class="headerlink" title="A 系统动力学的公式"></a>A 系统动力学的公式</h3><p>大多数在绳载负载的空中操作都采用一种混合方法，根据缆索的张力建立两种模式的系统模型。在第一种模式中，缆绳完全绷紧并在四旋翼和负载之间传递力;在第二种模式中，缆绳是松弛的，导致有效载荷服从自由落体动力学。这使得轨迹优化成为一个复杂的问题，因为需要混合轨迹优化，并且系统状态约束通常是非凸的。</p><p>相反地，我们引入了一种新颖而简单绳载负载的四旋翼系统参数化方法。我们通过一个由三个被动约束关节(两个转动关节和一个移动关节)组成的系统将负载建模为附着在四旋翼悬架基座上的质量点。通过利用关节限制的棱柱关节<em>ρ</em>模拟了绳载负载系统的混合模式。在<em>ρ</em>处于极限状态时，反作用力通过关节传输回悬挂基座。<u>(好像是把缆绳和负载当做机器臂的关节处理)</u>我们模型中的广义坐标如表1和图2所示：</p>$${q_{coord}} = {\left[ {x,y,z,\phi ,\theta ,\psi ,\eta ,\mu ,\rho } \right]^T} \tag{1}$$<p>动力学可以被描述为一个二阶系统或使用如<a href="https://link.springer.com/book/10.1007/978-1-84628-642-1">Robotics | SpringerLink</a>所述的欧拉-拉格朗日方程，得到类似<a href="https://www.sciencedirect.com/science/article/pii/S1474667016336928">Cartesian Impedance Control of a UAV with a Robotic Arm - ScienceDirect</a>的公式:</p>$$H(q)\ddot q + C(q,\dot q) + G(q) = B(q)u \tag{2}$$<p>其中$q = \left[ {{q_{coord}},{{\dot q}_{coord}}} \right]$</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gwdb9vb1gvj30c10alwfl.jpg" alt="模型描述和整体结构"></p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gwf0qtvzfvj30to07jjvs.jpg" alt="表1 绳载负载的四旋翼系统的变量"></p><h3 id="B-轨迹优化问题"><a href="#B-轨迹优化问题" class="headerlink" title="B 轨迹优化问题"></a>B 轨迹优化问题</h3><p>我们提出的轨迹优化问题如下：</p>$${\text{find }}\ddot q{\text{ subjiect to}}$$$$H(q)\ddot q + C(q,\dot q) + G(q) = B(q)u \tag{3}$$$$f(q,u) \geqslant 0 \tag{4}$$<p>该轨迹被划分为N个时间节点，其中系统动力学包括一个直接转化方式。我们决定使用直接方法<a href="https://www.researchgate.net/publication/230872953_Direct_Trajectory_Optimization_Using_Nonlinear_Programming_and_Collocation">(PDF) Direct Trajectory Optimization Using Nonlinear Programming and Collocation </a>，因为它在数值上优于其他技术，如射击方法<a href="https://link.springer.com/chapter/10.1007/978-3-642-36279-8_32">Direct Trajectory Optimization of Rigid Body Dynamical Systems through Contact </a>。此外，尽管它们会导致更大的优化问题，但这些问题是稀疏的，可以非常快地解决。</p><p>我们使用一阶欧拉逼近将动力学化作时间步长<em>q</em>(<em>n</em>)和<em>q</em>(<em>n</em>+ 1)之间的等式约束。这种等式约束通过最小化缺陷变量${\zeta _n}$被定义为:</p>$${\zeta _n} = q(n + 1) - q(n) - dt(n)\dot q(n) \tag{5}$$<p>这种一阶近似是可能的最简单的积分方案，因此可以得到有效的计算。此外，它得到了一个定义良好的非线性问题的近似，可以提供给求解器及其梯度。</p><h3 id="C-将绳载负载的四旋翼运动问题视作MPCC问题"><a href="#C-将绳载负载的四旋翼运动问题视作MPCC问题" class="headerlink" title="C 将绳载负载的四旋翼运动问题视作MPCC问题"></a>C 将绳载负载的四旋翼运动问题视作MPCC问题</h3><p>我们将这个特殊问题作为一个带互补约束的数学程序(Mathematical Program<br>with Complementarity Constraint,MPCC),如下：</p>$$\eqalign{  &amp; \min {\text{ }}L(q,\dot q,u,t){\text{ subject to}}  \cr   &amp; H(q)\ddot q + C(q,\dot q) + G(q) = B(q)u + J{(q)^T}\lambda ,  \cr   &amp; f(q,u) \geqslant 0,  \cr   &amp; \phi (q) = ({l_0} - \rho ) \geqslant 0,  \cr   &amp; \lambda  \geqslant 0,  \cr   &amp; \phi (q)\lambda  = 0 \cr} \tag{6}$$<p>接下来，我们介绍MPCC的成本函数和所有的约束。</p><ol><li><p>成本函数公式：</p><p>我们基于状态、输入和时间构建成本函数如下<br>$$L(q,u,t) = {S_f}{t_f} + \int_t {q{{(t)}^T}Qq(t)}  + u{(t)^T}Ru(t)dt  \tag{7}$$   其中，   ${S_f}$为终止时间系数，Q和R是状态和输入对应的对角正定代价矩阵，维度分别为${\mathbb{R}^{18 \times 18}}$和${\mathbb{R}^{4 \times 4}}$。<br>通过将代价描述为具有终止时间代价的状态和输入的二次函数，我们减少了优化参数的数量，并利用了优化中的解析导数。(成本函数中的q和公式中的q有矛盾？)</p></li><li><p>线性互补约束：<br>用一个互补约束来模拟缆绳长度的限制，即把缆绳长度当作一个关节的限制。该约束公式与<a href="https://link.springer.com/chapter/10.1007/978-3-642-36279-8_32">Direct Trajectory Optimization of Rigid Body Dynamical Systems through Contact | （这篇文章中的公式与本文中的很相似）</a>中提出的约束公式类似，其形式如下：</p>$$\eqalign{     &amp; \phi (q) = ({l_0} - \rho ) \ge 0  \cr      &amp; \lambda  \ge 0,  \cr      &amp; \phi (q)\lambda  = 0 \cr} $$<p>$\phi (q)$为${l_0}$的突破约束；<br>λ为表示约束力的决定变量；<br>$\phi (q)\lambda  = 0$为实现了两者的互补约束。</p></li><li><p>输入限制约束:<br>我们考虑到驱动系统的物理限制，对每个电机提供的推力施加一个上限和下限:</p>$${T_{\min }} \leqslant u \leqslant {T_{\max }} \tag{9}$$</li><li><p>关节限制约束：<br>限制了四旋翼和负载之间的最大角度以防止负载缆索进入旋翼。</p>${\alpha _{\min }} \leqslant \eta ,\mu  \leqslant {\alpha _{\max }} \tag{10}$</li><li><p>避障：<br>为了简化避障，我们在工作空间中将障碍物建模为球体，并使用与<a href="https://ieeexplore.ieee.org/abstract/document/5152817">CHOMP: Gradient optimization techniques for efficient motion planning</a>相似但使用经过简化的带符号距离函数。因此，绳载负载的四旋翼系统与障碍物之间的距离可以约束为:</p>$$d(q(t)) = \sqrt {{{(p(t) - o)}^T}(p(t) - o)}  - \rho (t) - r \tag{11}$$   其中$p(t) = {\left[ {x(t),y(t),z(t)} \right]^T}$是四旋翼的位置，$o = {[{x_o},{y_o},{z_o}]^T}$为半径为*r*的障碍物位置。描述带符号距离的方法同样适用于无数个圆柱形障碍物，其中距离函数为:   $$\eqalign{     &amp; {r_{op}}(t) = (p(t) - o) - (p(t - o) \cdot n) \cdot n  \cr      &amp; d(q(t)) = \sqrt {{r_{op}}{{(t)}^T}{r_{op}}(t)}  - \rho (t) - r \cr} \tag{12}$$<p>其中<em>n</em>为对称轴。这个函数可以作为一个不等式约束，因此，执行一个保守但安全的轨迹，实现无人机本体、负载、缆绳和障碍物之间的碰撞。从而就不需要任何模态序列或混合模型。</p></li></ol><h3 id="D-实现特定任务"><a href="#D-实现特定任务" class="headerlink" title="D 实现特定任务"></a>D 实现特定任务</h3><p>在本节中，我们将展示如何将优化问题的一般公式用于特定的任务，如航点导航和向预期目标投掷负载。</p><ol><li><p>航点导航：<br>航点导航任务可以描述为前三个状态变量$p(n) = {\left[ {x(n),y(n),z(n)} \right]^T}$(<em>n</em>为系统的给点时间点)的边界框约束。为了算法的鲁棒性，我们不使用等式约束，而是允许一个路径点存在很小的容许误差δ，不等式约束如下:</p>$${p_{w,i}} - \delta  \leqslant p(n) \leqslant {p_{w,i}} + \delta \tag{13}$$<p>此外，还可以设置负载的位置，因为它是在系统状态中是完全定义的。</p></li><li><p>负载投掷:<br>投掷运动的目标是：释放负载，使其落向给定的目标。释放后，负载将遵循一个弹道轨迹，其最终位置可以被限制在期望的目标位置周围的一个给定的阈值内。</p>${p_r} = \left[ {{x_r},{y_r},{z_r}} \right]$为释放负载瞬间的负载在世界坐标系下的负载位置，${{\dot p}_r}$为释放负载瞬间的负载在世界坐标系下的负载速度。${p_t} = \left[ {{x_t},{y_t},{z_t}} \right]$为目标位置。${p_h}$为无人机处于期望高度时在弹道轨迹中的位置。需要注意${p_r},{{\dot p}_r}$可以通过$q(t)$和正向运动学雅克比矩阵$J(q(t))$的乘积得到(${{\dot p}_r} = J(q(t))\dot q(t)$).   $$\eqalign{     &amp; {t_1} = \left\{ \matrix{     {{{{\dot z}_r}} \over g}{\rm{,  }}{{\dot z}_r} &gt; 0 \hfill \cr      0{\rm{, }}{{\dot z}_r} \le 0 \hfill \cr}  \right.  \cr      &amp; {z_{\max }} = {z_r} + {{\dot z}_r}{t_1} - g{{t_2^2} \over 2}  \cr      &amp; {t_2} = {t_1} + \sqrt {{{2({z_{\max }} - {z_t})} \over g}}   \cr      &amp; {p_h} = {p_r} + {{\dot p}_r}{t_2} + \left[ {0,0, - g} \right]{{t_2^2} \over 2} \cr} \tag{14}$$   其中，${t_1}$为载体自由落体抛物运动达到峰值的时间，${t_2}$为载体到达期望高度的时间   此外，我们施加以下约束:   $$0 \le \left\| {{p_h} - {p_t}} \right\| \le {d_{\max }} \tag{15}$$<p>${d_{\max }}$为所允许的与目标位置的最大距离。这个公式的优点是，我们不限制释放的位置，而是让优化过程找到它的最佳值。</p></li></ol><h2 id="3-实验过程简介"><a href="#3-实验过程简介" class="headerlink" title="3 实验过程简介"></a>3 实验过程简介</h2><p>用于实验的四旋翼系统的参数。</p><div class="table-container"><table><thead><tr><th style="text-align:center">无人机质量</th><th>0.76kg</th></tr></thead><tbody><tr><td style="text-align:center">负载质量</td><td>0.084kg</td></tr><tr><td style="text-align:center">磁力抓取器质量</td><td>0.062kg</td></tr><tr><td style="text-align:center">无人机臂长</td><td>0.22m</td></tr><tr><td style="text-align:center">缆绳长度</td><td>0.82m</td></tr><tr><td style="text-align:center">负载角度限制</td><td>-60度/+60度</td></tr><tr><td style="text-align:center">推力限制</td><td>1N/5N</td></tr></tbody></table></div><p>未完待更新~~~</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PS论文(1)</title>
      <link href="/2021/11/08/ps-lun-wen-1/"/>
      <url>/2021/11/08/ps-lun-wen-1/</url>
      
        <content type="html"><![CDATA[<p>对应文章地址：<a href="https://www.researchgate.net/publication/330591165_Decentralized_Motion_Control_in_a_Cabled-based_Multi-drone_Load_Transport_System">Decentralized Motion Control in a Cabled-based Multi-drone Load Transport System</a></p><h2 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1 摘要"></a>1 摘要</h2><p>提出了一种可证明稳定的<a href="https://zhuanlan.zhihu.com/p/45346771">分散式控制方案</a>，允许多架传统四轴飞行器通过缆绳悬挂携带负载。该方法利用无人机、缆绳和负载组成的系统的基本<a href="?">能量无源性</a>，稳定地将负载从原点移动到目的地。这是在不假设飞行期间缆绳张力的状态以及不对负载的进行任何测量的情况下实现的。  因为反馈测量的无人机之间的通信是不需要的，所以控制器是分散的。通过李雅普诺夫法分析证明了运动的稳定性。所提出的控制器使用光学跟踪系统和无人机机载 IMU 的测量数据成功地在室内环境中的三无人机负载运输系统上实施。</p><h2 id="2-引言"><a href="#2-引言" class="headerlink" title="2 引言"></a>2 引言</h2><h3 id="运输方案方案对比"><a href="#运输方案方案对比" class="headerlink" title="运输方案方案对比"></a>运输方案方案对比</h3><p>小型多旋翼无人机的缺点：运输负载质量受限，飞行时间短。</p><p>可以通过增加动力单元数目以及电池大小，可以提高负载上限以及相应的飞行时间。从而设计出大型多旋翼无人机。</p><p>但大型多旋翼无人机也存在缺点：在运送较小的物品时效率会非常低，在狭窄的环境中的运动也更不灵活，更难控制。</p><p>而另外一种运输负载的方式：多无人机运输有效解决了上述两种运输方式存在的问题:根据负载的重量和大小调整无人机数目。</p><h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p>本文提出了一种简单有效的运动控制方法，用于多架无人机携带缆绳悬吊载荷的控制。该系统除了具有可扩展性外，还因为其固有的冗余性而具有更强的容错能力。有一些有限的工作在多旋翼无人机的运动控制与缆索或刚性连杆悬挂负载在单一或多无人机配置。在<a href="https://ieeexplore.ieee.org/document/7843619">Geometric Control of Quadrotor UAVs Transporting a Cable-Suspended Rigid Body</a>中研究了多架四轴飞行器通过连接刚性连杆承载载荷的几何控制问题。虽然使用刚性连杆可以简化控制设计，但它限制了这种系统在航空运输中的实际用途。同时，这篇文章仅给出了仿真结果。</p><p>在<a href="https://link.springer.com/article/10.1007/s10514-017-9632-2">Cable-suspended load lifting by a quadrotor UAV: hybrid model, trajectory generation, and control </a>中给出了具有点质量负载的单四轴飞行器的混合模型，其轨迹设计使负载的摆动最小化，这篇文章进行了实验验证，但缺少稳定性的证明。在<a href="https://ieeexplore.ieee.org/document/8038248">Cable-suspended load lifting by a quadrotor UAV: hybrid model, trajectory generation, and control </a>中，基于点质量负载的单四轴飞行器的拉格朗日动力学模型，利用缆绳始终处于张力状态的假设，提出了一种控制器。然而，这篇文章所提出的控制器无法保证该假设在包含起飞和降落过程的任意轨迹上的有效性。</p><p>除了缆绳的灵活性外，无人机-负载系统的运动控制也因无人机的固有欠驱动而变得复杂<a href="https://ieeexplore.ieee.org/document/7353620">Adaptive motion control of aerial robotic manipulators based on virtual decomposition </a>，而悬挂负载的加入进一步加剧了这一问题<a href="https://ieeexplore.ieee.org/document/8038248">Nonlinear Hierarchical Control for Unmanned Quadrotor Transportation Systems </a>。在控制工程文献中，这个问题一般被认为是<a href="https://zhuanlan.zhihu.com/p/106492555">双欠驱动系统</a>的轨迹跟踪问题。<a href="https://ieeexplore.ieee.org/document/8038248">Nonlinear Hierarchical Control for Unmanned Quadrotor Transportation Systems</a>和<a href="https://www.researchgate.net/publication/272352741_Health_Healthcare_Access_and_Use_of_Traditional_Versus_Modern_Medicine_in_Remote_Peruvian_Amazon_Communities_A_Descriptive_Study_of_Knowledge_Attitudes_and_Practices">Quadcopter design for medicine transportation in the peruvian amazon rainforest</a>中提出的方法考虑的是固定的期望位置。在<a href="https://ieeexplore.ieee.org/abstract/document/6631275">Trajectory generation and control of a quadrotor with a cable-suspended load - A differentially-flat hybrid system </a>中，研究了具有点质量负载的单四轴飞行器的运动控制问题。然而，其分析仅限于平面情况。</p><p>本文提出了一种可证明稳定的多轴四轴飞行器的分布式运动控制方法。这种方法的控制思路为：运输应用不需要对负载本身进行非常精确的运动控制，真正重要的是整个控制系统的鲁棒稳定性。比例导数PD控制器可以在不需要精确跟踪的情况下，为传统机械臂提供鲁棒稳定的运动控制，这要归功于控制器和机械臂子系统的<a href="?">能量无源性</a>。事实上，在机器人的控制中，这种无源性已经得到了广泛的应用<a href="https://ieeexplore.ieee.org/document/194594">Adaptive motion control of rigid robots: a tutorial </a>,<br><a href="https://ieeexplore.ieee.org/document/1618740">Passive Bilateral Teleoperation With Constant Time Delay</a>,<br><a href="https://link.springer.com/book/10.1007/978-3-319-15171-7">Passivity-Based Control and Estimation in Networked Robotics（重点，是一本书）</a>。本文提出的运动控制方法依赖于无论缆绳的状态如何，相互连接的无人机负载系统都具有<a href="?">能源被动性</a>的原理。该控制律由系统的无源性启发的李雅普诺夫函数导出，并考虑了无人机的欠驱动性。该控制方案可以使用局部位置/速度测量值以分布式方式在单个无人机上实施，不需要对负载进行的任何测量，也不假设缆绳张力的状态。</p><blockquote><p>摘要中系统控制方案为 decentralized control (分散式控制方案)，而引言中的系统控制方案为distributed motion control(分布式运动控制)。我认为decentralized其实是被distributed所包含的，不用特意区分，具体理解可参考<a href="https://blog.csdn.net/John1688888/article/details/82966807"> “去中心化(分散式)”和“分布式”的区别</a>。</p></blockquote><h2 id="3-系统建模"><a href="#3-系统建模" class="headerlink" title="3  系统建模"></a>3  系统建模</h2><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1gwbfasj40rj309d05wwez.jpg" alt="多无人机运输绳系负载"></p><p>在本文中，我们用上标来表示表示矢量的所在的坐标系。上标’ 0 ‘表示固定的世界坐标系，为了简单起见，去掉了上标。该系统由非传统的四轴飞行器组成，通过柔性绳携带负载，如图1所示。每根缆绳的一端连接到无人机的质心。在系统动力学和控制器的开发中，忽略了缆绳质量。</p><p>根据图1，当缆绳处于张力时，下列运动学约束成立：$${q_i} - {q_L} = {R_L}(r_i^l - {l_i}e_i^l),\forall i \in \{ 1,...,n\} $$ $$\left\| {{q_i} - {q_L} - {R_L}r_i^l} \right\| &lt;  {l_i} $$其中， ${q_i}$和 ${q_L}$分别表示第 ${i}$个无人机质心和负载质心在世界坐标系中的三维位置； ${R_L}$是负载体坐标系(固定在负载上的坐标系)转换为世界坐标系对应的旋转矩阵； ${e_i^l}$是沿着第 ${i}$条缆绳连接且指向负载上相关连接点的单位向量，在负载体坐标系中表示； ${r_i^l}$是载荷的质心连接到第 ${i}$个附着点的矢量，并在负载体坐标系中表示； ${l_i}$表示第 ${i}$个无人机与负载连接的缆绳长度。而四旋翼的平动动力学方程如下所示：$${m_i}{\ddot q_i} = {f_i}{R_i}z - {m_i}gz + {T_i}{R_L}e_i^l$$其中 ${m_i}$， ${f_i}$分别表示无人机质量和推力； $g$为重力加速度； ${T_i}$为缆绳的拉力； ${R_i}$是第 ${i}$个无人机的机体坐标系(固定在四旋翼上的坐标系)转换为世界坐标系对应的旋转矩阵； $z = {\left[ {\matrix{   0 &amp; 0 &amp; 1  \cr  } } \right]^{\rm{T}}}$是在世界坐标系表示的单位向量。</p><p>四旋翼的姿态动力学方程如下所示：</p>$${M_i}({\eta _i}){\ddot \eta _i} + {C_i}({\eta _i},{\dot \eta _i}){\dot \eta _i} = \Psi {({\eta _i})^{\rm{T}}}{{\rm{\tau }}_i}$$<p>其中</p> $${\eta _i} = {\left[ {{\phi _i},{\theta _i},{\psi _i}} \right]^{\rm{T}}}$$$$\eqalign{  &amp; {M_i}({\eta _i}) = \Psi {({\eta _i})^{\rm{T}}}{J_i}\Psi ({\eta _i})  \cr   &amp; {C_i}({\eta _i},{{\dot \eta }_i}) = \Psi {({\eta _i})^{\rm{T}}}{J_i}\Psi ({\eta _i}) -  \Psi {({\eta _i})^{\rm{T}}}sk(\Psi ({\eta _i}){{\dot \eta }_i}){J_i}\Psi ({\eta _i})  \cr   &amp; \Psi ({\eta _i}) = \left[ {\matrix{   1 &amp; 0 &amp; { - \sin ({\theta _i})}  \cr    0 &amp; {\cos ({\phi _i})} &amp; {\cos ({\theta _i})\sin ({\phi _i})}  \cr    0 &amp; {\sin ({\phi _i})} &amp; {\cos ({\theta _i})\cos ({\phi _i})}  \cr  } } \right] \cr} $$ ${J_i}$是四轴飞行器在其固定坐标系中的转动矩阵， $τ$是机体坐标系中的被施加的扭矩。 $sk(·)$是所谓的斜算子。单刚体负载的平动动力学方程和姿态动力学方程可表示为：$$\eqalign{  &amp; {m_L}{{\ddot q}_L} =  - \sum\limits_{i = 1}^n {{T_i}{R_L}{e_i}}  - {m_L}gz  \cr   &amp; J_L^l\dot \Omega _L^l + sk(\Omega _L^l)J_L^l\Omega _L^l = \sum\limits_{i = 1}^n {sk(r_i^l)( - {T_i}e_i^l)}  \cr} $$<p>其中，其中 $J_L^l$是负载相对于质心的恒定惯量， ${m_L}$是负载的质量，  $\Omega _L^l$在其负载体坐标系中表示的负载的角速度。</p><p>四旋翼的动力学方程主要参考<a href="https://arc.aiaa.org/doi/10.2514/1.43768">Nonlinear Hierarchical Flight Controller for Unmanned Rotorcraft: Design, Stability, and Experiments |核心文章（文章推导主要依托的文章）</a>。</p><h2 id="4-控制器设计与稳定性分析"><a href="#4-控制器设计与稳定性分析" class="headerlink" title="4 控制器设计与稳定性分析"></a>4 控制器设计与稳定性分析</h2><h3 id="控制器设计"><a href="#控制器设计" class="headerlink" title="控制器设计"></a>控制器设计</h3><p>控制器设计从单个无人机的姿态控制开始。设 $\det \left( {\Psi \left( {{\eta _i}} \right)} \right) \ne 0$，采用以下反馈线性化控制律:</p>$${{\rm{\tau }}_i} = {(\psi {({\eta _i})^{\rm{T}}})^{ - 1}}({M_i}({\eta _i}){v_i} + {C_i}({\eta _i},{\dot \eta _i}){\dot \eta _i})$$ ${v_i}$的定义如下$${v_i} = {{\ddot \eta }_{{d_i}}} - {K_v}{{\dot e}_{{\eta _i}}} - {K_c}{e_{{\eta _i}}}$$ ${e_{{\eta _i}}}$定义如下$${e_{{\eta _i}}} = {\eta _i} - {\eta _{{d_i}}}$$<p>其中 ${\eta _{{d_i}}}$(<u>原文中的是 ${\eta _{{i}}}$，我怀疑是有错误，因为前文已经定义了 ${\eta _{{i}}}$</u>)为期望姿态将在后文定义。${K_v},{K_c} \in {\mathbb{R}^{3 \times 3}}$为正常量参数，该控制器的控制目标为：</p>$${{\ddot e}_{{\eta _i}}} + {K_v}{{\dot e}_{{\eta _i}}} + {K_c}{e_{{\eta _i}}} = 0,t \ge 0 \tag{9}$$<p>反过来，</p>$$\left\| {{e_{{\eta _i}}}(t)} \right\| \le {k_1}\left\| {{\eta _{{0_i}}}} \right\|\exp ( - \alpha t),t \ge 0$$<p>其中 ${k_1}，\alpha$为正常量。</p><p>空中运输系统的目标是从点A到点B运输负载。为了实现这一目标，为每架无人机分配一个参考虚拟点。控制律将被推导出来，这样无人机就会沿着虚拟点的轨迹从原点到终点。当无人机完全驱动时，简单的比例导数pd控制器作为无人机与参考虚拟点之间的虚拟弹簧阻尼器耦合来实现控制目标。这里提出的控制律是建立在这个简单的概念，且考虑到无人机欠驱动。</p><p>参考虚拟点的轨迹记为${{\dot q}_{{v_i}}}(t) \in {C^2}[0,\infty )$，其中${C^2}$为有一、二阶连续导数的连续实值函数空间。参考虚拟点的轨迹规划细节不在本文讨论范围内，但作以下假设。</p>$$\eqalign{  &amp; {{\dot q}_{{v_i}}} \buildrel \Delta \over = {{\dot q}_v} \in {l_\infty },i \in \{ 1,...,n\}   \cr   &amp; {{\ddot q}_{{v_i}}} \buildrel \Delta \over = {{\ddot q}_v} \in {l_\infty },i \in \{ 1,...,n\}  \cr} $$上述假设简单地暗示了参考虚拟点在飞行过程中保持其空间配置。这将有助于减少无人机之间发生碰撞的可能性。参考虚拟点加速度的选取规则为${{\ddot q}_v} \in {l_1}$和${\lim _{t \to \infty }}{{\ddot q}_v} = 0$。无人机期望推力为<img src="https://tvax3.sinaimg.cn/large/007mx13gly1gwcer09os9j30it01lwek.jpg" style="zoom:50%;">其中，$\tilde q \buildrel \Delta \over = q - {q_{{v_i}}}$，${K_p},{K_d} \in {\mathbb{R}^{3 \times 3}}$为表示虚拟弹簧-阻尼器的刚度和阻尼系数的正定矩阵。然而，考虑到无人机的力欠驱动，实际推力可能不完全遵循期望推力，即$${f_i}R({\eta _i})z = {f_i}R({\eta _{{d_i}}} + {e_{{\eta _i}}})z \buildrel \Delta \over = {f_i}R({\eta _{{d_i}}})z + {f_i}H({\eta _{{d_i}}},{e_{{\eta _i}}}) = {\mu _i} + {f_i}H({\eta _{{d_i}}},{e_{{\eta _i}}})$$<p>其中$H({\eta _{{d_i}}},{e_{{\eta _i}}}) \in {\mathbb{R}^{3}} $，$H({\eta _{{d_i}}},0) = 0$。上面等式的左边表示实际的推力。右手边的第一项是期望推力，第二项是推力误差。根据<a href="https://arc.aiaa.org/doi/10.2514/1.43768">Nonlinear Hierarchical Flight Controller for Unmanned Rotorcraft: Design, Stability, and Experiments |核心文章（文章推导主要依托的文章）</a>可以证明</p>$$\left\| {H({\eta _{{d_i}}},{e_{{\eta _i}}})} \right\| \le {k_2}\left\| {{e_{{\eta _i}}}} \right\|,{k_2} \in {\mathbb{R}^{+}}$$<p>三个非线性方程的集合为</p>$${f_i}R({\eta _{{d_i}}})z = {\mu _i} = {\left[ {\matrix{   {{\mu _{{x_i}}}} &amp; {{\mu _{{y_i}}}} &amp; {{\mu _{{z_i}}}}  \cr  } } \right]^{\rm{T}}}$$<p>其中包含四个未知量：推力的大小${f_i}$，三个欧拉角${\eta _{{d_i}}} = {\left[ {{\phi _{{d_i}}},{\theta _{{d_i}}},{\psi _{{d_i}}}} \right]^{\rm{T}}}$,这些方程可以解得拉力${f_i}$，两个欧拉角${{\phi _{{d_i}}}}$和${{\theta _{{d_i}}}}$。而剩下的期望欧拉角而${{\psi _{{d_i}}}}$被选着为线性运动的独立变量。</p><p>注意，从无人机期望推力方程可以得出推力大小满足不等式：</p><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gwcerbvp0xj30n80243yn.jpg" style="zoom:50%;"></p>$$M{\rm{ }} \buildrel \Delta \over = \mathop {\max }\limits_{i \in \{ 1,...,n\} } {m_i}$$<p><em>M</em>表示编队中最大的无人机质量。</p><h3 id="稳定性分析"><a href="#稳定性分析" class="headerlink" title="稳定性分析"></a>稳定性分析</h3><p>稳定性分析是使用<u>李雅普诺夫第二法</u>进行分析的。</p><p>定义无人机运输系统的能量函数E如下：</p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1gwceyoalizj30kz0eywg1.jpg" style="zoom:50%;"></p><p>能量函数非负证明：</p><p>其中$\mathcal{k}$调整重力势能参考点的正常数，${E_1}$明显大于0。已知${q_{{v_i}}}$的有界性($\left\| {{q_i} - {q_L} - {R_L}r_i^l} \right\| &lt;  {l_i}$)，我们还可以证明${E_2}$是下界的，所以通过选择适当的$\mathcal{k}$可以使${E_2}$非负。能量函数导数小于0证明：不管缆绳的状态如何，联合无人机-缆绳-负载系统的无源性可以被利用：无人机闭环姿态动力学如公式9所示。联合如下公式$${m_i}{\ddot q_i} = {f_i}{R_i}z - {m_i}gz + {T_i}{R_L}e_i^l$$<img src="https://tvax3.sinaimg.cn/large/007mx13gly1gwcer09os9j30it01lwek.jpg" style="zoom:50%;">$${f_i}R({\eta _i})z = {f_i}R({\eta _{{d_i}}} + {e_{{\eta _i}}})z \buildrel \Delta \over = {f_i}R({\eta _{{d_i}}})z + {f_i}H({\eta _{{d_i}}},{e_{{\eta _i}}}) = {\mu _i} + {f_i}H({\eta _{{d_i}}},{e_{{\eta _i}}})$$</p><p>可以得到无人机的闭环平动动力学</p><p><img src="https://tva3.sinaimg.cn/large/007mx13gly1gwcgnmpuq4j30fw02bwel.jpg" style="zoom: 67%;"></p><p>在任何给定的时间，以下两个约束中的一个适用于每根缆绳。</p><ul><li><p>如果绳子不受到拉力作用，则${T_i} = 0$</p></li><li><p>如果绳子不受到拉力作用，则${T_i} &gt; 0$，且存在如下关系：</p>$${({R_L}{e_i})^{\rm{T}}}({\dot q_i} - {\dot q_L} - {R_L}sk({\Omega _L}){r_i}) = 0$$<p>从而对能量函数求导得到：</p><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gwch7dahafj30be076aau.jpg" style="zoom: 80%;"></p><p>经过一系列操作后得到</p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1gwchbmlfo7j30hi06vt9e.jpg" style="zoom:67%;"></p><p>利用向量的内积和外积的性质，可以得到：</p>$$\sum\limits_{i = 1}^n {{{(sk({\Omega _L}){r_i})}^{\rm{T}}}( - {T_i}{e_i})}  = \sum\limits_{i = 1}^n {{{({R_L}sk({\Omega _L}){r_i})}^{\rm{T}}}( - {T_i}{R_L}{e_i})} $$<p>则有：</p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1gwchjrkl82j30hu04d74x.jpg" style="zoom:67%;"></p><p>无论缆绳张力的状态，最后一项始终是零，则得到最简单化的能量函数导数</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gwchlpu6qzj30h503fq38.jpg" style="zoom:80%;"></p><p>注意，第三项是由于系统欠驱动导致的。</p><p>接下来证明能量函数的有界性。</p><p>根据前面证明的约束条件：</p><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gwcerbvp0xj30n80243yn.jpg" style="zoom:50%;"></p>$$\left\| {H({\eta _{{d_i}}},{e_{{\eta _i}}})} \right\| \le {k_2}\left\| {{e_{{\eta _i}}}} \right\|,{k_2} \in {\mathbb{R}^{+}}$$<p>可以得到：</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gwcibvregfj30ho03o0t1.jpg" style="zoom:80%;"></p><p>对于任意的$\left\| {{{\dot q}_L}} \right\| \ge 1$，其服从于$\left\| {{e_{{\eta _i}}}(t)} \right\| \le {k_1}\left\| {{\eta _{{0_i}}}} \right\|\exp ( - \alpha t),t \ge 0$和<a href="https://www.sciencedirect.com/science/article/pii/S0045790616301999">A novel position and force coordination approach in four channel nonlinear teleoperation - ScienceDirect</a>中的不等式，从而可以得到</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gwcm201p0tj30fq04mq3a.jpg" style="zoom: 80%;"></p></li></ul><p>  其中${I_3}$为单位矩阵，上式的上界为以能量函数组成的式子，其中${K_1,K_2}$为大于0的常数</p><p>  <img src="https://tvax4.sinaimg.cn/large/007mx13gly1gwcir5ybmqj30bv025q2z.jpg" style="zoom:67%;"></p><p>  由<a href="https://www.tandfonline.com/doi/full/10.1080/00207179.2013.826385">Full article: Defending the beauty of the Invariance Principle (tandfonline.com)</a>中的Gronwall-Bellman引理可以得到</p><p>  <img src="https://tva4.sinaimg.cn/large/007mx13gly1gwcitoc9gpj30du03ydg0.jpg" style="zoom: 67%;"></p><p>  其中，$f(t) \buildrel \Delta \over = {K_1}\exp ( - \alpha t) + {K_3}\left\| {{{\ddot q}_v}} \right\|$，$g(t) \buildrel \Delta \over = {K_2}\exp ( - \alpha t)\ddot q_v^T + {m_L}\left\| {{{\dot q}_v}} \right\|\left\| {{{\ddot q}_v}} \right\|$</p><p>  因为${{\ddot q}_v} \in {l_1}$，所以$\int\limits_0^t {f(\tau )d} \tau $收敛，即右边的第一项是有界的。对于第二项有  $$\int_0^t {\exp (\int_r^t {f(\tau )} d\tau )} g(r)dr &lt; {{{\cal M}}_1}{{{\cal M}}_2}({{{\cal K}}_2} + {m_L})\int_0^t {\left\| {{{\ddot q}_v}(t)} \right\|} dr$$  其中    $$\eqalign{    &amp; {{{\cal M}}_1} \buildrel \Delta \over = {\sup _{[0,\infty )}}\exp (\int_r^t {f(\tau )} d\tau )  \cr     &amp; {{{\cal M}}_2} = {\sup _{[0,\infty )}}(\exp ( - \alpha t)\left\| {{{\ddot q}_v}} \right\| + \left\| {{{\dot q}_v}} \right\|) \cr} $$</p><p>  从而证明了本文所提出的能量函数E的有界性。因此，下列信号都是有界的，且属于${l_\infty }$<u>（本质有界函数全体?）</u></p><p>  <img src="https://tva1.sinaimg.cn/large/007mx13gly1gwckz6g7izj307x01bjra.jpg" style="zoom:67%;"></p><p>  现在，可以直接清楚地得到：</p>  $$\dot E \le {W_1} + {W_2}$$<p>  <img src="https://tva1.sinaimg.cn/large/007mx13gly1gwcl8ikfj0j30c403tq38.jpg" style="zoom:80%;"></p><p>  根据非自治系统的修正不变性原理<a href="https://www.sciencedirect.com/science/article/pii/S2405896317320190">Almost Sure Attitude Consensus in Multispacecraft Systems With Stochastic Communication Links - ScienceDirect</a>，可以得到</p><p>  <img src="https://tvax2.sinaimg.cn/large/007mx13gly1gwclcx5uz8j30bm01ct8n.jpg" alt=""></p><p>  上式的物理表述为无人机和负载在行程结束时达到静止稳态状态。这种状态可以确定为参考虚拟点的最终位置、无人机的质量和控制增益$k_p$的函数。由于篇幅关系，最后部分的证明和稳态分析的细节省略了。</p><h2 id="5-实验简述"><a href="#5-实验简述" class="headerlink" title="5 实验简述"></a>5 实验简述</h2><p>  在三无人机负载运输系统（结构如下图2）上进行了实验，验证了所提控制器的有效性。 0.23kg的负载通过缆绳连接到无人机上。每架带电池的无人机重量为0.75kg。目标是在两点之间运输负载。无人机位置由动态捕捉系统获得。三个参考虚拟点的期望轨迹被设计成一个固定三角形的顶点，以固定的方向平行于地面移动。</p><p>  <img src="https://tvax2.sinaimg.cn/large/007mx13gly1gwclik3cl5j30f70ebq6z.jpg" alt=""></p><blockquote><p>待了解点：无人机、缆绳和负载组成的系统的基本<a href="?">能量无源性</a>。</p><p> $sk(·)$是所谓的<a href="?">斜算子</a></p></blockquote><p>  未完待更新~~~</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
            <tag> PS论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ego-planner代码精读(1)-simple_run_launch文件</title>
      <link href="/2021/10/26/ego-planner-dai-ma-jing-du-simple-run-launch-wen-jian/"/>
      <url>/2021/10/26/ego-planner-dai-ma-jing-du-simple-run-launch-wen-jian/</url>
      
        <content type="html"><![CDATA[<p>完整代码：<a href="https://github.com/ZJU-FAST-Lab/ego-planner">GitHub - ZJU-FAST-Lab/ego-planner</a></p><p>对应文章：<a href="https://ieeexplore.ieee.org/document/9309347">EGO-Planner: An ESDF-Free Gradient-Based Local Planner for Quadrotors | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p>为区分注释，注意源码中文为本人注释，英文为源码自带</p><h2 id="simple-run-launch文件"><a href="#simple-run-launch文件" class="headerlink" title="simple_run.launch文件"></a>simple_run.launch文件</h2><h3 id="定位源码文件"><a href="#定位源码文件" class="headerlink" title="定位源码文件"></a>定位源码文件</h3><p>simple_run.launch基本上实现了论文中各个算法的功能，我们从该文件了解系统如何运行。</p><p>首先根据launch文件中定义的节点定位launch中用到的源码文件cpp(节选)(<a href="https://caodong-street.github.io/2021/10/26/li-cheng-ji-hua-ti-du-qu/">odom_topic里程计话题读取</a>)</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml">    <span class="token comment">&lt;!-- 此文件为ego-planner基本启动文件--&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>launch</span><span class="token punctuation">&gt;</span></span>  <span class="token comment">&lt;!-- size of map, change the size inflate x, y, z according to your application --&gt;</span>    <span class="token comment">&lt;!-- 定义仅在launch文件中起作用的局部变量大小，即地图大小--&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>40.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>40.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span> 3.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- topic of your odometry such as VIO or LIO --&gt;</span>  <span class="token comment">&lt;!-- 这里的odom_topic的value是由odom_world重映射得到，再将其value发布到/visual_slam/odom供给终端读取相应数值--&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/visual_slam/odom<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- main algorithm params --&gt;</span>  <span class="token comment">&lt;!--嵌套复用advanced_param.xml，从而引入主要优化参数 --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span> <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find ego_planner)/launch/advanced_param.xml<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_x_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_x)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_y_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_y)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_z_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_z)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odometry_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>      <span class="token comment">&lt;!-- camera pose: transform of camera frame in the world frame --&gt;</span>    <span class="token comment">&lt;!-- depth topic: depth image, 640x480 by default --&gt;</span>    <span class="token comment">&lt;!-- don't set cloud_topic if you already set these ones! --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>camera_pose_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/camera_pose<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>depth_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/depth<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!-- topic of point cloud measurement, such as from LIDAR  --&gt;</span>    <span class="token comment">&lt;!-- don't set camera pose and depth, if you already set this one! --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cloud_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/cloud<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!-- intrinsic params of the depth camera --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cx<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>321.04638671875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cy<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>243.44969177246094<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fx<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>387.229248046875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fy<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>387.229248046875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!-- maximum velocity and acceleration the drone will reach --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>max_vel<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>2.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>max_acc<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>3.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!--always set to 1.5 times grater than sensing horizen--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>planning_horizon<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>7.5<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>     <span class="token comment">&lt;!-- 1: use 2D Nav Goal to select goal  --&gt;</span>    <span class="token comment">&lt;!-- 2: use global waypoints below  --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>flight_type<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>2<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>        <span class="token comment">&lt;!-- global waypoints --&gt;</span>    <span class="token comment">&lt;!-- It generates a piecewise min-snap traj passing all waypoints --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point_num<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>5<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span> <span class="token comment">&lt;!-- trajectory server --&gt;</span> <span class="token comment">&lt;!-- 节点所在的链接包ego_planner，节点对应的可执行文件名称traj_server， 节点运行时对应的名称为traj_server，将节点的标准输出打印到终端屏幕screen --&gt;</span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ego_planner<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/position_cmd<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>planning/pos_cmd<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/odom_world<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server/time_forward<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>double<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>node</span><span class="token punctuation">&gt;</span></span> <span class="token comment">&lt;!-- 节点所在的链接包waypoint_generator，节点对应的可执行文件名称waypoint_generator， 节点运行时对应的名称为waypoint_generator，将节点的标准输出打印到终端屏幕screen --&gt;</span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>~odom<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>~goal<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/move_base_simple/goal<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>~traj_start_trigger<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/traj_start_trigger<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_type<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>manual-lonely-waypoint<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>node</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>节点所在的链接包，节点对应的可执行文件名称是找到源码文件的关键。</p><p>我们可以通过搜索节点对应的可执行文件名称定位到源码文件名称(在CMakeList.txt中)</p></blockquote><p>例如搜索可执行文件名称traj_server可以得到在CMakeList.txt的如下结果(节选)</p><pre class="line-numbers language-cmake" data-language="cmake"><code class="language-cmake"><span class="token comment"># catkin_package(CATKIN_DEPENDS message_runtime)</span><span class="token function">catkin_package</span><span class="token punctuation">(</span> INCLUDE_DIRS include LIBRARIES ego_planner<span class="token comment"># 此处是源码文件(cpp)生成的可执行文件对应的链接库</span> CATKIN_DEPENDS plan_env path_searching bspline_opt traj_utils message_runtime<span class="token comment">#  DEPENDS system_lib</span><span class="token punctuation">)</span><span class="token keyword">include_directories</span><span class="token punctuation">(</span>  include  SYSTEM  <span class="token punctuation">${</span>catkin_INCLUDE_DIRS<span class="token punctuation">}</span> <span class="token punctuation">${</span><span class="token variable">PROJECT_SOURCE_DIR</span><span class="token punctuation">}</span>/include  <span class="token punctuation">${</span>EIGEN3_INCLUDE_DIR<span class="token punctuation">}</span>  <span class="token punctuation">${</span>PCL_INCLUDE_DIRS<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>ego_planner_node  src/ego_planner_node.cpp   src/ego_replan_fsm.cpp  src/planner_manager.cpp  <span class="token punctuation">)</span>  <span class="token comment">#源码文件为：src/ego_planner_node.cpp</span>  <span class="token comment">#           src/ego_replan_fsm.cpp</span>  <span class="token comment">#           src/planner_manager.cpp     </span>  <span class="token comment">#可执行文件为 ego_planner_node</span><span class="token keyword">target_link_libraries</span><span class="token punctuation">(</span>ego_planner_node   <span class="token punctuation">${</span>catkin_LIBRARIES<span class="token punctuation">}</span>  <span class="token punctuation">)</span>  <span class="token comment">#可执行文件为 ego_planner_node</span>  <span class="token comment">#对应的链接库catkin_LIBRARIES为catkin_package中的ego_planner，即可执行文件放置在工作空间的~/ego-planner/devel/lib/ego_planner下</span><span class="token keyword">add_dependencies</span><span class="token punctuation">(</span>ego_planner_node <span class="token punctuation">${</span><span class="token punctuation">${</span><span class="token variable">PROJECT_NAME</span><span class="token punctuation">}</span>_EXPORTED_TARGETS<span class="token punctuation">}</span><span class="token punctuation">)</span>  <span class="token comment"># 添加对本package消息的依赖</span><span class="token keyword">add_executable</span><span class="token punctuation">(</span>traj_server src/traj_server.cpp<span class="token punctuation">)</span>  <span class="token comment">#源码文件为：src/traj_server.cpp    </span>  <span class="token comment">#可执行文件为 traj_server</span><span class="token keyword">target_link_libraries</span><span class="token punctuation">(</span>traj_server <span class="token punctuation">${</span>catkin_LIBRARIES<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token keyword">add_dependencies</span><span class="token punctuation">(</span>traj_server <span class="token punctuation">${</span><span class="token punctuation">${</span><span class="token variable">PROJECT_NAME</span><span class="token punctuation">}</span>_EXPORTED_TARGETS<span class="token punctuation">}</span><span class="token punctuation">)</span>  <span class="token comment"># 添加对本package消息的依赖</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到CMakeList.txt中的链接库ego_planner以及可执行文件名称traj_server都与simple_run.launch文件一一对应，再定位到代码行<code>add_executable(traj_server src/traj_server.cpp)</code>可以得到源码文件为src下的traj_server.cpp。</p><h3 id="确定嵌套复用文件"><a href="#确定嵌套复用文件" class="headerlink" title="确定嵌套复用文件"></a>确定嵌套复用文件</h3><p>嵌套服用文件中也存在需要运行的节点、各类需要用到的参数信息、或者直接是另外一个launch文件。simple_run.launch嵌套复用文件如下：</p><p>advanced_param.xml：包括主要的算法参数</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- main algorithm params --&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span> <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find ego_planner)/launch/advanced_param.xml<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_x_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_x)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_y_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_y)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_z_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_z)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odometry_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- camera pose: transform of camera frame in the world frame --&gt;</span>  <span class="token comment">&lt;!-- depth topic: depth image, 640x480 by default --&gt;</span>  <span class="token comment">&lt;!-- don't set cloud_topic if you already set these ones! --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>camera_pose_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/camera_pose<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>depth_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/depth<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- topic of point cloud measurement, such as from LIDAR  --&gt;</span>  <span class="token comment">&lt;!-- don't set camera pose and depth, if you already set this one! --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cloud_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/cloud<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- intrinsic params of the depth camera --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cx<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>321.04638671875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cy<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>243.44969177246094<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fx<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>387.229248046875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fy<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>387.229248046875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- maximum velocity and acceleration the drone will reach --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>max_vel<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>2.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>max_acc<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>3.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!--always set to 1.5 times grater than sensing horizen--&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>planning_horizon<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>7.5<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>   <span class="token comment">&lt;!-- 1: use 2D Nav Goal to select goal  --&gt;</span>  <span class="token comment">&lt;!-- 2: use global waypoints below  --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>flight_type<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>2<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!-- global waypoints --&gt;</span>  <span class="token comment">&lt;!-- It generates a piecewise min-snap traj passing all waypoints --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point_num<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>5<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>simulator.xml:包括仿真中需要用到的节点。</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- use simulator --&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span> <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find ego_planner)/launch/simulator.xml<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_x_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_x)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_y_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_y)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_z_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_z)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>c_num<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>p_num<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>min_dist<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.2<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odometry_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>rviz.launch:启动仿真环境rviz</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span> <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find ego_planner)/launch/rviz.launch<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="确定可运行文件名称"><a href="#确定可运行文件名称" class="headerlink" title="确定可运行文件名称"></a>确定可运行文件名称</h3><p>通过launch文件及其嵌套复用文件我们可以确定出可运行文件名称，从而找到我们需要重点阅读的源码程序cpp。</p><p>定义的全部节点为：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ego_planner<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>mockamap<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>mockamap_node<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>mockamap_node<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>so3_quadrotor_simulator<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>quadrotor_simulator_so3<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>quadrotor_simulator_so3<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>nodelet<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>nodelet<span class="token punctuation">"</span></span> <span class="token attr-name">args</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>standalone so3_control/SO3ControlNodelet<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>so3_control<span class="token punctuation">"</span></span> <span class="token attr-name">required</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom_visualization<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom_visualization<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom_visualization<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>local_sensing_node<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>pcl_render_node<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>pcl_render_node<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>rviz<span class="token punctuation">"</span></span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>rviz<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>rviz<span class="token punctuation">"</span></span> <span class="token attr-name">args</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-d $(find ego_planner)/launch/default.rviz<span class="token punctuation">"</span></span> <span class="token attr-name">required</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对应的可执行文件(依次执行)为</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml">traj_serverwaypoint_generatormockamap_nodequadrotor_simulator_so3standalone so3_control/SO3ControlNodeletodom_visualizationpcl_render_node/launch/default.rviz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 项目代码学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>里程计话题读取</title>
      <link href="/2021/10/26/li-cheng-ji-hua-ti-du-qu/"/>
      <url>/2021/10/26/li-cheng-ji-hua-ti-du-qu/</url>
      
        <content type="html"><![CDATA[<h2 id="源代码加注释"><a href="#源代码加注释" class="headerlink" title="源代码加注释"></a>源代码加注释</h2><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml">    <span class="token comment">&lt;!-- 此文件为ego-planner基本启动文件--&gt;</span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>launch</span><span class="token punctuation">&gt;</span></span>  <span class="token comment">&lt;!-- size of map, change the size inflate x, y, z according to your application --&gt;</span>    <span class="token comment">&lt;!-- 定义仅在launch文件中起作用的局部变量大小，即地图大小--&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>40.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>40.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span> 3.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- topic of your odometry such as VIO or LIO --&gt;</span>  <span class="token comment">&lt;!-- 这里的odom_topic的value是由odom_world重映射得到，再将其value发布到/visual_slam/odom供给终端读取相应数值--&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/visual_slam/odom<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token comment">&lt;!-- main algorithm params --&gt;</span>  <span class="token comment">&lt;!--嵌套复用advanced_param.xml，从而引入主要优化参数 --&gt;</span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span> <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find ego_planner)/launch/advanced_param.xml<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_x_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_x)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_y_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_y)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>map_size_z_<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg map_size_z)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odometry_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>      <span class="token comment">&lt;!-- camera pose: transform of camera frame in the world frame --&gt;</span>    <span class="token comment">&lt;!-- depth topic: depth image, 640x480 by default --&gt;</span>    <span class="token comment">&lt;!-- don't set cloud_topic if you already set these ones! --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>camera_pose_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/camera_pose<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>depth_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/depth<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!-- topic of point cloud measurement, such as from LIDAR  --&gt;</span>    <span class="token comment">&lt;!-- don't set camera pose and depth, if you already set this one! --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cloud_topic<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/pcl_render_node/cloud<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!-- intrinsic params of the depth camera --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cx<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>321.04638671875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>cy<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>243.44969177246094<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fx<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>387.229248046875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fy<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>387.229248046875<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!-- maximum velocity and acceleration the drone will reach --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>max_vel<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>2.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>max_acc<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>3.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token comment">&lt;!--always set to 1.5 times grater than sensing horizen--&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>planning_horizon<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>7.5<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>     <span class="token comment">&lt;!-- 1: use 2D Nav Goal to select goal  --&gt;</span>    <span class="token comment">&lt;!-- 2: use global waypoints below  --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>flight_type<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>2<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>        <span class="token comment">&lt;!-- global waypoints --&gt;</span>    <span class="token comment">&lt;!-- It generates a piecewise min-snap traj passing all waypoints --&gt;</span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point_num<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>5<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point0_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point1_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point2_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point3_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_x<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>-15.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_y<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>point4_z<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include</span><span class="token punctuation">&gt;</span></span> <span class="token comment">&lt;!-- trajectory server --&gt;</span> <span class="token comment">&lt;!-- 节点所在的链接包ego_planner，节点对应的可执行文件名称traj_server， 节点运行时对应的名称为traj_server，将节点的标准输出打印到终端屏幕screen --&gt;</span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ego_planner<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/position_cmd<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>planning/pos_cmd<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/odom_world<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>traj_server/time_forward<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>double<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>node</span><span class="token punctuation">&gt;</span></span> <span class="token comment">&lt;!-- 节点所在的链接包waypoint_generator，节点对应的可执行文件名称waypoint_generator， 节点运行时对应的名称为waypoint_generator，将节点的标准输出打印到终端屏幕screen --&gt;</span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span> <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_generator<span class="token punctuation">"</span></span> <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>~odom<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg odom_topic)<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>~goal<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/move_base_simple/goal<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span> <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>~traj_start_trigger<span class="token punctuation">"</span></span> <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/traj_start_trigger<span class="token punctuation">"</span></span> <span class="token punctuation">/&gt;</span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>waypoint_type<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>manual-lonely-waypoint<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>node</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="odom-topic里程计话题读取"><a href="#odom-topic里程计话题读取" class="headerlink" title="odom_topic里程计话题读取"></a>odom_topic里程计话题读取</h2><h3 id="1-查看话题"><a href="#1-查看话题" class="headerlink" title="1.查看话题"></a>1.查看话题</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">rostopic list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-打开rqt"><a href="#2-打开rqt" class="headerlink" title="2.打开rqt"></a>2.打开rqt</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">rqt_plot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-添加topic"><a href="#3-添加topic" class="headerlink" title="3.添加topic"></a>3.添加topic</h3><p>在topic处删掉/，然后打出/选择将要显示的话题，点击+按钮。</p><p>注意：如果添加了话题，无法点击+按钮添加，可能是话题数据的消息格式不对或者没有将话题选择到最底层。</p><p>解决办法：将要显示的话题数据保存到名为xxx.txt中，查看该话题的消息格式。</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">rostopic echo /topic_name <span class="token punctuation">&gt;</span> xxx.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后根据消息格式在rqt的topic中补全即可。</p><p>例如：我们想看里程计odom中xyz数据，但是rostopic list得出的话题名称为：/visual_slam/odom，在rqt中输入该话题后无法点击+按钮。<br>解决办法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">rostopic echo /visual_slam/odom <span class="token punctuation">&gt;</span> odom.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>根据得到的txt文档可以看出我们需要得到的xyz数据位于odom话题中的pose/pose/position下。所以我们应该在rqt中这样添加topic：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">/visual_slam/odom/pose/pose/position/x/visual_slam/odom/pose/pose/position/y/visual_slam/odom/pose/pose/position/z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>参考博客：<a href="https://blog.csdn.net/weixin_42591529/article/details/115323836">里程计话题读取</a></p>]]></content>
      
      
      <categories>
          
          <category> 项目代码学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>fast-planner初代论文笔记1</title>
      <link href="/2021/10/25/fast-planner-chu-dai-lun-wen-bi-ji-1-wei-xie-wan/"/>
      <url>/2021/10/25/fast-planner-chu-dai-lun-wen-bi-ji-1-wei-xie-wan/</url>
      
        <content type="html"><![CDATA[<p>对应代码地址：<a href="https://github.com/HKUST-Aerial-Robotics/Fast-Planner">GitHub - HKUST-Aerial-Robotics/Fast-Planner: A Robust and Efficient Trajectory Planner for Quadrotors</a></p><p>对应文章地址：<a href="https://ieeexplore.ieee.org/abstract/document/8758904">Robust and Efficient Quadrotor Trajectory Generation for Fast Autonomous Flight | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><h2 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1 摘要"></a>1 摘要</h2><p>利用b样条的凸包特性，结合欧几里得距离场的梯度信息和动态约束，采用b样条优化算法提高了轨迹的光滑性和间隙。最后，通过将最终轨迹表示为非均匀b样条，采用迭代时间调整方法保证轨迹的动态可行性和非保守性。</p><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><h3 id="硬约束方法"><a href="#硬约束方法" class="headerlink" title="硬约束方法"></a>硬约束方法</h3><p>硬约束方法的首创是最小snap轨迹生成<a href="https://ieeexplore.ieee.org/document/5980409">Minimum snap trajectory generation and control for quadrotors | IEEE Conference Publication | IEEE Xplore</a>.，其中轨迹表示为分段多项式，并通过求解二次规划( quadratic programming, QP)问题生成。硬约束方法通过凸形式保证全局最优性。然而，忽略了自由空间中与障碍物的距离，这往往导致轨迹接近障碍物。此外，动力学约束是保守的，使轨迹速度不足，以快速飞行。</p><h3 id="软约束方法-本文选用的"><a href="#软约束方法-本文选用的" class="headerlink" title="软约束方法(本文选用的)"></a>软约束方法(本文选用的)</h3><p>也有方法将轨迹生成作为一个非线性优化问题，考虑平滑和安全。软约束方法利用梯度信息推动轨迹远离障碍物，但存在局部极小问题，没有很强的成功率和动力学可行性保证。我们的优化方法还利用梯度信息提高了轨迹的安全性。然而，与以往计算昂贵的沿轨迹线积分的方法不同，基于b样条的凸包特性，将公式设计得更加简单。它大大提高了计算效率和收敛速度。</p><h2 id="3-运动动力学路径搜索"><a href="#3-运动动力学路径搜索" class="headerlink" title="3 运动动力学路径搜索"></a>3 运动动力学路径搜索</h2><p>前端运动学路径搜素源于自动汽车的混合A*(hybrid-state A*)搜索算法，其可再体素网格网络中搜索一个安全的，运动学可行的、且相对时间以及控制成本最低的轨迹。</p><p>未完待续~~~</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> fast planner </tag>
            
            <tag> 无人机 </tag>
            
            <tag> 轨迹优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于ego-planner的无人机编队：EGO-Swarm</title>
      <link href="/2021/10/23/ji-yu-ego-planner-de-wu-ren-ji-bian-dui-ego-swarm/"/>
      <url>/2021/10/23/ji-yu-ego-planner-de-wu-ren-ji-bian-dui-ego-swarm/</url>
      
        <content type="html"><![CDATA[<p>论文源码：<a href="https://github.com/ZJU-FAST-Lab/ego-planner-swarm">ZJU-FAST-Lab/ego-planner-swarm: An efficient single/multi-agent trajectory planner for multicopters. (github.com)</a></p><p>论文原文：<a href="https://arxiv.org/abs/2011.04183v1">EGO-Swarm: A Fully Autonomous and Decentralized Quadrotor Swarm System in Cluttered Environments (arxiv.org)</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>提出了一种分散的、异步的多机器人自主导航系统解决方案，用于未知障碍场景下仅使用板载资源的多机器人自主导航。</p><ol><li>该规划系统是在基于梯度的局部规划框架下制定的，其中通过将碰撞风险作为非线性优化问题的惩罚来实现避碰。(此方法与ego-planner相同，ego-planner的详细方案见<a href="https://caodong-street.github.io/2021/10/21/ji-yu-fast-planner-gai-jin-de-suan-fa-ego-planner-yue-du-bi-ji/">基于fast-planner改进的算法(1)-ego_planner阅读笔记 | Cao Dong (caodong-street.github.io)</a> )</li><li>为了提高鲁棒性和避免局部极小值，我们引入了一种轻量级的拓扑轨迹生成方法。</li><li>针对智能体所使用一个不可靠的轨迹共享网络，仅在几毫秒内生成安全、平滑、动态可行的轨迹。且利用深度图像中的智能体检测来校正智能体间的相对定位漂移。</li></ol><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>文章主要：</p><ol><li><p>扩展了之前的所作出的工作EGO-Planner。首先提出了一种新的、鲁棒的拓扑规划方法，几乎不需要额外的计算，避免了图3中的因局部最小值导致的动力学不可行以及导航碰撞问题。其次通过在目标函数中加入群碰撞的加权惩罚，实现了去中心化的互相避撞。</p><p><img src="https://tva3.sinaimg.cn/large/007mx13gly1gvpex6qfgbj60hn09stcq02.jpg" alt="原文图3"></p></li><li><p>我们提出了一种分散的、异步的且对不可靠的通信和定位漂移不敏感的无人机编队结构。</p></li><li><p>将提出的方法集成到一个全自主四旋翼系统中，并发布了硬件和软件。</p></li></ol><h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><h3 id="A-单四旋翼局部路径规划"><a href="#A-单四旋翼局部路径规划" class="headerlink" title="A. 单四旋翼局部路径规划"></a>A. 单四旋翼局部路径规划</h3><p>基于梯度的运动规划是四旋翼飞行器局部规划的主流。</p><h3 id="B-拓扑规划"><a href="#B-拓扑规划" class="headerlink" title="B. 拓扑规划"></a>B. 拓扑规划</h3><p>采用拓扑规划来避免局部极小值，进一步加速拓扑规划的前端。</p><h3 id="C-分散的无人机群"><a href="#C-分散的无人机群" class="headerlink" title="C. 分散的无人机群"></a>C. 分散的无人机群</h3><p>现有的无人机编队算法是通过仿真验证的，没有集成传感、映射和规划能力，且无法在野外环境中实现完全自主地运动。</p><h2 id="3-针对基于梯度的局部路径规划的隐式拓扑轨迹生成"><a href="#3-针对基于梯度的局部路径规划的隐式拓扑轨迹生成" class="headerlink" title="3 针对基于梯度的局部路径规划的隐式拓扑轨迹生成"></a>3 针对基于梯度的局部路径规划的隐式拓扑轨迹生成</h2><h3 id="3-1-基于EGO-PLANNER的局部路径规划"><a href="#3-1-基于EGO-PLANNER的局部路径规划" class="headerlink" title="3.1 基于EGO-PLANNER的局部路径规划"></a>3.1 基于EGO-PLANNER的局部路径规划</h3><p>ego-planner的详细方案见<a href="https://caodong-street.github.io/2021/10/21/ji-yu-fast-planner-gai-jin-de-suan-fa-ego-planner-yue-du-bi-ji/">基于fast-planner改进的算法(1)-ego_planner阅读笔记 | Cao Dong (caodong-street.github.io)</a> ，ego-planner主要是将轨迹生成问题作为一个非线性优化问题进行处理，权衡平滑性惩罚项$J_s$、碰撞惩罚项$J_c$、动力学可行性惩罚项$J_d$和终端进展惩罚项$J_t$(全称为terminal progress，我在ego-planer未完全看出其体现)。</p><p>但本文重新定义了描述惩罚项的函数类型：最小误差型和软单边约束型</p><blockquote><p>最小误差型惩罚项包括平滑性惩罚项$J_s$和终端进展惩罚项$J_t$</p><p>最小误差型惩罚项是指使决策变量的线性变换<em>L(Q)</em>与期望值<em>D</em>之间的总误差最小的惩罚项，其描述公式为：</p></blockquote>$${J_r} = \sum\limits_{\mathrm{Q} \in \Phi } {\left\| {L(\mathrm{Q}) -\mathcal{D}} \right\|_n^n} $$<blockquote><p>软单边约束型惩罚项包括碰撞惩罚项$J_c$和动力学可行性惩罚项$J_d$</p><p>软单边约束型惩罚项是用于惩罚超过特定阈值的决策变量的惩罚项$\mathcal{T}$，其描述公式为：</p></blockquote> $${J_r} = \sum\limits_{{\rm{Q}} \in \Phi } {\left\{ {\matrix{ {\left\| {{{L(Q) - ({\cal T} - \varepsilon )} \over S}} \right\|_n^n} &amp; {L(Q) &gt; ({\cal T} - \varepsilon )}  \cr  0 &amp; {L(Q) \le ({\cal T} - \varepsilon )}  \cr  } } \right.} $$<h3 id="3-2-隐式拓扑轨迹生成"><a href="#3-2-隐式拓扑轨迹生成" class="headerlink" title="3.2 隐式拓扑轨迹生成"></a>3.2 隐式拓扑轨迹生成</h3><p>定义1：</p><p>均匀的可见性不同形(uniform visibility deformation,UVD)(详细见<a href="https://caodong-street.github.io/2021/10/20/fast-planner-chu-dai-lun-wen-bi-ji-2/">fast-planner初代论文笔记2 | Cao Dong (caodong-street.github.io)</a>)的定义：</p><p>存在两条可以被s∈[0,1]参数化的轨迹τ1(s)、 τ2(s)并且满足τ1(0) =τ2(0)， τ1(1) =τ2(1)，如果对所有情况，连接τ1(s)、τ2(s)的线段是无碰撞的。那么这两条轨迹属于均匀的可见性不同形(UVD)类。</p><p>本文通过反演v得到来${{\rm{v}}_{new}} =  - {\rm{v}}$构造不同方向的距离场，再由图4(c)所示得到了新的$\left\{ {{{\rm{p}}_{new}}{\rm{,}}{{\rm{v}}_{new}}} \right\}$对。再如图4(b)所示，根据新的$\left\{ {{{\rm{p}}_{new}}{\rm{,}}{{\rm{v}}_{new}}} \right\}$对也得到了一条新的轨迹。这新旧两条轨迹之间明显是不满足定义1，从而可以说生成一条新的拓扑轨迹。采用该的轨迹生成方法没有采用直接搜索不同的拓扑路径的轨迹生成方法(详细见<a href="https://caodong-street.github.io/2021/10/20/fast-planner-chu-dai-lun-wen-bi-ji-2/">fast-planner初代论文笔记2 | Cao Dong (caodong-street.github.io)</a>)，而是通过之前生成的{p,v}对信息得到新拓扑轨迹，故称为<u>隐式拓扑轨迹生成</u>方法。</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gvpeiyyn50j60n90nydo602.jpg" alt="原文图4"></p><h2 id="4-无人机编队导航"><a href="#4-无人机编队导航" class="headerlink" title="4 无人机编队导航"></a>4 无人机编队导航</h2><h3 id="A-无人机相互避撞"><a href="#A-无人机相互避撞" class="headerlink" title="A. 无人机相互避撞"></a>A. 无人机相互避撞</h3><h4 id="a-主要思路"><a href="#a-主要思路" class="headerlink" title="a 主要思路"></a>a 主要思路</h4><p>首先，我们给出无人机避障的主要思路：如图6所示，单无人机自身<u>通过比较在相同轨迹时间内收到的其周围无人机的轨迹的距离</u>得到一条轨迹，从而实现避撞。</p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1gvpgz7pzlej60zr0g2n2t02.jpg" alt="原文图6"></p><h4 id="b-问题建模"><a href="#b-问题建模" class="headerlink" title="b 问题建模"></a>b 问题建模</h4><p>此时我们对处于轨迹规划中的单无人机<em>k</em>构造编队碰撞惩罚项${J_{w,k}}$，软单边约束型构造编队碰撞惩罚项，其描述如下(dt代表微分)</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gvpi6tyfd7j61a108swgq02.jpg" alt=""></p><p>其他不处于轨迹规划中的单无人机对应下标系数为<em>i</em>，$\Phi (t)$表示无人机在轨迹时间<em>t</em>的位置，$t_s$与$t_e$表示全局轨迹规划的开始时间和终止时间，${d_{k,t}}(t)$为定义的无人机k与无人机i之间的距离，$C{\rm{ + }}\epsilon $为无人机k与无人机i的机体安全距离之和，E=diag(1,1,1/c)表示一个对角矩阵（即指除了主对角线外的元素均为零的方阵），<u>c&gt;1将欧氏距离转换为z轴主轴较短的椭球型距离，以减轻下冲风险</u>。</p><blockquote><p>上述下滑线内容较抽象，我们推一下${d_{k,t}}(t)$的计算公式就可以明白这句话的意思了。</p><p>如下推导可得，最后的的{d_{k,t}}(t)的计算公式中z对应的系数为1/c，说明降低了z对应的惩罚权重，减少z轴的位移，以减轻下冲风险（障碍物里面不包括地面或者天花板，以免撞到地面或者天花板）。</p><p>椭球型距离是指$\sqrt {{x^2} + {y^2} + {{{z^2}} \over c}} $的计算项。</p></blockquote>$$\eqalign{  &amp; {E^{1/2}} = \left[ {\matrix{   1 &amp; 0 &amp; 0  \cr    0 &amp; 1 &amp; 0  \cr    0 &amp; 0 &amp; {{1 \over {\sqrt c }}}  \cr  } } \right],  \cr   &amp; let{\rm{  }}{\Phi _k}(t) - {\Phi _i}(t) = {[x,y,z]^T},  \cr   &amp; {E^{1/2}}({\Phi _k}(t) - {\Phi _i}(t)) = {[x,y,{z \over {\sqrt c }}]^T}  \cr   &amp; \left\| {{E^{1/2}}({\Phi _k}(t) - {\Phi _i}(t))} \right\| = \sqrt {{x^2} + {y^2} + {{{z^2}} \over c}}   \cr   &amp; {d_{k,t}}(t) = \sqrt {{x^2} + {y^2} + {{{z^2}} \over c}}  - (C + \epsilon ) \cr} $$<p>将加权的编队碰撞惩罚项${J_{w,k}}$与单个无人机的进行ego-planner对应的惩罚项${J_{EGO}}$得到每个单无人机的总优化问题：</p>$$\mathop {\min }\limits_Q J = {J_{EGO}} + {\lambda _w}{J_{w,k}}$$<p>本文利用均匀b样条参数化轨迹(详细参考<a href="https://ieeexplore.ieee.org/abstract/document/8758904">Robust and Efficient Quadrotor Trajectory Generation for Fast Autonomous Flight | IEEE Journals &amp; Magazine | IEEE Xplore</a>，<a href="https://github.com/CaoDong-street/Bspline">B样条曲线绘制项目</a>)</p><h3 id="B-定位漂移补偿"><a href="#B-定位漂移补偿" class="headerlink" title="B 定位漂移补偿"></a>B 定位漂移补偿</h3><h4 id="a-背景介绍"><a href="#a-背景介绍" class="headerlink" title="a 背景介绍"></a>a 背景介绍</h4><p>由于个体在未知环境下进行定位(没有可靠的高频回路闭合)，所以定位漂移会在飞行过程中积累。<a href="https://ieeexplore.ieee.org/document/9196944">Decentralized Visual-Inertial-UWB Fusion for Relative State Estimation of Aerial Swarm | IEEE Conference Publication | IEEE Xplore（港科大组）</a>提出了一种附加超宽带距离测量的空中群状态估计方法，实现了精确的协同定位。然而，我们更多地关注于遍历障碍环境，必须为其他应用程序保留计算和通信资源。因此，受<a href="https://ieeexplore.ieee.org/document/9196944">Decentralized Visual-Inertial-UWB Fusion for Relative State Estimation of Aerial Swarm | IEEE Conference Publication | IEEE Xplore（港科大组）</a>的启发，通过比较接收到的无人机轨迹估计的预测位置和记录无人机深度图像的测量位置，提出了一种简化的、轻量级的相对漂移估计方法。当轨迹跟踪误差可以忽略不计，且任意两个无人机中至少有一个可能会看到另一个时，这种策略就会起作用。因此，我们使用<a href="https://ieeexplore.ieee.org/document/5980409">Minimum snap trajectory generation and control for quadrotors | IEEE Conference Publication | IEEE Xplore</a>的控制器进行精确跟踪，并使用广角摄像机减少丢失无人机的可能性。<u>(机器视觉的知识)</u></p><h4 id="b-漂移消除过程"><a href="#b-漂移消除过程" class="headerlink" title="b 漂移消除过程"></a>b 漂移消除过程</h4><blockquote><p>(这部分真的读不懂，关于无人机的slam知识了)</p></blockquote><p>在利用VIO估计单无人机i的当前位置$\Phi ({t_{now}})$后，由$\Phi ({t_{now}})$为球心，以R为半径(R是一个经验参数，表示实验估计的典型漂移的上界,这个与机体安全距离相关的)确定出球形信任区域S。然后将S映射到当前捕获的深度图像，即区域${S^\prime }$，映射关系如下：</p>$$\eqalign{  &amp; z{\left[ {\matrix{   {{s^\prime }^{\rm{T}}} &amp; 1  \cr  } } \right]^{\rm{T}}} = {\rm{KT}}_{\rm{w}}^{\rm{c}}{\left[ {\matrix{   {{s^{\rm{T}}}} &amp; 1  \cr  } } \right]^{\rm{T}}}  \cr   &amp; {s^\prime } \in {S^\prime },s \in S \cr} $$<p><script type="math/tex">{\rm{K}}</script>和<script type="math/tex">{\rm{T}}_{\rm{w}}^{\rm{c}}</script>是相机的内在矩阵和外在矩阵。z是沿主光轴与光中心的偏差。${S^\prime }$是一个需要经过复杂计算才能得到的椭圆圆锥截面。因此，我们采用近似的轴向椭圆${\overline{S} ^\prime}$来代替精确的${S^\prime }$(<u>这里是不是能直接映射中心，然后画圆，减小算法量</u>)。由于信任区域只是一个经验区域，因此没有必要对其进行精确的定义。</p><p>然后我们将${\overline{S} ^\prime}$内的每一个点投射到世界框架中，收集属于S的点，就得到一个点簇$\mathcal{P}$⊂S。然后将无人机观测的位置P视为$\mathcal{P}$的中心(第一个原始矩)，即</p>$${\rm{P = }}\mu _1^\prime ({\cal P})$$<p>上式认为如果$\mathcal{P}$只包含相应的无人机的观察，没有任何不相关的对象，这是不能保证的。然而，由于每个无人机计划的轨迹都与附近的物体有一定的距离，所以上式在大多数情况下都适用。为了提高无人机检测的鲁棒性，还增加了像素数、$\mathcal{P}$的第二个中心矩、当前测量值与前一次测量值的偏差等判据。更严格的标准增加了假阴性率，但由于定位漂移变化缓慢，假阴性率是无害的。最后，误差将$\Phi ({t_{now}})$和P输入给一个滤波器，然后从滤波器获得估计的漂移。</p><blockquote><p>简单来说，VIO漂移是在从接收轨迹估计的预测位置和信任区域内深度图像中的观测位置比较估计得到的。</p></blockquote><h3 id="C-从深度图像中去除无人机"><a href="#C-从深度图像中去除无人机" class="headerlink" title="C 从深度图像中去除无人机"></a>C 从深度图像中去除无人机</h3><p>我们使用占用网格图来存储静态障碍物，并使用深度图像进行地图融合。 移动无人机在第四节 -A 中得到处理。 因此，记录移动无人机并将其视为地图构建中的障碍是没有必要的，甚至是有害的。 </p><blockquote><p>因为这里的障碍物是ego planner中的碰撞项针对的障碍对象，而移动无人机的问题已经再本文提出的编队碰撞惩罚项中处理了，所以移动无人机不能视作地图构建中的障碍。</p></blockquote><p>为了消除移动物体的影响，我们从深度图像中屏蔽并移除在第四节-B 中检测到的无人机的像素，如图 7 所示。 除此之外，覆盖大部分视图的移动物体会干扰视觉惯性里程计（visual-inertial odometry，VIO，<a href="https://blog.csdn.net/qq_40213457/article/details/81298696"> VIO学习总结</a>）。 因此，灰度图像上的无人机也被删除，使用相应的深度图像的相同掩码。 这里使用的无人机检测标准不太严格，因为误报比漏报更有害。 </p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gvpn27eqmcj60z10khqnw02.jpg" alt="原文图7"></p><h2 id="5-系统结构"><a href="#5-系统结构" class="headerlink" title="5 系统结构"></a>5 系统结构</h2><p>系统架构如图8所示，其中包含了单无人机和无人机编队通信系统的详细架构。</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gvq6phj44zj60en098add02.jpg" alt="图8"></p><h3 id="A-单无人机导航系统"><a href="#A-单无人机导航系统" class="headerlink" title="A.单无人机导航系统"></a>A.单无人机导航系统</h3><p>单无人机系统(包括硬件和软件设置)基于我们之前的工作EGO-Planner构造的，但包括有一个额外的模块，用于补偿VIO漂移并删除图像上的目击到的其他无人机。所有组件集成到一个自组装的250毫米轴距四旋翼。对于未知环境下的轨迹生成，采用局部规划方法。当当前轨迹与新发现的障碍物发生碰撞，或无人机接近当前轨迹的末端时(<u>后者这里的末端没懂</u>)，启动规划。</p><h3 id="B-通信框架"><a href="#B-通信框架" class="headerlink" title="B. 通信框架"></a>B. 通信框架</h3><p>两个网络将系统连接起来，一个是共享轨迹的广播网络，另一个是同步时间戳和管理顺序启动的链网络。</p><h4 id="1-广播网络"><a href="#1-广播网络" class="headerlink" title="1) 广播网络"></a>1) 广播网络</h4><p>当一个无人机生成一条新的无碰撞轨迹时，立即广播给所有无人机。然后其他无人机接收并存储这些轨迹，以便在必要时为自己生成安全的轨迹。这种闭环策略在连接稳定且延迟可以忽略的理想情况下可以正常工作。然而，这在实践中并不能保证。因此，我们提出了两种方法来减少碰撞的可能性。</p><p>首先，在网络容量下，<u>以给定的频率广播一条轨迹</u>。这不会造成计算负担，因为包含3-D路径点和其他参数的典型轨迹小于0.5KB。相比之下，现代的无线网络如蓝牙可以达到1Mbps以上的速度。其次，<u>各智能体从广播网络接收到一条碰撞轨迹后立即进行碰撞检测，如果检测到潜在的碰撞，则生成新的无碰撞轨迹</u>;该策略可以解决多个无人机在关闭时间内生成轨迹时由于延迟或丢包导致的不接收其他无人机轨迹的问题。</p><p>此外，还考虑了计算复杂度随着无人机数量的增加而增加的问题。在规划之前，每个无人机将其当前位置与接收到的周围无人机的轨迹进行比较，任何超出规划范围的轨迹都将被忽略。</p><h4 id="2-链网络"><a href="#2-链网络" class="headerlink" title="2) 链网络"></a>2) 链网络</h4><p>基于连接的稳定链网络，用于时间戳同步和系统启动管理。<u>在系统启动时，无人机按照预定义的顺序生成轨迹。每个无人机通过链网络接收到优先级更高的无人机的轨迹后，生成自己的初始轨迹。</u>该策略避免了系统启动时由于无人机没有其他轨迹信息而同时生成轨迹而引起的混沌。</p><h2 id="6-源码精读"><a href="#6-源码精读" class="headerlink" title="6 源码精读"></a>6 源码精读</h2><p>未完待续</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> fast planner </tag>
            
            <tag> ego planner </tag>
            
            <tag> 无人机 </tag>
            
            <tag> 编队控制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于fast-planner改进的算法(1)-ego_planner阅读笔记</title>
      <link href="/2021/10/21/ji-yu-fast-planner-gai-jin-de-suan-fa-ego-planner-yue-du-bi-ji/"/>
      <url>/2021/10/21/ji-yu-fast-planner-gai-jin-de-suan-fa-ego-planner-yue-du-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>对应文章：<a href="https://ieeexplore.ieee.org/document/9309347">EGO-Planner: An ESDF-Free Gradient-Based Local Planner for Quadrotors | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p>对应代码：<a href="https://github.com/ZJU-FAST-Lab/ego-planner">GitHub - ZJU-FAST-Lab/ego-planner</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ol><li>通过确定物体与障碍物表面距离，得到惩罚函数中的碰撞项</li><li>轨迹优化器只提取当前轨迹撞到的障碍物的信息，降低算法复杂度</li><li>如果某段轨迹动力学不可行，则延长该段轨迹分配的时间</li><li>异性曲线拟合算法——在保持原有轨迹形状的情况下降低轨迹的阶数</li></ol><h2 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h2><p>传统的基于梯度的运动规划算法需要构建所需的ESDF地图，然而构建地图花费了整个规划算法70%的时间，从而限制了在有限资源情况下的运动规划方法的使用。</p><p>ESDF的构建方式有全局增量式和批量本地计算两种方式，但他们并不是专门用于运动规划而构建的，也就是说对于运动规划来说现有的两种方法构建出的ESDF地图是多余的、不必要的。从图1中可以看出轨迹仅仅覆盖小范围的ESDF地图，大部分都是没用的。简单地手动减小ESDF地图范围，缺乏理论依据，也包含不必要的计算。</p><p><img src="https://pic1.zhimg.com/80/v2-e1d868a854700092790fc67caefede4c_720w.jpg" alt="原文图1"></p><p>EGO-Planer主要由基于梯度的样条曲线优化器和细化过程组成。</p><h3 id="1-1基于梯度的样条曲线优化器"><a href="#1-1基于梯度的样条曲线优化器" class="headerlink" title="1.1基于梯度的样条曲线优化器"></a>1.1基于梯度的样条曲线优化器</h3><p>使用平滑性、碰撞性和动力学可行性项优化轨迹。碰撞项的构成通过比较障碍物内的轨迹与无碰撞的引导路径，然后用梯度信息将碰撞到障碍物的轨迹拉出障碍物，从而算法只需要计算碰撞处的障碍物梯度即可。</p><h3 id="1-2细化过程"><a href="#1-2细化过程" class="headerlink" title="1.2细化过程"></a>1.2细化过程</h3><p>当某段轨迹动力学不可行时，激活细化过程，即增大该轨迹分配的时间。新生成的B样条曲线平衡了动力学可行性与拟合之前动力学不可行轨迹的准确性。在轴向和径向上拟合的准确性惩罚并不一样，以提高模型的鲁棒性。</p><h2 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h2><h3 id="2-1基于梯度的运动规划"><a href="#2-1基于梯度的运动规划" class="headerlink" title="2.1基于梯度的运动规划"></a>2.1基于梯度的运动规划</h3><h3 id="2-2带符号的欧式距离场（ESDF）"><a href="#2-2带符号的欧式距离场（ESDF）" class="headerlink" title="2.2带符号的欧式距离场（ESDF）"></a>2.2带符号的欧式距离场（ESDF）</h3><h2 id="三、避撞力的估计"><a href="#三、避撞力的估计" class="headerlink" title="三、避撞力的估计"></a>三、避撞力的估计</h2><p>定义B样条曲线的控制点为Q，一开始生成一条满足终端约束但不考虑障碍物的B样条曲线 $\Phi$，接着，对于每段被检测到的碰撞的线段，用优化程序（这里使用的是A星算法）生成一个无碰撞的路径 $\Gamma$  。对于发生碰撞的线段的每个控制点 ${Q_i}$ 都会生成一个在障碍物表面的定位点（anchor point） $p_{ij}$ ，且对应一个排斥单位方向向量  ${v_i}$与  ${Q_i}{p_{ij}}$同向(<strong>这里不应该是相等</strong>，${v_i}$为单位方向向量)。每对 {p,v}  对都对应一个特定的控制点Q。算法1为{p,v} 对的生成过程。</p><blockquote><p>这里{p,v} 对的生成过程可以通过图3读懂，但是读到这里没懂没有关系，论文把大量关键点放到最后的实验内容才讲清楚。</p></blockquote><p><img src="https://pic1.zhimg.com/80/v2-d6026bb43ab95c45706b88ea954f22d8_720w.jpg" alt="原文图3"></p><p>算法1伪代码：</p><p><img src="https://pic2.zhimg.com/80/v2-85b714bbfadf3d640020d52b8e8c0461_720w.jpg" alt="优化算法1"></p><p>算法1伪代码说明：</p><p><code>FindConsecutiveCollidingSegment(Q)</code>找到与Q发生碰撞的障碍物，并判断其是否存在</p><p><code>GetCollisionSegment()</code>提取出与Q发生碰撞的障碍物</p><p><code>.push_back()</code>将<code>障碍物</code>添加入<code>障碍物</code>集合中</p><p><code>PathSearch()</code>针对障碍物生成一个无碰撞的路径</p><p><code>Find_p_v_Pairs    (Q,path)</code>根据控制点与无碰撞路径确定匹配的{p,v}对</p><p> ${Q_i}$ 到第 j个障碍物的距离如下，需要注意单位向量v在第一次生成后就不会再次发生改变，所以${d_{ij}} $的值是分正负的。</p><p><img src="https://www.zhihu.com/equation?tex=+++d_%7Bij%7D%3D%28Q_i-p_%7Bij%7D%29v_%7Bij%7D+%5Ctag%7B1%7D+%5C%5C" alt=""></p><p>为了防止轨迹被拉出当前障碍物前，迭代过程中反复生成  {p,v}  对，判断是否为新障碍物的标准是：如果控制点${Q_i}$ 处于障碍物中时，并且对于当前得到的所有障碍物 <em>j</em>满足${d_{ij}} &gt; 0$，则该障碍物为新发现的障碍物。从而<u>只计算影响轨迹的障碍物信息</u>，减少运行时间。</p><p>为了将必要的环境意识融入当地的规划中，我们需要明确地构建一个目标函数(设计基于梯度的轨迹优化器)，使轨道远离障碍。ESDF提供了这种至关重要的碰撞信息，但代价是沉重的计算负担。此外，如图2所示，由于ESDF反馈的错误信息不足，基于ESDF的规划者很容易陷入局部最小值，无法逃脱障碍。为了避免这种情况，额外的前端总是需要提供一个无碰撞的初始轨迹。由于明确设计的斥力对于不同的任务和环境都是相当有效的，所以上述方法在提供避免碰撞的重要信息方面优于ESDF。</p><p><img src="https://pic3.zhimg.com/80/v2-d5111b783f90ebb2eb29ab431245e2da_720w.jpg" alt="原文图2"></p><h2 id="四、基于梯度的轨迹优化器"><a href="#四、基于梯度的轨迹优化器" class="headerlink" title="四、基于梯度的轨迹优化器"></a>四、基于梯度的轨迹优化器</h2><h3 id="4-1问题建模"><a href="#4-1问题建模" class="headerlink" title="4.1问题建模"></a>4.1问题建模</h3><p>本文使用均匀B样条曲线 $\Phi$来表示轨迹（均匀B样条曲线可以参考<a href="https://github.com/CaoDong-street/Bspline">B样条曲线绘制项目</a>进行学习），其阶数为${p_b}$，均匀B样条曲线的每个节点有相同的时间间隔 。</p><p><u>B样条曲线的凸包性质</u>表明，某段曲线只与${p_b}+1$个连续的控制点有关，并且曲线被包含在这些点构成的凸包内。B样条曲线的k阶导数是 ${p_b}-k$ 阶B样条曲线。轨迹  $\Phi$ 的一阶、二阶、三阶导数的控制点分别为</p><p><img src="https://www.zhihu.com/equation?tex=++V_i%3D%5Cfrac%7BQ_%7Bi%2B1%7D-Q_i%7D%7B%5CDelta+t%7D%2CA_i%3D%5Cfrac%7BV_%7Bi%2B1%7D-V_i%7D%7B%5CDelta+t%7D%EF%BC%8CJ_i%3D%5Cfrac%7BA_%7Bi%2B1%7D-A_i%7D%7B%5CDelta+t%7D+++%5Ctag%7B2%7D%5C%5C" alt=""></p><p>根据无人机的微分平坦特性降低要规划的变量，优化问题可以被定义为</p><p><img src="https://www.zhihu.com/equation?tex=Q%3Dargmin%5C+J%3D%5Clambda_sJ_s%2B%5Clambda_cJ_c%2B%5Clambda_dJ_d++%5Ctag%7B3%7D%5C%5C" alt=""></p><p>${J_s}$为光滑项惩罚， ${J_c}$为碰撞项惩罚，${J_d}$为动力学可行项惩罚，  $\lambda $ 为惩罚项的权值。</p><h4 id="4-1-1光滑项惩罚"><a href="#4-1-1光滑项惩罚" class="headerlink" title="4.1.1光滑项惩罚"></a>4.1.1光滑项惩罚</h4><p>在<a href="https://www.researchgate.net/publication/314258063_Real-Time_Trajectory_Replanning_for_MAVs_using_Uniform_B-splines_and_3D_Circular_Buffer">Real-Time Trajectory Replanning for MAVs using Uniform B-splines and 3D Circular Buffer (researchgate.net)</a>中提出，光滑性惩罚被公式化为轨迹参数(加速度、加加速度等)的平方导数上的时间积分。由于<u>B样条曲线的凸包性</u>质，只要最小化轨迹 $\Phi$ 的二阶和三阶控制点的平方和就能够有效地减小加速度和加加速度的平方和。</p><p><img src="https://www.zhihu.com/equation?tex=J_s%3D%5Csum_%7Bi%3D1%7D%5E%7BN_c-2%7D%5Cleft%7C%5Cleft%7C+A_i+%5Cright%7C+%5Cright%7C_2%5E2%2B%5Csum_%7Bi%3D1%7D%5E%7BN_c-3%7D%5Cleft%7C%5Cleft%7C+J_i+%5Cright%7C+%5Cright%7C_2%5E2+%5Ctag%7B4%7D%5C%5C" alt=""></p><h4 id="4-1-2碰撞项惩罚"><a href="#4-1-2碰撞项惩罚" class="headerlink" title="4.1.2碰撞项惩罚"></a>4.1.2碰撞项惩罚</h4><p>碰撞惩罚使控制点远离障碍物，这是通过采用安全间隙和惩罚控制点${d_{ij}}&lt; {s_f}$来实现的。为了进一步优化，我们构造了一个二次连续可微惩罚函数，并随着${d_{ij}}$的减小而抑制其斜率，从而得到分段函数</p><p><img src="https://www.zhihu.com/equation?tex=j_c%28i%2Cj%29+%3D+%5Cbegin%7Bcases%7D+0%2C+%26+c_%7Bij%7D%5Cleq0+%5C%5C+c_%7Bij%7D%5E3%2C+%26+0%5Cleq+c_%7Bij%7D%5Cleq+s_f+++%5C%5C+3s_fc_%7Bij%7D%5E2-3s_f%5E2c_%7Bij%7D%2Bs_f%5E3%2C%26+c_%7Bij%7D%3Es_f+%5C%5C+%5Cend%7Bcases%7D%5C%5C++%5Ctag%7B5%7D" alt=""></p><p> <img src="https://www.zhihu.com/equation?tex=c_%7Bij%7D%3Ds_f-d_%7Bij%7D" alt=""> </p><p>对所有控制点的惩罚求和得到总的碰撞项惩罚</p><p><img src="https://www.zhihu.com/equation?tex=J_c%3D%5Csum_%7Bi%3D1%7D%5E%7BN_c%7Dj_c%28Q_i%29+%5Ctag%7B6%7D%5C%5C" alt=""></p><p>相比于传统用三线性插值的方法求碰撞项的梯度，我们直接计算二次连续可微惩罚函数对${Q_i}$的导数来得到梯度：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7Bj_c%7D%7D%7B%5Cpartial%7BQ_i%7D%7D+%3D%5Csum_%7Bi%3D1%7D%5E%7BN_c%7D%5Csum_%7Bj%3D1%7D%5E%7BN_p%7D+%5Cbegin%7Bcases%7D+0%2C+%26+c_%7Bij%7D%5Cleq0+%5C%5C+-3c_%7Bij%7D%5E2%2C+%26+0%5Cleq+c_%7Bij%7D%5Cleq+s_f+++%5C%5C+-6s_fc_%7Bij%7D%2B3s_f%5E2%2C%26+c_%7Bij%7D%3Es_f+%5C%5C+%5Cend%7Bcases%7D%5C%5C++%5Ctag%7B7%7D" alt=""></p><h4 id="4-1-3可行项惩罚"><a href="#4-1-3可行项惩罚" class="headerlink" title="4.1.3可行项惩罚"></a>4.1.3可行项惩罚</h4><p>通过限制轨迹在每一维上的高阶导数来保证其可行性。由于<u>凸包的性质</u>，对控制点的导数进行约束足以约束整个b样条。<code>F()</code>为为每个维度的高阶导数构造的惩罚函数。</p><p><img src="https://www.zhihu.com/equation?tex=J_d%3D%5Csum_%7Bi%3D1%7D%5E%7BN_c-1%7D%5Comega_vF%28V_i%29%2B%5Csum_%7Bi%3D1%7D%5E%7BN_c-2%7D%5Comega_aF%28A_i%29%2B%5Csum_%7Bi%3D1%7D%5E%7BN_c-3%7D%5Comega_jF%28J_i%29%5Ctag%7B8%7D+%5C%5C" alt=""></p><p><img src="https://www.zhihu.com/equation?tex=F%28C%29%3D%5Csum_%7Br%3Dx%2Cy%2Cz%7Df%28c_r%29%5Ctag%7B9%7D%5C%5C" alt=""></p><p><img src="https://www.zhihu.com/equation?tex=f%28c_r%29%3D%5Cbegin%7Bcases%7D+a_1c_r%5E2%2Bb_1c_r%2Bc_1%2C+%26+c_r%3C-c_j+%5C%5C+%28-%5Clambda+c_m-c_r%29%5E3%2C+%26+-c_j+%3C+c_r+%3C+-%5Clambda+c_m+++%5C%5C+0%2C%26+-%5Clambda+c_m+%5Cleq+c_r+%5Cleq+%5Clambda+c_m+%5C%5C+%28c_r-%5Clambda+c_m%29%5E3%2C+%26+%5Clambda+c_m+%3C+c_r+%3C+c_j+++%5C%5C+a_2c_r%5E2%2Bb_2c_r%2Bc_2%2C%26+c_r%3Ec_j+%5C%5C+%5Cend%7Bcases%7D%5C%5C++%5Ctag%7B10%7D" alt=""></p><blockquote><p>可以看出问题建模中应用的惩罚函数全部是多项式和，这有利于降低求解最优化问题的复杂度。（轻量化算法）</p></blockquote><h3 id="4-2最优化求解方法"><a href="#4-2最优化求解方法" class="headerlink" title="4.2最优化求解方法"></a>4.2最优化求解方法</h3><p>目标函数 <em>J</em>会随着新障碍物的加入而不断改变，这就要求求解器能够快速重启，并且目标函数主要由二次项组成，所以Hessian（黑塞矩阵）信息能够加快收敛速度。但得到精确的Hessian消耗大量计算机资源。所以我们使用拟牛顿法（ quasi-Newton methods)从梯度信息中来近似计算Hessian。</p><p>在对比了<code>Barzilai-Borwein method</code>、<code>truncated Newton method</code>和<code>L-BFGS methodh</code>后发现，<code>L-BFGS</code>表现最好，平衡了重启损失和逆Hessian估计的准确性。L-BFGS从以前的目标函数评估近似Hessian，但需要一系列的迭代，以达到一个相对准确的估计。</p><blockquote><p>上述几种最优化求解方法在我们的最优化课本中就有提及</p></blockquote><h2 id="五、时间重分配和轨迹细化"><a href="#五、时间重分配和轨迹细化" class="headerlink" title="五、时间重分配和轨迹细化"></a>五、时间重分配和轨迹细化</h2><p>基于<strong>四节</strong>中得到的安全轨迹生成一条时间分配合理的均匀B样条曲线轨迹  ${\Phi_s}$ ，然后使用各向异性曲线拟合方法（an anisotropic curve fifitting method）使 ${\Phi_f}$ 自由地优化其控制点，以满足高阶导数约束，同时保持与 ${\Phi_s}$几乎相同的导数形状。</p><p>首先计算超过限制(下标m表示限制的最大值)的比例,</p><p><img src="https://www.zhihu.com/equation?tex=r_e%3Dmax%5C%7B+%5Cleft%7C+V_%7Bi%2Cr%7D%2Fv_m+%5Cright%7C%2C%5Csqrt%7B%5Cleft%7C+A_%7Bj%2Cr%7D%2Fa_m+%5Cright%7C%7D%2C%5Csqrt%5B3%5D%7B%5Cleft%7C+J_%7Bk%2Cr%7D%2Fj_m+%5Cright%7C%7D%2C1+%5C%7D%5Ctag%7B14%7D" alt=""></p><p>  ${r_s}$  表明相对于 ${\Phi_s}$ ，  ${\Phi_f}$  需要分配多少时间。  ${V_i}$ ， ${A_j}$ 和 ${J_k}$  分别与  ${\triangle{t}}$ 的一次、二次和三次成反比，通过与时间的反比关系可以降低速度及其导数，则 ${\Phi_f}$ 的新时间间隔为</p><p><img src="https://www.zhihu.com/equation?tex=%5CDelta+t%27%3Dr_e%5CDelta+t+%5Ctag%7B15%7D" alt=""></p><p>通过求解一个如下的闭式的最小二乘问题，在速度及其导数的约束下初始生成时间跨度为${\triangle{t}^{\prime}}$  的轨迹${\Phi_f}$ ，同时保持与 ${\Phi_s}$  相同的形状和控制点数。然后重新计算光滑项惩罚和可行性项惩罚得到新的目标函数</p><p><img src="https://www.zhihu.com/equation?tex=Q%3Dargmin%5C+J%E2%80%99%3D%5Clambda_sJ_s%2B%5Clambda_dJ_d%2B%5Clambda_fJ_f++%5Ctag%7B16%7D" alt=""></p><p>${J_f}$   被定义为从 ${{\Phi_f}(\alpha T^{\prime})}$ 到 ${{\Phi_s}(\alpha T)}$各向异性位移的积分，其中 $T$  和 $T^{\prime}$ 为轨迹  ${\Phi_s}$ 和  ${\Phi_f}$ 的时长，  其中$\alpha  \in \left[ {0,1} \right]$。</p><p>由于拟合的对象曲线 ${\Phi_s}$ 已经无碰撞，对于两条曲线，我们用带有低权重的轴向位移 ${d_a}$ 来放宽光滑调整限制，用高权重的径向位移 ${d_r}$ 来<u>防止碰撞</u>。如图5所示，我们使用球状度量来使在同一球体表面的位移产生相同的惩罚。<u>(关于径向位移和轴向位移应该在具体算法中了解，目前我认为轴向位移为该点的切线方向，而径向方向为该切线的垂线方向)</u></p><p><img src="https://pic2.zhimg.com/80/v2-8e5a619734086459c284ecb62fdd20a5_720w.jpg" alt="原文图5"></p><p>用于度量 ${{\Phi_f}(\alpha T^{\prime})}$ 惩罚大小的椭圆体是一个以  ${{\Phi_f}(\alpha T^{\prime})}$  为中心的椭圆，其半长轴长度为a、其半短轴长度为b。则轴向位移  ${d_a}$  和径向位移 ${d_r}$  为</p><p><img src="https://www.zhihu.com/equation?tex=d_a%28%5Calpha+T%27%29%3D%28%5CPhi_f%28%5Calpha+T%27%29-%5CPhi_s%28%5Calpha+T%29%29%5Ccdot+%5Cfrac%7B%5Cdot%7B%5CPhi_s%7D%28%5Calpha+T%29%7D%7B%5Cleft%7C+%5Cleft%7C+%5Cdot%7B%5CPhi_s%7D%28%5Calpha+T%29+%5Cright%7C+%5Cright%7C%7D%5C%5C++d_r%28%5Calpha+T%27%29%3D%5Cleft%7C+%5Cleft%7C+%28%5CPhi_f%28%5Calpha+T%27%29-%5CPhi_s%28%5Calpha+T%29%29%5Ctimes+%5Cfrac%7B%5Cdot%7B%5CPhi_s%7D%28%5Calpha+T%29%7D%7B%5Cleft%7C+%5Cleft%7C+%5Cdot%7B%5CPhi_s%7D%28%5Calpha+T%29+%5Cright%7C+%5Cright%7C%7D+%5Cright%7C+%5Cright%7C+%5Ctag%7B17%7D" alt=""></p><p>则拟合惩罚项可表示为为<img src="https://www.zhihu.com/equation?tex=J_f%3D%5Cint_%7B0%7D%5E%7B1%7D%5Cleft%5B+%5Cfrac%7Bd_a%28%5Calpha+T%27%29%5E2%7D%7Ba%5E2%7D%2B%5Cfrac%7Bd_r%28%5Calpha+T%27%29%5E2%7D%7Bb%5E2%7D+%5Cright%5Dd%5Calpha+%5Ctag%7B18%7D" alt=""></p><p>其中a和b分别是椭圆的半长轴和半短轴，径向位移对应的半短轴b使径向位移的惩罚权重增大以防止<u>防止碰撞</u>。</p><p>式18被离散化为有限个数的点  ${\Phi _f}(\alpha \Delta {t^\prime })$ 和  ${\Phi _s}(\alpha \Delta t)$  ，其中</p><p> <img src="https://www.zhihu.com/equation?tex=k+%5Cin+%5Cmathbb%7BR%7D" alt=""> </p><p> <img src="https://www.zhihu.com/equation?tex=0+%5Cleq+k+%5Cleq+%5Clfloor+T%2F%5CDelta+t+%5Crfloor" alt=""> </p><h2 id="六、实验结果"><a href="#六、实验结果" class="headerlink" title="六、实验结果"></a>六、实验结果</h2><h3 id="6-1实验细节"><a href="#6-1实验细节" class="headerlink" title="6.1实验细节"></a>6.1实验细节</h3><p>规划算法框架如算法2所示。</p><p><img src="https://pic2.zhimg.com/80/v2-b6480d2395342827e87fa79dbf6313d9_720w.jpg" alt="算法2"></p><p>算法2伪代码说明</p><p><code>FindInit(Q,G)</code>生成一条满足终端约束但不考虑障碍物的B样条曲线 $\Phi$对应的控制点</p><p><code>IsCollisionFree(E，Q)</code>判断控制点是否在环境中是无碰撞的，有碰撞时输出false</p><p><code>CheckAndAddObstacleInfo(E,Q)</code>检测控制点所在障碍物，并添加障碍物信息({p,v}对以及距离场)</p><p><code>EvaluatePenalty(Q)</code>根据问题建模构造控制点相应惩罚项J以及对应的梯度</p><p><code>OneStepOptimize(J,G)</code>求解惩罚项的最小化问题，即最优化求解，从而得到满足惩罚项的最小化的控制点位置，即完成第一步的轨迹优化</p><p><code>IsFeasible(Q)</code>判断由控制点Q决定的轨迹是否可行(主要是速度以及其多阶导数否超过限制最大值)</p><p><code>ReAllocateTime(Q)</code>通过重新分配由控制点Q决定的轨迹的时间降低速度以及其多阶导数，使其满足各类速度约束。</p><p><code>CurveFittingOptimize(Q)</code>将之前的惩罚中碰撞项替换为曲线拟合项，求解惩罚项最优化问题。使其在满足新时间间隔的前提下，拟合由旧控制点构成的轨迹得到新轨迹，在继承旧轨迹的无碰撞特性的前提下实现约束下可行性。</p><p>我们设置B样条曲线的阶数${p_b} = 3$，控制点的个数 ${N_c}$ 为25左右，具体由规划预期距离（大约7m）和初始的邻近点间距（大约0.3m）决定。这些参数根据经验通过平衡了问题的复杂度和自由度而得到。 </p><p>因为根据B样条曲线的性质，一个控制点只影响周围的轨迹，所以算法的时间复杂度为 $O({N_c})$。</p><p>L-BFGS的复杂性在相同的相对公差上也是线性的。(The complexity of L-BFGS is also linear on the same relative tolerance)</p><p>在无碰撞路径搜索中，我们采用A星算法进行轨迹优化，而它生成的轨迹$\Gamma $常常贴着障碍物。因此，我们可以直接在A星算法生成的轨迹$\Gamma $上选择定位点（anchor point）p 而不用搜索障碍物的表面(这里才真正解释出了<u>第三节中A星算法</u>的作用)。对于图3b中定义的向量$R_i $，通过均匀b样条参数化的性质，可以推导出</p><p><img src="https://www.zhihu.com/equation?tex=R_i%3D%5Cfrac%7BQ_%7Bi%2B1%7D-Q_%7Bi-1%7D%7D%7B2%5Ctriangle+t%7D+%5Ctag%7B19%7D" alt=""></p><p>这里的$R_i$是图3中确定{p,v}对的关键。</p><blockquote><p>读到这里，我们再看看论文中的图3。</p><p>第一步：根据生成一条满足终端约束但不考虑障碍物的B样条曲线 $\Phi$，依靠A星算法生成的轨迹$\Gamma $。</p><p>第二步：根据公式(19)通过B样条曲线的控制点计算出向量$R_i $，再做出垂直于$R_i $的平面$\Psi $，平面$\Psi $与依靠A星算法生成的轨迹$\Gamma $相交于定位点（anchor point）p，连接对应的定位点（anchor point）p与控制点Q，才得到直线<em>l</em>,而向量v是向量<em>l</em>对应的由起点控制点Q到终点定位点p对应的<u>单位向量</u>。(v可能是生成以后不会再变化的)。到这里才生成了{p,v}对。</p><p>论文第3节的内容到第6节才彻底解释清楚，真是折磨死我了！！！</p><p>note：思考问题：关于{p,v}对过程中，为什么将定位点p定位到A星算法生成的贴着障碍物的轨迹上，而不直接定位在障碍物表面？</p><p>我的理解：在A星算法生成的轨迹(线)定位的算力成本比直接定位在障碍物表面(面)低。</p></blockquote><p><img src="https://pic1.zhimg.com/80/v2-d6026bb43ab95c45706b88ea954f22d8_720w.jpg" alt="原文图3"></p><p>为了进一步保证安全，对最终轨迹周围具有固定半径的圆形管道进行碰撞检查，以保证轨迹和障碍物之间有足够的距离，优化程序在未检测到碰撞时停止。</p><p>真实世界的实验环境与<a href="https://link.zhihu.com/?target=https%3A//github.com/HKUST-Aerial-Robotics/Teach-Repeat-Replan">Teach-Repeat-Replan</a>相同，此外，我们还修改了Intel  RealSense的ROS驱动程序，使激光发射器每隔一帧频闪。这使得该设备在发射器的帮助下输出高质量的深度图像，以及不受激光干扰的双目图像。修改后的驱动也是开源的。</p><h3 id="6-2优化算法的比较"><a href="#6-2优化算法的比较" class="headerlink" title="6.2优化算法的比较"></a>6.2优化算法的比较</h3><h3 id="6-3有-无ESDF的轨迹生成"><a href="#6-3有-无ESDF的轨迹生成" class="headerlink" title="6.3有/无ESDF的轨迹生成"></a>6.3有/无ESDF的轨迹生成</h3><h3 id="6-4多个规划器的比较"><a href="#6-4多个规划器的比较" class="headerlink" title="6.4多个规划器的比较"></a>6.4多个规划器的比较</h3><h3 id="6-5真实世界实验"><a href="#6-5真实世界实验" class="headerlink" title="6.5真实世界实验"></a>6.5真实世界实验</h3><h2 id="七、结论和未来的工作"><a href="#七、结论和未来的工作" class="headerlink" title="七、结论和未来的工作"></a>七、结论和未来的工作</h2><p>该方法仍然存在一些缺陷，即A*搜索引入的局部最小值和统一时间重新分配引入的保守轨迹。因此，我们将致力于执行拓扑规划，以逃避局部最小值，并重新制定问题，以生成接近最优的轨迹。规划器为静态环境设计，无需处理缓慢移动的障碍物（低于0.5m/s）。在未来，我们将通过移动对象检测和拓扑规划来研究动态环境导航。</p><p>以上内容根据博客：<a href="https://zhuanlan.zhihu.com/p/366372048">EGO-Planner论文阅读笔记 - 知乎 (zhihu.com)</a>进行补充与修改。</p><h2 id="源码精读"><a href="#源码精读" class="headerlink" title="源码精读"></a>源码精读</h2><p>未完待更新</p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> fast planner </tag>
            
            <tag> ego planner </tag>
            
            <tag> 无人机 </tag>
            
            <tag> 轨迹优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无人机智能化的实现路径(高飞大佬)</title>
      <link href="/2021/10/21/wu-ren-ji-zhi-neng-hua-de-shi-xian-lu-jing/"/>
      <url>/2021/10/21/wu-ren-ji-zhi-neng-hua-de-shi-xian-lu-jing/</url>
      
        <content type="html"><![CDATA[<h2 id="轻量化"><a href="#轻量化" class="headerlink" title="轻量化"></a>轻量化</h2><p>减少算法中的冗余部分以保持无人机的良好性能。 </p><p>相关论文：</p><p>fast-planner相关文章:</p><p><a href="https://ieeexplore.ieee.org/document/9422918">RAPTOR: Robust and Perception-Aware Trajectory Replanning for Quadrotor Fast Flight | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p><a href="https://ieeexplore.ieee.org/abstract/document/8758904">Robust and Efficient Quadrotor Trajectory Generation for Fast Autonomous Flight | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p><a href="https://ieeexplore.ieee.org/document/9196996">Robust Real-time UAV Replanning Using Guided Gradient-based Optimization and Topological Paths | IEEE Conference Publication | IEEE Xplore</a></p><p>ego-planner相关文章：</p><p><a href="https://ieeexplore.ieee.org/abstract/document/9309347">EGO-Planner: An ESDF-Free Gradient-Based Local Planner for Quadrotors | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p>ESDF相关文章</p><p><a href="https://ieeexplore.ieee.org/document/8968199">FIESTA: Fast Incremental Euclidean Distance Fields for Online Motion Planning of Aerial Robots | IEEE Conference Publication | IEEE Xplore</a></p><h2 id="鲁棒性"><a href="#鲁棒性" class="headerlink" title="鲁棒性"></a>鲁棒性</h2><p>增强无人机抗干扰能力，使之安全可靠。</p><p>相关论文：</p><p> <a href="https://link.springer.com/chapter/10.1007/978-3-030-71151-1_4">CMPCC: Corridor-Based Model Predictive Contouring Control for Aggressive Drone Flight | SpringerLink</a>       </p><p><a href="https://ieeexplore.ieee.org/document/9560898">VID-Fusion: Robust Visual-Inertial-Dynamics Odometry for Accurate External Force Estimation | IEEE Conference Publication | IEEE Xplore</a>                                       </p><p><a href="https://ieeexplore.ieee.org/document/9531427">External Forces Resilient Safe Motion Planning for Quadrotor | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p><a href="https://ieeexplore.ieee.org/document/8721075">VIMO: Simultaneous Visual Inertial Model-Based Odometry and Force Estimation | IEEE Journals &amp; Magazine | IEEE Xplore</a>（非高飞组）</p><p><a href="https://ieeexplore.ieee.org/document/8968126">Robust Trajectory Planning for a Multirotor against Disturbance based on Hamilton-Jacobi Reachability Analysis | IEEE Conference Publication | IEEE Xplore</a>（非高飞组）</p><h2 id="敏捷化"><a href="#敏捷化" class="headerlink" title="敏捷化"></a>敏捷化</h2><p>在一定约束条件下，使无人机实时且可行地通过快速调整姿态完成规划任务。</p><p>相关论文：</p><p><a href="https://ieeexplore.ieee.org/document/9102390">Teach-Repeat-Replan: A Complete and Robust System for Aggressive Flight in Complex Environments | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p><a href="https://arxiv.org/abs/2103.00190v2">[2103.00190v2] Geometrically Constrained Trajectory Optimization for Multicopters (arxiv.org)</a></p><p><a href="https://arxiv.org/abs/2105.10276v2">[2105.10276v2] Fast-Racing: An Open-source Strong Baseline for SE(3) Planning in Autonomous Drone Racing (arxiv.org)</a></p><p><a href="https://ieeexplore.ieee.org/document/7138978">Efficient mixed-integer planning for UAVs in cluttered environments | IEEE Conference Publication | IEEE Xplore</a>（非高飞组）</p><p><a href="https://ieeexplore.ieee.org/document/5980409">Minimum snap trajectory generation and control for quadrotors | IEEE Conference Publication | IEEE Xplore</a>（非高飞组）</p><p><a href="https://journals.sagepub.com/doi/full/10.1177/1756829320924528">Robust autonomous flight in cluttered environment using a depth sensor - Liang Lu, Alexander Yunda, Adrian Carrio, Pascual Campoy, 2020 (sagepub.com)</a>（非高飞组）</p><p><a href="https://experts.illinois.edu/en/publications/fast-uav-trajectory-optimization-using-bilevel-optimization-with-">Fast UAV Trajectory Optimization using Bilevel Optimization with Analytical Gradients — University of Illinois Urbana-Champaign</a>（非高飞组）</p><p><a href="https://dl.acm.org/doi/10.1145/2558904">GPOPS-II: A MATLAB Software for Solving Multiple-Phase Optimal Control Problems Using hp-Adaptive Gaussian Quadrature Collocation Methods and Sparse Nonlinear Programming: ACM Transactions on Mathematical Software: Vol 41, No 1</a>（非高飞组）</p><h2 id="多无人机编队"><a href="#多无人机编队" class="headerlink" title="多无人机编队"></a>多无人机编队</h2><p>实现<strong>微小</strong>、<strong>智能</strong>、<strong>合作</strong>、<strong>去中心化</strong>的<strong>无人机编队</strong></p><p>相关论文：</p><p><a href="https://arxiv.org/abs/2011.04183v1">[2011.04183v1] EGO-Swarm: A Fully Autonomous and Decentralized Quadrotor Swarm System in Cluttered Environments (arxiv.org)</a></p><p><a href="https://export.arxiv.org/abs/2109.07682">[2109.07682] Distributed Swarm Trajectory Optimization for Formation Flight in Dense Environments (arxiv.org)</a></p><p><a href="https://arxiv.org/abs/2106.12481">[2106.12481] Decentralized Spatial-Temporal Trajectory Planning for Multicopter Swarms (arxiv.org)</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>轻量化、强鲁棒性、敏捷化常常互相关联，而这三者是实现<strong>微小</strong>、<strong>智能</strong>、<strong>合作</strong>、<strong>去中心化</strong>的<strong>无人机编队</strong>的关键所在。</p><p>未完待补充~~~</p><p>参考：<a href="https://www.bilibili.com/video/BV1Jq4y1T7QD?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click">Fastlab实验室高飞大佬讲解的导论内容</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>fast-planner初代论文笔记2</title>
      <link href="/2021/10/20/fast-planner-chu-dai-lun-wen-bi-ji-2/"/>
      <url>/2021/10/20/fast-planner-chu-dai-lun-wen-bi-ji-2/</url>
      
        <content type="html"><![CDATA[<p>对应代码地址：<a href="https://github.com/HKUST-Aerial-Robotics/Fast-Planner">GitHub - HKUST-Aerial-Robotics/Fast-Planner: A Robust and Efficient Trajectory Planner for Quadrotors</a></p><p>对应文章地址：<a href="https://ieeexplore.ieee.org/document/9196996">Robust Real-time UAV Replanning Using Guided Gradient-based Optimization and Topological Paths | IEEE Conference Publication | IEEE Xplore</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p> 基于梯度的轨迹优化(GTO)在四旋翼飞行器的轨迹重新规划中得到了广泛的应用。但是它存在<strong>局部极小值</strong>，这不仅对安全是致命的，而且不利于航行的顺利进行。本文提出了一种基于GTO的再规划方法，系统地解决了这一问题。针对不可行的局部极小点，提出了一种<strong>路径引导优化(PGO)方法</strong>，大大提高了重规划的成功率。提出了一种<strong>拓扑路径搜索算法</strong>，用于捕获三维环境中不同的有用路径集合，每条路径引导一个独立的轨迹优化。它激活了对解决方案空间的更全面的探索，并输出了更优的重新规划的轨迹。基准评估结果表明，该方法在重新规划成功率和最优性方面优于目前最先进的方法。给出了具有挑战性的主动自主飞行实验，证明了该方法的鲁棒性。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="基于梯度的路径优化"><a href="#基于梯度的路径优化" class="headerlink" title="基于梯度的路径优化"></a>基于梯度的路径优化</h3><p> GTO是一种主要的路径生成算法，把路径生成看作一个最小化目标函数的非线性优化问题。问题：<strong>局部最小值</strong>。</p><h3 id="拓扑路径规划"><a href="#拓扑路径规划" class="headerlink" title="拓扑路径规划"></a>拓扑路径规划</h3><p> 已经有人利用拓扑上不同路径的思想在2维平面或者3维空间进行路径规划，其中有一种寻找属于可见性不同形类的路径的算法。其缺点为<strong>算法的复杂度过高</strong>，本文基于此做出改进。</p><h2 id="路径引导轨迹优化"><a href="#路径引导轨迹优化" class="headerlink" title="路径引导轨迹优化"></a>路径引导轨迹优化</h2><p>PATH-GUIDED    TRAJECTORY    OPTIMIZATION    ,PGO</p><h3 id="A-优化失效分析"><a href="#A-优化失效分析" class="headerlink" title="A. 优化失效分析"></a>A. 优化失效分析</h3><p>GTO的失败与不利的初始化有关，即初始路径以某种方式通过障碍通常会被卡住。典型的GTO方法将欧几里得符号距离场(ESDF)的梯度纳入碰撞成本中，以推动轨道脱离障碍物。将该代价与平滑性代价和动态可行性代价相结合，形成目标函数，其梯度迭代地将轨迹变形为平稳、安全的轨迹。</p><p>但如下图所示，为GTO优化失败的典型例子，当轨迹穿过ESDF(用橙色虚线表示)的“谷”(a)或“脊”(b)时，轨迹的相邻部分被推向相反的方向。红色箭头表示ESDF的梯度，黄色箭头表示目标函数的梯度。这个目标函数就是我们B节中问题公式化需要产生的函数。<br><img src="https://img-blog.csdnimg.cn/20210511103645488.png" alt="轨道穿过ESDF的“山谷”(a)或“山脊”(b)"> </p><p>对于这种情况，仅仅靠ESDF的梯度并不够，需要额外的信息(目标函数)。</p><h3 id="B-问题公式化-PGO的实现方法的数学形式"><a href="#B-问题公式化-PGO的实现方法的数学形式" class="headerlink" title="B. 问题公式化(PGO的实现方法的数学形式)"></a>B. 问题公式化(PGO的实现方法的数学形式)</h3><p> 文中提出的PGO方法是对上面GTO的改进，它的路径用B样条来表示。对于PGO方法，分为两步，第一个阶段产生一个过渡的预热轨迹（warmup trajectory），第二阶段，对这个预热轨迹的平滑度以及与间隙值(与障碍物之间的)再进行优化。两个阶段如下图：<br><img src="https://img-blog.csdnimg.cn/20210511104613350.png" alt=""><br> 第一阶段：a图的绿色是初始B样条轨迹，橙色的是几何引导路径，几何引导路径把初始轨迹拉到没有碰撞的地方形成预热路径（蓝色)</p><p>​    第二阶段：b图中，对预热路径再进一步进行平滑度和间隙值(与障碍物之间的)的优化，得到红色最终轨迹。这个几何引导路径通过A星算法或者RRT<em>等传统方法就可以得到，但本文用的是<em>*采样</em></em>的方法(拓扑路径搜索 ,    TOPOLOGICAL    PATH    SEARCHING)得到这条引导路径。</p><p> 第一阶段的优化目标函数是：<br><img src="https://img-blog.csdnimg.cn/20210522155741955.png" alt=""><br>这里$f_s$是轨迹平滑性惩罚函数，而$f_g$是引导路径和b样条轨迹之间的距离的惩罚代价，其定义如下，主要是利用模拟弹性力来构造惩罚函数，其中$Q_i$为b样条轨迹的控制点，每个控制点$Q_i$都被分配了一个引导路径上关联的点$G_i$，其由沿着引导路径进行均匀采样得到：<br><img src="https://img-blog.csdnimg.cn/2021052215582930.png" alt=""></p><p><img src="https://img-blog.csdnimg.cn/2021052215593092.png" alt=""></p><p>第二阶段的优化目标函数如下，$f_s$是轨迹平滑性惩罚(成本)函数，$f_c$是在ESDF上评估的碰撞成本函数，当轨迹接近障碍物时，ESDF的碰撞成本迅速增长。再利用惩罚函数$f_v$与$f_a$对速度和加速度的不可行程度进行量化，第二阶段的主要内容参考<a href="https://ieeexplore.ieee.org/document/8758904">fast-planner文章：Robust and Efficient Quadrotor Trajectory Generation for Fast Autonomous Flight | IEEE Journals &amp; Magazine | IEEE Xplore</a>。</p><p><img src="https://img-blog.csdnimg.cn/20210522160705169.png" alt=""></p><h2 id="拓扑路径搜索"><a href="#拓扑路径搜索" class="headerlink" title="拓扑路径搜索"></a>拓扑路径搜索</h2><p>TOPOLOGICAL    PATH    SEARCHING</p><p>本文提出了一个采样的方法来寻找几条不同的引导路径来引导上面PGO，以实时解决路径再规划问题。</p><h3 id="A-拓扑等价关系"><a href="#A-拓扑等价关系" class="headerlink" title="A. 拓扑等价关系"></a>A. 拓扑等价关系</h3><p>通过改进<a href="https://www.researchgate.net/publication/220122862_Path_Deformation_Roadmaps_Compact_Graphs_with_Useful_Cycles_for_Motion_Planning"> Path Deformation Roadmaps: Compact Graphs with Useful Cycles for Motion Planning </a>中的可见性不同形(visibility deformation，VD)，定义了<strong>均匀的</strong>可见性不同形(uniform visibility deformation,UVD)，它也捕获了大量有用的轨迹信息，并对等价性检验更有效。</p><blockquote><p>可见性不同形：两条终点起点相同的轨迹，两者之间无障碍物(连线无碰撞，即可见)，但形状不相同</p></blockquote><p>对于等价性检查来说，VD的计算代价很高,要测试VD关系，应该计算一个可见性图，并在其中进行路径搜索，这比检验UVD的复杂性更高。</p><p>因此，提出一种<strong>均匀的</strong>可见性不同形(uniform visibility deformation,UVD)的定义：</p><p>存在两条可以被s∈[0,1]参数化的轨迹$τ_1(s)、 τ_2(s)$并且满足$τ1(0) =τ2(0)， τ1(1) =τ2(1)$，如果对所有情况，连接$τ_1(s)、τ_2(s)$的线段是无碰撞的。那么这两条轨迹属于均匀的可见性不同形(UVD)类。</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gx9ttetwaej30na0bvjv7.jpg" alt="UVD和VD对比"></p><p><img src="https://img-blog.csdnimg.cn/20210522163233453.png" alt="UVD效果展示"></p><h3 id="B-拓扑路径图"><a href="#B-拓扑路径图" class="headerlink" title="B. 拓扑路径图"></a>B. 拓扑路径图</h3><p>拓扑路径生成图如图7，e图中，红色和橙色路径都属于同一个UVD类，而粉色路径是其UVD类的唯一成员。</p><p>在设计拓扑路径图中，我们引入了两种不同的图节点，即guard(守卫点)和connector(连接点)，类似于Visibility-PRM。guard负责探索自由空间的不同部分，任何两个guard点g1和g2是彼此是不可见的(连接g1和g2的线段存在碰撞)。每次在地图上采样一个点，如果这个点另外的任何一个guard都看不到，那么这个点就记作一个新的guard点。然后继续采样，如果一个采样点刚好可以被两个guard点看到，那么就把这个点记作connector，然后把这个connector和这两个guard点连起来。连接好以后做两个事：如果这是一条全新的拓扑路径，那么就保留，否则判断两条拓扑路径的长度，把长的那条去掉，保留短的那条。</p><p><img src="https://img-blog.csdnimg.cn/20210524113127738.png" alt=""></p><p>伪代码说明：在设计拓扑路径图中，我们引入了两种不同的图节点，即guard(守卫点)和connector(连接点)，类似于Visibility-PRM。guard负责探索自由空间的不同部分，任何两个guard点g1和g2是彼此是不可见的(连接g1和g2的线段存在碰撞)。在主循环之前，在起始点和结束点创建两个guard点。每当采样点对所有其他guard都不可见时，就会在此点创建一个新的guard(第6-7行)。为了形成路线图的路径，使用连接器连接不同的guard(第7-19行)。当采样点恰好对两个guard可见时，就会创建一个新connector，要么连接guard以形成拓扑上不同的连接(第19-20行)，要么替换现有connector以创建更短的路径(第16-17行)。设置时间限制(t_max)或采样次数限制(N_max)来终止循环。其中起始点和终点之间的结点搜索算法参考<a href="https://www.sciencedirect.com/science/article/pii/S0921889016300495">Integrated online trajectory planning and optimization in distinctive topologies - ScienceDirect</a>。</p><p>设计拓扑路径的算法伪代码：</p><p><img src="https://img-blog.csdnimg.cn/20210522162830452.png" alt=""></p><p>设计拓扑路径的算法伪代码中函数的解释：</p><p><code>AddGuard(G,b)</code>增加guard节点到G中</p><p><code>sample()</code>通过采样节点，</p><p><code>VisibleGuard(G，Ps)</code>得到G中能观测到Ps的所有节点</p><p><code>.size(a)</code>计算节点个数（能观测到Ps）</p><p><code>Path(g1,c,g2)</code>连接connector点与guard点生成路径</p><p><code>SharedNeighbors(G,g1,g2)</code>从G体提取能够与g1、g2连接的连接点集</p><p><code>Equivalent(p1，p2)</code>判断是否的拓扑连接是是否相同</p><p><code>len(p)</code>计算路径长度</p><p><code>Replace(G，p，n)</code>替换connector点（p换下n）</p><p><code>distinct</code>bool型数据，true表示拓扑连接有差别，false表示拓扑连接无差别</p><p><code>t_max</code>时间限制</p><p><code>N_max</code>采样个数限制</p><p><code>G</code>所有guard点以及connect点的集合</p><h3 id="C-路径缩短和修剪"><a href="#C-路径缩短和修剪" class="headerlink" title="C. 路径缩短和修剪"></a>C. 路径缩短和修剪</h3><p>如图7(e)所示，由算法1得到的一些路径可能会绕行。导致PGO的第一阶段会使轨迹过度变形，使轨迹变得不光滑。因此，需要通过算法2为深度优先搜索得到的每条路径$P_r$找到一个拓扑上等效的捷径路径$P_s$(如图8所示)。</p><p>该算法首先将路径$P_r$一致地离散化为一组$P_d$点，而$P_r$的第一个点即为$P_s$的第一个点。在每次迭代中，如果$P_s$中的一个点第一次（按离散化的顺序）看不见$P_d$中的一个点(两点连线被障碍物占据的体素挡住了)(Line 3,4)，则第一个阻塞了P_s中的前一个点的视野的障碍物对应的占据的体素的中心点就可以被找到(Line 5)。然后通过以垂直于l_d与且与ESDF梯度共面的方向推离<strong>障碍物中心点</strong>得到新点$P_o$(Line 6)。之后，这个新点被添加$P_s$中(第7行)。这个过程一直持续到最后一个点。(离开的点)</p><p><img src="https://img-blog.csdnimg.cn/20210524114458852.png" alt=""></p><p>算法2伪代码函数</p><p><code>Disecreze(P)</code>将轨迹统一离散为点集</p><p><code>.front()</code>取点集中的前一个点</p><p><code>Line(a,b)</code>得到连接a和b的线段</p><p><code>LineVisib(l)</code>判断线段是否被障碍物遮挡</p><p><code>BlockPoint(l)</code>得到遮挡线段障碍物的体素的中心点</p><p><code>PushAwayObs(p,l)</code>以l方向推离点得到新点P_o</p><p><code>.push_back(p)</code>将P点加入点集</p><p><img src="https://img-blog.csdnimg.cn/20210524115705594.png" alt=""></p><h2 id="实时拓扑路径规划"><a href="#实时拓扑路径规划" class="headerlink" title="实时拓扑路径规划"></a>实时拓扑路径规划</h2><p>路径引导轨迹优化的算法输出了一组有效的路径，可以引导轨迹优化。我们将它们与PGO进行适当的集成，以便实时重新规划。在飞行过程中，特定视界内的一段全球轨道会被定期检查以确保安全。一旦检测到碰撞，拓扑路线图的构建就会在一个立方体内触发，这是由段的开始和结束位置以及(rx, ry, rz)指定立方体的大小决定的。从路线图中提取的路径被缩短和修剪，之后每条路径调用一个独立的PGO。</p><p>值得注意的是，可选择的UVD类的数量随着障碍的数量呈指数增长。因此，在复杂的环境中，为所有路径进行优化可能是很难的。由于这个原因，我们只选择第一次中的k_max中的最短路径，长度超过最短路径rmax的数倍的路径也被排除在外。这种策略限制了复杂性，不会导致潜在最优性的缺失，因为非常长的路径不太可能产生最优轨迹。在实际应用中，我们发现kmax = 5是充分的。</p><p>以上内容，本文参考<a href="https://blog.csdn.net/qq_39366151/article/details/116642551"> Robust Real-time UAV Replanning Using Guided Gradient-based Optimization and Topological Paths_无心留踪迹的博客-CSDN博客</a>进行修正与补充。</p><h2 id="源码精读"><a href="#源码精读" class="headerlink" title="源码精读"></a>源码精读</h2><p>未完待续~~~</p><p>参考文章：<a href="https://ieeexplore.ieee.org/document/9196996">Robust Real-time UAV Replanning Using Guided Gradient-based Optimization and Topological Paths | IEEE Conference Publication | IEEE Xplore</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> fast planner </tag>
            
            <tag> 无人机 </tag>
            
            <tag> 轨迹优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS中的CMakeLists.txt与package.xml</title>
      <link href="/2021/10/18/ros-zhong-de-cmakelists-txt-yu-package-xml/"/>
      <url>/2021/10/18/ros-zhong-de-cmakelists-txt-yu-package-xml/</url>
      
        <content type="html"><![CDATA[<h2 id="CMakeLists-txt文件编辑说明"><a href="#CMakeLists-txt文件编辑说明" class="headerlink" title="CMakeLists.txt文件编辑说明"></a>CMakeLists.txt文件编辑说明</h2><h3 id="编译功能包"><a href="#编译功能包" class="headerlink" title="编译功能包"></a>编译功能包</h3><p>节点的代码已经完成，C++是一种编译语言，在运行之前需要将代码编译成可执行文件，如果使用Python等解析语言编写代码，则不需要进行编译，可以省去此步骤。</p><p>ROS中的编译器使用的是CMake，编译规则通过功能包中的CMakeLists.txt文件设置，使用catkin命令创建的功能包中会自动生成该文件，已经配置多数编译选项，并且包含详细的注释，我们几乎不用查看相关的说明手册，稍作修改就可以编译自己的代码。</p><p>打开功能包中的CMakeLists.txt文件，找到以下配置项，去掉注释并稍作修改：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">include_directories(include  ${catkin_INCLUDE_DIRS})add_executable(talker  src/talker.cpp)target_link_libraries(talker  ${catkin_LIBRARIES})add_dependencies(talker  ${PROJECT_NAME}_generate_messages_cpp)    add_executable(listener  src/listener.cpp)target_link_libraries(listener  ${catkin_LIBRARIES})add_dependencies(talker  ${PROJECT_NAME}_generate_messages_cpp)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于这个较为简单的功能包，主要用到了以下四种编译配置项。</p><p>（1）include_directories</p><p>用于设置头文件的相对路径。全局路径默认是功能包的所在目录，比如功能包的头文件一般会放到功能包根目录下的include文件夹中，所以此处需要添加该文件夹。此外，该配置项还包含ROS catkin编译器默认包含的其他头文件路径，比如ROS默认安装路径、Linux系统路径等。</p><p>（2）add_executable</p><p>用于设置需要编译的代码和生成的可执行文件。第一个参数为期望生成的可执行文件的名称，后边的参数为<u>参与编译的源码文件（cpp）</u>，如果需要多个代码文件，则可在后面依次列出，中间使用空格进行分隔。</p><p>（3）target_link_libraries</p><p>用于设置链接库。很多功能需要使用系统或者第三方的库函数，通过该选项可以配置执行文件链接的库文件，其第一个参数与add_executable相同，是可执行文件的名称，后面依次列出需要链接的库。此处编译的Publisher和Subscriber没有使用其他库，添加默认链接库即可。</p><p>（4）add_dependencies</p><p>用于设置依赖。在很多应用中，我们需要定义语言无关的消息类型，消息类型会在编译过程中产生相应语言的代码，如果编译的可执行文件依赖这些动态生成的代码，则需要使用add_dependencies添加<code>${PROJECT_NAME}_generate_messages_cpp</code>配置，即该功能包动态产生的消息代码。该编译规则也可以添加其他需要依赖的功能包。<br>以上编译内容会帮助系统生成两个可执行文件：talker和listener，放置在工作空间的~/catkin_ws/devel/lib/<package name="">路径下。</package></p><h3 id="自定义话题消息"><a href="#自定义话题消息" class="headerlink" title="自定义话题消息"></a>自定义话题消息</h3><p>打开功能包的CMakeLists.txt文件，在find_package中添加消息生成依赖的功能包message_generation，这样在编译时才能找到所需要的文件：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">find_package(catkin  REQUIRED  COMPONENTS             geometry_msgs             roscpp             rospy             std_msgs             message_generation)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>catkin依赖也需要进行以下设置：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">catkin_package(……               CATKIN_DEPENDS  geometry_msgs  roscpp  rospy  std_msgs  message_runtime               ……)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>最后设置需要编译的msg文件：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">add_message_files(    FILES    Person.msg)generate_messages(DEPENDENCIES    std_msgs)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>相关热门文章</p><p><a href="https://blog.csdn.net/buzaishihaizi/article/details/78524929">ROS中的CMakelists_buzaishihaizi的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/weixin_44095441/article/details/88643752">ROS中的CMakeLists.txt详解_听涯的博客-CSDN博客</a></p><h2 id="package-xml文件编辑说明"><a href="#package-xml文件编辑说明" class="headerlink" title="package.xml文件编辑说明"></a>package.xml文件编辑说明</h2><p>参考热门文章</p><p><a href="https://blog.csdn.net/qq_43247439/article/details/107101646">ROS中的package.xml的使用_Alex的博客-CSDN博客</a></p><p><a href="https://sychaichangkun.gitbooks.io/ros-tutorial-icourse163/content/chapter2/2.5.html">package.xml · 中国大学MOOC———《机器人操作系统入门》讲义 (gitbooks.io)</a></p>]]></content>
      
      
      <categories>
          
          <category> ROS学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROS中的launch启动文件</title>
      <link href="/2021/10/18/ros-zhong-de-launch-qi-dong-wen-jian/"/>
      <url>/2021/10/18/ros-zhong-de-launch-qi-dong-wen-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="launch启动文件"><a href="#launch启动文件" class="headerlink" title="launch启动文件"></a>launch启动文件</h1><p>到目前为止，每当我们需要运行一个ROS节点或工具时，都需要打开一个新的终端运行一个命令。当系统中的节点数量不断增加时，“每个节点一个终端”的模式会变得非常麻烦。那么有没有一种方式可以一次性启动所有节点呢？答案当然是肯定的。</p><p>启动文件（Launch File）便是ROS中一种同时启动多个节点的途径，它还可以自动启动ROS Master节点管理器，并且可以实现每个节点的各种配置，为多个节点的操作提供很大便利。</p><h2 id="1-基本元素"><a href="#1-基本元素" class="headerlink" title="1 基本元素"></a>1 基本元素</h2><p>·首先来看一个简单的launch文件，对其产生初步的概念。</p><pre class="line-numbers language-XML" data-language="XML"><code class="language-XML">&lt;launch&gt;    &lt;node  pkg="turtlesim"  name="sim1"  type="turtlesim_node"/&gt;    &lt;node  pkg="turtlesim"  name="sim2"  type="turtlesim_node"/&gt;&lt;/launch&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这是一个简单而完整的launch文件，采用XML的形式进行描述，包含一个根元素<code>&lt;launch&gt;</code>和两个节点元素<code>&lt;node&gt;</code>。</p><h3 id="1-1-lt-launch-gt"><a href="#1-1-lt-launch-gt" class="headerlink" title="1.1 <launch>"></a>1.1 <code>&lt;launch&gt;</code></h3><p>XML文件必须包含一个根元素，launch文件中的根元素采用<launch>标签定义，文件中的其他内容都必须包含在这个标签中：</launch></p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>launch</span><span class="token punctuation">&gt;</span></span>  …  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>launch</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="1-2-lt-node-gt"><a href="#1-2-lt-node-gt" class="headerlink" title="1.2 <node>"></a>1.2 <code>&lt;node&gt;</code></h3><p>启动文件的核心是启动ROS节点，采用<code>&lt;node&gt;</code>标签定义，语法如下：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span>  <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>package-name<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>executable-name<span class="token punctuation">"</span></span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>node-name<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从上面的定义规则可以看出，<u>在启动文件中启动一个节点需要三个属性：pkg、type和name。其中pkg定义节点所在的功能包名称，type定义节点的可执行文件名称，这两个属性等同于在终端中使用rosrun命令执行节点时的输入参数。name属性用来定义节点运行的名称</u>，将覆盖节点中init()赋予节点的名称。这是三个最常用的属性，在某些情况下，我们还有可能用到以下属性。<br>·output=”screen”：将节点的标准输出打印到终端屏幕，默认输出为日志文档。<br>·respawn=”true”：复位属性，该节点停止时，会自动重启，默认为false。<br>·required=”true”：必要节点，当该节点终止时，launch文件中的其他节点也被终止。<br>·ns=”namespace”：命名空间，为节点内的相对名称添加命名空间前缀。<br>·args=”arguments”：节点需要的输入参数。<br>实际应用中的launch文件往往会更加复杂，使用的标签也会更多，如本书后续内容中一个启动机器人的launch文件如下：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>launch</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span>  <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>mrobot_bringup<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>mrobot_bringup<span class="token punctuation">"</span></span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>mrobot_bringup<span class="token punctuation">"</span></span>  <span class="token attr-name">output</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span>  <span class="token punctuation">"</span>screen<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>urdf_file<span class="token punctuation">"</span></span>  <span class="token attr-name">default</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find  xacro)/xacro  --inorder  <span class="token punctuation">'</span>$(find  mrobot_  description)/urdf/mrobot_with_rplidar.urdf.xacro<span class="token punctuation">'</span><span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>robot_description<span class="token punctuation">"</span></span>  <span class="token attr-name">command</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg  urdf_file)<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>joint_state_publisher<span class="token punctuation">"</span></span>  <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>joint_state_publisher<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>joint_state_publisher<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span>  <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>robot_state_publisher<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>robot_state_publisher<span class="token punctuation">"</span></span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>state_publisher<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>publish_frequency<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>double<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>5.0<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>node</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>base2laser<span class="token punctuation">"</span></span>  <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>tf<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>static_transform_publisher<span class="token punctuation">"</span></span>  <span class="token attr-name">args</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>0  0  0  0  0  0  1  /base_link  /laser  50<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span>  <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>robot_pose_ekf<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>robot_pose_ekf<span class="token punctuation">"</span></span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>robot_pose_ekf<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span>  <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>robot_pose_ekf/odom_combined<span class="token punctuation">"</span></span>  <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom_combined<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>freq<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>10.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>sensor_timeout<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>1.0<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>publish_tf<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom_used<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>imu_used<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>vo_used<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>output_frame<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>node</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span>  <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find  mrobot_bringup)/launch/rplidar.launch<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>launch</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>目前，我们只关注其中的标签元素，除了上面介绍的<code>&lt;launch&gt;</code>和<code>&lt;node&gt;</code>，这里还出现了<code>&lt;arg&gt;</code>、<code>&lt;param&gt;</code>、<code>&lt;remap&gt;</code>，这些都是常用的标签元素。</p><h2 id="2-参数设置"><a href="#2-参数设置" class="headerlink" title="2　参数设置"></a>2　参数设置</h2><p>为了方便设置和修改，launch文件支持参数设置的功能，类似于编程语言中的变量声明。关于参数设置的标签元素有两个：<code>&lt;param&gt;</code>和<code>&lt;arg&gt;</code>，一个代表parameter，另一个代表argument。这两个标签元素翻译成中文都是“参数”的意思，但是这两个“参数”的意义是完全不同的。</p><h3 id="2-1-lt-param-gt"><a href="#2-1-lt-param-gt" class="headerlink" title="2.1  <param>"></a>2.1  <code>&lt;param&gt;</code></h3><p>parameter是ROS系统运行中的参数，存储在参数服务器中。在launch文件中通过<param>元素加载parameter；launch文件执行后，parameter就加载到ROS的参数服务器上了。每个活跃的节点都可以通过ros：：param：：get()接口来获取parameter的值，用户也可以在终端中通过rosparam命令获得parameter的值。<br><code>&lt;param&gt;</code>的使用方法如下：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>output_frame<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>odom<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>运行launch文件后，output_frame这个parameter的值就设置为odom，并且加载到ROS参数服务器上了。但是在很多复杂的系统中参数的数量很多，如果这样一个一个地设置会非常麻烦，ROS也为我们提供了另外一种类似的参数（<code>&lt;rosparam&gt;</code>）加载方式：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>rosparam</span>  <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(find  2dnav_pr2)/config/costmap_common_params.yaml<span class="token punctuation">"</span></span>  <span class="token attr-name">command</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>load<span class="token punctuation">"</span></span>  <span class="token attr-name">ns</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>local_costmap<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>&lt;rosparam&gt;</code>可以帮助我们将一个YAML格式文件中的参数全部加载到ROS参数服务器中，需要设置command属性为“load”，还可以选择设置命名空间“ns”。</p><h3 id="2-2-lt-arg-gt"><a href="#2-2-lt-arg-gt" class="headerlink" title="2.2<arg>"></a>2.2<code>&lt;arg&gt;</code></h3><p>argument是另外一个概念，类似于launch文件内部的<code>局部变量</code>，仅限于launch文件使用，便于launch文件的重构，与ROS节点内部的实现没有关系。<br>设置argument使用<code>&lt;arg&gt;</code>标签元素，语法如下：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>arg-name<span class="token punctuation">"</span></span>  <span class="token attr-name">default</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span>  <span class="token punctuation">"</span>arg-value<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>launch文件中需要使用到argument时，可以使用如下方式调用：</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>param</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>foo<span class="token punctuation">"</span></span>  <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg  arg-name)<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span>  <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>node<span class="token punctuation">"</span></span>  <span class="token attr-name">pkg</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>package<span class="token punctuation">"</span></span>  <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>type  <span class="token punctuation">"</span></span>  <span class="token attr-name">args</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(arg  arg-name)<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="3-重映射机制"><a href="#3-重映射机制" class="headerlink" title="3　重映射机制"></a>3　重映射机制</h2><p>ROS的设计目标是提高代码的复用率，所以ROS社区中的很多功能包我们都可以拿来直接使用，而不需要关注功能包的内部实现。那么问题来了，别人的功能包的接口不一定和我们的系统兼容呀？<br>ROS提供一种重映射的机制，简单来说就是取别名，类似于C++中的别名机制，我们不需要修改别人的功能包的接口，只需要将接口名称重映射一下，取一个别名，我们的系统就认识了（接口的数据类型必须相同）。launch文件中的<code>&lt;remap&gt;</code>标签可以帮助我们实现这个重映射功能。<br>比如turtlebot的键盘控制节点发布的速度控制指令话题可能是/turtlebot/cmd_vel，但是我们自己的机器人订阅的速度控制话题是/cmd_vel，这时使用<remap>就可以轻松解决问题，将/turtlebot/cmd_vel重映射为/cmd_vel，我们的机器人就可以接收到速度控制指令了：</remap></p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>remap</span>  <span class="token attr-name">from</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/turtlebot/cmd_vel<span class="token punctuation">"</span></span>  <span class="token attr-name">to</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>/cmd_vel<span class="token punctuation">"</span></span><span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>重映射机制在ROS中的使用非常广泛，也非常重要，方法不止这一种，也可以在终端中实现重映射。</p><h2 id="4-嵌套复用"><a href="#4-嵌套复用" class="headerlink" title="4　嵌套复用"></a>4　嵌套复用</h2><p>在复杂的系统中，launch文件往往有很多，这些launch文件之间也会存在依赖关系。如果要直接复用一个已有launch文件中的内容，可以使用<code>&lt;include&gt;</code>标签包含其他launch文件，这与C语言中的include几乎是一样的。</p><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include</span>  <span class="token attr-name">file</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>$(dirname)/other.launch<span class="token punctuation">"</span></span>  <span class="token punctuation">/&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>launch是ROS框架中非常实用、灵活的功能，它类似于一种高级编程语言，可以帮助我们管理启动系统时的方方面面。在使用ROS的过程中，很多情况下我们并不需要编写大量代码，仅需要使用已有的功能包，编辑一下launch文件就可以完成很多机器人功能。<br>本节仅介绍了launch中最为常用的一些标签元素，还有更多高级的标签元素可以通过访问<a href="http://wiki.ros.org/roslaunch/XML">roslaunch/XML - ROS Wiki</a>来学习。</p><p>参考文献：</p><p>[1] ROS机器人开发实践，古月居</p>]]></content>
      
      
      <categories>
          
          <category> ROS学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ROS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无人机学习规划</title>
      <link href="/2021/10/16/wu-ren-ji-xue-xi/"/>
      <url>/2021/10/16/wu-ren-ji-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="ubuntu"><a href="#ubuntu" class="headerlink" title="ubuntu"></a>ubuntu</h2><p>这个下载一本工具书来随时查随时用就可以了，大部分时候我都是网上查指令。</p><p>推荐书籍: Linux命令行与shell脚本编程大全.第3版.pdf</p><h2 id="ROS"><a href="#ROS" class="headerlink" title="ROS"></a>ROS</h2><p>初学肯定是看古月居的</p><p>参考<a href="https://www.bilibili.com/video/BV1zt411G7Vn?from=search&amp;seid=17947951904162855689&amp;spm_id_from=333.337.0.0">【古月居】古月·ROS入门21讲 | 一学就会的ROS机器人入门教程_哔哩哔哩_bilibili</a></p><p>现在我推荐ros melodic（大部分开源兼容版本）+VSC编程</p><p>参考<a href="https://zhuanlan.zhihu.com/p/275654322">vscode开发ROS1(3)-创建第一个ROS项目 - 知乎 (zhihu.com)</a></p><h2 id="无人机入门"><a href="#无人机入门" class="headerlink" title="无人机入门"></a>无人机入门</h2><p><a href="https://www.bilibili.com/video/BV1my4y1v7yC">多旋翼飞行器设计与控制[官方原版]_哔哩哔哩_bilibili</a></p><p>上面是相当于研究基础，现在就要涉及无人机知识，北航全权组是无人机控制入门讲得最好的组，我本科毕业设计很多内容是来源于他们组。图书馆应该也有全权老师的书，尽量接过来看。</p><h2 id="阿木实验室Prometheus项目跑起来"><a href="#阿木实验室Prometheus项目跑起来" class="headerlink" title="阿木实验室Prometheus项目跑起来"></a>阿木实验室Prometheus项目跑起来</h2><p><a href="https://github.com/amov-lab/Prometheus/wiki/">Home · amov-lab/Prometheus Wiki (github.com)</a></p><p>重点学习</p><p>Demo学习 - 规划模块</p><p>Demo学习 - 规划模块</p><p>Demo学习 - SLAM模块</p><p>这里就是涉及到无人机控制、无人机轨迹优化、无人机SLAM等可以发文章的部分了，里面无人机多机等的研究价值不大了，可以跑着玩。</p><h2 id="浙大高飞组"><a href="#浙大高飞组" class="headerlink" title="浙大高飞组"></a>浙大高飞组</h2><p>这个是现在无人机届的真神，很多人都在看他，他发表了很多篇文章在IROS，ICRA等顶刊上面，而且注意所有代码都是开源的，而且大多数项目不是仿真全部都是有实践性！开发能力贼恐怖，所在在FASTlab实验室真的可以说是中国大陆无人机第一所。而高飞博士所在所就是大疆创始人汪涛所在的香港科技大学HKUST-Aerial-Robotics实验室，高飞很多文章是和大疆直接合作开发的。</p><p>高飞老师的无人机研发思路可以参考<a href="https://www.bilibili.com/video/BV1Jq4y1T7QD?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click">网课</a>，高飞老师最强的是无人机轨迹优化，其他的文章的创新也是很牛，现在也开始做多无人机的编队运动了。</p><p>高飞老师的开源项目横跨这两个所，所以都要给出。</p><h1 id="HKUST-Aerial-Robotics-Group："><a href="#HKUST-Aerial-Robotics-Group：" class="headerlink" title="HKUST Aerial Robotics Group："></a>HKUST Aerial Robotics Group：</h1><p><a href="https://github.com/HKUST-Aerial-Robotics/">HKUST Aerial Robotics Group (github.com)</a></p><h1 id="ZJU-FAST-Lab"><a href="#ZJU-FAST-Lab" class="headerlink" title="ZJU FAST Lab"></a>ZJU FAST Lab</h1><p><a href="https://github.com/ZJU-FAST-Lab/">ZJU FAST Lab (github.com)</a></p><p>高飞老师的文章都写在<a href="https://ustfei.com/">Dr. Fei Gao’s Home Page (ustfei.com)</a>，最好全部下载下来，仔细看，我最近看的是ego-planner比较多，但是高飞老师属于自成一派，一篇文章往往有很多文章的积累。</p><h2 id="无人机推荐连接"><a href="#无人机推荐连接" class="headerlink" title="无人机推荐连接"></a>无人机推荐连接</h2><p>下面是一些大组，但是了解不太多。</p><p><a href="https://www.kumarrobotics.org/">Vijay Kumar Lab (kumarrobotics.org)</a></p><p><a href="http://rpg.ifi.uzh.ch/">Robotics and Perception Group (uzh.ch)</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无人机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用PSP-CaRS框架撰写与工程相关的研究型文章</title>
      <link href="/2021/10/07/shi-yong-psp-cars-kuang-jia-zhuan-xie-yu-gong-cheng-xiang-guan-de-yan-jiu-xing-wen-zhang/"/>
      <url>/2021/10/07/shi-yong-psp-cars-kuang-jia-zhuan-xie-yu-gong-cheng-xiang-guan-de-yan-jiu-xing-wen-zhang/</url>
      
        <content type="html"><![CDATA[<h2 id="1-CaRS与PSP简介"><a href="#1-CaRS与PSP简介" class="headerlink" title="1    CaRS与PSP简介"></a>1    CaRS与PSP简介</h2><h3 id="1-1-CaRS简介"><a href="#1-1-CaRS简介" class="headerlink" title="1.1 CaRS简介"></a>1.1 CaRS简介</h3><p>CaRS全称为Create a Research Space（创造研究空间），是研究人员用来分析研究型文章（Research article，RA）引言写作的一种标准化模型。本文以2004年的CaRS模型进行介绍，其特点为gap-focused（以不足为重点）。其整体结构如下图所示。</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gv6v1vsn13j60sk0mgagv02.jpg" alt="英文原版CaRS结构"></p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1gv7120i76tj60sy0p3go402.jpg" alt="中文版CaRS结构"></p><p>但在学生将CaRs应用于引言写作中时常常出现“it was difficult for students to grasp the concept of “topic generalization of increasing specificity.”“（对学生难说，很难抓住越来越多的特殊研究对象中的共同主题的概念）的问题，其起因就在于it is abstract and thus difficult for some students to apply（这个共同主题太过抽象以至于学生很难去将其应用到具体问题。）</p><h3 id="1-2-PSP"><a href="#1-2-PSP" class="headerlink" title="1.2 PSP"></a>1.2 PSP</h3><p>一种不那么抽象因而更容易应用的方法是用一个问题和一个解决方案来描述一个人的研究，也就是问题解决方案模式（problem-solution patterns， PSP）。事实上，许多工程研究可以看作是解决问题的练习。由于问题-解决对在许多基于工程应用的研究中是自然和固有的，所以工科学生从问题解决的角度思考是很自然的，其特点是problem-focused（以问题为重点）。</p><h2 id="2-PSP-CaRS模型"><a href="#2-PSP-CaRS模型" class="headerlink" title="2 PSP-CaRS模型"></a>2 PSP-CaRS模型</h2><h3 id="2-1-PSP-CaRS结合的理论基础"><a href="#2-1-PSP-CaRS结合的理论基础" class="headerlink" title="2.1 PSP-CaRS结合的理论基础"></a>2.1 PSP-CaRS结合的理论基础</h3><p>在讨论PSP-CaRS模型之前，我们要先回答“引言撰写到底是gap-focused（以不足为重点，CaRS的特点）还是problem-focused（以问题为重点，PSP的特点）”的问题</p><p>首先，problems涉及作者认为应该解决的困难，而gap则凸显了目前研究的缺失，这两点都非常重要。</p><p>其次，进展和提出的解决方案通常是线性递增的。（Progress（对应gap-focused） and proposed solutions（对应problem-focused） are often incremental.）</p><p>举个例子，如果你家里有一面墙破了个洞，你面对的问题是怎么拿砖头放到堵上那面墙上洞的位置，然而当你一次一次通过用手搬砖头（proposed solutions，提出的解决方案）解决这个问题后，你其实也是补上了这个墙（progress，进展）。也就是说提出解决方案的过程也就是推进进展。（创造一种新的纳米材料来克服腐蚀或实现无线电力传输——经常演变成一个活跃的研究空间或领域）。</p><p>也就是说Progress与proposed solutions时常是相互关联的，所以gap-focused（以不足为重点）还是problem-focused（以问题为重点）在一篇文章中时常也是相互关联的。</p><p>所以我们应该结合PSP与CaRS来撰写引言，利用gap-focused与problem-focused的关联性使目前应该解决的问题以及目前研究的缺失都得以体现，并且通过PSP模型在工科学生群体的易用性解决利用CaRS撰写引言时主题过于抽象的问题。</p><h3 id="2-2-PSP-CaRS模型的具体结构"><a href="#2-2-PSP-CaRS模型的具体结构" class="headerlink" title="2.2 PSP-CaRS模型的具体结构"></a>2.2 PSP-CaRS模型的具体结构</h3><p>PSP-CaRS模型的具体结构如下图所示，接下来，我们介绍该模型在实际文章中的应用。</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gv6wb3h073j60i80gajvl02.jpg" alt="英文版PSP-CaRS结构"></p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1gv711no0idj60sy0rnjuc02.jpg" alt="中文版PSP-CaRS结构"></p><h3 id="2-3-PSP-CaRS模型在引言中的实际应用"><a href="#2-3-PSP-CaRS模型在引言中的实际应用" class="headerlink" title="2.3 PSP-CaRS模型在引言中的实际应用"></a>2.3 PSP-CaRS模型在引言中的实际应用</h3><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gv6wvl43sej60jz0hw7c302.jpg" alt="英文实际应用"></p><p>纳米结构(NS)金属和合金由于其高强度(或高硬度)而有望表现出高耐磨性[1-5]。<u>(SM1.1：背景描述)</u>然而，许多报道表明，与粗晶材料相比，NS材料的强度和硬度显著提高，但其磨损性能并没有改善甚至恶化[6-11]。<u>(SM1.2：问题描述)</u>这种现象可能是由于NS材料的延性较差，在滑动磨损时容易脆性断裂将材料从表面去除[6 - 9,12]。因此，在保持高强度的同时，提高塑性可以提高NS材料的耐磨性。</p><p>然而，强度和延性通常呈反比关系(即，增加强度牺牲延性，反之亦然)。幸运的是，通过在NS基体中引入粗晶粒，一些多模态结构(MMS)材料已经生产出来，在具有高强度的同时，塑性显著增强[13-14]。塑性的提高是由于粗晶粒的存在而增强应变硬化能力的结果。此外，晶粒尺寸的多模态分布，而不是均匀的晶粒尺寸分布，可能导致晶粒通过复杂的应变路径变形，这也有利于位错的储存和应变硬化[13]。这些发现表明了通过形成多模态结构来生产高耐磨NS材料的可能性。<u>(SM1.3：先前研究的解决方案评估以及描述)</u>虽然已经生产出了许多同时具有高强度和高延展性的MMS金属和合金[13-16]，但对MMS材料的磨损性能的研究却很少。<u>(SM2.1:指出现有研究的不足或增加已知内容或说明要解决的问题)</u></p><p>本研究旨在研究多模态结构对材料磨损性能的影响。<u>(SM3.1:通报当前研究内容)</u>通过强塑性变形(SPD)和后续热处理，制备了多模态层合(MML) TiZrAlV，提高了其在真空中的耐磨性。讨论了MML组织对磨损性能的影响。<u>(SM3.4+SM3.5：研究结果+研究思路)</u></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://ieeexplore.ieee.org/document/8245860">[1] Khaw L L ,  Tan W W . Establishing a Territory in the Introductions of Engineering Research Articles Using a Problem-Solution Patterns Approach[J]. IEEE Transactions on Professional Communication, 2018:1-18.</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文章写作技巧与文献阅读查找经验 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++学习路线</title>
      <link href="/2021/09/26/c-xue-xi-lu-xian/"/>
      <url>/2021/09/26/c-xue-xi-lu-xian/</url>
      
        <content type="html"><![CDATA[<p>二  基础四大件：<br>1.数据结构与算法 《大话数据结构》c/c++  ，《算法第四版》 java ，《剑指offer》<br>2.计算机网络《tcp/ip详解》<br>3.操作系统  《深入理解操作系统》<br>4.设计模式 《大话设计模式》<br>三 应用于编程<br>1.linux使用<br>《linux就该这么学》<br>2.编译和调试<br>GUN官方GCC和GDB文档<br>《debugging  with gdb 》中文版<br>《跟我一起写makefile》陈皓<br>3.linux环境编程<br>《unix环境高级编程》<br>《linux高性能服务器编程》<br>《posix多线程程序设计》</p>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献阅读</title>
      <link href="/2021/09/23/wen-xian-yue-du/"/>
      <url>/2021/09/23/wen-xian-yue-du/</url>
      
        <content type="html"><![CDATA[<h1 id="利用坚果云-pdf-expert实现文档云同步-可参考文献管理的多平台操作-Mendeley-坚果云-PDFexpert-——让iPad-pencil-成为科研生产力"><a href="#利用坚果云-pdf-expert实现文档云同步-可参考文献管理的多平台操作-Mendeley-坚果云-PDFexpert-——让iPad-pencil-成为科研生产力" class="headerlink" title="利用坚果云+pdf expert实现文档云同步,可参考文献管理的多平台操作(Mendeley +坚果云+PDFexpert) ——让iPad+pencil 成为科研生产力)"></a>利用坚果云+pdf expert实现文档云同步,可参考<a href="https://zhuanlan.zhihu.com/p/107061669">文献管理的多平台操作(Mendeley +坚果云+PDFexpert) ——让iPad+pencil 成为科研生产力)</a></h1><h1 id="使用endnote"><a href="#使用endnote" class="headerlink" title="使用endnote"></a>使用endnote</h1>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文章写作技巧与文献阅读查找经验 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python学习笔记（数据分析）</title>
      <link href="/2021/09/21/python-xue-xi-bi-ji/"/>
      <url>/2021/09/21/python-xue-xi-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="学习书籍-《利用Python进行数据分析·第2版》"><a href="#学习书籍-《利用Python进行数据分析·第2版》" class="headerlink" title="学习书籍: 《利用Python进行数据分析·第2版》"></a>学习书籍: <a href="https://www.bookstack.cn/read/pyda-2e-zh/README.md">《利用Python进行数据分析·第2版》</a></h1><h2 id="第02章-Python语法基础"><a href="#第02章-Python语法基础" class="headerlink" title="第02章 Python语法基础"></a><a href="https://www.bookstack.cn/read/pyda-2e-zh/2.md">第02章 Python语法基础</a></h2><h3 id="2-3-Python语法基础"><a href="#2-3-Python语法基础" class="headerlink" title="2.3 Python语法基础"></a><a href="https://www.bookstack.cn/read/pyda-2e-zh/2.3.md">2.3 Python语法基础</a></h3><h4 id="组织代码方式"><a href="#组织代码方式" class="headerlink" title="组织代码方式"></a>组织代码方式</h4><p><em>Python使用空白字符（tab和空格）来组织代码，而不是通过括号（）</em></p><p>例子：排序算法的for循环</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">for x in array</span><span class="token punctuation">:</span>    <span class="token key atrule">if x &lt; pivot</span><span class="token punctuation">:</span>        less.append(x)    <span class="token key atrule">else</span><span class="token punctuation">:</span>        greater.append(x)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><em>Python的语句不需要用分号结尾。但是，分号却可以用来给同在一行的语句切分</em></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">a = 5; b = 6; c = 7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="万物皆对象"><a href="#万物皆对象" class="headerlink" title="万物皆对象"></a>万物皆对象</h4><p>Python语言的一个重要特性就是它的对象模型的一致性。每个数字、字符串、数据结构、函数、类、模块等等，都是在Python解释器的自有“盒子”内，它被认为是Python对象。每个对象都有类型（例如，字符串或函数）和内部数据。在实际中，这可以让语言非常灵活，因为函数也可以被当做对象使用。</p><p><em>注释标记为#</em></p><p>例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">results = <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token key atrule">for line in file_handle</span><span class="token punctuation">:</span>    <span class="token comment"># keep the empty lines for now</span>    <span class="token comment"># if len(line) == 0:</span>    <span class="token comment">#   continue</span>    results.append(line.replace('foo'<span class="token punctuation">,</span> 'bar'))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="变量与参数传递"><a href="#变量与参数传递" class="headerlink" title="变量与参数传递"></a>变量与参数传递</h4><p>创建一个整数列表：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a = <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>假设将a赋值给一个新变量b：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b = a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在Python中，a和b实际上是同一个对象，即原有列表[1, 2, 3]。你可以在a中添加一个元素，然后检查b：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a.append(4)In <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bOut<span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p></p><h4 id="python是强类型化语言"><a href="#python是强类型化语言" class="headerlink" title="python是强类型化语言"></a>python是强类型化语言</h4><p><em>python是强类型化语言，意味着每个对象都有明确的类型（或类）（str型不能与int型相加），默许转换只会发生在特定的情况下（float型能与int型相加）</em><br>例子1：str型不能与int型相加<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">:</span> '5' + 5<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>TypeError                                 Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>16<span class="token punctuation">-</span>f9dbf5f0b234<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 '5' + 5<span class="token key atrule">TypeError</span><span class="token punctuation">:</span> must be str<span class="token punctuation">,</span> not int<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>例子2：loat型能与int型相加<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a = 4.5In <span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b = 2<span class="token comment"># String formatting, to be visited later</span>In <span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">:</span> print('a is <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">,</span> b is <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span>'.format(type(a)<span class="token punctuation">,</span> type(b)))a is &lt;class 'float'<span class="token punctuation">&gt;</span><span class="token punctuation">,</span> b is &lt;class 'int'<span class="token punctuation">&gt;</span>In <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a / bOut<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">2.25</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p><strong><em>isinstance</em></strong>函数 : 检查对象是某个类型的实例,可以用类型元组，检查对象的类型是否在元组中</p><p><em>Python的对象通常都有属性（其它存储在对象内部的Python对象）和方法（对象的附属函数可以访问对象的内部数据）</em></p><h4 id="可迭代对象"><a href="#可迭代对象" class="headerlink" title="可迭代对象"></a>可迭代对象</h4><p><strong>Iterable object（可迭代对象）</strong><br>可迭代（Iterable） 对象是数组的泛化。这个概念是说任何对象都可以被定制为可在 for..of 循环中使用的对象。</p><p>数组是可迭代的。但不仅仅是数组。很多其他内建对象也都是可迭代的。例如字符串也是可迭代的。</p><p>如果从技术上讲，对象不是数组，而是表示某物的集合（列表，集合），for..of 是一个能够遍历它的很好的语法</p><p><strong><em>iter</em></strong>函数 : 判断对象是否是可迭代的</p><p>可定义<strong><em>isiterable</em></strong>函数<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def isiterable(obj)</span><span class="token punctuation">:</span>    <span class="token key atrule">try</span><span class="token punctuation">:</span>        iter(obj)        return True    <span class="token key atrule">except TypeError</span><span class="token punctuation">:</span> <span class="token comment"># not iterable</span>        return False<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><strong><em>isiterable</em></strong>函数 ：返回字符串以及大多数Python集合类型为True<p></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">:</span> isiterable('a string')Out<span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>In <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">:</span> isiterable(<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>In <span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> isiterable(5)Out<span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="引入模块"><a href="#引入模块" class="headerlink" title="引入模块"></a>引入模块</h4><p>在Python中，模块就是一个有.py扩展名、包含Python代码的文件。假设有以下模块：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># some_module.py</span>PI = 3.14159<span class="token key atrule">def f(x)</span><span class="token punctuation">:</span>    return x + 2def g(a<span class="token punctuation">,</span> <span class="token key atrule">b)</span><span class="token punctuation">:</span>    return a + b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>如果想从同目录下的另一个文件访问<em>some_module.py</em>中定义的变量和函数，可以：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">import some_moduleresult = some_module.f(5)pi = some_module.PI<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>或</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">from some_module import f<span class="token punctuation">,</span> g<span class="token punctuation">,</span> PIresult = g(5<span class="token punctuation">,</span> PI)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>使用as关键词，你可以给引入起不同的变量名：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">import some_module as smfrom some_module import PI as pi<span class="token punctuation">,</span> g as gfr1 = sm.f(pi)r2 = gf(6<span class="token punctuation">,</span> pi)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="二元运算符和比较运算符"><a href="#二元运算符和比较运算符" class="headerlink" title="二元运算符和比较运算符"></a>二元运算符和比较运算符</h4><p><em>要判断两个引用是否指向同一个对象，可以使用**</em>is<strong><em>方法。</em></strong>is not<strong><em>方法可以判断两个对象是不同的（因为</em></strong>list<em>**总是创建一个新的Python列表（即复制），我们可以断定c是不同于a的。使用is比较与==运算符不同，如下）：</em></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a = <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b = aIn <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span><span class="token punctuation">:</span> c = list(a)In <span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a is bOut<span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>In <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a is not cOut<span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>In <span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a == cOut<span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1gum94jxbkuj60mj0elqao02.jpg" alt="二元运算符和比较运算符"></p><h4 id="可变与不可变对象"><a href="#可变与不可变对象" class="headerlink" title="可变与不可变对象"></a>可变与不可变对象</h4><p><em>Python中的大多数对象(列表、字典、NumPy数组，和用户定义的类型（类）)都是可变对象），即这些对象或包含的值可以被修改，而字符串和元组为不可变对象</em></p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1gumtsu38qdj60mg068n0l02.jpg" alt="标量类型"></p><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment">#单引号或双引号来写字符串</span>a ='one way of writing a string'b ="another way"<span class="token comment">#对于有换行符的字符串，可以使用三引号，’’’或”””写字符串</span>    c ="""    This is a longer string that    spans multiple lines    """<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Python的字符串是不可变的，不能修改字符串</p><p>str函数：可以被转化为字符串</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a =5.6In<span class="token punctuation">[</span><span class="token number">62</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s = str(a)In<span class="token punctuation">[</span><span class="token number">63</span><span class="token punctuation">]</span><span class="token punctuation">:</span>print(s)5.6<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>字符串是一个序列的Unicode字符，因此可以像其它序列，比如列表和元组一样处理：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s ='python'In<span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(s)Out<span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token string">'p'</span><span class="token punctuation">,</span><span class="token string">'y'</span><span class="token punctuation">,</span><span class="token string">'t'</span><span class="token punctuation">,</span><span class="token string">'h'</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">,</span><span class="token string">'n'</span><span class="token punctuation">]</span>In<span class="token punctuation">[</span><span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token string">'pyt'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>语法s[:3]被称作切片，适用于许多Python序列。</p><p><em>反斜杠是转义字符</em></p><p>意思是它备用来表示特殊字符，比如换行符\n或Unicode字符。要写一个包含反斜杠的字符串，需要进行转义：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s ='12\\34'In<span class="token punctuation">[</span><span class="token number">68</span><span class="token punctuation">]</span><span class="token punctuation">:</span>print(s)12\34<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p></p><p><em>可以在字符串前面加一个r(代表raw)，表明字符就是它自身</em></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a ='this is the first half 'In<span class="token punctuation">[</span><span class="token number">72</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b ='and this is the second half'In<span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a + bOut<span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token string">'this is the first half and this is the second half'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>字符串对象有format方法，可以替换格式化的参数为字符串，产生一个新的字符串：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">]</span><span class="token punctuation">:</span> template ='<span class="token punctuation">{</span>0<span class="token punctuation">:</span>.2f<span class="token punctuation">}</span> <span class="token punctuation">{</span>1<span class="token punctuation">:</span>s<span class="token punctuation">}</span> are worth US$<span class="token punctuation">{</span>2<span class="token punctuation">:</span>d<span class="token punctuation">}</span>'<span class="token comment">#{0:.2f}表示格式化第一个参数为带有两位小数的浮点数。</span><span class="token comment">#{1:s}表示格式化第二个参数为字符串。</span><span class="token comment">#{2:d}表示格式化第三个参数为一个整数。</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>要替换参数为这些格式化的参数，我们传递format方法一个序列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">:</span> template.format(4.5560<span class="token punctuation">,</span><span class="token string">'Argentine Pesos'</span><span class="token punctuation">,</span>1)Out<span class="token punctuation">[</span><span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token string">'4.56 Argentine Pesos are worth US$1'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="字节和Unicode"><a href="#字节和Unicode" class="headerlink" title="字节和Unicode"></a>字节和Unicode</h4><p>在Python 3及以上版本中，Unicode是一级的字符串类型，这样可以更一致的处理ASCII和Non-ASCII文本。在老的Python版本中，字符串都是字节，不使用Unicode编码。<br>相关函数：<strong><em>encode</em></strong> <strong><em>decode</em></strong></p><h4 id="布尔值"><a href="#布尔值" class="headerlink" title="布尔值"></a>布尔值</h4><p>Python中的布尔值有两个，True和False</p><h4 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h4><p>str、bool、int和float也是函数，可以用来转换类型：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">91</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s ='3.14159'In<span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">]</span><span class="token punctuation">:</span> fval = float(s)In<span class="token punctuation">[</span><span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">:</span> type(fval)Out<span class="token punctuation">[</span><span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">:</span> floatIn<span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span> int(fval)Out<span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token number">3</span>In<span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bool(fval)Out<span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token boolean important">True</span>In<span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bool(0)Out<span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token boolean important">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="None"><a href="#None" class="headerlink" title="None"></a>None</h4><p>None是Python的空值类型。如果一个函数没有明确的返回值，就会默认返回None：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">97</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a =NoneIn<span class="token punctuation">[</span><span class="token number">98</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a isNoneOut<span class="token punctuation">[</span><span class="token number">98</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token boolean important">True</span>In<span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b =5In<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b isnotNoneOut<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token boolean important">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>None也常常作为函数的默认参数</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">def add_and_maybe_multiply(a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> <span class="token key atrule">c=None)</span><span class="token punctuation">:</span>    result = a + b<span class="token key atrule">if c isnotNone</span><span class="token punctuation">:</span>        result = result * creturn result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另外，None不仅是一个保留字，还是唯一的NoneType的实例：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">:</span> type(None)Out<span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">:</span>NoneType<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="日期和时间"><a href="#日期和时间" class="headerlink" title="日期和时间"></a>日期和时间</h4><p>Python内建的datetime模块提供了datetime、date和time类型。datetime类型结合了date和time，是最常使用的：</p><p>Python内建的datetime模块提供了datetime、date和time类型。datetime类型结合了date和time，是最常使用的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">:</span>from datetime import datetime<span class="token punctuation">,</span> date<span class="token punctuation">,</span> timeIn<span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt = datetime(2011<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">29</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span>21)In<span class="token punctuation">[</span><span class="token number">104</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt.dayOut<span class="token punctuation">[</span><span class="token number">104</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token number">29</span>In<span class="token punctuation">[</span><span class="token number">105</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt.minuteOut<span class="token punctuation">[</span><span class="token number">105</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token number">30</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>根据datetime实例，你可以用date和time提取出各自的对象：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt.date()Out<span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.date(2011<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>29)In<span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt.time()Out<span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.time(20<span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span>21)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>strftime方法可以将datetime格式化为字符串：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">108</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt.strftime('%m/%d/%Y %H<span class="token punctuation">:</span>%M')Out<span class="token punctuation">[</span><span class="token number">108</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token string">'10/29/2011 20:30'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p></p><p>strptime可以将字符串转换成datetime对象：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.strptime('20091031'<span class="token punctuation">,</span>'%Y%m%d')Out<span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.datetime(2009<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">31</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span>0)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p></p><p><img src="https://tva3.sinaimg.cn/large/007mx13gly1gun84pnb4aj60j80b178b02.jpg" alt="格式化指令"></p><p><u>聚类或对时间序列进行分组</u>，替换datetimes的time字段有时会很有用。例如，用0替换分和秒：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">110</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt.replace(minute=0<span class="token punctuation">,</span> second=0)Out<span class="token punctuation">[</span><span class="token number">110</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.datetime(2011<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">29</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span>0)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>因为datetime.datetime是不可变类型，上面的方法会产生新的对象。</p><p>两个datetime对象的差会产生一个datetime.timedelta类型：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">111</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt2 = datetime(2011<span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span>30)In<span class="token punctuation">[</span><span class="token number">112</span><span class="token punctuation">]</span><span class="token punctuation">:</span> delta = dt2 <span class="token punctuation">-</span> dtIn<span class="token punctuation">[</span><span class="token number">113</span><span class="token punctuation">]</span><span class="token punctuation">:</span> deltaOut<span class="token punctuation">[</span><span class="token number">113</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.timedelta(17<span class="token punctuation">,</span>7179)In<span class="token punctuation">[</span><span class="token number">114</span><span class="token punctuation">]</span><span class="token punctuation">:</span> type(delta)Out<span class="token punctuation">[</span><span class="token number">114</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.timedelta<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果timedelta(17, 7179)指明了timedelta将17天、7179秒的编码方式。</p><p>将timedelta添加到datetime，会产生一个新的偏移datetime：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">115</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtOut<span class="token punctuation">[</span><span class="token number">115</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.datetime(2011<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">29</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span>21)In<span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dt + deltaOut<span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> datetime.datetime(2011<span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span>30)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="控制流"><a href="#控制流" class="headerlink" title="控制流"></a><strong>控制流</strong></h4><p>Python有若干内建的关键字进行条件逻辑、循环和其它控制流操作。<br>if、elif和else</p><h5 id="if"><a href="#if" class="headerlink" title="if"></a><em>if</em></h5><p>if是最广为人知的控制流语句。它检查一个条件，如果为True，就执行后面的语句：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">if x &lt;0</span><span class="token punctuation">:</span>print('It's negative')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>if后面可以跟一个或多个elif，所有条件都是False时，还可以添加一个else：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">if x &lt;0</span><span class="token punctuation">:</span>print('It's negative')<span class="token key atrule">elif x == 0</span><span class="token punctuation">:</span>    print('Equal to zero')<span class="token key atrule">elif 0 &lt; x &lt; 5</span><span class="token punctuation">:</span>    print('Positive but smaller than 5')<span class="token key atrule">else</span><span class="token punctuation">:</span>    print('Positiveand larger than or equal to 5')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>如果某个条件为True，后面的elif就不会被执行。当使用and和or时，复合条件语句是从左到右执行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">117</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a =5; b =7In<span class="token punctuation">[</span><span class="token number">118</span><span class="token punctuation">]</span><span class="token punctuation">:</span> c =8; d =4In<span class="token punctuation">[</span><span class="token number">119</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token key atrule">if a &lt; b or c &gt; d</span><span class="token punctuation">:</span><span class="token punctuation">...</span>..<span class="token punctuation">:</span>print('Made it')Made it<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个例子中，c &gt; d不会被执行，因为第一个比较是True：</p><p>也可以把比较式串在一起：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span>4<span class="token punctuation">&gt;</span>3<span class="token punctuation">&gt;</span>2<span class="token punctuation">&gt;</span>1Out<span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token boolean important">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p></p><h5 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a><em>for循环</em></h5><p>for循环是在一个集合（列表或元组）中进行迭代，或者就是一个迭代器。for循环的标准语法是：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">for value in collection</span><span class="token punctuation">:</span><span class="token comment"># do something with value</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p></p><p>你可以用continue使for循环提前，跳过剩下的部分。看下面这个例子，将一个列表中的整数相加，跳过None：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">sequence =<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>None<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>None<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>total =0<span class="token key atrule">for value in sequence</span><span class="token punctuation">:</span><span class="token key atrule">if value isNone</span><span class="token punctuation">:</span>continue    total += value<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>可以用break跳出for循环。下面的代码将各元素相加，直到遇到5：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">sequence =<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>total_until_5 =0<span class="token key atrule">for value in sequence</span><span class="token punctuation">:</span><span class="token key atrule">if value ==5</span><span class="token punctuation">:</span>break    total_until_5 += value<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>break只中断for循环的最内层，其余的for循环仍会运行：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token key atrule">for i in range(4)</span><span class="token punctuation">:</span><span class="token key atrule">.....:for j in range(4)</span><span class="token punctuation">:</span><span class="token key atrule">.....:if j &gt; i</span><span class="token punctuation">:</span><span class="token punctuation">...</span>..<span class="token punctuation">:</span>break<span class="token punctuation">...</span>..<span class="token punctuation">:</span>print((i<span class="token punctuation">,</span> j))<span class="token key atrule">.....</span><span class="token punctuation">:</span>(0<span class="token punctuation">,</span>0)(1<span class="token punctuation">,</span>0)(1<span class="token punctuation">,</span>1)(2<span class="token punctuation">,</span>0)(2<span class="token punctuation">,</span>1)(2<span class="token punctuation">,</span>2)(3<span class="token punctuation">,</span>0)(3<span class="token punctuation">,</span>1)(3<span class="token punctuation">,</span>2)(3<span class="token punctuation">,</span>3)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>如果集合或迭代器中的元素序列（元组或列表），可以用for循环将其方便地拆分成变量：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">for a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> <span class="token key atrule">c in iterator</span><span class="token punctuation">:</span><span class="token comment"># do something</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p></p><h5 id="While循环"><a href="#While循环" class="headerlink" title="While循环"></a><em>While循环</em></h5><p>while循环指定了条件和代码，当条件为False或用break退出循环，代码才会退出：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">x =256total =0<span class="token key atrule">while x &gt;0</span><span class="token punctuation">:</span><span class="token key atrule">if total &gt;500</span><span class="token punctuation">:</span>break    total += x    x = x //2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><h5 id="pass非操作语句"><a href="#pass非操作语句" class="headerlink" title="pass非操作语句"></a><em>pass非操作语句</em></h5><p>pass是Python中的非操作语句。代码块不需要任何动作时可以使用（作为未执行代码的占位符）；因为Python需要使用空白字符划定代码块，所以需要pass：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">if x &lt;0</span><span class="token punctuation">:</span>print('negative<span class="token tag">!')</span><span class="token key atrule">elif x ==0</span><span class="token punctuation">:</span><span class="token comment"># TODO: put something smart here</span>pass<span class="token key atrule">else</span><span class="token punctuation">:</span>print('positive<span class="token tag">!')</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><h5 id="range函数"><a href="#range函数" class="headerlink" title="range函数"></a><em>range函数</em></h5><p>range函数返回一个迭代器，它产生一个均匀分布的整数序列：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">122</span><span class="token punctuation">]</span><span class="token punctuation">:</span> range(10)Out<span class="token punctuation">[</span><span class="token number">122</span><span class="token punctuation">]</span><span class="token punctuation">:</span> range(0<span class="token punctuation">,</span>10)In<span class="token punctuation">[</span><span class="token number">123</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(range(10))Out<span class="token punctuation">[</span><span class="token number">123</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>range的三个参数是（起点，终点，步进）：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(range(0<span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span>2))Out<span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">]</span>In<span class="token punctuation">[</span><span class="token number">125</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(range(5<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">-</span>1))Out<span class="token punctuation">[</span><span class="token number">125</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>可以看到，<u>range产生的整数不包括终点</u>。range的常见用法是用序号迭代序列：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">seq =<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token key atrule">for i in range(len(seq))</span><span class="token punctuation">:</span>    val = seq<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>可以使用list来存储range在其他数据结构中生成的所有整数，默认的迭代器形式通常是你想要的。下面的代码对0到99999中3或5的倍数求和：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">sum =0<span class="token key atrule">for i in range(100000)</span><span class="token punctuation">:</span><span class="token comment"># % is the modulo operator</span><span class="token key atrule">if i %3==0or i %5==0</span><span class="token punctuation">:</span>        sum += i<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>虽然range可以产生任意大的数，但任意时刻耗用的内存却很小。<br>三元表达式</p><h4 id="三元表达式"><a href="#三元表达式" class="headerlink" title="三元表达式"></a>三元表达式</h4><p>Python中的三元表达式可以将if-else语句放到一行里。语法如下：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">value = true<span class="token punctuation">-</span>expr if condition else false<span class="token punctuation">-</span>expr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p></p><p>true-expr或false-expr可以是任何Python代码。它和下面的代码效果相同：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">if condition</span><span class="token punctuation">:</span>    value = true<span class="token punctuation">-</span>expr<span class="token key atrule">else</span><span class="token punctuation">:</span>    value = false<span class="token punctuation">-</span>expr<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>下面是一个更具体的例子：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In<span class="token punctuation">[</span><span class="token number">126</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x =5In<span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span>'Non<span class="token punctuation">-</span>negative'if x <span class="token punctuation">&gt;</span>=0else'Negative'Out<span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token string">'Non-negative'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>和if-else一样，只有一个表达式会被执行。因此，三元表达式中的if和else可以包含大量的计算，但只有True的分支会被执行。因此，三元表达式中的if和else可以包含大量的计算，但只有True的分支会被执行。<p></p><p>虽然使用三元表达式可以压缩代码，但会降低<u>代码可读性</u>。</p><h2 id="第03章-Python的数据结构、函数和文件"><a href="#第03章-Python的数据结构、函数和文件" class="headerlink" title="第03章 Python的数据结构、函数和文件"></a><a href="https://www.bookstack.cn/read/pyda-2e-zh/3.md">第03章 Python的数据结构、函数和文件</a></h2><h3 id="3-1-数据结构和序列"><a href="#3-1-数据结构和序列" class="headerlink" title="3.1 数据结构和序列"></a><a href="https://www.bookstack.cn/read/pyda-2e-zh/3.1.md">3.1 数据结构和序列</a></h3><h4 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h4><p>元组是<u>一个固定长度，不可改变的Python序列对象</u>。创建元组的最简单方式，是用<u>逗号分隔一列值</u>：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup = 4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span>In <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tupOut<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> 6)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>当用复杂的表达式定义元组，最好将值放到<u>圆括号</u>内，如下所示：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">:</span> nested_tup = (4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> 6)<span class="token punctuation">,</span> (7<span class="token punctuation">,</span> 8)In <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span> nested_tupOut<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ((4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> 6)<span class="token punctuation">,</span> (7<span class="token punctuation">,</span> 8))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>用<u>tuple可以将任意序列或迭代器</u>转换成元组：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tuple(<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (4<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> 2)In <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup = tuple('string')In <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tupOut<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ('s'<span class="token punctuation">,</span> <span class="token string">'t'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token string">'n'</span><span class="token punctuation">,</span> 'g')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>可以用方括号访问元组中的元素。和C、C++、JAVA等语言一样，<u>序列是从0开始的</u>：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'s'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>元组中存储的对象可能是可变对象。<u>一旦创建了元组，元组中的对象就不能修改了</u>：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup = tuple(<span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean important">True</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> = False<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>TypeError                                 Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>10<span class="token punctuation">-</span>c7308343b841<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 tup<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> = False<span class="token key atrule">TypeError</span><span class="token punctuation">:</span> 'tuple' object does not support item assignment<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br><u>如果元组中的某个对象是可变的，比如列表，可以在原位进行修改</u>：<p></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>.append(3)In <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tupOut<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ('foo'<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以用<u>加号运算符将元组串联起来</u>：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (4<span class="token punctuation">,</span> None<span class="token punctuation">,</span> 'foo') + (6<span class="token punctuation">,</span> 0) + ('bar'<span class="token punctuation">,</span>)Out<span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (4<span class="token punctuation">,</span> None<span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> 'bar')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>元组乘以一个整数，像列表一样，会将几个元组的复制串联起来：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ('foo'<span class="token punctuation">,</span> 'bar') * 4Out<span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ('foo'<span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> 'bar')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br><u>对象本身并没有被复制，只是引用了它</u>。<p></p><h5 id="拆分元组"><a href="#拆分元组" class="headerlink" title="拆分元组"></a>拆分元组</h5><p>如果你想将元组赋值给类似元组的变量，<u>Python会试图拆分等号右边的值</u>：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup = (4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> 6)In <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c = tupIn <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bOut<span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>即使含有元组的元组也会被拆分：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup = 4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> (6<span class="token punctuation">,</span> 7)In <span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> (c<span class="token punctuation">,</span> d) = tupIn <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dOut<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">7</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>使用这个功能，你可以很容易地替换变量的名字，其它语言可能是这样：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">tmp = aa = bb = tmp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>但是在<u>Python中，替换</u>可以这样做：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a<span class="token punctuation">,</span> b = 1<span class="token punctuation">,</span> <span class="token number">2</span>In <span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">:</span> aOut<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">1</span>In <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bOut<span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">2</span>In <span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b<span class="token punctuation">,</span> a = a<span class="token punctuation">,</span> bIn <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">:</span> aOut<span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">2</span>In <span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bOut<span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>变量拆分常用来迭代元组或列表序列：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq = <span class="token punctuation">[</span>(1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> (4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> 6)<span class="token punctuation">,</span> (7<span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> 9)<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">:</span> for a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> <span class="token key atrule">c in seq</span><span class="token punctuation">:</span><span class="token key atrule">....</span><span class="token punctuation">:</span>     print('a=<span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">,</span> b=<span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span> c=<span class="token punctuation">{</span><span class="token number">2</span><span class="token punctuation">}</span>'.format(a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c))a=1<span class="token punctuation">,</span> b=2<span class="token punctuation">,</span> c=3a=4<span class="token punctuation">,</span> b=5<span class="token punctuation">,</span> c=6a=7<span class="token punctuation">,</span> b=8<span class="token punctuation">,</span> c=9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>format的用法参考<a href="https://www.cnblogs.com/lovejh/p/9201219.html">python格式化输出之format用法</a><p></p><p>format基本用法参考<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span> print('<span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>'.format('hello'<span class="token punctuation">,</span>'world'))  <span class="token comment"># 不带字段</span>hello world<span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span> print('<span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span>'.format('hello'<span class="token punctuation">,</span>'world'))  <span class="token comment"># 带数字编号</span>hello world<span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span> print('<span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span>'.format('hello'<span class="token punctuation">,</span>'world'))  <span class="token comment"># 打乱顺序</span>hello world hello<span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span> print('<span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span>'.format('hello'<span class="token punctuation">,</span>'world'))world world hello<span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span> print('<span class="token punctuation">{</span>a<span class="token punctuation">}</span> <span class="token punctuation">{</span>tom<span class="token punctuation">}</span> <span class="token punctuation">{</span>a<span class="token punctuation">}</span>'.format(tom='hello'<span class="token punctuation">,</span>a='world'))  <span class="token comment"># 带关键字</span>world hello world<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>另一个常见用法是从函数返回多个值。后面会详解。</p><p>Python最近新增了更多高级的元组拆分功能，允许从元组的开头“摘取”几个元素。它使用了特殊的语法*rest，这也用在函数签名中以抓取任意长度列表的位置参数：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">:</span> values = 1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span>In <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> <span class="token important">*rest</span> = valuesIn <span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a<span class="token punctuation">,</span> bOut<span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (1<span class="token punctuation">,</span> 2)In <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">:</span> restOut<span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>rest的部分是想要舍弃的部分，rest的名字不重要。作为惯用写法，<u>许多Python程序员会将不需要的变量使用下划线</u>：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> <span class="token important">*_</span> = values<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p></p><h5 id="tuple方法"><a href="#tuple方法" class="headerlink" title="tuple方法"></a>tuple方法</h5><p>因为元组的大小和内容不能修改，它的实例方法都很轻量。其中一个很有用的就是count（也适用于列表），它可以统计某个值得出现频率：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">34</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a = (1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> 2)In <span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a.count(2)Out<span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p></p><h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>与元组对比(括号定义，不能修改)，<u>列表的长度可变、内容可以被修改。你可以用方括号定义，或用list函数</u>：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a_list = <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> None<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span><span class="token punctuation">:</span> tup = ('foo'<span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> 'baz')In <span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_list = list(tup)In <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_listOut<span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> = 'peekaboo'In <span class="token punctuation">[</span><span class="token number">41</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_listOut<span class="token punctuation">[</span><span class="token number">41</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'peekaboo'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>列表和元组的语义接近，在许多函数中可以交叉使用。<p></p><p>list函数常用来<u>在数据处理中实体化迭代器或生成器</u>：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">:</span> gen = range(10)In <span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span> genOut<span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span> range(0<span class="token punctuation">,</span> 10)In <span class="token punctuation">[</span><span class="token number">44</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(gen)Out<span class="token punctuation">[</span><span class="token number">44</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><h5 id="添加和删除元素"><a href="#添加和删除元素" class="headerlink" title="添加和删除元素"></a>添加和删除元素</h5><p>可以用<u>append</u>在列表末尾添加元素：<br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_list.append('dwarf')In <span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_listOut<span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'peekaboo'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">,</span> <span class="token string">'dwarf'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br><u>insert</u>可以在特定的位置插入元素：<br><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_list.insert(1<span class="token punctuation">,</span> 'red')In <span class="token punctuation">[</span><span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_listOut<span class="token punctuation">[</span><span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'peekaboo'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">,</span> <span class="token string">'dwarf'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><br>插入的序号必须在0和列表长度之间。<p></p><blockquote><p>警告：与append相比，insert耗费的计算量大，因为对后续元素的引用必须在内部迁移，以便为新元素提供空间。如果要在序列的头部和尾部插入元素，你可能需要使用collections.deque，一个双尾部队列。</p></blockquote><p>insert的逆运算是<u>pop</u>，它移除并返回指定位置的元素：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">49</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_list.pop(2)Out<span class="token punctuation">[</span><span class="token number">49</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'peekaboo'</span>In <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_listOut<span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">,</span> <span class="token string">'dwarf'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可以用remove去除某个值，remove会先寻找第一个值并除去：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_list.append('foo')In <span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_listOut<span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">,</span> <span class="token string">'dwarf'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">53</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_list.remove('foo')In <span class="token punctuation">[</span><span class="token number">54</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b_listOut<span class="token punctuation">[</span><span class="token number">54</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">,</span> <span class="token string">'dwarf'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果不考虑性能，使用<u>append和remove</u>，可以把Python的列表当做完美的“多重集”数据结构。</p><p>用in可以检查列表是否包含某个值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 'dwarf' in b_listOut<span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>否定in可以再加一个not：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">56</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 'dwarf' not in b_listOut<span class="token punctuation">[</span><span class="token number">56</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在列表中检查是否存在某个值远比字典和集合速度慢，因为Python是线性搜索列表中的值，但在字典和集合中，在同样的时间内还可以检查其它项（基于哈希表）。</p><h5 id="串联和组合列表"><a href="#串联和组合列表" class="headerlink" title="串联和组合列表"></a>串联和组合列表</h5><p>与元组类似，可以用加号将两个列表串联起来：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">57</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> None<span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span> + <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> (2<span class="token punctuation">,</span> 3)<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">57</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> None<span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> (2<span class="token punctuation">,</span> 3)<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果已经定义了一个列表，用extend方法可以追加多个元素：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">58</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x = <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> None<span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">59</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x.extend(<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> (2<span class="token punctuation">,</span> 3)<span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">:</span> xOut<span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> None<span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> (2<span class="token punctuation">,</span> 3)<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>通过加法将列表串联的计算量较大，因为要新建一个列表，并且要复制对象。用extend追加元素，尤其是到一个大列表中，更为可取。因此：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">everything = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token key atrule">for chunk in list_of_lists</span><span class="token punctuation">:</span>    everything.extend(chunk)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>要比串联方法快：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">everything = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token key atrule">for chunk in list_of_lists</span><span class="token punctuation">:</span>    everything = everything + chunk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h5><p>你可以用<u>sort函数</u>将一个列表原地排序（不创建新的对象）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a = <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">62</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a.sort()In <span class="token punctuation">[</span><span class="token number">63</span><span class="token punctuation">]</span><span class="token punctuation">:</span> aOut<span class="token punctuation">[</span><span class="token number">63</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>sort有一些选项，有时会很好用。其中之一是<u>二级排序key</u>，可以用这个key进行排序。例如，我们可以按长度对字符串进行排序：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b = <span class="token punctuation">[</span><span class="token string">'saw'</span><span class="token punctuation">,</span> <span class="token string">'small'</span><span class="token punctuation">,</span> <span class="token string">'He'</span><span class="token punctuation">,</span> <span class="token string">'foxes'</span><span class="token punctuation">,</span> <span class="token string">'six'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b.sort(key=len)In <span class="token punctuation">[</span><span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bOut<span class="token punctuation">[</span><span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'He'</span><span class="token punctuation">,</span> <span class="token string">'saw'</span><span class="token punctuation">,</span> <span class="token string">'six'</span><span class="token punctuation">,</span> <span class="token string">'small'</span><span class="token punctuation">,</span> <span class="token string">'foxes'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>稍后，我们会学习sorted函数，它可以产生一个排好序的序列副本。</p><h5 id="二分搜索和维护已排序的列表"><a href="#二分搜索和维护已排序的列表" class="headerlink" title="二分搜索和维护已排序的列表"></a>二分搜索和维护已排序的列表</h5><p><u>bisect模块支持二分查找</u>，和向已排序的列表插入值。bisect.bisect可以找到插入值后仍保证排序的位置，bisect.insort是向这个位置插入值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">:</span> import bisectIn <span class="token punctuation">[</span><span class="token number">68</span><span class="token punctuation">]</span><span class="token punctuation">:</span> c = <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bisect.bisect(c<span class="token punctuation">,</span> 2)Out<span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">4</span>In <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bisect.bisect(c<span class="token punctuation">,</span> 5)Out<span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">6</span>In <span class="token punctuation">[</span><span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bisect.insort(c<span class="token punctuation">,</span> 6)In <span class="token punctuation">[</span><span class="token number">72</span><span class="token punctuation">]</span><span class="token punctuation">:</span> cOut<span class="token punctuation">[</span><span class="token number">72</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>注意：bisect模块不会检查列表是否已排好序，进行检查的话会耗费大量计算。因此，对未排序的列表使用bisect不会产生错误，但结果不一定正确。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h5><p>用切边可以选取大多数序列类型的一部分，<u>切片的基本形式是在方括号中使用start:stop</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq = <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq<span class="token punctuation">[</span>1<span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>切片也可以被序列赋值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq<span class="token punctuation">[</span>3<span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span> = <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seqOut<span class="token punctuation">[</span><span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>切片的起始元素是包括的，<u>不包含结束元素</u>。因此，结果中包含的<u>元素个数是stop - start</u>。</p><p><u>start或stop都可以被省略，省略之后，分别默认序列的开头和结尾</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">77</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">77</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">78</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq<span class="token punctuation">[</span>3<span class="token punctuation">:</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">78</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><u>负数表明从后向前切片</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">79</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq<span class="token punctuation">[</span><span class="token punctuation">-</span>4<span class="token punctuation">:</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">79</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq<span class="token punctuation">[</span><span class="token punctuation">-</span>6<span class="token punctuation">:</span><span class="token number">-2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>需要一段时间来熟悉使用切片，尤其是当你之前学的是R或MATLAB。下图展示了正整数和负整数的切片。在图中，指数标示在边缘以表明切片是在哪里开始哪里结束的。</p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1guo30xjryij60yg0eswir02.jpg" alt="Python切片演示"></p><p>在<u>第二个冒号</u>后面使用<u>step</u>，可以隔一个取一个元素：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">81</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">81</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>一个聪明的方法是<u>使用-1，它可以将列表或元组颠倒过来</u>：</p><pre><code>In [82]: seq[::-1]Out[82]: [1, 0, 6, 5, 3, 6, 3, 2, 7]</code></pre><h4 id="序列函数"><a href="#序列函数" class="headerlink" title="序列函数"></a>序列函数</h4><p>Python有一些有用的序列函数。</p><h5 id="enumerate函数"><a href="#enumerate函数" class="headerlink" title="enumerate函数"></a>enumerate函数</h5><p>迭代一个序列时，你可能想跟踪当前项的序号。手动的方法可能是下面这样：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">i = 0<span class="token key atrule">for value in collection</span><span class="token punctuation">:</span>   <span class="token comment"># do something with value</span>   i += 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>因为这么做很常见，Python内建了一个enumerate函数，可以返回(i, value)元组序列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">for i<span class="token punctuation">,</span> <span class="token key atrule">value in enumerate(collection)</span><span class="token punctuation">:</span>   <span class="token comment"># do something with value</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>当你索引数据时，使用enumerate的一个好方法是计算序列（唯一的）dict映射到位置的值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">]</span><span class="token punctuation">:</span> some_list = <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mapping = <span class="token punctuation">{</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">]</span><span class="token punctuation">:</span> for i<span class="token punctuation">,</span> <span class="token key atrule">v in enumerate(some_list)</span><span class="token punctuation">:</span>   <span class="token key atrule">....</span><span class="token punctuation">:</span>     mapping<span class="token punctuation">[</span>v<span class="token punctuation">]</span> = iIn <span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mappingOut<span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'bar'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token key atrule">'baz'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token key atrule">'foo'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="sorted函数"><a href="#sorted函数" class="headerlink" title="sorted函数"></a>sorted函数</h5><p>sorted函数可以从任意序列的元素返回一个新的排好序的列表：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">:</span> sorted(<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span><span class="token punctuation">:</span> sorted('horse race')Out<span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">' '</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><u>sorted函数可以接受和sort相同的参数。</u></p><h5 id="zip函数"><a href="#zip函数" class="headerlink" title="zip函数"></a>zip函数</h5><p><u>zip可以将多个列表、元组或其它序列成对组合成一个元组列表</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq1 = <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'baz'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">90</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq2 = <span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">91</span><span class="token punctuation">]</span><span class="token punctuation">:</span> zipped = zip(seq1<span class="token punctuation">,</span> seq2)In <span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(zipped)Out<span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>('foo'<span class="token punctuation">,</span> 'one')<span class="token punctuation">,</span> ('bar'<span class="token punctuation">,</span> 'two')<span class="token punctuation">,</span> ('baz'<span class="token punctuation">,</span> 'three')<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>zip可以处理任意多的序列，元素的个数取决于最短的序列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seq3 = <span class="token punctuation">[</span><span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">True</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(zip(seq1<span class="token punctuation">,</span> seq2<span class="token punctuation">,</span> seq3))Out<span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>('foo'<span class="token punctuation">,</span> <span class="token string">'one'</span><span class="token punctuation">,</span> False)<span class="token punctuation">,</span> ('bar'<span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> True)<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>zip的常见用法之一是同时迭代多个序列，可能结合enumerate使用：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span><span class="token punctuation">:</span> for i<span class="token punctuation">,</span> (a<span class="token punctuation">,</span> b) in enumerate(zip(seq1<span class="token punctuation">,</span> <span class="token key atrule">seq2))</span><span class="token punctuation">:</span>   <span class="token key atrule">....</span><span class="token punctuation">:</span>     print('<span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token number">2</span><span class="token punctuation">}</span>'.format(i<span class="token punctuation">,</span> a<span class="token punctuation">,</span> b))   <span class="token key atrule">....</span><span class="token punctuation">:</span><span class="token key atrule">0</span><span class="token punctuation">:</span> foo<span class="token punctuation">,</span> one<span class="token key atrule">1</span><span class="token punctuation">:</span> bar<span class="token punctuation">,</span> two<span class="token key atrule">2</span><span class="token punctuation">:</span> baz<span class="token punctuation">,</span> three<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>给出一个“被压缩的”序列，zip可以被用来解压序列。也可以当作把行的列表转换为列的列表。这个方法看起来有点神奇：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pitchers = <span class="token punctuation">[</span>('Nolan'<span class="token punctuation">,</span> 'Ryan')<span class="token punctuation">,</span> ('Roger'<span class="token punctuation">,</span> 'Clemens')<span class="token punctuation">,</span>   <span class="token key atrule">....</span><span class="token punctuation">:</span>             ('Schilling'<span class="token punctuation">,</span> 'Curt')<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">97</span><span class="token punctuation">]</span><span class="token punctuation">:</span> first_names<span class="token punctuation">,</span> last_names = zip(<span class="token important">*pitchers)</span>In <span class="token punctuation">[</span><span class="token number">98</span><span class="token punctuation">]</span><span class="token punctuation">:</span> first_namesOut<span class="token punctuation">[</span><span class="token number">98</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ('Nolan'<span class="token punctuation">,</span> <span class="token string">'Roger'</span><span class="token punctuation">,</span> 'Schilling')In <span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">]</span><span class="token punctuation">:</span> last_namesOut<span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ('Ryan'<span class="token punctuation">,</span> <span class="token string">'Clemens'</span><span class="token punctuation">,</span> 'Curt')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="reversed函数"><a href="#reversed函数" class="headerlink" title="reversed函数"></a>reversed函数</h5><p>reversed可以<u>从后向前迭代一个序列</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(reversed(range(10)))Out<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>要记住<u>reversed是一个生成器</u>（后面详细介绍），只有<u>实体化（即列表或for循环）之后才能创建翻转的序列</u>。</p><h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><p>字典可能是Python最为重要的数据结构。它更为常见的名字是<u>哈希映射或关联数组</u>。它是<u>键值对的大小可变集合</u>，键和值都是Python对象。<u>创建字典的方法之一是使用尖括号，用冒号分隔键和值</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">:</span> empty_dict = <span class="token punctuation">{</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1 = <span class="token punctuation">{</span><span class="token key atrule">'a'</span> <span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1Out<span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>你可以像访问<u>列表或元组中的元素一样，访问、插入或设定字典中的元素</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">104</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span> = 'an integer'In <span class="token punctuation">[</span><span class="token number">105</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1Out<span class="token punctuation">[</span><span class="token number">105</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">7</span><span class="token punctuation">:</span> <span class="token string">'an integer'</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>你可以用<u>检查列表和元组是否包含某个值的方法，检查字典中是否包含某个键</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 'b' in d1Out<span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以用del关键字或pop方法（返回值的同时删除键）删除值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">108</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> = 'some value'In <span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1Out<span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">7</span><span class="token punctuation">:</span> <span class="token string">'an integer'</span><span class="token punctuation">,</span> <span class="token key atrule">5</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">110</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1<span class="token punctuation">[</span><span class="token string">'dummy'</span><span class="token punctuation">]</span> = 'another value'In <span class="token punctuation">[</span><span class="token number">111</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1Out<span class="token punctuation">[</span><span class="token number">111</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">7</span><span class="token punctuation">:</span> <span class="token string">'an integer'</span><span class="token punctuation">,</span> <span class="token key atrule">5</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'dummy'</span><span class="token punctuation">:</span> <span class="token string">'another value'</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">112</span><span class="token punctuation">]</span><span class="token punctuation">:</span> del d1<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">113</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1Out<span class="token punctuation">[</span><span class="token number">113</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">7</span><span class="token punctuation">:</span> <span class="token string">'an integer'</span><span class="token punctuation">,</span> <span class="token key atrule">'dummy'</span><span class="token punctuation">:</span> <span class="token string">'another value'</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">114</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ret = d1.pop('dummy')In <span class="token punctuation">[</span><span class="token number">115</span><span class="token punctuation">]</span><span class="token punctuation">:</span> retOut<span class="token punctuation">[</span><span class="token number">115</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'another value'</span>In <span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1Out<span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">7</span><span class="token punctuation">:</span> <span class="token string">'an integer'</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><u>keys和values是字典的键和值的迭代器方法</u>。虽然键值对没有顺序，这两个方法可以用相同的顺序输出键和值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">117</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(d1.keys())Out<span class="token punctuation">[</span><span class="token number">117</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">118</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(d1.values())Out<span class="token punctuation">[</span><span class="token number">118</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'an integer'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>用update方法可以将一个字典与另一个融合：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">119</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1.update(<span class="token punctuation">{</span><span class="token key atrule">'b'</span> <span class="token punctuation">:</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token key atrule">'c'</span> <span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">}</span>)In <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d1Out<span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token string">'some value'</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token key atrule">7</span><span class="token punctuation">:</span> <span class="token string">'an integer'</span><span class="token punctuation">,</span> <span class="token key atrule">'c'</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>update方法是原地改变字典，因此任何传递给update的键的旧的值都会被舍弃。</p><h5 id="用序列创建字典"><a href="#用序列创建字典" class="headerlink" title="用序列创建字典"></a>用序列创建字典</h5><p>常常，你可能想将<u>两个序列配对组合成字典</u>。下面是一种写法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">mapping = <span class="token punctuation">{</span><span class="token punctuation">}</span>for key<span class="token punctuation">,</span> value in zip(key_list<span class="token punctuation">,</span> <span class="token key atrule">value_list)</span><span class="token punctuation">:</span>    mapping<span class="token punctuation">[</span>key<span class="token punctuation">]</span> = value<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>因为<u>字典本质上是2元元组的集合</u>，dict可以接受2元元组的列表：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mapping = dict(zip(range(5)<span class="token punctuation">,</span> reversed(range(5))))In <span class="token punctuation">[</span><span class="token number">122</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mappingOut<span class="token punctuation">[</span><span class="token number">122</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">0</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token key atrule">1</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token key atrule">2</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token key atrule">3</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token key atrule">4</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h5 id="dict-函数"><a href="#dict-函数" class="headerlink" title="dict() 函数"></a>dict() 函数</h5><p>函数输入输出实例：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment">#输入：</span>dict0 = dict()  <span class="token comment"># 传一个空字典</span>print('dict0<span class="token punctuation">:</span>'<span class="token punctuation">,</span> dict0)dict1 = dict(<span class="token punctuation">{</span><span class="token key atrule">'three'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token key atrule">'four'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">}</span>)  <span class="token comment"># 传一个字典</span>print('dict1<span class="token punctuation">:</span>'<span class="token punctuation">,</span> dict1)dict2 = dict(five=5<span class="token punctuation">,</span> six=6)  <span class="token comment"># 传关键字</span>print('dict2<span class="token punctuation">:</span>'<span class="token punctuation">,</span> dict2)dict3 = dict(<span class="token punctuation">[</span>('seven'<span class="token punctuation">,</span> 7)<span class="token punctuation">,</span> ('eight'<span class="token punctuation">,</span> 8)<span class="token punctuation">]</span>)  <span class="token comment"># 传一个包含一个或多个元祖的列表</span>print('dict3<span class="token punctuation">:</span>'<span class="token punctuation">,</span> dict3)dict5 = dict(zip(<span class="token punctuation">[</span><span class="token string">'eleven'</span><span class="token punctuation">,</span> <span class="token string">'twelve'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span>))  <span class="token comment"># 传一个zip()函数</span>print('dict5<span class="token punctuation">:</span>'<span class="token punctuation">,</span> dict5)<span class="token comment">#输出：</span><span class="token key atrule">dict0</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token key atrule">dict1</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'four'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token key atrule">'three'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token key atrule">dict2</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'five'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token key atrule">'six'</span><span class="token punctuation">:</span> <span class="token number">6</span><span class="token punctuation">}</span><span class="token key atrule">dict3</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'seven'</span><span class="token punctuation">:</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token key atrule">'eight'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">}</span><span class="token key atrule">dict5</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'twelve'</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token key atrule">'eleven'</span><span class="token punctuation">:</span> <span class="token number">11</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>后面会谈到dict comprehensions，另一种构建字典的优雅方式。<br>默认值</p><p>下面的逻辑很常见：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">if key in some_dict</span><span class="token punctuation">:</span>    value = some_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token key atrule">else</span><span class="token punctuation">:</span>    value = default_value<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>因此，dict的方法get和pop可以取默认值进行返回，上面的if-else语句可以简写成下面：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">value = some_dict.get(key<span class="token punctuation">,</span> default_value)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>get默认会返回None，如果不存在键，pop会抛出一个例外。关于设定值，常见的情况是在字典的值是属于其它集合，如列表。例如，你可以通过首字母，将一个列表中的单词分类：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">123</span><span class="token punctuation">]</span><span class="token punctuation">:</span> words = <span class="token punctuation">[</span><span class="token string">'apple'</span><span class="token punctuation">,</span> <span class="token string">'bat'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'atom'</span><span class="token punctuation">,</span> <span class="token string">'book'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">:</span> by_letter = <span class="token punctuation">{</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">125</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">for word in words</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     letter = word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     <span class="token key atrule">if letter not in by_letter</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>         by_letter<span class="token punctuation">[</span>letter<span class="token punctuation">]</span> = <span class="token punctuation">[</span>word<span class="token punctuation">]</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     <span class="token key atrule">else</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>         by_letter<span class="token punctuation">[</span>letter<span class="token punctuation">]</span>.append(word)   <span class="token key atrule">.....</span><span class="token punctuation">:</span>In <span class="token punctuation">[</span><span class="token number">126</span><span class="token punctuation">]</span><span class="token punctuation">:</span> by_letterOut<span class="token punctuation">[</span><span class="token number">126</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'apple'</span><span class="token punctuation">,</span> <span class="token string">'atom'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'bat'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'book'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>setdefault方法就正是用于单词分类。前面的for循环可以改写为：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">for word in words</span><span class="token punctuation">:</span>    letter = word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    by_letter.setdefault(letter<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>).append(word)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>collections模块有一个很有用的类，defaultdict，它可以进一步简化上面。传递类型或函数以生成每个位置的默认值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">from collections import defaultdictby_letter = defaultdict(list)<span class="token key atrule">for word in words</span><span class="token punctuation">:</span>    by_letter<span class="token punctuation">[</span>word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>.append(word)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="如何使用defaultdict"><a href="#如何使用defaultdict" class="headerlink" title="如何使用defaultdict"></a>如何使用defaultdict</h5><p>defaultdict接受一个工厂函数作为参数，如下来构造：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">dict =defaultdict( factory_function)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个factory_function可以是list、set、str等等，作用是当key不存在时，返回的是工厂函数的默认值，比如list对应[ ]，str对应的是空字符串，set对应set( )，int对应0，如下举例：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">from collections import defaultdictdict1 = defaultdict(int)dict2 = defaultdict(set)dict3 = defaultdict(str)dict4 = defaultdict(list)dict1<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> ='two'print(dict1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>)print(dict2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>)print(dict3<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>)print(dict4<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>)<span class="token comment">#输出为</span>0set()<span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="有效的键类型"><a href="#有效的键类型" class="headerlink" title="有效的键类型"></a>有效的键类型</h5><p>字典的值可以是任意Python对象，而键通常是不可变的标量类型（<u>整数、浮点型、字符串</u>）或<u>元组（元组中的对象必须是不可变的）</u>，这被称为“可哈希性。可以用<u>hash函数可检测一个对象是否是可哈希的</u>（可被用作字典的键）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span> hash('string')Out<span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">5023931463650008331</span>In <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">:</span> hash((1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> (2<span class="token punctuation">,</span> 3)))Out<span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">1097636502276347782</span>In <span class="token punctuation">[</span><span class="token number">129</span><span class="token punctuation">]</span><span class="token punctuation">:</span> hash((1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>)) <span class="token comment"># fails because lists are mutable</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>TypeError                                 Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>129<span class="token punctuation">-</span>800cd14ba8be<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 hash((1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>)) <span class="token comment"># fails because lists are mutable</span><span class="token key atrule">TypeError</span><span class="token punctuation">:</span> <span class="token key atrule">unhashable type</span><span class="token punctuation">:</span> <span class="token string">'list'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>要用列表当做键，一种方法是将列表转化为元组，只要内部元素可以被哈希，它也就可以被哈希：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">130</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d = <span class="token punctuation">{</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">131</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d<span class="token punctuation">[</span>tuple(<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>)<span class="token punctuation">]</span> = 5In <span class="token punctuation">[</span><span class="token number">132</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dOut<span class="token punctuation">[</span><span class="token number">132</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>(1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token key atrule">3)</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h4><p>集合是<u>无序的不可重复的元素的集合</u>。你可以把它当做<u>字典，但是只有键没有值</u>。可以用两种方式创建集合：通过set函数或使用尖括号set语句：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">133</span><span class="token punctuation">]</span><span class="token punctuation">:</span> set(<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">133</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">134</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">}</span>Out<span class="token punctuation">[</span><span class="token number">134</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>集合支持<u>合并、交集、差分和对称差等数学集合运算</u>。考虑两个示例集合：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">135</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a = <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">136</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b = <span class="token punctuation">{</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>合并是取两个集合中不重复的元素。可以用union方法，或者|运算符：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">137</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a.union(b)Out<span class="token punctuation">[</span><span class="token number">137</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">138</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a <span class="token punctuation">|</span> bOut<span class="token punctuation">[</span><span class="token number">138</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>交集的元素包含在两个集合中。可以用intersection或&amp;运算符：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">139</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a.intersection(b)Out<span class="token punctuation">[</span><span class="token number">139</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">140</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a &amp; bOut<span class="token punctuation">[</span><span class="token number">140</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1guoajywdctj60jb0cj7a902.jpg" alt="常用的集合方法">。</p><p>所有逻辑集合操作都有另外的原地实现方法，可以直接用结果替代集合的内容。对于大的集合，这么做效率更高：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">141</span><span class="token punctuation">]</span><span class="token punctuation">:</span> c = a.copy()In <span class="token punctuation">[</span><span class="token number">142</span><span class="token punctuation">]</span><span class="token punctuation">:</span> c <span class="token punctuation">|</span>= bIn <span class="token punctuation">[</span><span class="token number">143</span><span class="token punctuation">]</span><span class="token punctuation">:</span> cOut<span class="token punctuation">[</span><span class="token number">143</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">144</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d = a.copy()In <span class="token punctuation">[</span><span class="token number">145</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d <span class="token important">&amp;=</span> bIn <span class="token punctuation">[</span><span class="token number">146</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dOut<span class="token punctuation">[</span><span class="token number">146</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与字典类似，<u>集合元素通常都是不可变的</u>。要获得类似列表的元素，必须转换成元组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">147</span><span class="token punctuation">]</span><span class="token punctuation">:</span> my_data = <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">148</span><span class="token punctuation">]</span><span class="token punctuation">:</span> my_set = <span class="token punctuation">{</span>tuple(my_data)<span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">149</span><span class="token punctuation">]</span><span class="token punctuation">:</span> my_setOut<span class="token punctuation">[</span><span class="token number">149</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>(1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> 4)<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>你使用issubset还可以检测一个集合是否是另一个集合的子集或父集：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a_set = <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">151</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">}</span>.issubset(a_set)Out<span class="token punctuation">[</span><span class="token number">151</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>In <span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a_set.issuperset(<span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">}</span>)Out<span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>集合的内容相同时，集合才对等：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">153</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">}</span> == <span class="token punctuation">{</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span>Out<span class="token punctuation">[</span><span class="token number">153</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="列表、集合和字典推导式"><a href="#列表、集合和字典推导式" class="headerlink" title="列表、集合和字典推导式"></a>列表、集合和字典推导式</h4><p><u>列表推导式</u>是Python最受喜爱的特性之一。它允许用户方便的从一个集合过滤元素，形成列表，在传递参数的过程中还可以修改元素。形式如下：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">[</span>expr for val in collection if condition<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>它等同于下面的for循环;</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">result = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token key atrule">for val in collection</span><span class="token punctuation">:</span>    <span class="token key atrule">if condition</span><span class="token punctuation">:</span>        result.append(expr)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>filter条件可以被忽略，只留下表达式就行。例如，给定一个字符串列表，我们可以过滤出长度在2及以下的字符串，并将其转换成大写：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">154</span><span class="token punctuation">]</span><span class="token punctuation">:</span> strings = <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'as'</span><span class="token punctuation">,</span> <span class="token string">'bat'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'dove'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">155</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>x.upper() for x in strings if len(x) <span class="token punctuation">&gt;</span> 2<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">155</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'BAT'</span><span class="token punctuation">,</span> <span class="token string">'CAR'</span><span class="token punctuation">,</span> <span class="token string">'DOVE'</span><span class="token punctuation">,</span> <span class="token string">'PYTHON'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>用相似的方法，还可以推导集合和字典。<u>字典的推导式</u>如下所示：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">dict_comp = <span class="token punctuation">{</span><span class="token key atrule">key-expr</span> <span class="token punctuation">:</span> value<span class="token punctuation">-</span>expr for value in collection if condition<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><u>集合的推导式</u>与列表很像，只不过用的是<u>尖括号</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">set_comp = <span class="token punctuation">{</span>expr for value in collection if condition<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>与列表推导式类似，集合与字典的推导也很方便，而且使代码的读写都很容易。来看前面的字符串列表。假如我们只想要字符串的长度，用集合推导式的方法非常方便：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">156</span><span class="token punctuation">]</span><span class="token punctuation">:</span> unique_lengths = <span class="token punctuation">{</span>len(x) for x in strings<span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">157</span><span class="token punctuation">]</span><span class="token punctuation">:</span> unique_lengthsOut<span class="token punctuation">[</span><span class="token number">157</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>map函数可以进一步简化：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">158</span><span class="token punctuation">]</span><span class="token punctuation">:</span> set(map(len<span class="token punctuation">,</span> strings))Out<span class="token punctuation">[</span><span class="token number">158</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>map()是一个 Python 内建函数，它允许你不需要使用循环就可以编写简洁的代码，具体用法参考<a href="[Python Map 函数的使用 - 知乎 (zhihu.com">Python Map 函数的使用</a>](<a href="https://zhuanlan.zhihu.com/p/205466485))，基本用法为：">https://zhuanlan.zhihu.com/p/205466485))，基本用法为：</a></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">map(function<span class="token punctuation">,</span> iterable<span class="token punctuation">,</span> <span class="token punctuation">...</span>)<span class="token comment">#function` - 针对每一个迭代调用的函数</span><span class="token comment">#iterable` - 支持迭代的一个或者多个对象。在 Python 中大部分内建对象，例如 lists, dictionaries, 和 tuples 都是可迭代的</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>作为一个字典推导式的例子，我们可以创建一个字符串的查找映射表以确定它在列表中的位置：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">159</span><span class="token punctuation">]</span><span class="token punctuation">:</span> loc_mapping = <span class="token punctuation">{</span><span class="token key atrule">val</span> <span class="token punctuation">:</span> index for index<span class="token punctuation">,</span> val in enumerate(strings)<span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">160</span><span class="token punctuation">]</span><span class="token punctuation">:</span> loc_mappingOut<span class="token punctuation">[</span><span class="token number">160</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token key atrule">'as'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token key atrule">'bat'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token key atrule">'car'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token key atrule">'dove'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token key atrule">'python'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="嵌套列表推导式"><a href="#嵌套列表推导式" class="headerlink" title="嵌套列表推导式"></a>嵌套列表推导式</h4><p>假设我们有一个包含列表的列表，包含了一些英文名和西班牙名：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">161</span><span class="token punctuation">]</span><span class="token punctuation">:</span> all_data = <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'John'</span><span class="token punctuation">,</span> <span class="token string">'Emily'</span><span class="token punctuation">,</span> <span class="token string">'Michael'</span><span class="token punctuation">,</span> <span class="token string">'Mary'</span><span class="token punctuation">,</span> <span class="token string">'Steven'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>             <span class="token punctuation">[</span><span class="token string">'Maria'</span><span class="token punctuation">,</span> <span class="token string">'Juan'</span><span class="token punctuation">,</span> <span class="token string">'Javier'</span><span class="token punctuation">,</span> <span class="token string">'Natalia'</span><span class="token punctuation">,</span> <span class="token string">'Pilar'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>你可能是从一些文件得到的这些名字，然后想按照语言进行分类。现在假设我们想用一个列表包含所有的名字，这些名字中包含两个或更多的e。可以用for循环来做：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">names_of_interest = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token key atrule">for names in all_data</span><span class="token punctuation">:</span>    enough_es = <span class="token punctuation">[</span>name for name in names if name.count('e') <span class="token punctuation">&gt;</span>= 2<span class="token punctuation">]</span>    names_of_interest.extend(enough_es)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可以用嵌套列表推导式的方法，将这些写在一起，如下所示：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">162</span><span class="token punctuation">]</span><span class="token punctuation">:</span> result = <span class="token punctuation">[</span>name for names in all_data for name in names   <span class="token key atrule">.....</span><span class="token punctuation">:</span>           if name.count('e') <span class="token punctuation">&gt;</span>= 2<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">163</span><span class="token punctuation">]</span><span class="token punctuation">:</span> resultOut<span class="token punctuation">[</span><span class="token number">163</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Steven'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>嵌套列表推导式看起来有些复杂。列表推导式的for部分是根据嵌套的顺序，过滤条件还是放在最后。下面是另一个例子，我们将一个整数元组的列表扁平化成了一个整数列表：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">164</span><span class="token punctuation">]</span><span class="token punctuation">:</span> some_tuples = <span class="token punctuation">[</span>(1<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> (4<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> 6)<span class="token punctuation">,</span> (7<span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> 9)<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">165</span><span class="token punctuation">]</span><span class="token punctuation">:</span> flattened = <span class="token punctuation">[</span>x for tup in some_tuples for x in tup<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">166</span><span class="token punctuation">]</span><span class="token punctuation">:</span> flattenedOut<span class="token punctuation">[</span><span class="token number">166</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>记住，for表达式的顺序是与嵌套for循环的顺序一样（而不是列表推导式的顺序）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">flattened = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token key atrule">for tup in some_tuples</span><span class="token punctuation">:</span>    <span class="token key atrule">for x in tup</span><span class="token punctuation">:</span>        flattened.append(x)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>你可以有任意多级别的嵌套，但是如果你有两三个以上的嵌套，你就应该考虑下代码可读性的问题了。分辨列表推导式的列表推导式中的语法也是很重要的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">167</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x for x in tup<span class="token punctuation">]</span> for tup in some_tuples<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">167</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这段代码产生了一个列表的列表，而不是扁平化的只包含元素的列表。</p><h3 id="3-2-函数"><a href="#3-2-函数" class="headerlink" title="3.2 函数"></a><a href="https://www.bookstack.cn/read/pyda-2e-zh/3.2.md">3.2 函数</a></h3><p>函数是Python中最主要也是最重要的代码组织和复用手段。作为最重要的原则，如果你要重复使用相同或非常类似的代码，就需要写一个函数。通过给函数起一个名字，还可以提高代码的可读性。</p><p>函数使用<code>def</code>关键字声明，用<code>return</code>关键字返回值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">def my_function(x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token key atrule">z=1.5)</span><span class="token punctuation">:</span>    <span class="token key atrule">if z &gt; 1</span><span class="token punctuation">:</span>        return z * (x + y)    <span class="token key atrule">else</span><span class="token punctuation">:</span>        return z / (x + y)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同时拥有多条<code>return</code>语句也是可以的。如果到达函数末尾时没有遇到任何一条<code>return</code>语句，则返回<code>None</code>。</p><p>函数可以有一些位置参数（<code>positional</code>）和一些关键字参数（<code>keyword</code>）。<u>关键字参数通常用于指定默认值或可选参数</u>。在上面的函数中，<u>x和y是位置参数，而z则是关键字参数</u>。也就是说，该函数可以下面这3种方式进行调用：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">my_function(5<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> z=0.7)my_function(3.14<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> 3.5)my_function(10<span class="token punctuation">,</span> 20)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><u>函数参数的主要限制在于：关键字参数必须位于位置参数（如果有的话）之后。</u>你可以任何顺序指定关键字参数。也就是说，你不用死记硬背函数参数的顺序，只要记得它们的名字就可以了。</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment">#笔记：也可以用"关键字传递位置参数"。前面的例子，也可以写为：</span>    my_function(x=5<span class="token punctuation">,</span> y=6<span class="token punctuation">,</span> z=7)    my_function(y=6<span class="token punctuation">,</span> x=5<span class="token punctuation">,</span> z=7)<span class="token comment">#这种写法可以提高可读性。</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="命名空间、作用域，和局部函数"><a href="#命名空间、作用域，和局部函数" class="headerlink" title="命名空间、作用域，和局部函数"></a>命名空间、作用域，和局部函数</h4><p>函数可以访问两种不同作用域中的变量：<u>全局（global）和局部（local）</u>。Python有一种更科学的<u>用于描述变量作用域的名称，即命名空间（namespace）</u>。任何<u>在函数中赋值的变量</u>默认都是被分配到<u>局部命名空间</u>（local namespace）中的。局部命名空间是在函数被调用时创建的，函数参数会立即填入该命名空间。在函数执行完毕之后，局部命名空间就会被销毁（会有一些例外的情况，具体请参见后面介绍闭包的那一节）。看看下面这个函数：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def func()</span><span class="token punctuation">:</span>    a = <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token key atrule">for i in range(5)</span><span class="token punctuation">:</span>        a.append(i)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>调用<code>func()</code>之后，首先会创建出空列表a，然后添加5个元素，最后a会在该函数退出的时候被销毁。假如我们像下面这样定义a：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">a = <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token key atrule">def func()</span><span class="token punctuation">:</span>    <span class="token key atrule">for i in range(5)</span><span class="token punctuation">:</span>        a.append(i)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>虽然可以在函数中对全局变量进行赋值操作，但是那些变量必须用global关键字声明成全局的才行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">168</span><span class="token punctuation">]</span><span class="token punctuation">:</span> a = NoneIn <span class="token punctuation">[</span><span class="token number">169</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">def bind_a_variable()</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     global a   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     a = <span class="token punctuation">[</span><span class="token punctuation">]</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span> bind_a_variable()   <span class="token key atrule">.....</span><span class="token punctuation">:</span>In <span class="token punctuation">[</span><span class="token number">170</span><span class="token punctuation">]</span><span class="token punctuation">:</span> print(a)<span class="token punctuation">[</span><span class="token punctuation">]</span>注意：我常常建议人们不要频繁使用global关键字。因为全局变量一般是用于存放系统的某些状态的。如果你发现自己用了很多，那可能就说明得要来点儿面向对象编程了（即使用类）。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="返回多个值"><a href="#返回多个值" class="headerlink" title="返回多个值"></a>返回多个值</h4><p>在我第一次用Python编程时（之前已经习惯了Java和C++），最喜欢的一个功能是：函数可以返回多个值。下面是一个简单的例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def f()</span><span class="token punctuation">:</span>    a = 5    b = 6    c = 7    return a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> ca<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c = f()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在数据分析和其他科学计算应用中，你会发现自己常常这么干。该函数其实只返回了一个对象，也就是一个元组，最后该元组会被拆包到各个结果变量中。在上面的例子中，我们还可以这样写：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">return_value = f()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里的return_value将会是一个含有3个返回值的三元元组。此外，还有一种非常具有吸引力的多值返回方式——返回字典：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def f()</span><span class="token punctuation">:</span>    a = 5    b = 6    c = 7    return <span class="token punctuation">{</span><span class="token key atrule">'a'</span> <span class="token punctuation">:</span> a<span class="token punctuation">,</span> <span class="token key atrule">'b'</span> <span class="token punctuation">:</span> b<span class="token punctuation">,</span> <span class="token key atrule">'c'</span> <span class="token punctuation">:</span> c<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>取决于工作内容，第二种方法可能很有用。</p><h4 id="函数也是对象"><a href="#函数也是对象" class="headerlink" title="函数也是对象"></a>函数也是对象</h4><p>由于Python函数都是对象(<a href="https://zhuanlan.zhihu.com/p/75265007">2分钟让你明白什么是面向对象编程 - 知乎 (zhihu.com)</a>)，因此，在其他语言中较难表达的一些设计思想在Python中就要简单很多了。假设我们有下面这样一个字符串数组，希望对其进行一些数据清理工作并执行一堆转换：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">171</span><span class="token punctuation">]</span><span class="token punctuation">:</span> states = <span class="token punctuation">[</span><span class="token string">'   Alabama '</span><span class="token punctuation">,</span> <span class="token string">'Georgia!'</span><span class="token punctuation">,</span> <span class="token string">'Georgia'</span><span class="token punctuation">,</span> <span class="token string">'georgia'</span><span class="token punctuation">,</span> <span class="token string">'FlOrIda'</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>           <span class="token string">'south   carolina##'</span><span class="token punctuation">,</span> <span class="token string">'West virginia?'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>不管是谁，只要处理过由用户提交的调查数据，就能明白这种乱七八糟的数据是怎么一回事。为了得到一组能用于分析工作的格式统一的字符串，需要做很多事情：去除空白符、删除各种标点符号、正确的大写格式等。做法之一是使用内建的字符串方法和正则表达式re模块(<a href="http://www.itwangqing.net.cn/15623206542335.html#:~:text=正则表达式（RE,过re模块实现。">可参考正则表达式re模块 </a>)：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">import re<span class="token key atrule">def clean_strings(strings)</span><span class="token punctuation">:</span>    result = <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token key atrule">for value in strings</span><span class="token punctuation">:</span>        value = value.strip()        value = re.sub('<span class="token punctuation">[</span><span class="token tag">!</span><span class="token comment">#?]', '', value)</span>        value = value.title()<span class="token comment">#</span>        result.append(value)    return result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，<code>strip</code>方法的功能为移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。其语法与实例为（可参考<a href="https://www.runoob.com/python/att-string-strip.html">Python strip()方法)</a>）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment">#语法</span>str.strip(<span class="token punctuation">[</span>chars<span class="token punctuation">]</span>);<span class="token comment">#实例</span>str = "00000003210Runoob01230000000"; print str.strip( '0' );  <span class="token comment"># 去除首尾字符 0</span>str2 = "   Runoob      ";   <span class="token comment"># 去除首尾空格</span>print str2.strip();<span class="token comment">#输出：</span>3210Runoob0123Runoob<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>title</code>方法返回”标题化”的字符串,就是说所有单词的首个字母转化为大写，其余字母均为小写，用法为：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">str.title();<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果如下所示：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> clean_strings(states)Out<span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Alabama'</span><span class="token punctuation">,</span> <span class="token string">'Georgia'</span><span class="token punctuation">,</span> <span class="token string">'Georgia'</span><span class="token punctuation">,</span> <span class="token string">'Georgia'</span><span class="token punctuation">,</span> <span class="token string">'Florida'</span><span class="token punctuation">,</span> <span class="token string">'South   Carolina'</span><span class="token punctuation">,</span> <span class="token string">'West Virginia'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实还有另外一种不错的办法：将<u>需要在一组给定字符串上执行的所有运算做成一个列表，再将列表中的运算一个一个执行</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def remove_punctuation(value)</span><span class="token punctuation">:</span>    return re.sub('<span class="token punctuation">[</span><span class="token tag">!</span><span class="token comment">#?]', '', value)</span>clean_ops = <span class="token punctuation">[</span>str.strip<span class="token punctuation">,</span> remove_punctuation<span class="token punctuation">,</span> str.title<span class="token punctuation">]</span>def clean_strings(strings<span class="token punctuation">,</span> <span class="token key atrule">ops)</span><span class="token punctuation">:</span>    result = <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token key atrule">for value in strings</span><span class="token punctuation">:</span>        <span class="token key atrule">for function in ops</span><span class="token punctuation">:</span>            value = function(value)        result.append(value)    return result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后我们就有了：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> clean_strings(states<span class="token punctuation">,</span> clean_ops)Out<span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Alabama'</span><span class="token punctuation">,</span> <span class="token string">'Georgia'</span><span class="token punctuation">,</span> <span class="token string">'Georgia'</span><span class="token punctuation">,</span> <span class="token string">'Georgia'</span><span class="token punctuation">,</span> <span class="token string">'Florida'</span><span class="token punctuation">,</span> <span class="token string">'South   Carolina'</span><span class="token punctuation">,</span> <span class="token string">'West Virginia'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种多函数模式使你能在很高的层次上轻松修改字符串的转换方式。此时的clean_strings也更具可复用性！</p><p>还可以将函数用作其他函数的参数，比如内置的<code>map</code>函数，它用于<u>在一组数据上应用一个函数</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> for x in map(remove_punctuation<span class="token punctuation">,</span> <span class="token key atrule">states)</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     print(x)Alabama GeorgiaGeorgiageorgiaFlOrIdasouth   carolinaWest virginia<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="匿名（lambda）函数"><a href="#匿名（lambda）函数" class="headerlink" title="匿名（lambda）函数"></a>匿名（lambda）函数</h4><p>Python支持一种被称为匿名的、或<code>lambda</code>函数。<u>它仅由单条语句组成，该语句的结果就是返回值</u>。它是通过<code>lambda</code>关键字定义的，<u>这个关键字没有别的含义，仅仅是说“我们正在声明的是一个匿名函数”</u>。</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def short_function(x)</span><span class="token punctuation">:</span>    return x * 2<span class="token key atrule">equiv_anon = lambda x</span><span class="token punctuation">:</span> x * 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>本书其余部分一般将其称为lambda函数。它们在数据分析工作中非常方便，因为你会发现很多数据转换函数都以函数作为参数的。<u>直接传入lambda函数比编写完整函数声明要少输入很多字（也更清晰）</u>，甚至比将<code>lambda</code>函数赋值给一个变量还要少输入很多字。看看下面这个简单得有些傻的例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">def apply_to_list(some_list<span class="token punctuation">,</span> <span class="token key atrule">f)</span><span class="token punctuation">:</span>    return <span class="token punctuation">[</span>f(x) for x in some_list<span class="token punctuation">]</span>ints = <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>apply_to_list(ints<span class="token punctuation">,</span> <span class="token key atrule">lambda x</span><span class="token punctuation">:</span> x * 2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>虽然你可以直接编写<code>[x *2for x in ints]</code>，但是这里我们可以非常轻松地传入一个自定义运算给apply_to_list函数。</p><p>再来看另外一个例子。假设有一组字符串，你想要根据各字符串不同字母的数量对其进行排序：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">177</span><span class="token punctuation">]</span><span class="token punctuation">:</span> strings = <span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'card'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'aaaa'</span><span class="token punctuation">,</span> <span class="token string">'abab'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里，我们可以传入一个lambda函数到列表的sort方法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">178</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">strings.sort(key=lambda x</span><span class="token punctuation">:</span> len(set(list(x)))) <span class="token comment">#字符串中的不同的字符数目</span>In <span class="token punctuation">[</span><span class="token number">179</span><span class="token punctuation">]</span><span class="token punctuation">:</span> stringsOut<span class="token punctuation">[</span><span class="token number">179</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'aaaa'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'abab'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'card'</span><span class="token punctuation">]</span><span class="token comment">#笔记：lambda函数之所以会被称为匿名函数，与def声明的函数不同，原因之一就是这种函数对象本身是没有提供名称name属性。</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="柯里化：部分参数应用"><a href="#柯里化：部分参数应用" class="headerlink" title="柯里化：部分参数应用"></a>柯里化：部分参数应用</h4><p>柯里化（currying）是一个有趣的计算机科学术语，它指的是通过“部分参数应用”（partial argument application）从现有函数派生出新函数的技术。例如，假设我们有一个执行两数相加的简单函数：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">def add_numbers(x<span class="token punctuation">,</span> <span class="token key atrule">y)</span><span class="token punctuation">:</span>    return x + y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>通过这个函数，我们可以派生出一个新的只有一个参数的函数——add_five，它用于对其参数加5：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">add_five = lambda y</span><span class="token punctuation">:</span> add_numbers(5<span class="token punctuation">,</span> y)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>add_numbers的第二个参数称为“柯里化的”（curried）。这里没什么特别花哨的东西，因为我们其实就只是定义了一个可以调用现有函数的新函数而已。内置的<code>functools</code>模块可以用partial函数将此过程简化：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">from functools import partialadd_five = partial(add_numbers<span class="token punctuation">,</span> 5)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><p>能以一种一致的方式对序列进行迭代（比如列表中的对象或文件中的行）是Python的一个重要特点。这是通过一种叫做迭代器协议（iterator protocol，它是一种使对象可迭代的通用方式）的方式实现的，一个原生的使对象可迭代的方法。比如说，对字典进行迭代可以得到其所有的键：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">180</span><span class="token punctuation">]</span><span class="token punctuation">:</span> some_dict = <span class="token punctuation">{</span><span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token key atrule">'c'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">181</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">for key in some_dict</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     print(key)abc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当你编写<code>for key in some_dict</code>时，Python解释器首先会尝试从some_dict创建一个迭代器：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">182</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dict_iterator = iter(some_dict)In <span class="token punctuation">[</span><span class="token number">183</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dict_iteratorOut<span class="token punctuation">[</span><span class="token number">183</span><span class="token punctuation">]</span><span class="token punctuation">:</span> &lt;dict_keyiterator at 0x7fbbd5a9f908<span class="token punctuation">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>迭代器是一种特殊对象，它可以在诸如for循环之类的上下文中向Python解释器输送对象。大部分能接受列表之类的对象的方法也都可以接受任何可迭代对象。比如<code>min、max、sum</code>等内置方法以及<code>list、tuple</code>等类型构造器：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">184</span><span class="token punctuation">]</span><span class="token punctuation">:</span> list(dict_iterator)Out<span class="token punctuation">[</span><span class="token number">184</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>生成器（generator）是构造新的可迭代对象的一种简单方式。一般的函数执行之后只会返回单个值，而生成器则是<u>以延迟的方式返回一个值序列，即每返回一个值之后暂停，直到下一个值被请求时再继续</u>。要创建一个生成器，只需将函数中的<code>return</code>替换为<code>yeild</code>即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def squares(n=10)</span><span class="token punctuation">:</span>    print('Generating squares from 1 to <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span>'.format(n <span class="token important">**</span> 2))    for i in range(1<span class="token punctuation">,</span> <span class="token key atrule">n + 1)</span><span class="token punctuation">:</span>        yield i <span class="token important">**</span> 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>调用该生成器时，没有任何代码会被立即执行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">186</span><span class="token punctuation">]</span><span class="token punctuation">:</span> gen = squares()In <span class="token punctuation">[</span><span class="token number">187</span><span class="token punctuation">]</span><span class="token punctuation">:</span> genOut<span class="token punctuation">[</span><span class="token number">187</span><span class="token punctuation">]</span><span class="token punctuation">:</span> &lt;generator object squares at 0x7fbbd5ab4570<span class="token punctuation">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>直到你从<u>该生成器中请求元素</u>时，它才会开始执行其代码：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">188</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">for x in gen</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     print(x<span class="token punctuation">,</span> end=' ')Generating squares from 1 to 1001 4 9 16 25 36 49 64 81 100<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="生成器表达式"><a href="#生成器表达式" class="headerlink" title="生成器表达式"></a>生成器表达式</h5><p>另一种更简洁的构造生成器的方法是使用生成器表达式（generator expression）。<u>这是一种类似于列表、字典、集合推导式的生成器。其创建方式为，把列表推导式两端的方括号改成圆括号</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">189</span><span class="token punctuation">]</span><span class="token punctuation">:</span> gen = (x <span class="token important">**</span> 2 for x in range(100))In <span class="token punctuation">[</span><span class="token number">190</span><span class="token punctuation">]</span><span class="token punctuation">:</span> genOut<span class="token punctuation">[</span><span class="token number">190</span><span class="token punctuation">]</span><span class="token punctuation">:</span> &lt;generator object &lt;genexpr<span class="token punctuation">&gt;</span> at 0x7fbbd5ab29e8<span class="token punctuation">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>它跟下面这个冗长得多的生成器是完全等价的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def _make_gen()</span><span class="token punctuation">:</span>    <span class="token key atrule">for x in range(100)</span><span class="token punctuation">:</span>        yield x <span class="token important">**</span> 2gen = _make_gen()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>生成器表达式也可以取代列表推导式，作为函数参数：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">191</span><span class="token punctuation">]</span><span class="token punctuation">:</span> sum(x <span class="token important">**</span> 2 for x in range(100))Out<span class="token punctuation">[</span><span class="token number">191</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">328350</span>In <span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dict((i<span class="token punctuation">,</span> i <span class="token important">**2)</span> for i in range(5))Out<span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">0</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token key atrule">1</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token key atrule">2</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token key atrule">3</span><span class="token punctuation">:</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token key atrule">4</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="itertools模块"><a href="#itertools模块" class="headerlink" title="itertools模块"></a><code>itertools</code>模块</h5><p>标准库<code>itertools</code>模块中有一组用于许多常见数据算法的生成器。例如，<code>groupby</code>可以接受任何序列和一个函数。它根据函数的返回值对序列中的连续元素进行分组。下面是一个例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">193</span><span class="token punctuation">]</span><span class="token punctuation">:</span> import itertoolsIn <span class="token punctuation">[</span><span class="token number">194</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">first_letter = lambda x</span><span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">195</span><span class="token punctuation">]</span><span class="token punctuation">:</span> names = <span class="token punctuation">[</span><span class="token string">'Alan'</span><span class="token punctuation">,</span> <span class="token string">'Adam'</span><span class="token punctuation">,</span> <span class="token string">'Wes'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">,</span> <span class="token string">'Albert'</span><span class="token punctuation">,</span> <span class="token string">'Steven'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">196</span><span class="token punctuation">]</span><span class="token punctuation">:</span> for letter<span class="token punctuation">,</span> names in itertools.groupby(names<span class="token punctuation">,</span> <span class="token key atrule">first_letter)</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     print(letter<span class="token punctuation">,</span> list(names)) <span class="token comment"># names is a generator</span>A <span class="token punctuation">[</span><span class="token string">'Alan'</span><span class="token punctuation">,</span> <span class="token string">'Adam'</span><span class="token punctuation">]</span>W <span class="token punctuation">[</span><span class="token string">'Wes'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">]</span>A <span class="token punctuation">[</span><span class="token string">'Albert'</span><span class="token punctuation">]</span>S <span class="token punctuation">[</span><span class="token string">'Steven'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下表中列出了一些我经常用到的<code>itertools</code>函数。建议参阅Python官方文档，进一步学习。</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1guomv4yveej60jc06pac302.jpg" alt="一些有用的itertools函数"></p><h4 id="错误和异常处理"><a href="#错误和异常处理" class="headerlink" title="错误和异常处理"></a>错误和异常处理</h4><p>优雅地处理Python的错误和异常是构建健壮程序的重要部分。在数据分析中，许多函数函数只用于部分输入。例如，Python的<code>float</code>函数可以将字符串转换成浮点数，但输入有误时，有ValueError错误：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">197</span><span class="token punctuation">]</span><span class="token punctuation">:</span> float('1.2345')Out<span class="token punctuation">[</span><span class="token number">197</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">1.2345</span>In <span class="token punctuation">[</span><span class="token number">198</span><span class="token punctuation">]</span><span class="token punctuation">:</span> float('something')<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>ValueError                                Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>198<span class="token punctuation">-</span>439904410854<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 float('something')<span class="token key atrule">ValueError</span><span class="token punctuation">:</span> <span class="token key atrule">could not convert string to float</span><span class="token punctuation">:</span> <span class="token string">'something'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>假如想优雅地处理<code>float</code>的错误，让它返回输入值。我们可以写一个函数，在try/except中调用float：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def attempt_float(x)</span><span class="token punctuation">:</span>    <span class="token key atrule">try</span><span class="token punctuation">:</span>        return float(x)    <span class="token key atrule">except</span><span class="token punctuation">:</span>        return x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当<code>float(x)</code>抛出异常时，才会执行<code>except</code>的部分：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">:</span> attempt_float('1.2345')Out<span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">1.2345</span>In <span class="token punctuation">[</span><span class="token number">201</span><span class="token punctuation">]</span><span class="token punctuation">:</span> attempt_float('something')Out<span class="token punctuation">[</span><span class="token number">201</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'something'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>你可能注意到float抛出的异常不仅是<code>ValueError</code>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">202</span><span class="token punctuation">]</span><span class="token punctuation">:</span> float((1<span class="token punctuation">,</span> 2))<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>TypeError                                 Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>202<span class="token punctuation">-</span>842079ebb635<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 float((1<span class="token punctuation">,</span> 2))<span class="token key atrule">TypeError</span><span class="token punctuation">:</span> float() argument must be a string or a number<span class="token punctuation">,</span> not 'tuple'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>你可能只想处理<code>ValueError，TypeError</code>错误（输入不是字符串或数值）可能是合理的bug。可以写一个异常类型：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def attempt_float(x)</span><span class="token punctuation">:</span>    <span class="token key atrule">try</span><span class="token punctuation">:</span>        return float(x)    <span class="token key atrule">except ValueError</span><span class="token punctuation">:</span>        return x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后有：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">204</span><span class="token punctuation">]</span><span class="token punctuation">:</span> attempt_float((1<span class="token punctuation">,</span> 2))<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>TypeError                                 Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>204<span class="token punctuation">-</span>9bdfd730cead<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 attempt_float((1<span class="token punctuation">,</span> 2))&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>203<span class="token punctuation">-</span>3e06b8379b6b<span class="token punctuation">&gt;</span> in attempt_float(x)      <span class="token key atrule">1 def attempt_float(x)</span><span class="token punctuation">:</span>      <span class="token key atrule">2     try</span><span class="token punctuation">:</span><span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 3         return float(x)      <span class="token key atrule">4     except ValueError</span><span class="token punctuation">:</span>      5         return x<span class="token key atrule">TypeError</span><span class="token punctuation">:</span> float() argument must be a string or a number<span class="token punctuation">,</span> not 'tuple'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以用<u>元组包含多个异常</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">def attempt_float(x)</span><span class="token punctuation">:</span>    <span class="token key atrule">try</span><span class="token punctuation">:</span>        return float(x)    except (TypeError<span class="token punctuation">,</span> <span class="token key atrule">ValueError)</span><span class="token punctuation">:</span>        return x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>某些情况下，你可能不想抑制异常，你想无论try部分的代码是否成功，都执行一段代码。可以使用finally：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">f = open(path<span class="token punctuation">,</span> 'w')<span class="token key atrule">try</span><span class="token punctuation">:</span>    write_to_file(f)<span class="token key atrule">finally</span><span class="token punctuation">:</span>    f.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里，文件处理f总会被关闭。相似的，你可以用else让只在try部分成功的情况下，才执行代码：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">f = open(path<span class="token punctuation">,</span> 'w')<span class="token key atrule">try</span><span class="token punctuation">:</span>    write_to_file(f)<span class="token key atrule">except</span><span class="token punctuation">:</span>    print('Failed')<span class="token key atrule">else</span><span class="token punctuation">:</span>    print('Succeeded')<span class="token key atrule">finally</span><span class="token punctuation">:</span>    f.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="IPython的异常"><a href="#IPython的异常" class="headerlink" title="IPython的异常"></a>IPython的异常</h5><p>如果是在%run一个脚本或一条语句时抛出异常，IPython默认会打印完整的调用栈（traceback），在栈的每个点都会有几行上下文：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span> %run examples/ipython_bug.py<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>AssertionError                            Traceback (most recent call last)/home/wesm/code/pydata<span class="token punctuation">-</span>book/examples/ipython_bug.py in &lt;module<span class="token punctuation">&gt;</span>()     13     throws_an_exception()     14<span class="token punctuation">---</span><span class="token punctuation">&gt;</span> 15 calling_things()/home/wesm/code/pydata<span class="token punctuation">-</span>book/examples/ipython_bug.py in calling_things()     <span class="token key atrule">11 def calling_things()</span><span class="token punctuation">:</span>     12     works_fine()<span class="token punctuation">---</span><span class="token punctuation">&gt;</span> 13     throws_an_exception()     14     15 calling_things()/home/wesm/code/pydata<span class="token punctuation">-</span>book/examples/ipython_bug.py in throws_an_exception()      7     a = 5      8     b = 6<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 9     assert(a + b == 10)     10     <span class="token key atrule">11 def calling_things()</span><span class="token punctuation">:</span>AssertionError<span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>自身就带有文本是相对于Python标准解释器的极大优点。你可以用魔术命令%xmode，从Plain（与Python标准解释器相同）到Verbose（带有函数的参数值）控制文本显示的数量。后面可以看到，发生错误之后，（用%debug或%pdb magics）可以进入stack进行事后调试。</p><h3 id="3-3-文件和操作系统"><a href="#3-3-文件和操作系统" class="headerlink" title="3.3 文件和操作系统"></a>3.3 文件和操作系统</h3><p>本书的代码示例大多使用诸如pandas.read_csv之类的高级工具将磁盘上的数据文件读入Python数据结构。但我们还是需要了解一些有关Python文件处理方面的基础知识。好在它本来就很简单，这也是Python在文本和文件处理方面的如此流行的原因之一。</p><p>为了打开一个文件以便读写，可以使用内置的<code>open</code>函数以及一个相对或绝对的文件路径：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">207</span><span class="token punctuation">]</span><span class="token punctuation">:</span> path = 'examples/segismundo.txt'In <span class="token punctuation">[</span><span class="token number">208</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f = open(path)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>默认情况下，文件是以只读模式<code>（’r’）</code>打开的。然后，我们就可以像处理列表那样来处理这个文件句柄f了，比如对行进行迭代：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">for line in f</span><span class="token punctuation">:</span>    pass<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>从文件中取出的行都带有完整的行结束符（EOL），因此你常常会看到下面这样的代码（得到一组没有EOL的行）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">209</span><span class="token punctuation">]</span><span class="token punctuation">:</span> lines = <span class="token punctuation">[</span>x.rstrip() for x in open(path)<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">210</span><span class="token punctuation">]</span><span class="token punctuation">:</span> linesOut<span class="token punctuation">[</span><span class="token number">210</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Sueña el rico en su riqueza,'</span><span class="token punctuation">,</span> <span class="token string">'que más cuidados le ofrece;'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'sueña el pobre que padece'</span><span class="token punctuation">,</span> <span class="token string">'su miseria y su pobreza;'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'sueña el que a medrar empieza,'</span><span class="token punctuation">,</span> <span class="token string">'sueña el que afana y pretende,'</span><span class="token punctuation">,</span> <span class="token string">'sueña el que agravia y ofende,'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> <span class="token string">'y en el mundo, en conclusión,'</span><span class="token punctuation">,</span> <span class="token string">'todos sueñan lo que son,'</span><span class="token punctuation">,</span> <span class="token string">'aunque ninguno lo entiende.'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果<u>使用<code>open</code>创建文件对象，一定要用<code>close</code>关闭它</u>。关闭文件可以返回操作系统资源：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">211</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f.close()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用<code>with</code>语句可以可以更容易地清理打开的文件：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">212</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">with open(path) as f</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     lines = <span class="token punctuation">[</span>x.rstrip() for x in f<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这样可以在退出代码块时，自动关闭文件。</p><p><code>rstrip()</code>函数： 删除 string 字符串末尾的指定字符（默认为空格），语法与实例如下：（可参考<a href="https://www.runoob.com/python/att-string-rstrip.html"><code>rstrip()</code> )</a>）</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment">#用法</span>str.rstrip(<span class="token punctuation">[</span>chars<span class="token punctuation">]</span>)<span class="token comment">#实例</span>str = "     this is string example<span class="token punctuation">...</span>.wow<span class="token tag">!</span><span class="token tag">!</span><span class="token tag">!</span>     ";print str.rstrip();str = "88888888this is string example<span class="token punctuation">...</span>.wow<span class="token tag">!</span><span class="token tag">!!8888888</span>";print str.rstrip('8');<span class="token comment">#输出</span>     this is string example<span class="token punctuation">...</span>.wow<span class="token tag">!</span><span class="token tag">!</span><span class="token tag">!</span>88888888this is string example<span class="token punctuation">...</span>.wow<span class="token tag">!</span><span class="token tag">!</span><span class="token tag">!</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果输入<code>f =open(path,’w’)</code>，就会有一个新文件被创建在examples/segismundo.txt，并覆盖掉该位置原来的任何数据。另外有一个x文件模式，它可以创建可写的文件，但是如果文件路径存在，就无法创建。下表列出了所有的读/写模式。</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gup4do8w6pj60yg0b3ad702.jpg" alt="Python的文件模式"></p><p>对于可读文件，一些常用的方法是<code>read、seek和tell</code>。<code>read</code>会从文件返回字符。字符的内容是由文件的编码决定的（如UTF-8），如果是二进制模式打开的就是原始字节：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">213</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f = open(path)In <span class="token punctuation">[</span><span class="token number">214</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f.read(10)Out<span class="token punctuation">[</span><span class="token number">214</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'Sueña el r'</span>In <span class="token punctuation">[</span><span class="token number">215</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f2 = open(path<span class="token punctuation">,</span> 'rb')  <span class="token comment"># Binary mode</span>In <span class="token punctuation">[</span><span class="token number">216</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f2.read(10)Out<span class="token punctuation">[</span><span class="token number">216</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b'Sue\xc3\xb1a el '<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>read</code>模式会将文件句柄的位置提前，<u>提前的数量是读取的字节数</u>。<code>tell</code>可以给出当前的位置：</p><pre class="line-numbers language-YAML" data-language="YAML"><code class="language-YAML">In [217]: f.tell()Out[217]: 11In [218]: f2.tell()Out[218]: 10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>尽管我们从文件读取了10个字符，位置却是11，这是因为用默认的编码用了这么多字节才解码了这10个字符。你可以用sys模块检查默认的编码：</p><pre class="line-numbers language-YAML" data-language="YAML"><code class="language-YAML">In [219]: import sysIn [220]: sys.getdefaultencoding()Out[220]: 'utf-8'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><code>seek</code>将文件位置更改为<u>文件中的指定字节</u>：</p><pre class="line-numbers language-YAML" data-language="YAML"><code class="language-YAML">In [221]: f.seek(3)Out[221]: 3In [222]: f.read(1)Out[222]: 'ñ'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>最后，关闭文件：</p><pre class="line-numbers language-YAML" data-language="YAML"><code class="language-YAML">In [223]: f.close()In [224]: f2.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>向文件写入，可以使用文件的write或writelines方法。例如，我们可以创建一个无空行版的prof_mod.py：</p><pre class="line-numbers language-YAML" data-language="YAML"><code class="language-YAML">In [225]: with open('tmp.txt', 'w') as handle:   .....:     handle.writelines(x for x in open(path) if len(x) &gt; 1)In [226]: with open('tmp.txt') as f:   .....:     lines = f.readlines()In [227]: linesOut[227]: ['Sueña el rico en su riqueza,\n', 'que más cuidados le ofrece;\n', 'sueña el pobre que padece\n', 'su miseria y su pobreza;\n', 'sueña el que a medrar empieza,\n', 'sueña el que afana y pretende,\n', 'sueña el que agravia y ofende,\n', 'y en el mundo, en conclusión,\n', 'todos sueñan lo que son,\n', 'aunque ninguno lo entiende.\n']<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下表列出了一些最常用的文件方法。</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1gup4xa6mknj60yg0e8q7h02.jpg" alt="Python重要的文件方法或属性"></p><h5 id="文件的字节和Unicode"><a href="#文件的字节和Unicode" class="headerlink" title="文件的字节和Unicode"></a>文件的字节和Unicode</h5><p>Python文件的默认操作是“文本模式”，也就是说，你需要处理Python的字符串（即Unicode）。它与“二进制模式”相对，文件模式加一个b。我们来看上一节的文件（UTF-8编码、包含非ASCII字符）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">230</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">with open(path) as f</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     chars = f.read(10)In <span class="token punctuation">[</span><span class="token number">231</span><span class="token punctuation">]</span><span class="token punctuation">:</span> charsOut<span class="token punctuation">[</span><span class="token number">231</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'Sueña el r'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>UTF-8是长度可变的Unicode编码，所以当我从文件请求一定数量的字符时，Python会从文件读取足够多（可能少至10或多至40字节）的字节进行解码。如果以“rb”模式打开文件，则读取确切的请求字节数：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">232</span><span class="token punctuation">]</span><span class="token punctuation">:</span> with open(path<span class="token punctuation">,</span> 'rb') as f<span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     data = f.read(10)In <span class="token punctuation">[</span><span class="token number">233</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">233</span><span class="token punctuation">]</span><span class="token punctuation">:</span> b'Sue\xc3\xb1a el '<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>取决于文本的编码，你可以将字节解码为str对象，但只有当<u>每个编码的Unicode字符都完全成形时</u>才能这么做：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">234</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.decode('utf8')Out<span class="token punctuation">[</span><span class="token number">234</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'Sueña el '</span>In <span class="token punctuation">[</span><span class="token number">235</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>.decode('utf8')<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>UnicodeDecodeError                        Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>235<span class="token punctuation">-</span>300e0af10bb7<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>.decode('utf8')<span class="token key atrule">UnicodeDecodeError</span><span class="token punctuation">:</span> 'utf<span class="token punctuation">-</span><span class="token key atrule">8' codec can't decode byte 0xc3 in position 3</span><span class="token punctuation">:</span> unexpected end of data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>文本模式结合了<code>open</code>的编码选项，提供了一种更方便的方法将Unicode转换为另一种编码：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">236</span><span class="token punctuation">]</span><span class="token punctuation">:</span> sink_path = 'sink.txt'In <span class="token punctuation">[</span><span class="token number">237</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">with open(path) as source</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     with open(sink_path<span class="token punctuation">,</span> <span class="token string">'xt'</span><span class="token punctuation">,</span> <span class="token key atrule">encoding='iso-8859-1') as sink</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>         sink.write(source.read())In <span class="token punctuation">[</span><span class="token number">238</span><span class="token punctuation">]</span><span class="token punctuation">:</span> with open(sink_path<span class="token punctuation">,</span> <span class="token key atrule">encoding='iso-8859-1') as f</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     print(f.read(10))Sueña el r<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意，<u>不要在二进制模式中使用<code>seek</code></u>。如果文件位置位于定义Unicode字符的字节的中间位置，读取后面会产生错误：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">240</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f = open(path)In <span class="token punctuation">[</span><span class="token number">241</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f.read(5)Out<span class="token punctuation">[</span><span class="token number">241</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token string">'Sueña'</span>In <span class="token punctuation">[</span><span class="token number">242</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f.seek(4)Out<span class="token punctuation">[</span><span class="token number">242</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">4</span>In <span class="token punctuation">[</span><span class="token number">243</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f.read(1)<span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span><span class="token punctuation">---</span>UnicodeDecodeError                        Traceback (most recent call last)&lt;ipython<span class="token punctuation">-</span>input<span class="token punctuation">-</span>243<span class="token punctuation">-</span>7841103e33f5<span class="token punctuation">&gt;</span> in &lt;module<span class="token punctuation">&gt;</span>()<span class="token punctuation">---</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 1 f.read(1)/miniconda/envs/book<span class="token punctuation">-</span>env/lib/python3.6/codecs.py in decode(self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> final)    319         <span class="token comment"># decode input (taking the buffer into account)</span>    320         data = self.buffer + input<span class="token punctuation">-</span><span class="token punctuation">-</span><span class="token punctuation">&gt;</span> 321         (result<span class="token punctuation">,</span> consumed) = self._buffer_decode(data<span class="token punctuation">,</span> self.errors<span class="token punctuation">,</span> final)    322         <span class="token comment"># keep undecoded input until the next call</span>    323         self.buffer = data<span class="token punctuation">[</span>consumed<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token key atrule">UnicodeDecodeError</span><span class="token punctuation">:</span> 'utf<span class="token punctuation">-</span><span class="token key atrule">8' codec can't decode byte 0xb1 in position 0</span><span class="token punctuation">:</span> invalid start byteIn <span class="token punctuation">[</span><span class="token number">244</span><span class="token punctuation">]</span><span class="token punctuation">:</span> f.close()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果你经常要对非ASCII字符文本进行数据分析，通晓Python的Unicode功能是非常重要的。更多内容，参阅Python官方文档。</p><h2 id="第-04-章-NumPy-基础：数组和矢量计算"><a href="#第-04-章-NumPy-基础：数组和矢量计算" class="headerlink" title="第 04 章 NumPy 基础：数组和矢量计算"></a><a href="https://www.bookstack.cn/read/pyda-2e-zh/4.md">第 04 章 NumPy 基础：数组和矢量计算</a></h2><p>NumPy（Numerical Python的简称）是Python数值计算最重要的基础包。大多数提供科学计算的包都是用NumPy的数组作为构建基础。</p><p>NumPy的部分功能如下：</p><ul><li>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。</li><li>用于对整组数据进行快速运算的标准数学函数（无需编写循环）。</li><li>用于读写磁盘数据的工具以及用于操作内存映射文件的工具。</li><li>线性代数、随机数生成以及傅里叶变换功能。</li><li>用于集成由C、C++、Fortran等语言编写的代码的A C API。</li></ul><p>由于NumPy提供了一个简单易用的C API，因此很容易将数据传递给由低级语言编写的外部库，外部库也能以NumPy数组的形式将数据返回给Python。这个功能使Python成为一种包装C/C++/Fortran历史代码库的选择，并使被包装库拥有一个动态的、易用的接口。</p><p>NumPy本身并没有提供多么高级的数据分析功能，<u>理解NumPy数组以及面向数组的计算</u>将有助于你更加高效地使用诸如pandas之类的工具。因为NumPy是一个很大的题目，我会在附录A中介绍更多NumPy高级功能，比如广播。</p><p>对于大部分数据分析应用而言，我最关注的功能主要集中在：</p><ul><li>用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。</li><li>常用的数组算法，如排序、唯一化、集合运算等。</li><li>高效的描述统计和数据聚合/摘要运算。</li><li>用于异构数据集的合并/连接运算的数据对齐和关系型数据运算。</li><li>将条件逻辑表述为数组表达式（而不是带有if-elif-else分支的循环）。</li><li>数据的分组运算（聚合、转换、函数应用等）</li></ul><p>虽然NumPy提供了通用的数值数据处理的计算基础，但大多数读者可能还是想将<u>pandas作为统计和分析工作</u>的基础，尤其是处理表格数据时。pandas还提供了一些NumPy所没有的领域特定的功能，如时间序列处理等。</p><ul><li>笔记：Python的面向数组计算可以追溯到1995年，Jim Hugunin创建了Numeric库。接下来的10年，许多科学编程社区纷纷开始使用Python的数组编程，但是进入21世纪，库的生态系统变得碎片化了。2005年，Travis Oliphant从Numeric和Numarray项目整了出了NumPy项目，进而所有社区都集合到了这个框架下。</li></ul><p>NumPy之于数值计算特别重要的原因之一，是因为它可以高效处理大数组的数据。这是因为：</p><ul><li>NumPy是在一个连续的内存块中存储数据，独立于其他Python内置对象。NumPy的C语言编写的算法库可以操作内存，而不必进行类型检查或其它前期工作。比起Python的内置序列，NumPy数组使用的内存更少。</li><li>NumPy可以在整个数组上执行复杂的计算，而不需要Python的for循环。</li></ul><p>要搞明白具体的性能差距，考察一个包含一百万整数的数组，和一个等价的Python列表：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">:</span> import numpy as npIn <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">:</span> my_arr = np.arange(1000000)In <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">:</span> my_list = list(range(1000000))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>各个序列分别乘以2：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">:</span> %time for _ in range(10)<span class="token punctuation">:</span> my_arr2 = my_arr * 2<span class="token key atrule">CPU times</span><span class="token punctuation">:</span> user 20 ms<span class="token punctuation">,</span> <span class="token key atrule">sys</span><span class="token punctuation">:</span> 50 ms<span class="token punctuation">,</span> <span class="token key atrule">total</span><span class="token punctuation">:</span> 70 ms<span class="token key atrule">Wall time</span><span class="token punctuation">:</span> 72.4 msIn <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">:</span> %time for _ in range(10)<span class="token punctuation">:</span> my_list2 = <span class="token punctuation">[</span>x * 2 for x in my_list<span class="token punctuation">]</span><span class="token key atrule">CPU times</span><span class="token punctuation">:</span> user 760 ms<span class="token punctuation">,</span> <span class="token key atrule">sys</span><span class="token punctuation">:</span> 290 ms<span class="token punctuation">,</span> <span class="token key atrule">total</span><span class="token punctuation">:</span> 1.05 s<span class="token key atrule">Wall time</span><span class="token punctuation">:</span> 1.05 s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>基于NumPy的算法要比纯Python快10到100倍（甚至更快），并且使用的内存更少。</p><h3 id="4-1-NumPy的ndarray：一种多维数组对象"><a href="#4-1-NumPy的ndarray：一种多维数组对象" class="headerlink" title="4.1 NumPy的ndarray：一种多维数组对象"></a>4.1 NumPy的ndarray：一种多维数组对象</h3><p><code>NumPy</code>最重要的一个特点就是其N维数组对象（即<code>ndarray</code>），该对象是一个快速而灵活的大数据集容器。你可以利用这种数组对整块数据执行一些数学运算，其语法跟标量元素之间的运算一样。</p><p>要明白Python是如何利用与标量值类似的语法进行批次计算，我先引入<code>NumPy</code>，然后生成一个包含随机数据的小数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">:</span> import numpy as np<span class="token comment"># Generate some random data</span>In <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data = np.random.randn(2<span class="token punctuation">,</span> 3)In <span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-0.2047</span><span class="token punctuation">,</span>  <span class="token number">0.4789</span><span class="token punctuation">,</span> <span class="token number">-0.5194</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">-0.5557</span><span class="token punctuation">,</span>  <span class="token number">1.9658</span><span class="token punctuation">,</span>  <span class="token number">1.3934</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后进行数学运算：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data * 10Out<span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">-2.0471</span><span class="token punctuation">,</span>   <span class="token number">4.7894</span><span class="token punctuation">,</span>  <span class="token number">-5.1944</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span> <span class="token number">-5.5573</span><span class="token punctuation">,</span>  <span class="token number">19.6578</span><span class="token punctuation">,</span>  <span class="token number">13.9341</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data + dataOut<span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-0.4094</span><span class="token punctuation">,</span>  <span class="token number">0.9579</span><span class="token punctuation">,</span> <span class="token number">-1.0389</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">-1.1115</span><span class="token punctuation">,</span>  <span class="token number">3.9316</span><span class="token punctuation">,</span>  <span class="token number">2.7868</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>第一个例子中，所有的元素都乘以10。第二个例子中，每个元素都与自身相加。</p><blockquote><p>笔记：在本章及全书中，我会使用标准的NumPy惯用法<code>import numpy as np</code>。你当然也可以在代码中使用<code>from numpy import *</code>，但不建议这么做。<code>numpy</code>的命名空间很大，包含许多函数，其中一些的名字与Python的内置函数重名（比如min和max）。</p></blockquote><p>ndarray是一个通用的同构数据多维容器，也就是说，其中的所有元素必须是相同类型的。每个数组都有一个shape（一个表示各维度大小的元组）和一个dtype（一个用于说明数组数据类型的对象）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.shapeOut<span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (2<span class="token punctuation">,</span> 3)In <span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.dtypeOut<span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtype('float64')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>本章将会介绍<code>NumPy</code>数组的基本用法，这对于本书后面各章的理解基本够用。虽然大多数数据分析工作不需要深入理解<code>NumPy</code>，但是精通面向数组的编程和思维方式是成为Python科学计算牛人的一大关键步骤。</p><blockquote><p>笔记：当你在本书中看到“数组”、“<code>NumPy</code>数组”、”<code>ndarray</code>”时，基本上都指的是同一样东西，即<code>ndarray</code>对象。</p></blockquote><h4 id="创建ndarray"><a href="#创建ndarray" class="headerlink" title="创建ndarray"></a>创建<code>ndarray</code></h4><p>创建数组最简单的办法就是使用<code>array</code>函数。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的<code>NumPy</code>数组。以一个列表的转换为例：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data1 = <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7.5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr1 = np.array(data1)In <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr1Out<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">6.</span> <span class="token punctuation">,</span>  <span class="token number">7.5</span><span class="token punctuation">,</span>  <span class="token number">8.</span> <span class="token punctuation">,</span>  <span class="token number">0.</span> <span class="token punctuation">,</span>  <span class="token number">1.</span> <span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data2 = <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2 = np.array(data2)In <span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2Out<span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>因为data2是列表的列表，<code>NumPy</code>数组arr2的两个维度的shape是从data2引入的。可以用属性ndim和shape验证：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2.ndimOut<span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">2</span>In <span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2.shapeOut<span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (2<span class="token punctuation">,</span> 4)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>除非特别说明（稍后将会详细介绍），<code>np.array</code>会尝试为新建的这个数组推断出一个较为合适的数据类型。数据类型保存在一个特殊的<code>dtype</code>对象中。比如说，在上面的两个例子中，我们有：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr1.dtypeOut<span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtype('float64')In <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2.dtypeOut<span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtype('int64')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>除<code>np.array</code>之外，还有一些函数也可以新建数组。比如，zeros和ones分别可以创建指定长度或形状的全0或全1数组。empty可以创建一个没有任何具体值的数组。要用这些方法创建多维数组，只需传入一个表示形状的元组即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.zeros(10)Out<span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.zeros((3<span class="token punctuation">,</span> 6))Out<span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.empty((2<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> 2))Out<span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>注意：认为np.empty会返回全0数组的想法是不安全的。很多情况下（如前所示），它返回的都是一些未初始化的垃圾值。</p></blockquote><p><code>arange</code>是Python内置函数<code>range</code>的数组版：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.arange(15)Out<span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了一些数组创建函数。由于NumPy关注的是数值计算，因此，如果没有特别指定，数据类型基本都是float64（浮点数）。</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1guq8uv8wuzj60jc08xtd802.jpg" alt="数组创建函数"></p><h4 id="ndarray的数据类型"><a href="#ndarray的数据类型" class="headerlink" title="ndarray的数据类型"></a><code>ndarray</code>的数据类型</h4><p>dtype（数据类型）是一个特殊的对象，它含有<code>ndarray</code>将一块内存解释为特定数据类型所需的信息：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr1 = np.array(<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=np.float64)    In <span class="token punctuation">[</span><span class="token number">34</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2 = np.array(<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=np.int32)    In <span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr1.dtype    Out<span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtype('float64')    In <span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2.dtype    Out<span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtype('int32')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>dtype是<code>NumPy</code>灵活交互其它系统的源泉之一。多数情况下，它们直接映射到相应的机器表示，这使得“读写磁盘上的二进制数据流”以及“集成低级语言代码（如C、Fortran）”等工作变得更加简单。数值型dtype的命名方式相同：一个类型名（如float或int），后面跟一个用于表示各元素位长的数字。标准的双精度浮点值（即Python中的float对象）需要占用8字节（即64位）。因此，该类型在NumPy中就记作float64。下表列出了NumPy所支持的全部数据类型。</p><blockquote><p>笔记：记不住这些NumPy的dtype也没关系，新手更是如此。通常只需要知道你所处理的数据的大致类型是浮点数、复数、整数、布尔值、字符串，还是普通的Python对象即可。当你需要控制数据在内存和磁盘中的存储方式时（尤其是对大数据集），那就得了解如何控制存储类型。</p></blockquote><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1guq8vovj85j60y30l0jxz02.jpg" alt="一种多维数组对象"></p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1guq8vq13wkj60y30boq6002.jpg" alt="一种多维数组对象"></p><p>你可以通过<code>ndarray</code>的astype方法明确地将一个数组从一个dtype转换成另一个dtype：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.array(<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.dtypeOut<span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtype('int64')In <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">:</span> float_arr = arr.astype(np.float64)In <span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">:</span> float_arr.dtypeOut<span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dtype('float64')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在本例中，整数被转换成了浮点数。如果将浮点数转换成整数，则小数部分将会被截取删除：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">41</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.array(<span class="token punctuation">[</span><span class="token number">3.7</span><span class="token punctuation">,</span> <span class="token number">-1.2</span><span class="token punctuation">,</span> <span class="token number">-2.6</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">12.9</span><span class="token punctuation">,</span> <span class="token number">10.1</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>  <span class="token number">3.7</span><span class="token punctuation">,</span>  <span class="token number">-1.2</span><span class="token punctuation">,</span>  <span class="token number">-2.6</span><span class="token punctuation">,</span>   <span class="token number">0.5</span><span class="token punctuation">,</span>  <span class="token number">12.9</span><span class="token punctuation">,</span>  <span class="token number">10.1</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.astype(np.int32)Out<span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">-2</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=int32)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果某字符串数组表示的全是数字，也可以用astype将其转换为数值形式：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">44</span><span class="token punctuation">]</span><span class="token punctuation">:</span> numeric_strings = np.array(<span class="token punctuation">[</span><span class="token string">'1.25'</span><span class="token punctuation">,</span> <span class="token string">'-9.6'</span><span class="token punctuation">,</span> <span class="token string">'42'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=np.string_)In <span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">:</span> numeric_strings.astype(float)Out<span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>  <span class="token number">1.25</span><span class="token punctuation">,</span>  <span class="token number">-9.6</span> <span class="token punctuation">,</span>  <span class="token number">42.</span>  <span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>注意：使用<code>numpy.string</code>_类型时，一定要小心，因为<code>NumPy</code>的字符串数据是大小固定的，发生截取时，不会发出警告。<code>pandas</code>提供了更多非数值数据的便利的处理方法。</p></blockquote><p>如果转换过程因为某种原因而失败了（比如某个不能被转换为float64的字符串），就会引发一个ValueError。这里，我比较懒，写的是float而不是np.float64；NumPy很聪明，它会将Python类型映射到等价的dtype上。</p><p>数组的dtype还有另一个属性：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span><span class="token punctuation">:</span> int_array = np.arange(10)In <span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span><span class="token punctuation">:</span> calibers = np.array(<span class="token punctuation">[</span><span class="token number">.22</span><span class="token punctuation">,</span> <span class="token number">.270</span><span class="token punctuation">,</span> <span class="token number">.357</span><span class="token punctuation">,</span> <span class="token number">.380</span><span class="token punctuation">,</span> <span class="token number">.44</span><span class="token punctuation">,</span> <span class="token number">.50</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=np.float64)In <span class="token punctuation">[</span><span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">:</span> int_array.astype(calibers.dtype)Out<span class="token punctuation">[</span><span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">7.</span><span class="token punctuation">,</span>  <span class="token number">8.</span><span class="token punctuation">,</span>  <span class="token number">9.</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>你还可以用简洁的类型代码来表示dtype：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">49</span><span class="token punctuation">]</span><span class="token punctuation">:</span> empty_uint32 = np.empty(8<span class="token punctuation">,</span> dtype='u4')In <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">:</span> empty_uint32Out<span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>         <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1075314688</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1075707904</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">,</span>       <span class="token number">1075838976</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1072693248</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=uint32)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>笔记：调用astype总会创建一个新的数组（一个数据的备份），即使新的dtype与旧的dtype相同。</p></blockquote><h4 id="NumPy数组的运算"><a href="#NumPy数组的运算" class="headerlink" title="NumPy数组的运算"></a><code>NumPy</code>数组的运算</h4><p>数组很重要，因为它使你不用编写循环即可对数据执行批量运算。NumPy用户称其为矢量化（vectorization）。大小相等的数组之间的任何算术运算都会将运算应用到元素级：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">,</span> <span class="token number">6.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">53</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr * arrOut<span class="token punctuation">[</span><span class="token number">53</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">1.</span><span class="token punctuation">,</span>   <span class="token number">4.</span><span class="token punctuation">,</span>   <span class="token number">9.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">16.</span><span class="token punctuation">,</span>  <span class="token number">25.</span><span class="token punctuation">,</span>  <span class="token number">36.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">54</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token punctuation">-</span> arrOut<span class="token punctuation">[</span><span class="token number">54</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>数组与标量的算术运算会将标量值传播到各个元素：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 1 / arrOut<span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.</span>    <span class="token punctuation">,</span>  <span class="token number">0.5</span>   <span class="token punctuation">,</span>  <span class="token number">0.3333</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.25</span>  <span class="token punctuation">,</span>  <span class="token number">0.2</span>   <span class="token punctuation">,</span>  <span class="token number">0.1667</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">56</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token important">**</span> 0.5Out<span class="token punctuation">[</span><span class="token number">56</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.</span>    <span class="token punctuation">,</span>  <span class="token number">1.4142</span><span class="token punctuation">,</span>  <span class="token number">1.7321</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.2361</span><span class="token punctuation">,</span>  <span class="token number">2.4495</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>大小相同的数组之间的比较会生成布尔值数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">57</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2 = np.array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">12.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">58</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2Out<span class="token punctuation">[</span><span class="token number">58</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0.</span><span class="token punctuation">,</span>   <span class="token number">4.</span><span class="token punctuation">,</span>   <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">7.</span><span class="token punctuation">,</span>   <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">12.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">59</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2 <span class="token punctuation">&gt;</span> arrOut<span class="token punctuation">[</span><span class="token number">59</span><span class="token punctuation">]</span><span class="token punctuation">:</span>array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=bool)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>不同大小的数组之间的运算叫做广播（broadcasting），将在附录A中对其进行详细讨论。本书的内容不需要对广播机制有多深的理解。</p><h4 id="基本的索引和切片"><a href="#基本的索引和切片" class="headerlink" title="基本的索引和切片"></a>基本的索引和切片</h4><p>NumPy数组的索引是一个内容丰富的主题，因为选取数据子集或单个元素的方式有很多。一维数组很简单。从表面上看，它们跟Python列表的功能差不多：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.arange(10)In <span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">62</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">62</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 5In <span class="token punctuation">[</span><span class="token number">63</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span>5<span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">63</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span>5<span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span> = 12In <span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如上所示，当你将一个标量值赋值给一个切片时（如arr[5:8]=12），该值会自动传播（也就说后面将会讲到的“广播”）到整个选区。跟列表最重要的区别在于，数组切片是原始数组的视图。这意味着数据不会被复制，视图上的任何修改都会直接反映到源数组上。</p><p>作为例子，先创建一个arr的切片：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr_slice = arr<span class="token punctuation">[</span>5<span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr_sliceOut<span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在，当我修稿arr_slice中的值，变动也会体现在原始数组arr中：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">68</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr_slice<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> = 12345In <span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>    <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">1</span><span class="token punctuation">,</span>     <span class="token number">2</span><span class="token punctuation">,</span>     <span class="token number">3</span><span class="token punctuation">,</span>     <span class="token number">4</span><span class="token punctuation">,</span>    <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12345</span><span class="token punctuation">,</span>    <span class="token number">12</span><span class="token punctuation">,</span>     <span class="token number">8</span><span class="token punctuation">,</span>   <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>切片[ : ]会给数组中的所有值赋值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr_slice<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> = 64In <span class="token punctuation">[</span><span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果你刚开始接触NumPy，可能会对此感到惊讶（尤其是当你曾经用过其他热衷于复制数组数据的编程语言）。由于NumPy的设计目的是处理大数据，所以你可以想象一下，假如NumPy坚持要将数据复制来复制去的话会产生何等的性能和内存问题。</p><blockquote><p>注意：如果你想要得到的是ndarray切片的一份副本而非视图，就需要明确地进行复制操作，例如<code>arr[5:8].copy()</code>。</p></blockquote><p>对于高维度数组，能做的事情更多。在一个二维数组中，各索引位置上的元素不再是标量而是一维数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">72</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d = np.array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因此，可以对各个元素进行递归访问，但这样需要做的事情有点多。你可以传入一个以逗号隔开的索引列表来选取单个元素。也就是说，下面两种方式是等价的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 3In <span class="token punctuation">[</span><span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">3</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下图说明了二维数组的索引方式。轴0作为行，轴1作为列。</p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1guq91p9gxzj60kp0ifws802.jpg" alt="NumPy数组中的元素索引"></p><p>在多维数组中，如果省略了后面的索引，则返回对象会是一个维度低一点的<code>ndarray</code>（它含有高一级维度上的所有数据）。因此，在2×2×3数组arr3d中：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3d = np.array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">77</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3dOut<span class="token punctuation">[</span><span class="token number">77</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>arr3d[0]是一个2×3数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">78</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    Out<span class="token punctuation">[</span><span class="token number">78</span><span class="token punctuation">]</span><span class="token punctuation">:</span>     array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>标量值和数组都可以被赋值给arr3d[0]：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">79</span><span class="token punctuation">]</span><span class="token punctuation">:</span> old_values = arr3d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>.copy()    In <span class="token punctuation">[</span><span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> = 42    In <span class="token punctuation">[</span><span class="token number">81</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3d    Out<span class="token punctuation">[</span><span class="token number">81</span><span class="token punctuation">]</span><span class="token punctuation">:</span>     array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)    In <span class="token punctuation">[</span><span class="token number">82</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> = old_values    In <span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3d    Out<span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">]</span><span class="token punctuation">:</span>     array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>相似的，arr3d[1,0]可以访问索引以(1,0)开头的那些值（以一维数组的形式返回）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr3d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>    Out<span class="token punctuation">[</span><span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>虽然是用两步进行索引的，表达式是相同的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x = arr3d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    In <span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x    Out<span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span><span class="token punctuation">:</span>     array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)    In <span class="token punctuation">[</span><span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    Out<span class="token punctuation">[</span><span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意，在上面所有这些选取数组子集的例子中，返回的数组都是视图。</p><h4 id="切片索引"><a href="#切片索引" class="headerlink" title="切片索引"></a>切片索引</h4><p>ndarray的切片语法跟Python列表这样的一维对象差不多：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span>1<span class="token punctuation">:</span><span class="token number">6</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于之前的二维数组arr2d，其切片方式稍显不同：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">90</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2dOut<span class="token punctuation">[</span><span class="token number">90</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">91</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">91</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看出，它是沿着第0轴（即第一个轴）切片的。也就是说，切片是沿着一个轴向选取元素的。表达式arr2d[:2]可以被认为是“选取arr2d的前两行”。</p><p>你可以一次传入多个切片，就像传入多个索引那样：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> 1<span class="token punctuation">:</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>像这样进行切片时，只能得到相同维数的数组视图。通过将整数索引和切片混合，可以得到低维度的切片。</p><p>例如，我可以选取第二行的前两列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>相似的，还可以选择第三列的前两行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下图对此进行了说明。注意，“只有冒号”表示选取整个轴，因此你可以像下面这样只对高维轴进行切片：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://static.sitestack.cn/projects/pyda-2e-zh/img/7178691-9da32d2f4629c304.png" alt="图4-2 二维数组切片"></p><p>自然，对切片表达式的赋值操作也会被扩散到整个选区：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> 1<span class="token punctuation">:</span><span class="token punctuation">]</span> = 0In <span class="token punctuation">[</span><span class="token number">97</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr2dOut<span class="token punctuation">[</span><span class="token number">97</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="布尔型索引"><a href="#布尔型索引" class="headerlink" title="布尔型索引"></a>布尔型索引</h4><p>来看这样一个例子，假设我们有一个用于存储数据的数组以及一个存储姓名的数组（含有重复项）。在这里，我将使用numpy.random中的randn函数生成一些正态分布的随机数据：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">98</span><span class="token punctuation">]</span><span class="token punctuation">:</span> names = np.array(<span class="token punctuation">[</span><span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">,</span> <span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data = np.random.randn(7<span class="token punctuation">,</span> 4)In <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">:</span> namesOut<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">,</span> <span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype='&lt;U4')In <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0929</span><span class="token punctuation">,</span>  <span class="token number">0.2817</span><span class="token punctuation">,</span>  <span class="token number">0.769</span> <span class="token punctuation">,</span>  <span class="token number">1.2464</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.0072</span><span class="token punctuation">,</span> <span class="token number">-1.2962</span><span class="token punctuation">,</span>  <span class="token number">0.275</span> <span class="token punctuation">,</span>  <span class="token number">0.2289</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.3529</span><span class="token punctuation">,</span>  <span class="token number">0.8864</span><span class="token punctuation">,</span> <span class="token number">-2.0016</span><span class="token punctuation">,</span> <span class="token number">-0.3718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.669</span> <span class="token punctuation">,</span> <span class="token number">-0.4386</span><span class="token punctuation">,</span> <span class="token number">-0.5397</span><span class="token punctuation">,</span>  <span class="token number">0.477</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.2489</span><span class="token punctuation">,</span> <span class="token number">-1.0212</span><span class="token punctuation">,</span> <span class="token number">-0.5771</span><span class="token punctuation">,</span>  <span class="token number">0.1241</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.3026</span><span class="token punctuation">,</span>  <span class="token number">0.5238</span><span class="token punctuation">,</span>  <span class="token number">0.0009</span><span class="token punctuation">,</span>  <span class="token number">1.3438</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.7135</span><span class="token punctuation">,</span> <span class="token number">-0.8312</span><span class="token punctuation">,</span> <span class="token number">-2.3702</span><span class="token punctuation">,</span> <span class="token number">-1.8608</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>假设每个名字都对应data数组中的一行，而我们想要选出对应于名字”Bob”的所有行。跟算术运算一样，数组的比较运算（如==）也是矢量化的。因此，对names和字符串”Bob”的比较运算将会产生一个布尔型数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">:</span> names == 'Bob'Out<span class="token punctuation">[</span><span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=bool)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个布尔型数组可用于数组索引：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>names == 'Bob'<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0929</span><span class="token punctuation">,</span>  <span class="token number">0.2817</span><span class="token punctuation">,</span>  <span class="token number">0.769</span> <span class="token punctuation">,</span>  <span class="token number">1.2464</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.669</span> <span class="token punctuation">,</span> <span class="token number">-0.4386</span><span class="token punctuation">,</span> <span class="token number">-0.5397</span><span class="token punctuation">,</span>  <span class="token number">0.477</span> <span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>布尔型数组的长度必须跟被索引的轴长度一致。此外，还可以将布尔型数组跟切片、整数（或整数序列，稍后将对此进行详细讲解）混合使用：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>names == 'Bob'<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0929</span><span class="token punctuation">,</span>  <span class="token number">0.2817</span><span class="token punctuation">,</span>  <span class="token number">0.769</span> <span class="token punctuation">,</span>  <span class="token number">1.2464</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.669</span> <span class="token punctuation">,</span> <span class="token number">-0.4386</span><span class="token punctuation">,</span> <span class="token number">-0.5397</span><span class="token punctuation">,</span>  <span class="token number">0.477</span> <span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>注意：如果布尔型数组的长度不对，布尔型选择就会出错，因此一定要小心。</p></blockquote><p>下面的例子，我选取了<code>names == 'Bob'</code>的行，并索引了列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">104</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>names == 'Bob'<span class="token punctuation">,</span> 2<span class="token punctuation">:</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">104</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.769</span> <span class="token punctuation">,</span>  <span class="token number">1.2464</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.5397</span><span class="token punctuation">,</span>  <span class="token number">0.477</span> <span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">105</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>names == 'Bob'<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">105</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">1.2464</span><span class="token punctuation">,</span>  <span class="token number">0.477</span> <span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>要选择除”Bob”以外的其他值，既可以使用不等于符号（!=），也可以通过~对条件进行否定：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> names <span class="token tag">!=</span> 'Bob'Out<span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=bool)In <span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>~(names == 'Bob')<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span><span class="token punctuation">:</span>array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0072</span><span class="token punctuation">,</span> <span class="token number">-1.2962</span><span class="token punctuation">,</span>  <span class="token number">0.275</span> <span class="token punctuation">,</span>  <span class="token number">0.2289</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.3529</span><span class="token punctuation">,</span>  <span class="token number">0.8864</span><span class="token punctuation">,</span> <span class="token number">-2.0016</span><span class="token punctuation">,</span> <span class="token number">-0.3718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.2489</span><span class="token punctuation">,</span> <span class="token number">-1.0212</span><span class="token punctuation">,</span> <span class="token number">-0.5771</span><span class="token punctuation">,</span>  <span class="token number">0.1241</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.3026</span><span class="token punctuation">,</span>  <span class="token number">0.5238</span><span class="token punctuation">,</span>  <span class="token number">0.0009</span><span class="token punctuation">,</span>  <span class="token number">1.3438</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.7135</span><span class="token punctuation">,</span> <span class="token number">-0.8312</span><span class="token punctuation">,</span> <span class="token number">-2.3702</span><span class="token punctuation">,</span> <span class="token number">-1.8608</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>~操作符用来反转条件很好用：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">108</span><span class="token punctuation">]</span><span class="token punctuation">:</span> cond = names == 'Bob'In <span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>~cond<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0072</span><span class="token punctuation">,</span> <span class="token number">-1.2962</span><span class="token punctuation">,</span>  <span class="token number">0.275</span> <span class="token punctuation">,</span>  <span class="token number">0.2289</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.3529</span><span class="token punctuation">,</span>  <span class="token number">0.8864</span><span class="token punctuation">,</span> <span class="token number">-2.0016</span><span class="token punctuation">,</span> <span class="token number">-0.3718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.2489</span><span class="token punctuation">,</span> <span class="token number">-1.0212</span><span class="token punctuation">,</span> <span class="token number">-0.5771</span><span class="token punctuation">,</span>  <span class="token number">0.1241</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.3026</span><span class="token punctuation">,</span>  <span class="token number">0.5238</span><span class="token punctuation">,</span>  <span class="token number">0.0009</span><span class="token punctuation">,</span>  <span class="token number">1.3438</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.7135</span><span class="token punctuation">,</span> <span class="token number">-0.8312</span><span class="token punctuation">,</span> <span class="token number">-2.3702</span><span class="token punctuation">,</span> <span class="token number">-1.8608</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>选取这三个名字中的两个需要组合应用多个布尔条件，使用&amp;（和）、|（或）之类的布尔算术运算符即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">110</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mask = (names == 'Bob') <span class="token punctuation">|</span> (names == 'Will')In <span class="token punctuation">[</span><span class="token number">111</span><span class="token punctuation">]</span><span class="token punctuation">:</span> maskOut<span class="token punctuation">[</span><span class="token number">111</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=bool)In <span class="token punctuation">[</span><span class="token number">112</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">112</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0929</span><span class="token punctuation">,</span>  <span class="token number">0.2817</span><span class="token punctuation">,</span>  <span class="token number">0.769</span> <span class="token punctuation">,</span>  <span class="token number">1.2464</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.3529</span><span class="token punctuation">,</span>  <span class="token number">0.8864</span><span class="token punctuation">,</span> <span class="token number">-2.0016</span><span class="token punctuation">,</span> <span class="token number">-0.3718</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.669</span> <span class="token punctuation">,</span> <span class="token number">-0.4386</span><span class="token punctuation">,</span> <span class="token number">-0.5397</span><span class="token punctuation">,</span>  <span class="token number">0.477</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.2489</span><span class="token punctuation">,</span> <span class="token number">-1.0212</span><span class="token punctuation">,</span> <span class="token number">-0.5771</span><span class="token punctuation">,</span>  <span class="token number">0.1241</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过布尔型索引选取数组中的数据，将总是创建数据的副本，即使返回一模一样的数组也是如此。</p><blockquote><p>注意：Python关键字and和or在布尔型数组中无效。要使用&amp;与|。</p></blockquote><p>通过布尔型数组设置值是一种经常用到的手段。为了将data中的所有负值都设置为0，我们只需：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">113</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>data &lt; 0<span class="token punctuation">]</span> = 0In <span class="token punctuation">[</span><span class="token number">114</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">114</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0929</span><span class="token punctuation">,</span>  <span class="token number">0.2817</span><span class="token punctuation">,</span>  <span class="token number">0.769</span> <span class="token punctuation">,</span>  <span class="token number">1.2464</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.0072</span><span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.275</span> <span class="token punctuation">,</span>  <span class="token number">0.2289</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.3529</span><span class="token punctuation">,</span>  <span class="token number">0.8864</span><span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.669</span> <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.477</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.2489</span><span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.1241</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.3026</span><span class="token punctuation">,</span>  <span class="token number">0.5238</span><span class="token punctuation">,</span>  <span class="token number">0.0009</span><span class="token punctuation">,</span>  <span class="token number">1.3438</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过一维布尔数组设置整行或列的值也很简单：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">115</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>names <span class="token tag">!=</span> 'Joe'<span class="token punctuation">]</span> = 7In <span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.0072</span><span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.275</span> <span class="token punctuation">,</span>  <span class="token number">0.2289</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">,</span>  <span class="token number">7.</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.3026</span><span class="token punctuation">,</span>  <span class="token number">0.5238</span><span class="token punctuation">,</span>  <span class="token number">0.0009</span><span class="token punctuation">,</span>  <span class="token number">1.3438</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>后面会看到，这类二维数据的操作也可以用pandas方便的来做。</p><h4 id="花式索引"><a href="#花式索引" class="headerlink" title="花式索引"></a>花式索引</h4><p>花式索引（Fancy indexing）是一个NumPy术语，它指的是利用整数数组进行索引。假设我们有一个8×4数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">117</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.empty((8<span class="token punctuation">,</span> 4))In <span class="token punctuation">[</span><span class="token number">118</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">for i in range(8):.....</span><span class="token punctuation">:</span>     arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span> = iIn <span class="token punctuation">[</span><span class="token number">119</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">119</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.</span><span class="token punctuation">,</span>  <span class="token number">7.</span><span class="token punctuation">,</span>  <span class="token number">7.</span><span class="token punctuation">,</span>  <span class="token number">7.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为了以特定顺序选取行子集，只需传入一个用于指定顺序的整数列表或<code>ndarray</code>即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这段代码确实达到我们的要求了！使用负数索引将会从末尾开始选取行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-3</span><span class="token punctuation">,</span> <span class="token number">-5</span><span class="token punctuation">,</span> <span class="token number">-7</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>一次传入多个索引数组会有一点特别。它返回的是一个一维数组，其中的元素对应各个索引元组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">122</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.arange(32).reshape((8<span class="token punctuation">,</span> 4))In <span class="token punctuation">[</span><span class="token number">123</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">123</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>附录A中会详细介绍reshape方法。</p><p>最终选出的是元素(1,0)、(5,3)、(7,1)和(2,2)。无论数组是多少维的，花式索引总是一维的。</p><p>这个花式索引的行为可能会跟某些用户的预期不一样（包括我在内），选取矩阵的行列子集应该是矩形区域的形式才对。下面是得到该结果的一个办法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">125</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">125</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>记住，花式索引跟切片不一样，它总是将数据复制到新数组中。</p></blockquote><h4 id="数组转置和轴对换"><a href="#数组转置和轴对换" class="headerlink" title="数组转置和轴对换"></a>数组转置和轴对换</h4><p>转置是重塑的一种特殊形式，它返回的是源数据的视图（不会进行任何复制操作）。数组不仅有transpose方法，还有一个特殊的T属性：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">126</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.arange(15).reshape((3<span class="token punctuation">,</span> 5))In <span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.TOut<span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在进行矩阵计算时，经常需要用到该操作，比如利用np.dot计算矩阵内积：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">129</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.random.randn(6<span class="token punctuation">,</span> 3)In <span class="token punctuation">[</span><span class="token number">130</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">130</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-0.8608</span><span class="token punctuation">,</span>  <span class="token number">0.5601</span><span class="token punctuation">,</span> <span class="token number">-1.2659</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.1198</span><span class="token punctuation">,</span> <span class="token number">-1.0635</span><span class="token punctuation">,</span>  <span class="token number">0.3329</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-2.3594</span><span class="token punctuation">,</span> <span class="token number">-0.1995</span><span class="token punctuation">,</span> <span class="token number">-1.542</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.9707</span><span class="token punctuation">,</span> <span class="token number">-1.307</span> <span class="token punctuation">,</span>  <span class="token number">0.2863</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.378</span> <span class="token punctuation">,</span> <span class="token number">-0.7539</span><span class="token punctuation">,</span>  <span class="token number">0.3313</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.3497</span><span class="token punctuation">,</span>  <span class="token number">0.0699</span><span class="token punctuation">,</span>  <span class="token number">0.2467</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">131</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.dot(arr.T<span class="token punctuation">,</span> arr)Out<span class="token punctuation">[</span><span class="token number">131</span><span class="token punctuation">]</span><span class="token punctuation">:</span>array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">9.2291</span><span class="token punctuation">,</span>  <span class="token number">0.9394</span><span class="token punctuation">,</span>  <span class="token number">4.948</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.9394</span><span class="token punctuation">,</span>  <span class="token number">3.7662</span><span class="token punctuation">,</span> <span class="token number">-1.3622</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4.948</span> <span class="token punctuation">,</span> <span class="token number">-1.3622</span><span class="token punctuation">,</span>  <span class="token number">4.3437</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于高维数组，transpose需要得到一个由轴编号组成的元组才能对这些轴进行转置（比较费脑子）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">132</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.arange(16).reshape((2<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> 4))In <span class="token punctuation">[</span><span class="token number">133</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">133</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">134</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.transpose((1<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> 2))Out<span class="token punctuation">[</span><span class="token number">134</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里，第一个轴被换成了第二个，第二个轴被换成了第一个，最后一个轴不变。</p><p>简单的转置可以使用.T，它其实就是进行轴对换而已。ndarray还有一个swapaxes方法，它需要接受一对轴编号：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">135</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">135</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">136</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.swapaxes(1<span class="token punctuation">,</span> 2)Out<span class="token punctuation">[</span><span class="token number">136</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>swapaxes也是返回源数据的视图（不会进行任何复制操作）。</p><h3 id="4-2-通用函数：快速的元素级数组函数"><a href="#4-2-通用函数：快速的元素级数组函数" class="headerlink" title="4.2 通用函数：快速的元素级数组函数"></a>4.2 通用函数：快速的元素级数组函数</h3><p>通用函数（即ufunc）是一种对ndarray中的数据执行元素级运算的函数。你可以将其看做简单函数（接受一个或多个标量值，并产生一个或多个标量值）的矢量化包装器。</p><p>许多ufunc都是简单的元素级变体，如<code>sqrt</code>和<code>exp</code>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">137</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.arange(10)In <span class="token punctuation">[</span><span class="token number">138</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">138</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">139</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.sqrt(arr)Out<span class="token punctuation">[</span><span class="token number">139</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">1.</span>    <span class="token punctuation">,</span>  <span class="token number">1.4142</span><span class="token punctuation">,</span>  <span class="token number">1.7321</span><span class="token punctuation">,</span>  <span class="token number">2.</span>    <span class="token punctuation">,</span>  <span class="token number">2.2361</span><span class="token punctuation">,</span>  <span class="token number">2.4495</span><span class="token punctuation">,</span>        <span class="token number">2.6458</span><span class="token punctuation">,</span>  <span class="token number">2.8284</span><span class="token punctuation">,</span>  <span class="token number">3.</span>    <span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">140</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.exp(arr)Out<span class="token punctuation">[</span><span class="token number">140</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>    <span class="token number">1.</span>    <span class="token punctuation">,</span>     <span class="token number">2.7183</span><span class="token punctuation">,</span>     <span class="token number">7.3891</span><span class="token punctuation">,</span>    <span class="token number">20.0855</span><span class="token punctuation">,</span>    <span class="token number">54.5982</span><span class="token punctuation">,</span>         <span class="token number">148.4132</span><span class="token punctuation">,</span>   <span class="token number">403.4288</span><span class="token punctuation">,</span>  <span class="token number">1096.6332</span><span class="token punctuation">,</span>  <span class="token number">2980.958</span> <span class="token punctuation">,</span>  <span class="token number">8103.0839</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这些都是一元（unary）ufunc。另外一些（如<code>add</code>或<code>maximum</code>）接受2个数组（因此也叫二元（binary）ufunc），并返回一个结果数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">141</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x = np.random.randn(8)In <span class="token punctuation">[</span><span class="token number">142</span><span class="token punctuation">]</span><span class="token punctuation">:</span> y = np.random.randn(8)In <span class="token punctuation">[</span><span class="token number">143</span><span class="token punctuation">]</span><span class="token punctuation">:</span> xOut<span class="token punctuation">[</span><span class="token number">143</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">-0.0119</span><span class="token punctuation">,</span>  <span class="token number">1.0048</span><span class="token punctuation">,</span>  <span class="token number">1.3272</span><span class="token punctuation">,</span> <span class="token number">-0.9193</span><span class="token punctuation">,</span> <span class="token number">-1.5491</span><span class="token punctuation">,</span>  <span class="token number">0.0222</span><span class="token punctuation">,</span>  <span class="token number">0.7584</span><span class="token punctuation">,</span>       <span class="token number">-0.6605</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">144</span><span class="token punctuation">]</span><span class="token punctuation">:</span> yOut<span class="token punctuation">[</span><span class="token number">144</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.8626</span><span class="token punctuation">,</span> <span class="token number">-0.01</span>  <span class="token punctuation">,</span>  <span class="token number">0.05</span>  <span class="token punctuation">,</span>  <span class="token number">0.6702</span><span class="token punctuation">,</span>  <span class="token number">0.853</span> <span class="token punctuation">,</span> <span class="token number">-0.9559</span><span class="token punctuation">,</span> <span class="token number">-0.0235</span><span class="token punctuation">,</span>       <span class="token number">-2.3042</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">145</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.maximum(x<span class="token punctuation">,</span> y)Out<span class="token punctuation">[</span><span class="token number">145</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.8626</span><span class="token punctuation">,</span>  <span class="token number">1.0048</span><span class="token punctuation">,</span>  <span class="token number">1.3272</span><span class="token punctuation">,</span>  <span class="token number">0.6702</span><span class="token punctuation">,</span>  <span class="token number">0.853</span> <span class="token punctuation">,</span>  <span class="token number">0.0222</span><span class="token punctuation">,</span>  <span class="token number">0.7584</span><span class="token punctuation">,</span>          <span class="token number">-0.6605</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里，<code>numpy.maximum</code>计算了x和y中元素级别最大的元素。</p><p>虽然并不常见，但有些ufunc的确可以返回多个数组。<code>modf</code>就是一个例子，它是Python内置函数<code>divmod</code>(返回小数)的矢量化版本，<u>它会返回浮点数数组的小数和整数部分</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">146</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.random.randn(7) * 5In <span class="token punctuation">[</span><span class="token number">147</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">147</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">-3.2623</span><span class="token punctuation">,</span> <span class="token number">-6.0915</span><span class="token punctuation">,</span> <span class="token number">-6.663</span> <span class="token punctuation">,</span>  <span class="token number">5.3731</span><span class="token punctuation">,</span>  <span class="token number">3.6182</span><span class="token punctuation">,</span>  <span class="token number">3.45</span>  <span class="token punctuation">,</span>  <span class="token number">5.0077</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">148</span><span class="token punctuation">]</span><span class="token punctuation">:</span> remainder<span class="token punctuation">,</span> whole_part = np.modf(arr)In <span class="token punctuation">[</span><span class="token number">149</span><span class="token punctuation">]</span><span class="token punctuation">:</span> remainderOut<span class="token punctuation">[</span><span class="token number">149</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">-0.2623</span><span class="token punctuation">,</span> <span class="token number">-0.0915</span><span class="token punctuation">,</span> <span class="token number">-0.663</span> <span class="token punctuation">,</span>  <span class="token number">0.3731</span><span class="token punctuation">,</span><span class="token number">0.6182</span><span class="token punctuation">,</span>  <span class="token number">0.45</span>  <span class="token punctuation">,</span>  <span class="token number">0.0077</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">]</span><span class="token punctuation">:</span> whole_partOut<span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">-3.</span><span class="token punctuation">,</span> <span class="token number">-6.</span><span class="token punctuation">,</span> <span class="token number">-6.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Ufuncs可以接受一个out可选参数，这样就能在数组原地进行操作：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">151</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">151</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">-3.2623</span><span class="token punctuation">,</span> <span class="token number">-6.0915</span><span class="token punctuation">,</span> <span class="token number">-6.663</span> <span class="token punctuation">,</span>  <span class="token number">5.3731</span><span class="token punctuation">,</span>  <span class="token number">3.6182</span><span class="token punctuation">,</span>  <span class="token number">3.45</span>  <span class="token punctuation">,</span>  <span class="token number">5.0077</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.sqrt(arr)Out<span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>    nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>  <span class="token number">2.318</span> <span class="token punctuation">,</span>  <span class="token number">1.9022</span><span class="token punctuation">,</span>  <span class="token number">1.8574</span><span class="token punctuation">,</span>  <span class="token number">2.2378</span><span class="token punctuation">]</span>)<span class="token comment">#影响对象arr</span>In <span class="token punctuation">[</span><span class="token number">153</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.sqrt(arr<span class="token punctuation">,</span> arr)Out<span class="token punctuation">[</span><span class="token number">153</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>    nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>  <span class="token number">2.318</span> <span class="token punctuation">,</span>  <span class="token number">1.9022</span><span class="token punctuation">,</span>  <span class="token number">1.8574</span><span class="token punctuation">,</span>  <span class="token number">2.2378</span><span class="token punctuation">]</span>)<span class="token comment">#不影响对象arr</span>In <span class="token punctuation">[</span><span class="token number">154</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">154</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>    nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>     nan<span class="token punctuation">,</span>  <span class="token number">2.318</span> <span class="token punctuation">,</span>  <span class="token number">1.9022</span><span class="token punctuation">,</span>  <span class="token number">1.8574</span><span class="token punctuation">,</span>  <span class="token number">2.2378</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下表分别列出了一些一元和二元ufunc。</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1guqdusy290j60yg0i7jxf02.jpg" alt="快速的元素级数组函数"></p><p><img src="https://tvax4.sinaimg.cn/large/007mx13gly1guqdvwgwrjj60yg0bkdjz02.jpg" alt="快速的元素级数组函数"></p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1guqdwlc3ubj60yg07mabp02.jpg" alt="快速的元素级数组函数"></p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1guqdxnskoqj60yg0ijq8u02.jpg" alt="快速的元素级数组函数"></p><h3 id="4-3-利用数组进行数据处理"><a href="#4-3-利用数组进行数据处理" class="headerlink" title="4.3 利用数组进行数据处理"></a><img src="https://tvax2.sinaimg.cn/large/007mx13gly1guqdxrg4ydj60yg06vjts02.jpg" alt="快速的元素级数组函数">4.3 利用数组进行数据处理</h3><p>NumPy数组使你可以将许多种数据处理任务表述为简洁的数组表达式（否则需要编写循环）。<u>用数组表达式代替循环的做法，通常被称为矢量化。</u>一般来说，矢量化数组运算要比等价的纯Python方式快上一两个数量级（甚至更多），尤其是各种数值计算。在后面内容中（见附录A）我将介绍广播，这是一种针对矢量化计算的强大手段。</p><p>作为简单的例子，假设我们想要在一组值（网格型）上计算函数sqrt(x^2+y^2)。<code>np.meshgrid</code>函数接受两个一维数组，并产生两个二维矩阵（对应于两个数组中所有的(x,y)对）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">155</span><span class="token punctuation">]</span><span class="token punctuation">:</span> points = np.arange(<span class="token punctuation">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> 0.01) <span class="token comment"># 1000 equally spaced points</span>In <span class="token punctuation">[</span><span class="token number">156</span><span class="token punctuation">]</span><span class="token punctuation">:</span> xs<span class="token punctuation">,</span> ys = np.meshgrid(points<span class="token punctuation">,</span> points)In <span class="token punctuation">[</span><span class="token number">157</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ysOut<span class="token punctuation">[</span><span class="token number">157</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-5.</span>  <span class="token punctuation">,</span> <span class="token number">-5.</span>  <span class="token punctuation">,</span> <span class="token number">-5.</span>  <span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span> <span class="token number">-5.</span>  <span class="token punctuation">,</span> <span class="token number">-5.</span>  <span class="token punctuation">,</span> <span class="token number">-5.</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-4.99</span><span class="token punctuation">,</span> <span class="token number">-4.99</span><span class="token punctuation">,</span> <span class="token number">-4.99</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span> <span class="token number">-4.99</span><span class="token punctuation">,</span> <span class="token number">-4.99</span><span class="token punctuation">,</span> <span class="token number">-4.99</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-4.98</span><span class="token punctuation">,</span> <span class="token number">-4.98</span><span class="token punctuation">,</span> <span class="token number">-4.98</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span> <span class="token number">-4.98</span><span class="token punctuation">,</span> <span class="token number">-4.98</span><span class="token punctuation">,</span> <span class="token number">-4.98</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">...</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4.97</span><span class="token punctuation">,</span>  <span class="token number">4.97</span><span class="token punctuation">,</span>  <span class="token number">4.97</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">4.97</span><span class="token punctuation">,</span>  <span class="token number">4.97</span><span class="token punctuation">,</span>  <span class="token number">4.97</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4.98</span><span class="token punctuation">,</span>  <span class="token number">4.98</span><span class="token punctuation">,</span>  <span class="token number">4.98</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">4.98</span><span class="token punctuation">,</span>  <span class="token number">4.98</span><span class="token punctuation">,</span>  <span class="token number">4.98</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4.99</span><span class="token punctuation">,</span>  <span class="token number">4.99</span><span class="token punctuation">,</span>  <span class="token number">4.99</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">4.99</span><span class="token punctuation">,</span>  <span class="token number">4.99</span><span class="token punctuation">,</span>  <span class="token number">4.99</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在，对该函数的求值运算就好办了，把这两个数组当做两个浮点数那样编写表达式即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">158</span><span class="token punctuation">]</span><span class="token punctuation">:</span> z = np.sqrt(xs <span class="token important">**</span> 2 + ys <span class="token important">**</span> 2)In <span class="token punctuation">[</span><span class="token number">159</span><span class="token punctuation">]</span><span class="token punctuation">:</span> zOut<span class="token punctuation">[</span><span class="token number">159</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">7.0711</span><span class="token punctuation">,</span>  <span class="token number">7.064</span> <span class="token punctuation">,</span>  <span class="token number">7.0569</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">,</span>  <span class="token number">7.0569</span><span class="token punctuation">,</span>  <span class="token number">7.064</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.064</span> <span class="token punctuation">,</span>  <span class="token number">7.0569</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">,</span>  <span class="token number">7.0569</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.0569</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">7.0357</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">,</span> <span class="token number">7.0499</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">...</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">7.0499</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">,</span>  <span class="token number">7.0357</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">7.0286</span><span class="token punctuation">,</span>  <span class="token number">7.0357</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.0569</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">7.0357</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">7.064</span> <span class="token punctuation">,</span>  <span class="token number">7.0569</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span>  <span class="token number">7.0428</span><span class="token punctuation">,</span>  <span class="token number">7.0499</span><span class="token punctuation">,</span>  <span class="token number">7.0569</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>作为第9章的先导，我用<code>matplotlib</code>创建了这个二维数组的可视化：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">160</span><span class="token punctuation">]</span><span class="token punctuation">:</span> import matplotlib.pyplot as pltIn <span class="token punctuation">[</span><span class="token number">161</span><span class="token punctuation">]</span><span class="token punctuation">:</span> plt.imshow(z<span class="token punctuation">,</span> cmap=plt.cm.gray); plt.colorbar()Out<span class="token punctuation">[</span><span class="token number">161</span><span class="token punctuation">]</span><span class="token punctuation">:</span> &lt;matplotlib.colorbar.Colorbar at 0x7f715e3fa630<span class="token punctuation">&gt;</span>In <span class="token punctuation">[</span><span class="token number">162</span><span class="token punctuation">]</span><span class="token punctuation">:</span> plt.title("Image plot of $\sqrt<span class="token punctuation">{</span>x^2 + y^2<span class="token punctuation">}</span>$ for a grid of values")Out<span class="token punctuation">[</span><span class="token number">162</span><span class="token punctuation">]</span><span class="token punctuation">:</span> &lt;matplotlib.text.Text at 0x7f715d2de748<span class="token punctuation">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下图是用<code>matplotlib</code>的<code>imshow</code>函数创建的。</p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1guqe73hxqpj608a07k74p02.jpg" alt="根据网格对函数求值的结果"></p><h4 id="将条件逻辑表述为数组运算"><a href="#将条件逻辑表述为数组运算" class="headerlink" title="将条件逻辑表述为数组运算"></a>将条件逻辑表述为数组运算</h4><p><code>numpy.where</code>函数是三元表达式<code>x if condition else y</code>的矢量化版本。假设我们有一个布尔数组和两个值数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">165</span><span class="token punctuation">]</span><span class="token punctuation">:</span> xarr = np.array(<span class="token punctuation">[</span><span class="token number">1.1</span><span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">,</span> <span class="token number">1.3</span><span class="token punctuation">,</span> <span class="token number">1.4</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">166</span><span class="token punctuation">]</span><span class="token punctuation">:</span> yarr = np.array(<span class="token punctuation">[</span><span class="token number">2.1</span><span class="token punctuation">,</span> <span class="token number">2.2</span><span class="token punctuation">,</span> <span class="token number">2.3</span><span class="token punctuation">,</span> <span class="token number">2.4</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">167</span><span class="token punctuation">]</span><span class="token punctuation">:</span> cond = np.array(<span class="token punctuation">[</span><span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>假设我们想要根据cond中的值选取xarr和yarr的值：当cond中的值为True时，选取xarr的值，否则从yarr中选取。列表推导式的写法应该如下所示：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">168</span><span class="token punctuation">]</span><span class="token punctuation">:</span> result = <span class="token punctuation">[</span><span class="token key atrule">(x if c else y)   .....</span><span class="token punctuation">:</span>           for x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> c in zip(xarr<span class="token punctuation">,</span> yarr<span class="token punctuation">,</span> cond)<span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">169</span><span class="token punctuation">]</span><span class="token punctuation">:</span> resultOut<span class="token punctuation">[</span><span class="token number">169</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1.1000000000000001</span><span class="token punctuation">,</span> <span class="token number">2.2000000000000002</span><span class="token punctuation">,</span> <span class="token number">1.3</span><span class="token punctuation">,</span> <span class="token number">1.3999999999999999</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这有几个问题。第一，它对大数组的处理速度不是很快（因为所有工作都是由纯Python完成的）。第二，无法用于多维数组。若使用<code>np.where</code>，则可以将该功能写得非常简洁：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">170</span><span class="token punctuation">]</span><span class="token punctuation">:</span> result = np.where(cond<span class="token punctuation">,</span> xarr<span class="token punctuation">,</span> yarr)In <span class="token punctuation">[</span><span class="token number">171</span><span class="token punctuation">]</span><span class="token punctuation">:</span> resultOut<span class="token punctuation">[</span><span class="token number">171</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">1.1</span><span class="token punctuation">,</span>  <span class="token number">2.2</span><span class="token punctuation">,</span>  <span class="token number">1.3</span><span class="token punctuation">,</span>  <span class="token number">1.4</span><span class="token punctuation">,</span>  <span class="token number">2.5</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>np.where</code>的第二个和第三个参数不必是数组，它们都可以是标量值。在数据分析工作中，where通常用于根据另一个数组而产生一个新的数组。假设有一个由随机数据组成的矩阵，你希望将所有正值替换为2，将所有负值替换为－2。若利用np.where，则会非常简单：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">172</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.random.randn(4<span class="token punctuation">,</span> 4)In <span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-0.5031</span><span class="token punctuation">,</span> <span class="token number">-0.6223</span><span class="token punctuation">,</span> <span class="token number">-0.9212</span><span class="token punctuation">,</span> <span class="token number">-0.7262</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.2229</span><span class="token punctuation">,</span>  <span class="token number">0.0513</span><span class="token punctuation">,</span> <span class="token number">-1.1577</span><span class="token punctuation">,</span>  <span class="token number">0.8167</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.4336</span><span class="token punctuation">,</span>  <span class="token number">1.0107</span><span class="token punctuation">,</span>  <span class="token number">1.8249</span><span class="token punctuation">,</span> <span class="token number">-0.9975</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.8506</span><span class="token punctuation">,</span> <span class="token number">-0.1316</span><span class="token punctuation">,</span>  <span class="token number">0.9124</span><span class="token punctuation">,</span>  <span class="token number">0.1882</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token punctuation">&gt;</span> 0Out<span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=bool)In <span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.where(arr <span class="token punctuation">&gt;</span> 0<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">-</span>2)Out<span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-2</span><span class="token punctuation">,</span> <span class="token number">-2</span><span class="token punctuation">,</span> <span class="token number">-2</span><span class="token punctuation">,</span> <span class="token number">-2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">-2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">-2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">-2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用<code>np.where</code>，可以将标量和数组结合起来。例如，我可用常数2替换arr中所有正的值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.where(arr <span class="token punctuation">&gt;</span> 0<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> arr) <span class="token comment"># set only positive values to 2Out[176]: array([[-0.5031, -0.6223, -0.9212, -0.7262],       [ 2.    ,  2.    , -1.1577,  2.    ],       [ 2.    ,  2.    ,  2.    , -0.9975],       [ 2.    , -0.1316,  2.    ,  2.    ]])</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>传递给where的数组大小可以不相等，甚至可以是标量值。</p><h4 id="数学和统计方法"><a href="#数学和统计方法" class="headerlink" title="数学和统计方法"></a>数学和统计方法</h4><p>可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算。<code>sum、mean</code>以及标准差<code>std</code>等聚合计算（aggregation，通常叫做约简（reduction））既可以当做数组的实例方法调用，也可以当做顶级NumPy函数使用。</p><p>这里，我生成了一些正态分布随机数据，然后做了聚类统计：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">177</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.random.randn(5<span class="token punctuation">,</span> 4)In <span class="token punctuation">[</span><span class="token number">178</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">178</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">2.1695</span><span class="token punctuation">,</span> <span class="token number">-0.1149</span><span class="token punctuation">,</span>  <span class="token number">2.0037</span><span class="token punctuation">,</span>  <span class="token number">0.0296</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.7953</span><span class="token punctuation">,</span>  <span class="token number">0.1181</span><span class="token punctuation">,</span> <span class="token number">-0.7485</span><span class="token punctuation">,</span>  <span class="token number">0.585</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.1527</span><span class="token punctuation">,</span> <span class="token number">-1.5657</span><span class="token punctuation">,</span> <span class="token number">-0.5625</span><span class="token punctuation">,</span> <span class="token number">-0.0327</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.929</span> <span class="token punctuation">,</span> <span class="token number">-0.4826</span><span class="token punctuation">,</span> <span class="token number">-0.0363</span><span class="token punctuation">,</span>  <span class="token number">1.0954</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.9809</span><span class="token punctuation">,</span> <span class="token number">-0.5895</span><span class="token punctuation">,</span>  <span class="token number">1.5817</span><span class="token punctuation">,</span> <span class="token number">-0.5287</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">179</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.mean()Out<span class="token punctuation">[</span><span class="token number">179</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 0.19607051119998253In <span class="token punctuation">[</span><span class="token number">180</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.mean(arr)Out<span class="token punctuation">[</span><span class="token number">180</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 0.19607051119998253In <span class="token punctuation">[</span><span class="token number">181</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.sum()Out<span class="token punctuation">[</span><span class="token number">181</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">3.9214102239996507</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>mean和sum这类的函数可以接受一个axis选项参数，用于计算该轴向上的统计值，最终结果是一个<u>少一维的数组</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">182</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.mean(axis=1)Out<span class="token punctuation">[</span><span class="token number">182</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">1.022</span> <span class="token punctuation">,</span>  <span class="token number">0.1875</span><span class="token punctuation">,</span> <span class="token number">-0.502</span> <span class="token punctuation">,</span> <span class="token number">-0.0881</span><span class="token punctuation">,</span>  <span class="token number">0.3611</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">183</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.sum(axis=0)Out<span class="token punctuation">[</span><span class="token number">183</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">3.1693</span><span class="token punctuation">,</span> <span class="token number">-2.6345</span><span class="token punctuation">,</span>  <span class="token number">2.2381</span><span class="token punctuation">,</span>  <span class="token number">1.1486</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里，<code>arr.mean(1)</code>是“计算行的平均值”，<code>arr.sum(0)</code>是“计算每列的和”。</p><p>其他如cumsum和cumprod之类的方法则不聚合，而是产生一个由中间结果组成的数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">184</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.array(<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">185</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.cumsum()Out<span class="token punctuation">[</span><span class="token number">185</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在多维数组中，累加函数（如cumsum）返回的是同样大小的数组，但是会根据每个低维的切片沿着标记轴计算部分聚类：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">186</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">187</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">187</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">188</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.cumsum(axis=0)Out<span class="token punctuation">[</span><span class="token number">188</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">189</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.cumprod(axis=1)Out<span class="token punctuation">[</span><span class="token number">189</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0</span><span class="token punctuation">,</span>   <span class="token number">0</span><span class="token punctuation">,</span>   <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">12</span><span class="token punctuation">,</span>  <span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">336</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了全部的基本数组统计方法。后续章节中有很多例子都会用到这些方法。</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1guqeinaiw4j60yg0b577s02.jpg" alt="利用数组进行数据处理"></p><p><img src="https://tva1.sinaimg.cn/large/007mx13gly1guqeiuk84mj60yg06dwfs02.jpg" alt=" 利用数组进行数据处理"></p><h4 id="用于布尔型数组的方法"><a href="#用于布尔型数组的方法" class="headerlink" title="用于布尔型数组的方法"></a>用于布尔型数组的方法</h4><p>在上面这些方法中，布尔值会被强制转换为1（True）和0（False）。因此，sum经常被用来对布尔型数组中的True值计数：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">190</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.random.randn(100)In <span class="token punctuation">[</span><span class="token number">191</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (arr <span class="token punctuation">&gt;</span> 0).sum() <span class="token comment"># Number of positive valuesOut[191]: 42</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另外还有两个方法<code>any</code>和<code>all</code>，它们对布尔型数组非常有用。<code>any</code>用于测试数组中是否存在一个或多个<code>True</code>，而<code>all</code>则检查数组中所有值是否都是<code>True</code>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bools = np.array(<span class="token punctuation">[</span><span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">193</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bools.any()Out<span class="token punctuation">[</span><span class="token number">193</span><span class="token punctuation">]</span><span class="token punctuation">:</span> TrueIn <span class="token punctuation">[</span><span class="token number">194</span><span class="token punctuation">]</span><span class="token punctuation">:</span> bools.all()Out<span class="token punctuation">[</span><span class="token number">194</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这两个方法也能用于非布尔型数组，所有非0元素将会被当做True。</p><h4 id="排序-1"><a href="#排序-1" class="headerlink" title="排序"></a>排序</h4><p>跟Python内置的列表类型一样，NumPy数组也可以通过sort方法就地排序：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">195</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.random.randn(6)In <span class="token punctuation">[</span><span class="token number">196</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">196</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.6095</span><span class="token punctuation">,</span> <span class="token number">-0.4938</span><span class="token punctuation">,</span>  <span class="token number">1.24</span>  <span class="token punctuation">,</span> <span class="token number">-0.1357</span><span class="token punctuation">,</span>  <span class="token number">1.43</span>  <span class="token punctuation">,</span> <span class="token number">-0.8469</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">197</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.sort()In <span class="token punctuation">[</span><span class="token number">198</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">198</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">-0.8469</span><span class="token punctuation">,</span> <span class="token number">-0.4938</span><span class="token punctuation">,</span> <span class="token number">-0.1357</span><span class="token punctuation">,</span>  <span class="token number">0.6095</span><span class="token punctuation">,</span>  <span class="token number">1.24</span>  <span class="token punctuation">,</span>  <span class="token number">1.43</span>  <span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>多维数组可以在任何一个轴向上进行排序，只需将轴编号传给sort即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">199</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.random.randn(5<span class="token punctuation">,</span> 3)In <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.6033</span><span class="token punctuation">,</span>  <span class="token number">1.2636</span><span class="token punctuation">,</span> <span class="token number">-0.2555</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.4457</span><span class="token punctuation">,</span>  <span class="token number">0.4684</span><span class="token punctuation">,</span> <span class="token number">-0.9616</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-1.8245</span><span class="token punctuation">,</span>  <span class="token number">0.6254</span><span class="token punctuation">,</span>  <span class="token number">1.0229</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1.1074</span><span class="token punctuation">,</span>  <span class="token number">0.0909</span><span class="token punctuation">,</span> <span class="token number">-0.3501</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.218</span> <span class="token punctuation">,</span> <span class="token number">-0.8948</span><span class="token punctuation">,</span> <span class="token number">-1.7415</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">201</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr.sort(1)In <span class="token punctuation">[</span><span class="token number">202</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">202</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-0.2555</span><span class="token punctuation">,</span>  <span class="token number">0.6033</span><span class="token punctuation">,</span>  <span class="token number">1.2636</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.9616</span><span class="token punctuation">,</span> <span class="token number">-0.4457</span><span class="token punctuation">,</span>  <span class="token number">0.4684</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-1.8245</span><span class="token punctuation">,</span>  <span class="token number">0.6254</span><span class="token punctuation">,</span>  <span class="token number">1.0229</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.3501</span><span class="token punctuation">,</span>  <span class="token number">0.0909</span><span class="token punctuation">,</span>  <span class="token number">1.1074</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-1.7415</span><span class="token punctuation">,</span> <span class="token number">-0.8948</span><span class="token punctuation">,</span>  <span class="token number">0.218</span> <span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>顶级方法np.sort返回的是数组的已排序副本，而就地排序则会修改数组本身。计算数组分位数最简单的办法是对其进行排序，然后选取特定位置的值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">203</span><span class="token punctuation">]</span><span class="token punctuation">:</span> large_arr = np.random.randn(1000)In <span class="token punctuation">[</span><span class="token number">204</span><span class="token punctuation">]</span><span class="token punctuation">:</span> large_arr.sort()In <span class="token punctuation">[</span><span class="token number">205</span><span class="token punctuation">]</span><span class="token punctuation">:</span> large_arr<span class="token punctuation">[</span>int(0.05 * len(large_arr))<span class="token punctuation">]</span> <span class="token comment"># 5% quantileOut[205]: -1.5311513550102103</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>更多关于NumPy排序方法以及诸如间接排序之类的高级技术，请参阅附录A。在pandas中还可以找到一些其他跟排序有关的数据操作（比如根据一列或多列对表格型数据进行排序）。<br>唯一化以及其它的集合逻辑</p><p>NumPy提供了一些针对一维ndarray的基本集合运算。最常用的可能要数<code>np.unique</code>了，它用于找出数组中的唯一值并返回已排序的结果：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">206</span><span class="token punctuation">]</span><span class="token punctuation">:</span> names = np.array(<span class="token punctuation">[</span><span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">,</span> <span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">207</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.unique(names)Out<span class="token punctuation">[</span><span class="token number">207</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      dtype='&lt;U4')In <span class="token punctuation">[</span><span class="token number">208</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ints = np.array(<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">209</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.unique(ints)Out<span class="token punctuation">[</span><span class="token number">209</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>拿跟np.unique等价的纯Python代码来对比一下：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">210</span><span class="token punctuation">]</span><span class="token punctuation">:</span> sorted(set(names))Out<span class="token punctuation">[</span><span class="token number">210</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Joe'</span><span class="token punctuation">,</span> <span class="token string">'Will'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另一个函数<code>np.in1d</code>用于测试一个数组中的值在另一个数组中的成员资格，返回一个布尔型数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">211</span><span class="token punctuation">]</span><span class="token punctuation">:</span> values = np.array(<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">212</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.in1d(values<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">212</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=bool)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>NumPy中的集合函数请参见下表。<br><img src="https://tva1.sinaimg.cn/large/007mx13gly1guqes9xyq2j60yg0ds0xj02.jpg" alt="利用数组进行数据处理 "></p><h3 id="4-4-用于数组的文件输入输出"><a href="#4-4-用于数组的文件输入输出" class="headerlink" title="4.4 用于数组的文件输入输出"></a>4.4 用于数组的文件输入输出</h3><p><code>NumPy</code>能够读写磁盘上的文本数据或二进制数据。这一小节只讨论<code>NumPy</code>的内置二进制格式，因为更多的用户会使用pandas或其它工具加载文本或表格数据（见第6章）。</p><p><code>np.save</code>和<code>np.load</code>是读写磁盘数组数据的两个主要函数。默认情况下，数组是以未压缩的原始二进制格式保存在扩展名为.npy的文件中的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">213</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.arange(10)In <span class="token punctuation">[</span><span class="token number">214</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.save('some_array'<span class="token punctuation">,</span> arr)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果文件路径末尾没有扩展名.npy，则该扩展名会被自动加上。然后就可以通过np.load读取磁盘上的数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">215</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.load('some_array.npy')Out<span class="token punctuation">[</span><span class="token number">215</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过np.savez可以将多个数组保存到一个未压缩文件中，将数组以关键字参数的形式传入即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">216</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.savez('array_archive.npz'<span class="token punctuation">,</span> a=arr<span class="token punctuation">,</span> b=arr)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载.npz文件时，你会得到一个类似字典的对象，该对象会对各个数组进行延迟加载：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">217</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arch = np.load('array_archive.npz')In <span class="token punctuation">[</span><span class="token number">218</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arch<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">218</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果要将数据压缩，可以使用numpy.savez_compressed：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">219</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.savez_compressed('arrays_compressed.npz'<span class="token punctuation">,</span> a=arr<span class="token punctuation">,</span> b=arr)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-5-线性代数"><a href="#4-5-线性代数" class="headerlink" title="4.5 线性代数"></a>4.5 线性代数</h3><p>线性代数（如矩阵乘法、矩阵分解、行列式以及其他方阵数学等）是任何数组库的重要组成部分。不像某些语言（如MATLAB），通过*对两个二维数组相乘得到的是一个元素级的积，而不是一个矩阵点积。因此，NumPy提供了一个用于矩阵乘法的dot函数（既是一个数组方法也是numpy命名空间中的一个函数）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">223</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x = np.array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4.</span><span class="token punctuation">,</span> <span class="token number">5.</span><span class="token punctuation">,</span> <span class="token number">6.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">:</span> y = np.array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">6.</span><span class="token punctuation">,</span> <span class="token number">23.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">225</span><span class="token punctuation">]</span><span class="token punctuation">:</span> xOut<span class="token punctuation">[</span><span class="token number">225</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">226</span><span class="token punctuation">]</span><span class="token punctuation">:</span> yOut<span class="token punctuation">[</span><span class="token number">226</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">23.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">-1.</span><span class="token punctuation">,</span>   <span class="token number">7.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">8.</span><span class="token punctuation">,</span>   <span class="token number">9.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">227</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x.dot(y)Out<span class="token punctuation">[</span><span class="token number">227</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">28.</span><span class="token punctuation">,</span>   <span class="token number">64.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">67.</span><span class="token punctuation">,</span>  <span class="token number">181.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>x.dot(y)等价于np.dot(x, y)：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">228</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.dot(x<span class="token punctuation">,</span> y)Out<span class="token punctuation">[</span><span class="token number">228</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">28.</span><span class="token punctuation">,</span>   <span class="token number">64.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">67.</span><span class="token punctuation">,</span>  <span class="token number">181.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>一个二维数组跟一个大小合适的一维数组的矩阵点积运算之后将会得到一个一维数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">229</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.dot(x<span class="token punctuation">,</span> np.ones(3))Out<span class="token punctuation">[</span><span class="token number">229</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">15.</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>@</code>符（类似Python 3.5）也可以用作中缀运算符，进行矩阵乘法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">230</span><span class="token punctuation">]</span><span class="token punctuation">:</span> x @ np.ones(3)Out<span class="token punctuation">[</span><span class="token number">230</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">15.</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>numpy.linalg中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的东西。它们跟MATLAB和R等语言所使用的是相同的行业标准线性代数库，如BLAS、LAPACK、Intel MKL（Math Kernel Library，可能有，取决于你的NumPy版本）等：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">231</span><span class="token punctuation">]</span><span class="token punctuation">:</span> from numpy.linalg import inv<span class="token punctuation">,</span> qrIn <span class="token punctuation">[</span><span class="token number">232</span><span class="token punctuation">]</span><span class="token punctuation">:</span> X = np.random.randn(5<span class="token punctuation">,</span> 5)In <span class="token punctuation">[</span><span class="token number">233</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mat = X.T.dot(X)In <span class="token punctuation">[</span><span class="token number">234</span><span class="token punctuation">]</span><span class="token punctuation">:</span> inv(mat)Out<span class="token punctuation">[</span><span class="token number">234</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">933.1189</span><span class="token punctuation">,</span>   <span class="token number">871.8258</span><span class="token punctuation">,</span> <span class="token number">-1417.6902</span><span class="token punctuation">,</span> <span class="token number">-1460.4005</span><span class="token punctuation">,</span>  <span class="token number">1782.1391</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">871.8258</span><span class="token punctuation">,</span>   <span class="token number">815.3929</span><span class="token punctuation">,</span> <span class="token number">-1325.9965</span><span class="token punctuation">,</span> <span class="token number">-1365.9242</span><span class="token punctuation">,</span>  <span class="token number">1666.9347</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-1417.6902</span><span class="token punctuation">,</span> <span class="token number">-1325.9965</span><span class="token punctuation">,</span>  <span class="token number">2158.4424</span><span class="token punctuation">,</span>  <span class="token number">2222.0191</span><span class="token punctuation">,</span> <span class="token number">-2711.6822</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-1460.4005</span><span class="token punctuation">,</span> <span class="token number">-1365.9242</span><span class="token punctuation">,</span>  <span class="token number">2222.0191</span><span class="token punctuation">,</span>  <span class="token number">2289.0575</span><span class="token punctuation">,</span> <span class="token number">-2793.422</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">1782.1391</span><span class="token punctuation">,</span>  <span class="token number">1666.9347</span><span class="token punctuation">,</span> <span class="token number">-2711.6822</span><span class="token punctuation">,</span> <span class="token number">-2793.422</span> <span class="token punctuation">,</span>  <span class="token number">3409.5128</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">235</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mat.dot(inv(mat))Out<span class="token punctuation">[</span><span class="token number">235</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">-0.</span><span class="token punctuation">,</span> <span class="token number">-0.</span><span class="token punctuation">,</span> <span class="token number">-0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">-0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">236</span><span class="token punctuation">]</span><span class="token punctuation">:</span> q<span class="token punctuation">,</span> r = qr(mat)In <span class="token punctuation">[</span><span class="token number">237</span><span class="token punctuation">]</span><span class="token punctuation">:</span> rOut<span class="token punctuation">[</span><span class="token number">237</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-1.6914</span><span class="token punctuation">,</span>  <span class="token number">4.38</span>  <span class="token punctuation">,</span>  <span class="token number">0.1757</span><span class="token punctuation">,</span>  <span class="token number">0.4075</span><span class="token punctuation">,</span> <span class="token number">-0.7838</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span>    <span class="token punctuation">,</span> <span class="token number">-2.6436</span><span class="token punctuation">,</span>  <span class="token number">0.1939</span><span class="token punctuation">,</span> <span class="token number">-3.072</span> <span class="token punctuation">,</span> <span class="token number">-1.0702</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span> <span class="token number">-0.8138</span><span class="token punctuation">,</span>  <span class="token number">1.5414</span><span class="token punctuation">,</span>  <span class="token number">0.6155</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span> <span class="token number">-2.6445</span><span class="token punctuation">,</span> <span class="token number">-2.1669</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.</span>    <span class="token punctuation">,</span>  <span class="token number">0.0002</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>表达式X.T.dot(X)计算X和它的转置X.T的点积。</p><p>下表中列出了一些最常用的线性代数函数。</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1guquel4jgaj60xu0l478x02.jpg" alt="线性代数函数"></p><h3 id="4-6-伪随机数生成"><a href="#4-6-伪随机数生成" class="headerlink" title="4.6 伪随机数生成"></a>4.6 伪随机数生成</h3><p><code>numpy.random</code>模块对Python内置的random进行了补充，增加了一些用于高效生成多种概率分布的样本值的函数。例如，你可以用normal来得到一个标准正态分布的4×4样本数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">238</span><span class="token punctuation">]</span><span class="token punctuation">:</span> samples = np.random.normal(size=(4<span class="token punctuation">,</span> 4))In <span class="token punctuation">[</span><span class="token number">239</span><span class="token punctuation">]</span><span class="token punctuation">:</span> samplesOut<span class="token punctuation">[</span><span class="token number">239</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5732</span><span class="token punctuation">,</span>  <span class="token number">0.1933</span><span class="token punctuation">,</span>  <span class="token number">0.4429</span><span class="token punctuation">,</span>  <span class="token number">1.2796</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.575</span> <span class="token punctuation">,</span>  <span class="token number">0.4339</span><span class="token punctuation">,</span> <span class="token number">-0.7658</span><span class="token punctuation">,</span> <span class="token number">-1.237</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">-0.5367</span><span class="token punctuation">,</span>  <span class="token number">1.8545</span><span class="token punctuation">,</span> <span class="token number">-0.92</span>  <span class="token punctuation">,</span> <span class="token number">-0.1082</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">0.1525</span><span class="token punctuation">,</span>  <span class="token number">0.9435</span><span class="token punctuation">,</span> <span class="token number">-1.0953</span><span class="token punctuation">,</span> <span class="token number">-0.144</span> <span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>而Python内置的random模块则只能一次生成一个样本值。从下面的测试结果中可以看出，如果需要产生大量样本值，<code>numpy.random</code>快了不止一个数量级：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">240</span><span class="token punctuation">]</span><span class="token punctuation">:</span> from random import normalvariateIn <span class="token punctuation">[</span><span class="token number">241</span><span class="token punctuation">]</span><span class="token punctuation">:</span> N = 1000000In <span class="token punctuation">[</span><span class="token number">242</span><span class="token punctuation">]</span><span class="token punctuation">:</span> %timeit samples = <span class="token punctuation">[</span>normalvariate(0<span class="token punctuation">,</span> 1) for _ in range(N)<span class="token punctuation">]</span>1.77 s +<span class="token punctuation">-</span> 126 ms per loop (mean +<span class="token punctuation">-</span> std. dev. of 7 runs<span class="token punctuation">,</span> 1 loop each)In <span class="token punctuation">[</span><span class="token number">243</span><span class="token punctuation">]</span><span class="token punctuation">:</span> %timeit np.random.normal(size=N)61.7 ms +<span class="token punctuation">-</span> 1.32 ms per loop (mean +<span class="token punctuation">-</span> std. dev. of 7 runs<span class="token punctuation">,</span> 10 loops each)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们说这些都是伪随机数，是因为它们都是通过算法基于随机数生成器种子，在确定性的条件下生成的。你可以用NumPy的np.random.seed更改随机数生成种子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">244</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.random.seed(1234)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>numpy.random的数据生成函数使用了全局的随机种子。要避免全局状态，你可以使用numpy.random.RandomState，创建一个与其它隔离的随机数生成器：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">245</span><span class="token punctuation">]</span><span class="token punctuation">:</span> rng = np.random.RandomState(1234)In <span class="token punctuation">[</span><span class="token number">246</span><span class="token punctuation">]</span><span class="token punctuation">:</span> rng.randn(10)Out<span class="token punctuation">[</span><span class="token number">246</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.4714</span><span class="token punctuation">,</span> <span class="token number">-1.191</span> <span class="token punctuation">,</span>  <span class="token number">1.4327</span><span class="token punctuation">,</span> <span class="token number">-0.3127</span><span class="token punctuation">,</span> <span class="token number">-0.7206</span><span class="token punctuation">,</span>  <span class="token number">0.8872</span><span class="token punctuation">,</span>  <span class="token number">0.8596</span><span class="token punctuation">,</span>       <span class="token number">-0.6365</span><span class="token punctuation">,</span>  <span class="token number">0.0157</span><span class="token punctuation">,</span> <span class="token number">-2.2427</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了<code>numpy.random</code>中的部分函数。在下一节中，我将给出一些利用这些函数一次性生成大量样本值的范例。</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1guqux37jlcj60yg0hen2h02.jpg" alt="伪随机数生成"></p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1guqupxmswzj60yg07xdhs02.jpg" alt="伪随机数生成"></p><h3 id="4-7-示例：随机漫步"><a href="#4-7-示例：随机漫步" class="headerlink" title="4.7 示例：随机漫步"></a>4.7 示例：随机漫步</h3><p>我们通过模拟随机漫步来说明如何运用数组运算。先来看一个简单的随机漫步的例子：从0开始，步长1和－1出现的概率相等。</p><p>下面是一个通过内置的<code>random</code>模块以纯Python的方式实现1000步的随机漫步：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">247</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">import random   .....</span><span class="token punctuation">:</span> <span class="token key atrule">position = 0   .....</span><span class="token punctuation">:</span> walk = <span class="token punctuation">[</span>position<span class="token punctuation">]</span>   <span class="token punctuation">...</span>..<span class="token punctuation">:</span> <span class="token key atrule">steps = 1000   .....</span><span class="token punctuation">:</span> <span class="token key atrule">for i in range(steps)</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     step = 1 if random.randint(0<span class="token punctuation">,</span> <span class="token key atrule">1) else -1   .....</span><span class="token punctuation">:</span>     <span class="token key atrule">position += step   .....</span><span class="token punctuation">:</span>     walk.append(position)   <span class="token punctuation">...</span>..<span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>图4-4是根据前100个随机漫步值生成的折线图：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">249</span><span class="token punctuation">]</span><span class="token punctuation">:</span> plt.plot(walk<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1guqv95lkbxj60ah06w74v02.jpg" alt="简单的随机漫步"></p><p>不难看出，这其实就是随机漫步中各步的累计和，可以用一个数组运算来实现。因此，我用<code>np.random</code>模块一次性随机产生1000个“掷硬币”结果（即两个数中任选一个），将其分别设置为1或－1，然后计算累计和：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">251</span><span class="token punctuation">]</span><span class="token punctuation">:</span> nsteps = 1000In <span class="token punctuation">[</span><span class="token number">252</span><span class="token punctuation">]</span><span class="token punctuation">:</span> draws = np.random.randint(0<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> size=nsteps)In <span class="token punctuation">[</span><span class="token number">253</span><span class="token punctuation">]</span><span class="token punctuation">:</span> steps = np.where(draws <span class="token punctuation">&gt;</span> 0<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">-</span>1)In <span class="token punctuation">[</span><span class="token number">254</span><span class="token punctuation">]</span><span class="token punctuation">:</span> walk = steps.cumsum()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>有了这些数据之后，我们就可以沿着漫步路径做一些统计工作了，比如求取最大值和最小值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">255</span><span class="token punctuation">]</span><span class="token punctuation">:</span> walk.min()Out<span class="token punctuation">[</span><span class="token number">255</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">-</span>3In <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">:</span> walk.max()Out<span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">31</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在来看一个复杂点的统计任务——首次穿越时间，即随机漫步过程中第一次到达某个特定值的时间。假设我们想要知道本次随机漫步需要多久才能距离初始0点至少10步远（任一方向均可）。np.abs(walk)&gt;=10可以得到一个布尔型数组，它表示的是距离是否达到或超过10，而我们想要知道的是第一个10或－10的索引。可以用argmax来解决这个问题，它返回的是该布尔型数组第一个最大值的索引（True就是最大值）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">257</span><span class="token punctuation">]</span><span class="token punctuation">:</span> (np.abs(walk) <span class="token punctuation">&gt;</span>= 10).argmax()Out<span class="token punctuation">[</span><span class="token number">257</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">37</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意，这里使用argmax并不是很高效，因为它无论如何都会对数组进行完全扫描。在本例中，只要发现了一个True，那我们就知道它是个最大值了。</p><h4 id="一次模拟多个随机漫步"><a href="#一次模拟多个随机漫步" class="headerlink" title="一次模拟多个随机漫步"></a>一次模拟多个随机漫步</h4><p>如果你希望模拟多个随机漫步过程（比如5000个），只需对上面的代码做一点点修改即可生成所有的随机漫步过程。只要给<code>numpy.random</code>的函数传入一个二元元组就可以产生一个二维数组，然后我们就可以一次性计算5000个随机漫步过程（一行一个）的累计和了：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">258</span><span class="token punctuation">]</span><span class="token punctuation">:</span> nwalks = 5000In <span class="token punctuation">[</span><span class="token number">259</span><span class="token punctuation">]</span><span class="token punctuation">:</span> nsteps = 1000In <span class="token punctuation">[</span><span class="token number">260</span><span class="token punctuation">]</span><span class="token punctuation">:</span> draws = np.random.randint(0<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> size=(nwalks<span class="token punctuation">,</span> nsteps)) <span class="token comment"># 0 or 1In [261]: steps = np.where(draws &gt; 0, 1, -1)In [262]: walks = steps.cumsum(1)In [263]: walksOut[263]: array([[  1,   0,   1, ...,   8,   7,   8],       [  1,   0,  -1, ...,  34,  33,  32],       [  1,   0,  -1, ...,   4,   5,   4],       ...,        [  1,   2,   1, ...,  24,  25,  26],       [  1,   2,   3, ...,  14,  13,  14],       [ -1,  -2,  -3, ..., -24, -23, -22]])</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在，我们来计算所有随机漫步过程的最大值和最小值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">264</span><span class="token punctuation">]</span><span class="token punctuation">:</span> walks.max()Out<span class="token punctuation">[</span><span class="token number">264</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 138In <span class="token punctuation">[</span><span class="token number">265</span><span class="token punctuation">]</span><span class="token punctuation">:</span> walks.min()Out<span class="token punctuation">[</span><span class="token number">265</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">-133</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>得到这些数据之后，我们来计算30或－30的最小穿越时间。这里稍微复杂些，因为不是5000个过程都到达了30。我们可以用any方法来对此进行检查：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">266</span><span class="token punctuation">]</span><span class="token punctuation">:</span> hits30 = (np.abs(walks) <span class="token punctuation">&gt;</span>= 30).any(1)In <span class="token punctuation">[</span><span class="token number">267</span><span class="token punctuation">]</span><span class="token punctuation">:</span> hits30Out<span class="token punctuation">[</span><span class="token number">267</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span> <span class="token punctuation">...</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">,</span>  <span class="token boolean important">True</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=bool)In <span class="token punctuation">[</span><span class="token number">268</span><span class="token punctuation">]</span><span class="token punctuation">:</span> hits30.sum() <span class="token comment"># Number that hit 30 or -30Out[268]: 3410</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后我们利用这个布尔型数组选出那些穿越了30（绝对值）的随机漫步（行），并调用argmax在轴1上获取穿越时间：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">269</span><span class="token punctuation">]</span><span class="token punctuation">:</span> crossing_times = (np.abs(walks<span class="token punctuation">[</span>hits30<span class="token punctuation">]</span>) <span class="token punctuation">&gt;</span>= 30).argmax(1)In <span class="token punctuation">[</span><span class="token number">270</span><span class="token punctuation">]</span><span class="token punctuation">:</span> crossing_times.mean()Out<span class="token punctuation">[</span><span class="token number">270</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">498.88973607038122</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>请尝试用其他分布方式得到漫步数据。只需使用不同的随机数生成函数即可，如normal用于生成指定均值和标准差的正态分布数据：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">271</span><span class="token punctuation">]</span><span class="token punctuation">:</span> steps = np.random.normal(loc=0<span class="token punctuation">,</span> scale=0.25<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                          size=(nwalks<span class="token punctuation">,</span> nsteps))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="第-05-章-pandas-入门"><a href="#第-05-章-pandas-入门" class="headerlink" title="第 05 章 pandas 入门"></a><a href="https://www.bookstack.cn/read/pyda-2e-zh/5.md">第 05 章 pandas 入门</a></h2><p>pandas是本书后续内容的首选库。它含有使数据清洗和分析工作变得更快更简单的数据结构和操作工具。pandas经常和其它工具一同使用，如数值计算工具NumPy和SciPy，分析库statsmodels和scikit-learn，和数据可视化库matplotlib。pandas是基于NumPy数组构建的，特别是基于数组的函数和不使用for循环的数据处理。</p><p>虽然pandas采用了大量的NumPy编码风格，但二者最大的不同是pandas是专门为处理表格和混杂数据设计的。而NumPy更适合处理统一的数值数组数据。</p><p>自从2010年pandas开源以来，pandas逐渐成长为一个非常大的库，应用于许多真实案例。开发者社区已经有了800个独立的贡献者，他们在解决日常数据问题的同时为这个项目提供贡献。</p><p>在本书后续部分中，我将使用下面这样的pandas引入约定：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span> import pandas as pd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因此，只要你在代码中看到pd.，就得想到这是pandas。因为Series和DataFrame用的次数非常多，所以将其引入本地命名空间中会更方便：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span> from pandas import Series<span class="token punctuation">,</span> DataFrame<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-1-pandas的数据结构介绍"><a href="#5-1-pandas的数据结构介绍" class="headerlink" title="5.1 pandas的数据结构介绍"></a>5.1 pandas的数据结构介绍</h3><p>要使用<code>pandas</code>，你首先就得熟悉它的两个主要数据结构：<code>Series</code>和<code>DataFrame</code>。虽然它们并不能解决所有问题，但它们为大多数应用提供了一种可靠的、易于使用的基础。</p><h5 id="Series"><a href="#Series" class="headerlink" title="Series"></a><code>Series</code></h5><p>Series是一种类似于一维数组的对象，它由一组数据（各种NumPy数据类型）以及一组与之相关的数据标签（即索引）组成。仅由一组数据即可产生最简单的Series：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">-5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 0    41    72   <span class="token punctuation">-</span><span class="token number">5</span>3    3<span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>Series</code>的字符串表现形式为：<u>索引在左边，值在右边</u>。由于我们没有为数据指定索引，于是会自动创建一个0到N-1（N为数据的长度）的整数型索引。你可以通过<code>Series</code> 的<code>values</code>和<code>index</code>属性获取其数组表示形式和索引对象：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.valuesOut<span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">-5</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.index  <span class="token comment"># like range(4)</span>Out<span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">:</span> RangeIndex(start=0<span class="token punctuation">,</span> stop=4<span class="token punctuation">,</span> step=1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>通常，我们希望所创建的Series带有一个可以对各个数据点进行标记的索引：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2 = pd.Series(<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">-5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2Out<span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d    4b    7a   <span class="token punctuation">-</span><span class="token number">5</span>c    3<span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2.indexOut<span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Index(<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='object')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与普通<code>NumPy</code>数组相比，你可以通过<u>索引的方式</u>选取Series中的单个或一组值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">-5</span>In <span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">]</span> = 6In <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">:</span> c    3a   <span class="token punctuation">-</span><span class="token number">5</span>d    6<span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>[‘c’, ‘a’, ‘d’]是索引列表，即使它包含的是字符串而不是整数。</p><p>使用<code>NumPy</code>函数或类似<code>NumPy</code>的运算（如根据布尔型数组进行过滤、标量乘法、应用数学函数等）都会<u>保留索引值的链接</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2<span class="token punctuation">[</span>obj2 <span class="token punctuation">&gt;</span> 0<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d    6b    7c    3<span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2 * 2Out<span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">:</span>d    12b    14a   <span class="token punctuation">-</span><span class="token number">10</span>c     6<span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.exp(obj2)Out<span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">:</span> d     403.428793b    1096.633158a       0.006738c      20.085537<span class="token key atrule">dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>还可以将<code>Series</code>看成是一个定长的有序字典，因为它是索引值到数据值的一个映射。它可以用在许多原本需要字典参数的函数中：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 'b' in obj2Out<span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>In <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 'e' in obj2Out<span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如果数据被存放在一个Python字典中，也可以直接通过这个字典来创建Series：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">:</span> sdata = <span class="token punctuation">{</span><span class="token key atrule">'Ohio'</span><span class="token punctuation">:</span> <span class="token number">35000</span><span class="token punctuation">,</span> <span class="token key atrule">'Texas'</span><span class="token punctuation">:</span> <span class="token number">71000</span><span class="token punctuation">,</span> <span class="token key atrule">'Oregon'</span><span class="token punctuation">:</span> <span class="token number">16000</span><span class="token punctuation">,</span> <span class="token key atrule">'Utah'</span><span class="token punctuation">:</span> <span class="token number">5000</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj3 = pd.Series(sdata)In <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj3Out<span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">Ohio      35000Oregon    16000Texas     71000Utah       5000dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果只传入一个字典，则结果Series中的索引就是原字典的键（有序排列）。你可以传入排好序的字典的键以改变顺序：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">:</span> states = <span class="token punctuation">[</span><span class="token string">'California'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Oregon'</span><span class="token punctuation">,</span> <span class="token string">'Texas'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj4 = pd.Series(sdata<span class="token punctuation">,</span> index=states)In <span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj4Out<span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">California        NaNOhio          35000.0Oregon        16000.0Texas         71000.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在这个例子中，sdata中跟states索引相匹配的那3个值会被找出来并放到相应的位置上，但由于”California”所对应的sdata值找不到，所以其结果就为NaN（即“非数字”（not a number），在pandas中，它用于表示缺失或NA值）。因为‘Utah’不在states中，它被从结果中除去。</p><p>我将使用缺失（missing）或NA表示缺失数据。pandas的isnull和notnull函数可用于检测缺失数据：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pd.isnull(obj4)Out<span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">California     TrueOhio          FalseOregon        FalseTexas         Falsedtype</span><span class="token punctuation">:</span> boolIn <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pd.notnull(obj4)Out<span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">California    FalseOhio           TrueOregon         TrueTexas          Truedtype</span><span class="token punctuation">:</span> bool<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Series也有类似的实例方法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">34</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj4.isnull()Out<span class="token punctuation">[</span><span class="token number">34</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">California     TrueOhio          FalseOregon        FalseTexas         Falsedtype</span><span class="token punctuation">:</span> bool<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我将在第7章详细讲解如何处理缺失数据。</p><p>对于许多应用而言，<code>Series</code>最重要的一个功能是，它会根据运算的索引标签自动对齐数据：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj3Out<span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">Ohio      35000Oregon    16000Texas     71000Utah       5000dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj4Out<span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">California        NaNOhio          35000.0Oregon        16000.0Texas         71000.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj3 + obj4Out<span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">California         NaNOhio           70000.0Oregon         32000.0Texas         142000.0Utah               NaNdtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>数据对齐功能将在后面详细讲解。如果你使用过数据库，你可以认为是类似join的操作。</p><p>Series对象本身及其索引都有一个<code>name</code>属性，该属性跟<code>pandas</code>其他的关键功能关系非常密切：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">38</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj4.name = 'population'In <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj4.index.name = 'state'In <span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj4Out<span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">stateCalifornia        NaNOhio          35000.0Oregon        16000.0Texas         71000.0Name</span><span class="token punctuation">:</span> population<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Series的索引可以通过赋值的方式就地修改：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">41</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">41</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    41    72   -53    3dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.index = <span class="token punctuation">[</span><span class="token string">'Bob'</span><span class="token punctuation">,</span> <span class="token string">'Steve'</span><span class="token punctuation">,</span> <span class="token string">'Jeff'</span><span class="token punctuation">,</span> <span class="token string">'Ryan'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">Bob      4Steve    7Jeff    -5Ryan     3dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h5><p>DataFrame是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame既有行索引也有列索引，它可以被看做由Series组成的字典（共用同一个索引）。DataFrame中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。有关DataFrame内部的技术细节远远超出了本书所讨论的范围。</p><ul><li>笔记：虽然DataFrame是以二维结构保存数据的，但你仍然可以轻松地将其表示为更高维度的数据（层次化索引的表格型结构，这是pandas中许多高级数据处理功能的关键要素，我们会在第8章讨论这个问题）。</li></ul><p>建DataFrame的办法有很多，最常用的一种是直接传入一个由等长列表或NumPy数组组成的字典：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">data = <span class="token punctuation">{</span><span class="token key atrule">'state'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Nevada'</span><span class="token punctuation">,</span> <span class="token string">'Nevada'</span><span class="token punctuation">,</span> <span class="token string">'Nevada'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token key atrule">'year'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2000</span><span class="token punctuation">,</span> <span class="token number">2001</span><span class="token punctuation">,</span> <span class="token number">2002</span><span class="token punctuation">,</span> <span class="token number">2001</span><span class="token punctuation">,</span> <span class="token number">2002</span><span class="token punctuation">,</span> <span class="token number">2003</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token key atrule">'pop'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">1.7</span><span class="token punctuation">,</span> <span class="token number">3.6</span><span class="token punctuation">,</span> <span class="token number">2.4</span><span class="token punctuation">,</span> <span class="token number">2.9</span><span class="token punctuation">,</span> <span class="token number">3.2</span><span class="token punctuation">]</span><span class="token punctuation">}</span>frame = pd.DataFrame(data)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果DataFrame会自动加上索引（跟<code>Series</code>一样），且全部列会被有序排列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frameOut<span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    pop   state  year0  1.5    Ohio  20001  1.7    Ohio  20012  3.6    Ohio  20023  2.4  Nevada  20014  2.9  Nevada  20025  3.2  Nevada  2003<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果你使用的是Jupyter notebook，pandas DataFrame对象会以对浏览器友好的HTML表格的方式呈现。</p><p>对于特别大的<code>DataFrame</code>，<code>head</code>方法会选取前五行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.head()Out<span class="token punctuation">[</span><span class="token number">46</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    pop   state  year0  1.5    Ohio  20001  1.7    Ohio  20012  3.6    Ohio  20023  2.4  Nevada  20014  2.9  Nevada  2002<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果指定了列序列，则<code>DataFrame</code>的列就会按照指定顺序进行排列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pd.DataFrame(data<span class="token punctuation">,</span> columns=<span class="token punctuation">[</span><span class="token string">'year'</span><span class="token punctuation">,</span> <span class="token string">'state'</span><span class="token punctuation">,</span> <span class="token string">'pop'</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">47</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    year   state  pop0  2000    Ohio  1.51  2001    Ohio  1.72  2002    Ohio  3.63  2001  Nevada  2.44  2002  Nevada  2.95  2003  Nevada  3.2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果传入的列在数据中找不到，就会在结果中产生缺失值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2 = pd.DataFrame(data<span class="token punctuation">,</span> columns=<span class="token punctuation">[</span><span class="token string">'year'</span><span class="token punctuation">,</span> <span class="token string">'state'</span><span class="token punctuation">,</span> <span class="token string">'pop'</span><span class="token punctuation">,</span> <span class="token string">'debt'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">....</span><span class="token punctuation">:</span>                       index=<span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">,</span> <span class="token string">'four'</span><span class="token punctuation">,</span>   <span class="token key atrule">....</span><span class="token punctuation">:</span>                              <span class="token string">'five'</span><span class="token punctuation">,</span> <span class="token string">'six'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">49</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2Out<span class="token punctuation">[</span><span class="token number">49</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        year   state  pop debtone    2000    Ohio  1.5  NaNtwo    2001    Ohio  1.7  NaNthree  2002    Ohio  3.6  NaNfour   2001  Nevada  2.4  NaNfive   2002  Nevada  2.9  NaNsix    2003  Nevada  3.2  NaNIn <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2.columnsOut<span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Index(<span class="token punctuation">[</span><span class="token string">'year'</span><span class="token punctuation">,</span> <span class="token string">'state'</span><span class="token punctuation">,</span> <span class="token string">'pop'</span><span class="token punctuation">,</span> <span class="token string">'debt'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='object')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过类似字典标记的方式或属性的方式，可以将<code>DataFrame</code>的列获取为一个<code>Series</code>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2<span class="token punctuation">[</span><span class="token string">'state'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">one        Ohiotwo        Ohiothree      Ohiofour     Nevadafive     Nevadasix      NevadaName</span><span class="token punctuation">:</span> state<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> objectIn <span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2.yearOut<span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">one      2000two      2001three    2002four     2001five     2002six      2003Name</span><span class="token punctuation">:</span> year<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>笔记：IPython提供了类似属性的访问（即frame2.year）和tab补全。<br>frame2[column]适用于任何列的名，但是frame2.column只有在列名是一个合理的Python变量名时才适用。</p></blockquote><p>注意，返回的<code>Series</code>拥有原<code>DataFrame</code>相同的索引，且其<code>name</code>属性也已经被相应地设置好了。</p><p>行也可以通过位置或名称的方式进行获取，比如用<code>loc</code>属性（稍后将对此进行详细讲解）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">53</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2.loc<span class="token punctuation">[</span><span class="token string">'three'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">53</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">year     2002state    Ohiopop       3.6debt      NaNName</span><span class="token punctuation">:</span> three<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> object<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>列可以通过赋值的方式进行修改。例如，我们可以给那个空的”debt”列赋上一个标量值或一组值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">54</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2<span class="token punctuation">[</span><span class="token string">'debt'</span><span class="token punctuation">]</span> = 16.5In <span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2Out<span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        year   state  pop  debtone    2000    Ohio  1.5  16.5two    2001    Ohio  1.7  16.5three  2002    Ohio  3.6  16.5four   2001  Nevada  2.4  16.5five   2002  Nevada  2.9  16.5six    2003  Nevada  3.2  16.5In <span class="token punctuation">[</span><span class="token number">56</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2<span class="token punctuation">[</span><span class="token string">'debt'</span><span class="token punctuation">]</span> = np.arange(6.)In <span class="token punctuation">[</span><span class="token number">57</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2Out<span class="token punctuation">[</span><span class="token number">57</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        year   state  pop  debtone    2000    Ohio  1.5   0.0two    2001    Ohio  1.7   1.0three  2002    Ohio  3.6   2.0four   2001  Nevada  2.4   3.0five   2002  Nevada  2.9   4.0six    2003  Nevada  3.2   5.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将列表或数组赋值给某个列时，其长度必须跟DataFrame的长度相匹配。如果赋值的是一个Series，就会精确匹配DataFrame的索引，所有的空位都将被填上缺失值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">58</span><span class="token punctuation">]</span><span class="token punctuation">:</span> val = pd.Series(<span class="token punctuation">[</span><span class="token number">-1.2</span><span class="token punctuation">,</span> <span class="token number">-1.5</span><span class="token punctuation">,</span> <span class="token number">-1.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'four'</span><span class="token punctuation">,</span> <span class="token string">'five'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">59</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2<span class="token punctuation">[</span><span class="token string">'debt'</span><span class="token punctuation">]</span> = valIn <span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2Out<span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        year   state  pop  debtone    2000    Ohio  1.5   NaNtwo    2001    Ohio  1.7  <span class="token punctuation">-</span>1.2three  2002    Ohio  3.6   NaNfour   2001  Nevada  2.4  <span class="token punctuation">-</span>1.5five   2002  Nevada  2.9  <span class="token punctuation">-</span>1.7six    2003  Nevada  3.2   NaN<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为不存在的列赋值会创建出一个新列。<u>关键字del用于删除列</u>。</p><p>作为del的例子，我先添加一个新的布尔值的列，state是否为’Ohio’：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2<span class="token punctuation">[</span><span class="token string">'eastern'</span><span class="token punctuation">]</span> = frame2.state == 'Ohio'In <span class="token punctuation">[</span><span class="token number">62</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2Out<span class="token punctuation">[</span><span class="token number">62</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        year   state  pop  debt  easternone    2000    Ohio  1.5   NaN     Truetwo    2001    Ohio  1.7  <span class="token punctuation">-</span>1.2     Truethree  2002    Ohio  3.6   NaN     Truefour   2001  Nevada  2.4  <span class="token punctuation">-</span>1.5    Falsefive   2002  Nevada  2.9  <span class="token punctuation">-</span>1.7    Falsesix    2003  Nevada  3.2   NaN    False<span class="token comment">#注意：不能用frame2.eastern创建新的列。</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>del方法可以用来删除这列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">63</span><span class="token punctuation">]</span><span class="token punctuation">:</span> del frame2<span class="token punctuation">[</span><span class="token string">'eastern'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2.columnsOut<span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Index(<span class="token punctuation">[</span><span class="token string">'year'</span><span class="token punctuation">,</span> <span class="token string">'state'</span><span class="token punctuation">,</span> <span class="token string">'pop'</span><span class="token punctuation">,</span> <span class="token string">'debt'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='object')<span class="token comment">#注意：通过索引方式返回的列只是相应数据的视图而已，并不是副本。因此，对返回的Series所做的任何就地修改全都会反映到源DataFrame上。通过Series的copy方法即可指定复制列。</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另一种常见的数据形式是嵌套字典：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pop = <span class="token punctuation">{</span><span class="token key atrule">'Nevada'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">2001</span><span class="token punctuation">:</span> <span class="token number">2.4</span><span class="token punctuation">,</span> <span class="token key atrule">2002</span><span class="token punctuation">:</span> <span class="token number">2.9</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token key atrule">....</span><span class="token punctuation">:</span>        <span class="token key atrule">'Ohio'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token key atrule">2000</span><span class="token punctuation">:</span> <span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token key atrule">2001</span><span class="token punctuation">:</span> <span class="token number">1.7</span><span class="token punctuation">,</span> <span class="token key atrule">2002</span><span class="token punctuation">:</span> <span class="token number">3.6</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果嵌套字典传给<code>DataFrame</code>，<code>pandas</code>就会被解释为：外层字典的键作为列，内层键则作为行索引：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3 = pd.DataFrame(pop)In <span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3Out<span class="token punctuation">[</span><span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">:</span>       Nevada  Ohio2000     NaN   1.52001     2.4   1.72002     2.9   3.6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>你也可以使用类似<code>NumPy</code>数组的方法，对<code>DataFrame</code>进行转置（交换行和列）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">68</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3.TOut<span class="token punctuation">[</span><span class="token number">68</span><span class="token punctuation">]</span><span class="token punctuation">:</span>         2000  2001  2002Nevada   NaN   2.4   2.9Ohio     1.5   1.7   3.6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>内层字典的键会被合并、排序以形成最终的索引。如果明确指定了索引，则不会这样：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pd.DataFrame(pop<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token number">2001</span><span class="token punctuation">,</span> <span class="token number">2002</span><span class="token punctuation">,</span> <span class="token number">2003</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">]</span><span class="token punctuation">:</span>       Nevada  Ohio2001     2.4   1.72002     2.9   3.62003     NaN   NaN<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>由Series组成的字典差不多也是一样的用法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pdata = <span class="token punctuation">{</span><span class="token key atrule">'Ohio'</span><span class="token punctuation">:</span> frame3<span class="token punctuation">[</span><span class="token string">'Ohio'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token key atrule">....</span><span class="token punctuation">:</span>          <span class="token key atrule">'Nevada'</span><span class="token punctuation">:</span> frame3<span class="token punctuation">[</span><span class="token string">'Nevada'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">}</span>In <span class="token punctuation">[</span><span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pd.DataFrame(pdata)Out<span class="token punctuation">[</span><span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">:</span>       Nevada  Ohio2000     NaN   1.52001     2.4   1.7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了<code>DataFrame</code>构造函数所能接受的各种数据。</p><p><img src="https://tvax1.sinaimg.cn/large/007mx13gly1gus2tfct4kj60tv0la7b702.jpg" alt="pandas的数据结构介绍"> </p><p>如果设置了DataFrame的index和columns的name属性，则这些信息也会被显示出来：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">72</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3.index.name = 'year'; frame3.columns.name = 'state'In <span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3Out<span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">]</span><span class="token punctuation">:</span> state  Nevada  Ohioyear2000      NaN   1.52001      2.4   1.72002      2.9   3.6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>跟<code>Series</code>一样，<code>values</code>属性也会以二维<code>ndarray</code>的形式返回<code>DataFrame</code>中的数据：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3.valuesOut<span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> nan<span class="token punctuation">,</span>  <span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.4</span><span class="token punctuation">,</span>  <span class="token number">1.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">2.9</span><span class="token punctuation">,</span>  <span class="token number">3.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果DataFrame各列的数据类型不同，则值数组的dtype就会选用能兼容所有列的数据类型：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2.valuesOut<span class="token punctuation">[</span><span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">:</span>array(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2000</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">,</span> nan<span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2001</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token number">1.7</span><span class="token punctuation">,</span> <span class="token number">-1.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2002</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token number">3.6</span><span class="token punctuation">,</span> nan<span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2001</span><span class="token punctuation">,</span> <span class="token string">'Nevada'</span><span class="token punctuation">,</span> <span class="token number">2.4</span><span class="token punctuation">,</span> <span class="token number">-1.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2002</span><span class="token punctuation">,</span> <span class="token string">'Nevada'</span><span class="token punctuation">,</span> <span class="token number">2.9</span><span class="token punctuation">,</span> <span class="token number">-1.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2003</span><span class="token punctuation">,</span> <span class="token string">'Nevada'</span><span class="token punctuation">,</span> <span class="token number">3.2</span><span class="token punctuation">,</span> nan<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=object)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="索引对象"><a href="#索引对象" class="headerlink" title="索引对象"></a>索引对象</h5><p>pandas的索引对象负责管理轴标签和其他元数据（比如轴名称等）。构建Series或DataFrame时，所用到的任何数组或其他序列的标签都会被转换成一个Index：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(range(3)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">77</span><span class="token punctuation">]</span><span class="token punctuation">:</span> index = obj.indexIn <span class="token punctuation">[</span><span class="token number">78</span><span class="token punctuation">]</span><span class="token punctuation">:</span> indexOut<span class="token punctuation">[</span><span class="token number">78</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Index(<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='object')In <span class="token punctuation">[</span><span class="token number">79</span><span class="token punctuation">]</span><span class="token punctuation">:</span> index<span class="token punctuation">[</span>1<span class="token punctuation">:</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">79</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Index(<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='object')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><u>Index对象是不可变的</u>，因此用户不能对其进行修改：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">index<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> = 'd'  <span class="token comment"># TypeError</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>不可变可以使Index对象在多个数据结构之间安全共享：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">:</span> labels = pd.Index(np.arange(3))In <span class="token punctuation">[</span><span class="token number">81</span><span class="token punctuation">]</span><span class="token punctuation">:</span> labelsOut<span class="token punctuation">[</span><span class="token number">81</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Int64Index(<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='int64')In <span class="token punctuation">[</span><span class="token number">82</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2 = pd.Series(<span class="token punctuation">[</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">-2.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index=labels)In <span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2Out<span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    1.51   -2.52    0.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2.index is labelsOut<span class="token punctuation">[</span><span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">True</span><span class="token comment">#注意：虽然用户不需要经常使用Index的功能，但是因为一些操作会生成包含被索引化的数据，理解它们的工作原理是很重要的。</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>除了类似于数组，Index的功能也类似一个固定大小的集合：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3Out<span class="token punctuation">[</span><span class="token number">85</span><span class="token punctuation">]</span><span class="token punctuation">:</span> state  Nevada  Ohioyear               2000      NaN   1.52001      2.4   1.72002      2.9   3.6In <span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame3.columnsOut<span class="token punctuation">[</span><span class="token number">86</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Index(<span class="token punctuation">[</span><span class="token string">'Nevada'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='object'<span class="token punctuation">,</span> name='state')In <span class="token punctuation">[</span><span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 'Ohio' in frame3.columnsOut<span class="token punctuation">[</span><span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">:</span> TrueIn <span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 2003 in frame3.indexOut<span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>与python的集合不同，pandas的<u>Index可以包含重复的标签</u>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dup_labels = pd.Index(<span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">90</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dup_labelsOut<span class="token punctuation">[</span><span class="token number">90</span><span class="token punctuation">]</span><span class="token punctuation">:</span> Index(<span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype='object')<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>选择重复的标签，会显示所有的结果。</p><p>每个索引都有一些方法和属性，它们可用于设置逻辑并回答有关该索引所包含的数据的常见问题。下表列出了这些函数。</p><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gus3dtezl8j60yg0kbtb202.jpg" alt="pandas的数据结构介绍"></p><h3 id="5-2-基本功能"><a href="#5-2-基本功能" class="headerlink" title="5.2 基本功能"></a>5.2 基本功能</h3><p>本节中，我将介绍操作Series和DataFrame中的数据的基本手段。后续章节将更加深入地挖掘pandas在数据分析和处理方面的功能。本书不是pandas库的详尽文档，主要关注的是最重要的功能，那些不大常用的内容（也就是那些更深奥的内容）就交给你自己去摸索吧。</p><h4 id="重新索引"><a href="#重新索引" class="headerlink" title="重新索引"></a>重新索引</h4><p>pandas对象的一个重要方法是reindex，其作用是创建一个新对象，它的数据符合新的索引。看下面的例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">91</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(<span class="token punctuation">[</span><span class="token number">4.5</span><span class="token punctuation">,</span> <span class="token number">7.2</span><span class="token punctuation">,</span> <span class="token number">-5.3</span><span class="token punctuation">,</span> <span class="token number">3.6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">d    4.5b    7.2a   -5.3c    3.6dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用该Series的<code>reindex</code>将会根据新索引进行重排。如果某个索引值当前不存在，就引入缺失值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2 = obj.reindex(<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj2Out<span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a   -5.3b    7.2c    3.6d    4.5e    NaNdtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于时间序列这样的有序数据，重新索引时可能需要做一些插值处理。<code>method</code>选项即可达到此目的，例如，使用ffill可以实现前向值填充：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj3 = pd.Series(<span class="token punctuation">[</span><span class="token string">'blue'</span><span class="token punctuation">,</span> <span class="token string">'purple'</span><span class="token punctuation">,</span> <span class="token string">'yellow'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj3Out<span class="token punctuation">[</span><span class="token number">96</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0      blue2    purple4    yellowdtype</span><span class="token punctuation">:</span> objectIn <span class="token punctuation">[</span><span class="token number">97</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj3.reindex(range(6)<span class="token punctuation">,</span> method='ffill')Out<span class="token punctuation">[</span><span class="token number">97</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0      blue1      blue2    purple3    purple4    yellow5    yellowdtype</span><span class="token punctuation">:</span> object<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>借助DataFrame，reindex可以修改（行）索引和列。只传递一个序列时，会重新索引结果的行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">98</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame = pd.DataFrame(np.arange(9).reshape((3<span class="token punctuation">,</span> 3))<span class="token punctuation">,</span>   <span class="token key atrule">....</span><span class="token punctuation">:</span>                      index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">....</span><span class="token punctuation">:</span>                      columns=<span class="token punctuation">[</span><span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Texas'</span><span class="token punctuation">,</span> <span class="token string">'California'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frameOut<span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    Ohio  Texas  Californiaa     0      1           2c     3      4           5d     6      7           8In <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2 = frame.reindex(<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame2Out<span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    Ohio  Texas  Californiaa   0.0    1.0         2.0b   NaN    NaN         NaNc   3.0    4.0         5.0d   6.0    7.0         8.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>列可以用columns关键字重新索引：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">:</span> states = <span class="token punctuation">[</span><span class="token string">'Texas'</span><span class="token punctuation">,</span> <span class="token string">'Utah'</span><span class="token punctuation">,</span> <span class="token string">'California'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.reindex(columns=states)Out<span class="token punctuation">[</span><span class="token number">103</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    Texas  Utah  Californiaa      1   NaN           2c      4   NaN           5d      7   NaN           8<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1guu2jexpxyj60yg0ftdi502.jpg" alt="reindex函数的各参数及说明"></p><h4 id="丢弃指定轴上的项"><a href="#丢弃指定轴上的项" class="headerlink" title="丢弃指定轴上的项"></a>丢弃指定轴上的项</h4><p>丢弃某条轴上的一个或多个项很简单，只要有一个索引数组或列表即可。由于需要执行一些数据整理和集合逻辑，所以drop方法返回的是一个在指定轴上删除了指定值的新对象：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">105</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(np.arange(5.)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">106</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0.0b    1.0c    2.0d    3.0e    4.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">107</span><span class="token punctuation">]</span><span class="token punctuation">:</span> new_obj = obj.drop('c')In <span class="token punctuation">[</span><span class="token number">108</span><span class="token punctuation">]</span><span class="token punctuation">:</span> new_objOut<span class="token punctuation">[</span><span class="token number">108</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0.0b    1.0d    3.0e    4.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.drop(<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">109</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0.0b    1.0e    4.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于<code>DataFrame</code>，可以删除任意轴上的索引值。为了演示，先新建一个DataFrame例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">110</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data = pd.DataFrame(np.arange(16).reshape((4<span class="token punctuation">,</span> 4))<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                     index=<span class="token punctuation">[</span><span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Colorado'</span><span class="token punctuation">,</span> <span class="token string">'Utah'</span><span class="token punctuation">,</span> <span class="token string">'New York'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                     columns=<span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">,</span> <span class="token string">'four'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">111</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">111</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  two  three  fourOhio        0    1      2     3Colorado    4    5      6     7Utah        8    9     10    11New York   12   13     14    15<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用标签序列调用drop会从行标签（axis 0）删除值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">112</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.drop(<span class="token punctuation">[</span><span class="token string">'Colorado'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">112</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  two  three  fourUtah        8    9     10    11New York   12   13     14    15<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过传递<code>axis=1</code>或<code>axis=’columns’</code>可以删除列的值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">113</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.drop('two'<span class="token punctuation">,</span> axis=1)Out<span class="token punctuation">[</span><span class="token number">113</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  three  fourOhio        0      2     3Colorado    4      6     7Utah        8     10    11New York   12     14    15In <span class="token punctuation">[</span><span class="token number">114</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.drop(<span class="token punctuation">[</span><span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'four'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis='columns')Out<span class="token punctuation">[</span><span class="token number">114</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  threeOhio        0      2Colorado    4      6Utah        8     10New York   12     14<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>许多函数，如drop，会修改Series或DataFrame的大小或形状，可以就地修改对象，不会返回新的对象：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">115</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.drop('c'<span class="token punctuation">,</span> inplace=True)In <span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0.0b    1.0d    3.0e    4.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>小心使用inplace，它会销毁所有被删除的数据。</p><h4 id="索引、选取和过滤"><a href="#索引、选取和过滤" class="headerlink" title="索引、选取和过滤"></a>索引、选取和过滤</h4><p>Series索引（obj[…]）的工作方式类似于<code>NumPy</code>数组的索引，只不过<code>Series</code>的索引值不只是整数。下面是几个例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">117</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(np.arange(4.)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">118</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">118</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0.0b    1.0c    2.0d    3.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">119</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">119</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 1.0In <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 1.0In <span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span>2<span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">c    2.0d    3.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">122</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">122</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token key atrule">b    1.0a    0.0d    3.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">123</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">123</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">b    1.0d    3.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span>obj &lt; 2<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0.0b    1.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>利用标签的切片运算与普通的Python切片运算不同，其末端是包含的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">125</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span>'b'<span class="token punctuation">:</span><span class="token string">'c'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">125</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token key atrule">b    1.0c    2.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用切片可以对<code>Series</code>的相应部分进行设置：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">126</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span>'b'<span class="token punctuation">:</span><span class="token string">'c'</span><span class="token punctuation">]</span> = 5In <span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">127</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0.0b    5.0c    5.0d    3.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用一个值或序列对DataFrame进行索引其实就是获取一个或多个列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data = pd.DataFrame(np.arange(16).reshape((4<span class="token punctuation">,</span> 4))<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                     index=<span class="token punctuation">[</span><span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Colorado'</span><span class="token punctuation">,</span> <span class="token string">'Utah'</span><span class="token punctuation">,</span> <span class="token string">'New York'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                     columns=<span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">,</span> <span class="token string">'four'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">129</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">129</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  two  three  fourOhio        0    1      2     3Colorado    4    5      6     7Utah        8    9     10    11New York   12   13     14    15In <span class="token punctuation">[</span><span class="token number">130</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token string">'two'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">130</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">Ohio         1Colorado     5Utah         9New York    13Name</span><span class="token punctuation">:</span> two<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">131</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'three'</span><span class="token punctuation">,</span> <span class="token string">'one'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">131</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           three  oneOhio          2    0Colorado      6    4Utah         10    8New York     14   12<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这种索引方式有几个特殊的情况。首先通过切片或布尔型数组选取数据：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">132</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">132</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  two  three  fourOhio        0    1      2     3Colorado    4    5      6     7In <span class="token punctuation">[</span><span class="token number">133</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">'three'</span><span class="token punctuation">]</span> <span class="token punctuation">&gt;</span> 5<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">133</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  two  three  fourColorado    4    5      6     7Utah        8    9     10    11New York   12   13     14    15<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>选取行的语法data[:2]十分方便。向[ ]传递单一的元素或列表，就可选择列。</p><p>另一种用法是通过布尔型DataFrame（比如下面这个由标量比较运算得出的）进行索引：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">134</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data &lt; 5Out<span class="token punctuation">[</span><span class="token number">134</span><span class="token punctuation">]</span><span class="token punctuation">:</span>             one    two  three   fourOhio       True   True   True   TrueColorado   True  False  False  FalseUtah      False  False  False  FalseNew York  False  False  False  FalseIn <span class="token punctuation">[</span><span class="token number">135</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span>data &lt; 5<span class="token punctuation">]</span> = 0In <span class="token punctuation">[</span><span class="token number">136</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">136</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  two  three  fourOhio        0    0      0     0Colorado    0    5      6     7Utah        8    9     10    11New York   12   13     14    15<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这使得DataFrame的语法与NumPy二维数组的语法很像。</p><h4 id="用loc和iloc进行选取"><a href="#用loc和iloc进行选取" class="headerlink" title="用loc和iloc进行选取"></a>用loc和iloc进行选取</h4><p>对于DataFrame的行的标签索引，我引入了特殊的标签运算符loc和iloc。它们可以让你用类似NumPy的标记，使用轴标签（loc）或整数索引（iloc），从DataFrame选择行和列的子集。</p><p>作为一个初步示例，让我们通过标签选择一行和多列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">137</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.loc<span class="token punctuation">[</span><span class="token string">'Colorado'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">137</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">two      5three    6Name</span><span class="token punctuation">:</span> Colorado<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后用iloc和整数进行选取：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">138</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.iloc<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">138</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">four    11one      8two      9Name</span><span class="token punctuation">:</span> Utah<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">139</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.iloc<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">139</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">one       8two       9three    10four     11Name</span><span class="token punctuation">:</span> Utah<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">140</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.iloc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">140</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           four  one  twoColorado     7    0    5Utah        11    8    9<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这两个索引函数也适用于一个标签或多个标签的切片：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">141</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token string">'Utah'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">141</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">Ohio        0Colorado    5Utah        9Name</span><span class="token punctuation">:</span> two<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">142</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data.iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">[</span>data.three <span class="token punctuation">&gt;</span> 5<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">142</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           one  two  threeColorado    0    5      6Utah        8    9     10New York   12   13     14<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>所以，在pandas中，有多个方法可以选取和重新组合数据。对于DataFrame，表5-4进行了总结。后面会看到，还有更多的方法进行层级化索引。</p><blockquote><p>笔记：在一开始设计pandas时，我觉得用frame[:, col]选取列过于繁琐（也容易出错），因为列的选择是非常常见的操作。我做了些取舍，将花式索引的功能（标签和整数）放到了ix运算符中。在实践中，这会导致许多边缘情况，数据的轴标签是整数，所以pandas团队决定创造loc和iloc运算符分别处理严格基于标签和整数的索引。<br>ix运算符仍然可用，但并不推荐。</p></blockquote><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1guu3ygk9nhj60pt0fqk0g02.jpg" alt="DataFrame的索引选项"></p><h4 id="整数索引"><a href="#整数索引" class="headerlink" title="整数索引"></a>整数索引</h4><p>处理整数索引的pandas对象常常难住新手，因为它与Python内置的列表和元组的索引语法不同。例如，你可能不认为下面的代码会出错：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">ser = pd.Series(np.arange(3.))serser<span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里，pandas可以勉强进行整数索引，但是会导致小bug。我们有包含0,1,2的索引，但是引入用户想要的东西（基于标签或位置的索引）很难：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">144</span><span class="token punctuation">]</span><span class="token punctuation">:</span> serOut<span class="token punctuation">[</span><span class="token number">144</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    0.01    1.02    2.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另外，对于非整数索引，不会产生歧义：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">145</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ser2 = pd.Series(np.arange(3.)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">146</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ser2<span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">146</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">2.0</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为了进行统一，如果轴索引含有整数，数据选取总会使用标签。为了更准确，请使用loc（标签）或iloc（整数）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">147</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ser<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">147</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    0.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">148</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ser.loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">148</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    0.01    1.0dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">149</span><span class="token punctuation">]</span><span class="token punctuation">:</span> ser.iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">149</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    0.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="算术运算和数据对齐"><a href="#算术运算和数据对齐" class="headerlink" title="算术运算和数据对齐"></a>算术运算和数据对齐</h4><p><code>pandas</code>最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。对于有数据库经验的用户，这就像在索引标签上进行自动外连接。看一个简单的例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s1 = pd.Series(<span class="token punctuation">[</span><span class="token number">7.3</span><span class="token punctuation">,</span> <span class="token number">-2.5</span><span class="token punctuation">,</span> <span class="token number">3.4</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">151</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s2 = pd.Series(<span class="token punctuation">[</span><span class="token number">-2.1</span><span class="token punctuation">,</span> <span class="token number">3.6</span><span class="token punctuation">,</span> <span class="token number">-1.5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token string">'f'</span><span class="token punctuation">,</span> <span class="token string">'g'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s1Out<span class="token punctuation">[</span><span class="token number">152</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    7.3c   -2.5d    3.4e    1.5dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">153</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s2Out<span class="token punctuation">[</span><span class="token number">153</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a   -2.1c    3.6e   -1.5f    4.0g    3.1dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将它们相加就会产生：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">154</span><span class="token punctuation">]</span><span class="token punctuation">:</span> s1 + s2Out<span class="token punctuation">[</span><span class="token number">154</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    5.2c    1.1d    NaNe    0.0f    NaNg    NaNdtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>自动的数据对齐操作在不重叠的索引处引入了NA值。<u>缺失值会在算术运算过程中传播</u>。</p><p>对于DataFrame，对齐操作会同时发生在行和列上：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">155</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1 = pd.DataFrame(np.arange(9.).reshape((3<span class="token punctuation">,</span> 3))<span class="token punctuation">,</span> columns=list('bcd')<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                    index=<span class="token punctuation">[</span><span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Texas'</span><span class="token punctuation">,</span> <span class="token string">'Colorado'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">156</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2 = pd.DataFrame(np.arange(12.).reshape((4<span class="token punctuation">,</span> 3))<span class="token punctuation">,</span> columns=list('bde')<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                    index=<span class="token punctuation">[</span><span class="token string">'Utah'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Texas'</span><span class="token punctuation">,</span> <span class="token string">'Oregon'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">157</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1Out<span class="token punctuation">[</span><span class="token number">157</span><span class="token punctuation">]</span><span class="token punctuation">:</span>             b    c    dOhio      0.0  1.0  2.0Texas     3.0  4.0  5.0Colorado  6.0  7.0  8.0In <span class="token punctuation">[</span><span class="token number">158</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2Out<span class="token punctuation">[</span><span class="token number">158</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           b     d     eUtah    0.0   1.0   2.0Ohio    3.0   4.0   5.0Texas   6.0   7.0   8.0Oregon  9.0  10.0  11.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>把它们相加后将会返回一个新的DataFrame，其索引和列为原来那两个DataFrame的并集：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">159</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1 + df2Out<span class="token punctuation">[</span><span class="token number">159</span><span class="token punctuation">]</span><span class="token punctuation">:</span>             b   c     d   eColorado  NaN NaN   NaN NaNOhio      3.0 NaN   6.0 NaNOregon    NaN NaN   NaN NaNTexas     9.0 NaN  12.0 NaNUtah      NaN NaN   NaN NaN<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为’c’和’e’列均不在两个DataFrame对象中，在结果中以缺省值呈现。行也是同样。</p><p>如果DataFrame对象相加，没有共用的列或行标签，结果都会是空：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">160</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1 = pd.DataFrame(<span class="token punctuation">{</span><span class="token key atrule">'A'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">}</span>)In <span class="token punctuation">[</span><span class="token number">161</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2 = pd.DataFrame(<span class="token punctuation">{</span><span class="token key atrule">'B'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">}</span>)In <span class="token punctuation">[</span><span class="token number">162</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1Out<span class="token punctuation">[</span><span class="token number">162</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    A0  11  2In <span class="token punctuation">[</span><span class="token number">163</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2Out<span class="token punctuation">[</span><span class="token number">163</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    B0  31  4In <span class="token punctuation">[</span><span class="token number">164</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1 <span class="token punctuation">-</span> df2Out<span class="token punctuation">[</span><span class="token number">164</span><span class="token punctuation">]</span><span class="token punctuation">:</span>     A   B0 NaN NaN1 NaN NaN<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="在算术方法中填充值"><a href="#在算术方法中填充值" class="headerlink" title="在算术方法中填充值"></a>在算术方法中填充值</h4><p>在对不同索引的对象进行算术运算时，你可能希望当一个对象中某个轴标签在另一个对象中找不到时填充一个特殊值（比如0）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">165</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1 = pd.DataFrame(np.arange(12.).reshape((3<span class="token punctuation">,</span> 4))<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                    columns=list('abcd'))In <span class="token punctuation">[</span><span class="token number">166</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2 = pd.DataFrame(np.arange(20.).reshape((4<span class="token punctuation">,</span> 5))<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                    columns=list('abcde'))In <span class="token punctuation">[</span><span class="token number">167</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2.loc<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span> = np.nanIn <span class="token punctuation">[</span><span class="token number">168</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1Out<span class="token punctuation">[</span><span class="token number">168</span><span class="token punctuation">]</span><span class="token punctuation">:</span>      a    b     c     d0  0.0  1.0   2.0   3.01  4.0  5.0   6.0   7.02  8.0  9.0  10.0  11.0In <span class="token punctuation">[</span><span class="token number">169</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df2Out<span class="token punctuation">[</span><span class="token number">169</span><span class="token punctuation">]</span><span class="token punctuation">:</span>       a     b     c     d     e0   0.0   1.0   2.0   3.0   4.01   5.0   NaN   7.0   8.0   9.02  10.0  11.0  12.0  13.0  14.03  15.0  16.0  17.0  18.0  19.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将它们相加时，没有重叠的位置就会产生NA值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">170</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1 + df2Out<span class="token punctuation">[</span><span class="token number">170</span><span class="token punctuation">]</span><span class="token punctuation">:</span>       a     b     c     d   e0   0.0   2.0   4.0   6.0 NaN1   9.0   NaN  13.0  15.0 NaN2  18.0  20.0  22.0  24.0 NaN3   NaN   NaN   NaN   NaN NaN<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>使用df1的add方法，传入df2以及一个fill_value参数：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">171</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1.add(df2<span class="token punctuation">,</span> fill_value=0)Out<span class="token punctuation">[</span><span class="token number">171</span><span class="token punctuation">]</span><span class="token punctuation">:</span>       a     b     c     d     e0   0.0   2.0   4.0   6.0   4.01   9.0   5.0  13.0  15.0   9.02  18.0  20.0  22.0  24.0  14.03  15.0  16.0  17.0  18.0  19.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了Series和DataFrame的算术方法。它们每个都有一个副本，以字母r开头，它会翻转参数。因此这两个语句是等价的：</p><p><img src="https://tvax2.sinaimg.cn/large/007mx13gly1guu4b99k53j60as072gmh02.jpg" alt="灵活的算术方法"></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">172</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 1 / df1Out<span class="token punctuation">[</span><span class="token number">172</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           a         b         c         d0       inf  1.000000  0.500000  0.3333331  0.250000  0.200000  0.166667  0.1428572  0.125000  0.111111  0.100000  0.090909In <span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1.rdiv(1)Out<span class="token punctuation">[</span><span class="token number">173</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           a         b         c         d0       inf  1.000000  0.500000  0.3333331  0.250000  0.200000  0.166667  0.1428572  0.125000  0.111111  0.100000  0.090909<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>与此类似，在对Series或DataFrame重新索引时，也可以指定一个填充值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df1.reindex(columns=df2.columns<span class="token punctuation">,</span> fill_value=0)Out<span class="token punctuation">[</span><span class="token number">174</span><span class="token punctuation">]</span><span class="token punctuation">:</span>      a    b     c     d  e0  0.0  1.0   2.0   3.0  01  4.0  5.0   6.0   7.0  02  8.0  9.0  10.0  11.0  0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="DataFrame和Series之间的运算"><a href="#DataFrame和Series之间的运算" class="headerlink" title="DataFrame和Series之间的运算"></a>DataFrame和Series之间的运算</h4><p>跟不同维度的NumPy数组一样，<code>DataFrame</code>和<code>Series</code>之间算术运算也是有明确规定的。先来看一个具有启发性的例子，计算一个二维数组与其某行之间的差：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">175</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr = np.arange(12.).reshape((3<span class="token punctuation">,</span> 4))In <span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arrOut<span class="token punctuation">[</span><span class="token number">176</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0.</span><span class="token punctuation">,</span>   <span class="token number">1.</span><span class="token punctuation">,</span>   <span class="token number">2.</span><span class="token punctuation">,</span>   <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">4.</span><span class="token punctuation">,</span>   <span class="token number">5.</span><span class="token punctuation">,</span>   <span class="token number">6.</span><span class="token punctuation">,</span>   <span class="token number">7.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span>  <span class="token number">8.</span><span class="token punctuation">,</span>   <span class="token number">9.</span><span class="token punctuation">,</span>  <span class="token number">10.</span><span class="token punctuation">,</span>  <span class="token number">11.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">177</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">177</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">178</span><span class="token punctuation">]</span><span class="token punctuation">:</span> arr <span class="token punctuation">-</span> arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">178</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span> <span class="token number">8.</span><span class="token punctuation">,</span>  <span class="token number">8.</span><span class="token punctuation">,</span>  <span class="token number">8.</span><span class="token punctuation">,</span>  <span class="token number">8.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当我们从arr减去arr[0]，每一行都会执行这个操作。这就叫做广播（broadcasting），附录A将对此进行详细讲解。DataFrame和Series之间的运算差不多也是如此：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">179</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame = pd.DataFrame(np.arange(12.).reshape((4<span class="token punctuation">,</span> 3))<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                      columns=list('bde')<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                      index=<span class="token punctuation">[</span><span class="token string">'Utah'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Texas'</span><span class="token punctuation">,</span> <span class="token string">'Oregon'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">180</span><span class="token punctuation">]</span><span class="token punctuation">:</span> series = frame.iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">181</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frameOut<span class="token punctuation">[</span><span class="token number">181</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           b     d     eUtah    0.0   1.0   2.0Ohio    3.0   4.0   5.0Texas   6.0   7.0   8.0Oregon  9.0  10.0  11.0In <span class="token punctuation">[</span><span class="token number">182</span><span class="token punctuation">]</span><span class="token punctuation">:</span> seriesOut<span class="token punctuation">[</span><span class="token number">182</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">b    0.0d    1.0e    2.0Name</span><span class="token punctuation">:</span> Utah<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>默认情况下，DataFrame和Series之间的算术运算会将Series的索引匹配到DataFrame的列，然后沿着行一直向下广播：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">183</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame <span class="token punctuation">-</span> seriesOut<span class="token punctuation">[</span><span class="token number">183</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           b    d    eUtah    0.0  0.0  0.0Ohio    3.0  3.0  3.0Texas   6.0  6.0  6.0Oregon  9.0  9.0  9.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果某个索引值在<code>DataFrame</code>的列或<code>Series</code>的索引中找不到，则参与运算的两个对象就会被重新索引以形成并集：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">184</span><span class="token punctuation">]</span><span class="token punctuation">:</span> series2 = pd.Series(range(3)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token string">'f'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">185</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame + series2Out<span class="token punctuation">[</span><span class="token number">185</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           b   d     e   fUtah    0.0 NaN   3.0 NaNOhio    3.0 NaN   6.0 NaNTexas   6.0 NaN   9.0 NaNOregon  9.0 NaN  12.0 NaN<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果你希望匹配行且在列上广播，则必须使用算术运算方法。例如：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">186</span><span class="token punctuation">]</span><span class="token punctuation">:</span> series3 = frame<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">]</span>In <span class="token punctuation">[</span><span class="token number">187</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frameOut<span class="token punctuation">[</span><span class="token number">187</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           b     d     eUtah    0.0   1.0   2.0Ohio    3.0   4.0   5.0Texas   6.0   7.0   8.0Oregon  9.0  10.0  11.0In <span class="token punctuation">[</span><span class="token number">188</span><span class="token punctuation">]</span><span class="token punctuation">:</span> series3Out<span class="token punctuation">[</span><span class="token number">188</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">Utah       1.0Ohio       4.0Texas      7.0Oregon    10.0Name</span><span class="token punctuation">:</span> d<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> float64In <span class="token punctuation">[</span><span class="token number">189</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.sub(series3<span class="token punctuation">,</span> axis='index')Out<span class="token punctuation">[</span><span class="token number">189</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           b    d    eUtah   <span class="token punctuation">-</span>1.0  0.0  1.0Ohio   <span class="token punctuation">-</span>1.0  0.0  1.0Texas  <span class="token punctuation">-</span>1.0  0.0  1.0Oregon <span class="token punctuation">-</span>1.0  0.0  1.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>传入的轴号就是希望匹配的轴。在本例中，我们的目的是匹配DataFrame的行索引（axis=’index’ or axis=0）并进行广播。</p><h4 id="函数应用和映射"><a href="#函数应用和映射" class="headerlink" title="函数应用和映射"></a>函数应用和映射</h4><p>NumPy的ufuncs（元素级数组方法）也可用于操作pandas对象：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">190</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame = pd.DataFrame(np.random.randn(4<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> columns=list('bde')<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                      index=<span class="token punctuation">[</span><span class="token string">'Utah'</span><span class="token punctuation">,</span> <span class="token string">'Ohio'</span><span class="token punctuation">,</span> <span class="token string">'Texas'</span><span class="token punctuation">,</span> <span class="token string">'Oregon'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">191</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frameOut<span class="token punctuation">[</span><span class="token number">191</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                b         d         eUtah   <span class="token punctuation">-</span>0.204708  0.478943 <span class="token punctuation">-</span>0.519439Ohio   <span class="token punctuation">-</span>0.555730  1.965781  1.393406Texas   0.092908  0.281746  0.769023Oregon  1.246435  1.007189 <span class="token punctuation">-</span>1.296221In <span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">]</span><span class="token punctuation">:</span> np.abs(frame)Out<span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                b         d         eUtah    0.204708  0.478943  0.519439Ohio    0.555730  1.965781  1.393406Texas   0.092908  0.281746  0.769023Oregon  1.246435  1.007189  1.296221<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另一个常见的操作是，将函数应用到由各列或行所形成的一维数组上。DataFrame的apply方法即可实现此功能：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">193</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">f = lambda x</span><span class="token punctuation">:</span> x.max() <span class="token punctuation">-</span> x.min()In <span class="token punctuation">[</span><span class="token number">194</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.apply(f)Out<span class="token punctuation">[</span><span class="token number">194</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">b    1.802165d    1.684034e    2.689627dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里的函数f，计算了一个<code>Series</code>的最大值和最小值的差，在<code>frame</code>的每列都执行了一次。结果是一个Series，使用frame的列作为索引。</p><p>如果传递axis=’columns’到apply，这个函数会在每行执行：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">195</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.apply(f<span class="token punctuation">,</span> axis='columns')Out<span class="token punctuation">[</span><span class="token number">195</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token key atrule">Utah      0.998382Ohio      2.521511Texas     0.676115Oregon    2.542656dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>许多最为常见的数组统计功能都被实现成<code>DataFrame</code>的方法（如<code>sum</code>和<code>mean</code>），因此无需使用apply方法。</p><p>传递到apply的函数不是必须返回一个标量，还可以返回由多个值组成的<code>Series</code>：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">196</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">def f(x)</span><span class="token punctuation">:</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>     return pd.Series(<span class="token punctuation">[</span>x.min()<span class="token punctuation">,</span> x.max()<span class="token punctuation">]</span><span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'min'</span><span class="token punctuation">,</span> <span class="token string">'max'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">197</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.apply(f)Out<span class="token punctuation">[</span><span class="token number">197</span><span class="token punctuation">]</span><span class="token punctuation">:</span>             b         d         emin <span class="token punctuation">-</span>0.555730  0.281746 <span class="token punctuation">-</span>1.296221max  1.246435  1.965781  1.393406<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>元素级的Python函数也是可以用的。假如你想得到frame中各个浮点值的格式化字符串，使用applymap即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">198</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">format = lambda x</span><span class="token punctuation">:</span> '%.2f' % xIn <span class="token punctuation">[</span><span class="token number">199</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.applymap(format)Out<span class="token punctuation">[</span><span class="token number">199</span><span class="token punctuation">]</span><span class="token punctuation">:</span>             b     d      eUtah    <span class="token punctuation">-</span>0.20  0.48  <span class="token punctuation">-</span>0.52Ohio    <span class="token punctuation">-</span>0.56  1.97   1.39Texas    0.09  0.28   0.77Oregon   1.25  1.01  <span class="token punctuation">-</span><span class="token number">1.30</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>之所以叫做applymap，是因为Series有一个用于应用元素级函数的map方法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame<span class="token punctuation">[</span><span class="token string">'e'</span><span class="token punctuation">]</span>.map(format)Out<span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">Utah      -0.52Ohio       1.39Texas      0.77Oregon    -1.30Name</span><span class="token punctuation">:</span> e<span class="token punctuation">,</span> <span class="token key atrule">dtype</span><span class="token punctuation">:</span> object<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="排序和排名"><a href="#排序和排名" class="headerlink" title="排序和排名"></a>排序和排名</h4><p>根据条件对数据集排序（<code>sorting</code>）也是一种重要的内置运算。要对行或列索引进行排序（按字典顺序），可使用sort_index方法，它将返回一个已排序的新对象：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">201</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(range(4)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">202</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.sort_index()Out<span class="token punctuation">[</span><span class="token number">202</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token key atrule">a    1b    2c    3d    0dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于DataFrame，则可以根据任意一个轴上的索引进行排序：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">203</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame = pd.DataFrame(np.arange(8).reshape((2<span class="token punctuation">,</span> 4))<span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                      index=<span class="token punctuation">[</span><span class="token string">'three'</span><span class="token punctuation">,</span> <span class="token string">'one'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                      columns=<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">204</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.sort_index()Out<span class="token punctuation">[</span><span class="token number">204</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        d  a  b  cone    4  5  6  7three  0  1  2  3In <span class="token punctuation">[</span><span class="token number">205</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.sort_index(axis=1)Out<span class="token punctuation">[</span><span class="token number">205</span><span class="token punctuation">]</span><span class="token punctuation">:</span>       a  b  c  dthree  1  2  3  0one    5  6  7  4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>数据默认是按升序排序的，但也可以降序排序：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">206</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.sort_index(axis=1<span class="token punctuation">,</span> ascending=False)Out<span class="token punctuation">[</span><span class="token number">206</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        d  c  b  athree  0  3  2  1one    4  7  6  5<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>若要按值对Series进行排序，可使用其sort_values方法：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">207</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">-3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">208</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.sort_values()Out<span class="token punctuation">[</span><span class="token number">208</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">2   -33    20    41    7dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在排序时，任何缺失值默认都会被放到Series的末尾：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">209</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> np.nan<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> np.nan<span class="token punctuation">,</span> <span class="token number">-3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">210</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.sort_values()Out<span class="token punctuation">[</span><span class="token number">210</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">4   -3.05    2.00    4.02    7.01    NaN3    NaNdtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当排序一个<code>DataFrame</code>时，你可能希望根据一个或多个列中的值进行排序。将一个或多个列的名字传递给sort_values的by选项即可达到该目的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">211</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame = pd.DataFrame(<span class="token punctuation">{</span><span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">-3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span>)In <span class="token punctuation">[</span><span class="token number">212</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frameOut<span class="token punctuation">[</span><span class="token number">212</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    a  b0  0  41  1  72  0 <span class="token punctuation">-</span>33  1  2In <span class="token punctuation">[</span><span class="token number">213</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.sort_values(by='b')Out<span class="token punctuation">[</span><span class="token number">213</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    a  b2  0 <span class="token punctuation">-</span>33  1  20  0  41  1  7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>要根据多个列进行排序，传入名称的列表即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">214</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.sort_values(by=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">214</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    a  b2  0 <span class="token punctuation">-</span>30  0  43  1  21  1  7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>排名会从1开始一直到数组中有效数据的数量。接下来介绍<code>Series</code>和<code>DataFrame</code>的rank方法。默认情况下，rank是通过“为各组分配一个平均排名”的方式破坏平级关系的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">215</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">-5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">216</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.rank()Out<span class="token punctuation">[</span><span class="token number">216</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    6.51    1.02    6.53    4.54    3.05    2.06    4.5dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也可以根据值在原数据中出现的顺序给出排名：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">217</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.rank(method='first')Out<span class="token punctuation">[</span><span class="token number">217</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    6.01    1.02    7.03    4.04    3.05    2.06    5.0dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里，条目0和2没有使用平均排名6.5，它们被设成了6和7，因为数据中标签0位于标签2的前面。</p><p>你也可以按降序进行排名：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># Assign tie values the maximum rank in the groupIn [218]: obj.rank(ascending=False, method='max')Out[218]: 0    2.01    7.02    2.03    4.04    5.05    6.06    4.0dtype: float64</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了所有用于破坏平级关系的。DataFrame可以在行或列上计算排名：</p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1guu604be0mj60i5068dh002.jpg" alt="排名时用于破坏平级关系的方法"></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">219</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame = pd.DataFrame(<span class="token punctuation">{</span><span class="token key atrule">'b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4.3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">-3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token key atrule">'a'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                       <span class="token key atrule">'c'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">-2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">-2.5</span><span class="token punctuation">]</span><span class="token punctuation">}</span>)In <span class="token punctuation">[</span><span class="token number">220</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frameOut<span class="token punctuation">[</span><span class="token number">220</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    a    b    c0  0  4.3 <span class="token punctuation">-</span>2.01  1  7.0  5.02  0 <span class="token punctuation">-</span>3.0  8.03  1  2.0 <span class="token punctuation">-</span>2.5In <span class="token punctuation">[</span><span class="token number">221</span><span class="token punctuation">]</span><span class="token punctuation">:</span> frame.rank(axis='columns')Out<span class="token punctuation">[</span><span class="token number">221</span><span class="token punctuation">]</span><span class="token punctuation">:</span>      a    b    c0  2.0  3.0  1.01  1.0  3.0  2.02  2.0  1.0  3.03  2.0  3.0  1.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="带有重复标签的轴索引"><a href="#带有重复标签的轴索引" class="headerlink" title="带有重复标签的轴索引"></a>带有重复标签的轴索引</h4><p>直到目前为止，我所介绍的所有范例都有着唯一的轴标签（索引值）。虽然许多pandas函数（如reindex）都要求标签唯一，但这并不是强制性的。我们来看看下面这个简单的带有重复索引值的Series：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">222</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(range(5)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">223</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">223</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0a    1b    2b    3c    4dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>索引的is_unique属性可以告诉你它的值是否是唯一的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.index.is_uniqueOut<span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token boolean important">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于带有重复值的索引，数据选取的行为将会有些不同。如果某个索引对应多个值，则返回一个Series；而对应单个值的，则返回一个标量值：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">225</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">225</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    0a    1dtype</span><span class="token punctuation">:</span> int64In <span class="token punctuation">[</span><span class="token number">226</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">226</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">4</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样会使代码变复杂，因为索引的输出类型会根据标签是否有重复发生变化。</p><p>对DataFrame的行进行索引时也是如此：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">227</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df = pd.DataFrame(np.random.randn(4<span class="token punctuation">,</span> 3)<span class="token punctuation">,</span> index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">228</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dfOut<span class="token punctuation">[</span><span class="token number">228</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           0         1         2a  0.274992  0.228913  1.352917a  0.886429 <span class="token punctuation">-</span>2.001637 <span class="token punctuation">-</span>0.371843b  1.669025 <span class="token punctuation">-</span>0.438570 <span class="token punctuation">-</span>0.539741b  0.476985  3.248944 <span class="token punctuation">-</span>1.021228In <span class="token punctuation">[</span><span class="token number">229</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df.loc<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">229</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           0         1         2b  1.669025 <span class="token punctuation">-</span>0.438570 <span class="token punctuation">-</span>0.539741b  0.476985  3.248944 <span class="token punctuation">-</span><span class="token number">1.021228</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-3-汇总和计算描述统计"><a href="#5-3-汇总和计算描述统计" class="headerlink" title="5.3 汇总和计算描述统计"></a>5.3 汇总和计算描述统计</h3><p><code>pandas</code>对象拥有一组常用的数学和统计方法。它们大部分都属于约简和汇总统计，用于从Series中提取单个值（如sum或mean）或从DataFrame的行或列中提取一个Series。跟对应的NumPy数组方法相比，它们都是基于没有缺失数据的假设而构建的。看一个简单的DataFrame：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">230</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df = pd.DataFrame(<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.4</span><span class="token punctuation">,</span> np.nan<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.1</span><span class="token punctuation">,</span> <span class="token number">-4.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                    <span class="token punctuation">[</span>np.nan<span class="token punctuation">,</span> np.nan<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.75</span><span class="token punctuation">,</span> <span class="token number">-1.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                   index=<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                   columns=<span class="token punctuation">[</span><span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">231</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dfOut<span class="token punctuation">[</span><span class="token number">231</span><span class="token punctuation">]</span><span class="token punctuation">:</span>     one  twoa  1.40  NaNb  7.10 <span class="token punctuation">-</span>4.5c   NaN  NaNd  0.75 <span class="token punctuation">-</span><span class="token number">1.3</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>调用DataFrame的sum方法将会返回一个含有列的和的Series：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">232</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df.sum()Out<span class="token punctuation">[</span><span class="token number">232</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">one    9.25two   -5.80dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>传入axis=’columns’或axis=1将会按行进行求和运算：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">233</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df.sum(axis=1)Out<span class="token punctuation">[</span><span class="token number">233</span><span class="token punctuation">]</span><span class="token punctuation">:</span>a    1.40b    2.60c     NaNd   <span class="token punctuation">-</span><span class="token number">0.55</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>NA值会自动被排除，除非整个切片（这里指的是行或列）都是NA。通过skipna选项可以禁用该功能：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">234</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df.mean(axis='columns'<span class="token punctuation">,</span> skipna=False)Out<span class="token punctuation">[</span><span class="token number">234</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a      NaNb    1.300c      NaNd   -0.275dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了这些约简方法的常用选项。</p><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1guu6vovafqj60yg081gmd02.jpg" alt="汇总和计算描述统计"></p><p>有些方法（如idxmin和idxmax）返回的是间接统计（比如达到最小值或最大值的索引）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">235</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df.idxmax()Out<span class="token punctuation">[</span><span class="token number">235</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">one    btwo    ddtype</span><span class="token punctuation">:</span> object <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另一些方法则是<u>累计型</u>的：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">236</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df.cumsum()Out<span class="token punctuation">[</span><span class="token number">236</span><span class="token punctuation">]</span><span class="token punctuation">:</span>     one  twoa  1.40  NaNb  8.50 <span class="token punctuation">-</span>4.5c   NaN  NaNd  9.25 <span class="token punctuation">-</span><span class="token number">5.8</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>还有一种方法，它既不是约简型也不是累计型。describe就是一个例子，它用于一次性产生多个汇总统计：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">237</span><span class="token punctuation">]</span><span class="token punctuation">:</span> df.describe()Out<span class="token punctuation">[</span><span class="token number">237</span><span class="token punctuation">]</span><span class="token punctuation">:</span>             one       twocount  3.000000  2.000000mean   3.083333 <span class="token punctuation">-</span>2.900000std    3.493685  2.262742min    0.750000 <span class="token punctuation">-</span>4.50000025%    1.075000 <span class="token punctuation">-</span>3.70000050%    1.400000 <span class="token punctuation">-</span>2.90000075%    4.250000 <span class="token punctuation">-</span>2.100000max    7.100000 <span class="token punctuation">-</span><span class="token number">1.300000</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于非数值型数据，<code>describe</code>会产生另外一种汇总统计：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">238</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span> * 4)In <span class="token punctuation">[</span><span class="token number">239</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.describe()Out<span class="token punctuation">[</span><span class="token number">239</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">count     16unique     3top        afreq       8dtype</span><span class="token punctuation">:</span> object<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下表列出了所有与描述统计相关的方法。</p><p><img src="https://tva4.sinaimg.cn/large/007mx13gly1guu72rt5btj60xh0vrtbs02.jpg" alt="汇总和计算描述统计"></p><h4 id="相关系数与协方差"><a href="#相关系数与协方差" class="headerlink" title="相关系数与协方差"></a>相关系数与协方差</h4><p>有些汇总统计（如相关系数和协方差）是通过参数对计算出来的。我们来看几个DataFrame，它们的数据来自Yahoo!Finance的股票价格和成交量，使用的是pandas-datareader包（可以用conda或pip安装）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">conda install pandas<span class="token punctuation">-</span>datareader<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我使用pandas_datareader模块下载了一些股票数据：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">import pandas_datareader.data as weball_data = <span class="token punctuation">{</span><span class="token key atrule">ticker</span><span class="token punctuation">:</span> web.get_data_yahoo(ticker)            for ticker in <span class="token punctuation">[</span><span class="token string">'AAPL'</span><span class="token punctuation">,</span> <span class="token string">'IBM'</span><span class="token punctuation">,</span> <span class="token string">'MSFT'</span><span class="token punctuation">,</span> <span class="token string">'GOOG'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>price = pd.DataFrame(<span class="token punctuation">{</span><span class="token key atrule">ticker</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token string">'Adj Close'</span><span class="token punctuation">]</span>                     for ticker<span class="token punctuation">,</span> data in all_data.items()<span class="token punctuation">}</span>)volume = pd.DataFrame(<span class="token punctuation">{</span><span class="token key atrule">ticker</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token string">'Volume'</span><span class="token punctuation">]</span>                      for ticker<span class="token punctuation">,</span> data in all_data.items()<span class="token punctuation">}</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>注意：此时Yahoo! Finance已经不存在了，因为2017年Yahoo!被Verizon收购了。参阅pandas-datareader文档，可以学习最新的功能。</p></blockquote><p>现在计算价格的百分数变化，时间序列的操作会在第11章介绍：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">242</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns = price.pct_change()In <span class="token punctuation">[</span><span class="token number">243</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns.tail()Out<span class="token punctuation">[</span><span class="token number">243</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                 AAPL      GOOG       IBM      MSFTDate                                              2016<span class="token punctuation">-</span>10<span class="token punctuation">-</span>17 <span class="token punctuation">-</span>0.000680  0.001837  0.002072 <span class="token punctuation">-</span>0.0034832016<span class="token punctuation">-</span>10<span class="token punctuation">-</span>18 <span class="token punctuation">-</span>0.000681  0.019616 <span class="token punctuation">-</span>0.026168  0.0076902016<span class="token punctuation">-</span>10<span class="token punctuation">-</span>19 <span class="token punctuation">-</span>0.002979  0.007846  0.003583 <span class="token punctuation">-</span>0.0022552016<span class="token punctuation">-</span>10<span class="token punctuation">-</span>20 <span class="token punctuation">-</span>0.000512 <span class="token punctuation">-</span>0.005652  0.001719 <span class="token punctuation">-</span>0.0048672016<span class="token punctuation">-</span>10<span class="token punctuation">-</span>21 <span class="token punctuation">-</span>0.003930  0.003011 <span class="token punctuation">-</span>0.012474  0.042096<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Series的corr方法用于计算两个Series中重叠的、非NA的、按索引对齐的值的相关系数。与此类似，cov用于计算协方差：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">244</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns<span class="token punctuation">[</span><span class="token string">'MSFT'</span><span class="token punctuation">]</span>.corr(returns<span class="token punctuation">[</span><span class="token string">'IBM'</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">244</span><span class="token punctuation">]</span><span class="token punctuation">:</span> 0.49976361144151144In <span class="token punctuation">[</span><span class="token number">245</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns<span class="token punctuation">[</span><span class="token string">'MSFT'</span><span class="token punctuation">]</span>.cov(returns<span class="token punctuation">[</span><span class="token string">'IBM'</span><span class="token punctuation">]</span>)Out<span class="token punctuation">[</span><span class="token number">245</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">8.8706554797035462e-05</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为MSTF是一个合理的Python属性，我们还可以用更简洁的语法选择列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">246</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns.MSFT.corr(returns.IBM)Out<span class="token punctuation">[</span><span class="token number">246</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token number">0.49976361144151144</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>另一方面，DataFrame的corr和cov方法将以DataFrame的形式分别返回完整的相关系数或协方差矩阵：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">247</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns.corr()Out<span class="token punctuation">[</span><span class="token number">247</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           AAPL      GOOG       IBM      MSFTAAPL  1.000000  0.407919  0.386817  0.389695GOOG  0.407919  1.000000  0.405099  0.465919IBM   0.386817  0.405099  1.000000  0.499764MSFT  0.389695  0.465919  0.499764  1.000000In <span class="token punctuation">[</span><span class="token number">248</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns.cov()Out<span class="token punctuation">[</span><span class="token number">248</span><span class="token punctuation">]</span><span class="token punctuation">:</span>           AAPL      GOOG       IBM      MSFTAAPL  0.000277  0.000107  0.000078  0.000095GOOG  0.000107  0.000251  0.000078  0.000108IBM   0.000078  0.000078  0.000146  0.000089MSFT  0.000095  0.000108  0.000089  0.000215<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>利用DataFrame的corrwith方法，你可以计算其列或行跟另一个Series或DataFrame之间的相关系数。传入一个Series将会返回一个相关系数值Series（针对各列进行计算）：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">249</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns.corrwith(returns.IBM)Out<span class="token punctuation">[</span><span class="token number">249</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">AAPL    0.386817GOOG    0.405099IBM     1.000000MSFT    0.499764dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>传入一个<code>DataFrame</code>则会计算按列名配对的相关系数。这里，我计算百分比变化与成交量的相关系数：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">250</span><span class="token punctuation">]</span><span class="token punctuation">:</span> returns.corrwith(volume)Out<span class="token punctuation">[</span><span class="token number">250</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">AAPL   -0.075565GOOG   -0.007067IBM    -0.204849MSFT   -0.092950dtype</span><span class="token punctuation">:</span> float64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>传入axis=’columns’即可按行进行计算。无论如何，在计算相关系数之前，所有的数据项都会按标签对齐。<br>唯一值、值计数以及成员资格</p><p>还有一类方法可以从一维Series的值中抽取信息。看下面的例子：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">251</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj = pd.Series(<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第一个函数是unique，它可以得到Series中的唯一值数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">252</span><span class="token punctuation">]</span><span class="token punctuation">:</span> uniques = obj.unique()In <span class="token punctuation">[</span><span class="token number">253</span><span class="token punctuation">]</span><span class="token punctuation">:</span> uniquesOut<span class="token punctuation">[</span><span class="token number">253</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype=object)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>返回的唯一值是未排序的，如果需要的话，可以对结果再次进行排序（uniques.sort()）。相似的，value_counts用于计算一个Series中各值出现的频率：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">254</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj.value_counts()Out<span class="token punctuation">[</span><span class="token number">254</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">c    3a    3b    2d    1dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为了便于查看，结果Series是按值频率降序排列的。value_counts还是一个顶级pandas方法，可用于任何数组或序列：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">255</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pd.value_counts(obj.values<span class="token punctuation">,</span> sort=False)Out<span class="token punctuation">[</span><span class="token number">255</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">a    3b    2c    3d    1dtype</span><span class="token punctuation">:</span> int64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>isin用于判断矢量化集合的成员资格，可用于过滤Series中或DataFrame列中数据的子集：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">:</span> objOut<span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    c1    a2    d3    a4    a5    b6    b7    c8    cdtype</span><span class="token punctuation">:</span> objectIn <span class="token punctuation">[</span><span class="token number">257</span><span class="token punctuation">]</span><span class="token punctuation">:</span> mask = obj.isin(<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">258</span><span class="token punctuation">]</span><span class="token punctuation">:</span> maskOut<span class="token punctuation">[</span><span class="token number">258</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0     True1    False2    False3    False4    False5     True6     True7     True8     Truedtype</span><span class="token punctuation">:</span> boolIn <span class="token punctuation">[</span><span class="token number">259</span><span class="token punctuation">]</span><span class="token punctuation">:</span> obj<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>Out<span class="token punctuation">[</span><span class="token number">259</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token key atrule">0    c5    b6    b7    c8    cdtype</span><span class="token punctuation">:</span> object<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>与isin类似的是Index.get_indexer方法，它可以给你一个索引数组，从可能包含重复值的数组到另一个不同值的数组：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">260</span><span class="token punctuation">]</span><span class="token punctuation">:</span> to_match = pd.Series(<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">261</span><span class="token punctuation">]</span><span class="token punctuation">:</span> unique_vals = pd.Series(<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">]</span>)In <span class="token punctuation">[</span><span class="token number">262</span><span class="token punctuation">]</span><span class="token punctuation">:</span> pd.Index(unique_vals).get_indexer(to_match)Out<span class="token punctuation">[</span><span class="token number">262</span><span class="token punctuation">]</span><span class="token punctuation">:</span> array(<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>表给出了这几个方法的一些参考信息。</p><p><img src="https://tvax3.sinaimg.cn/large/007mx13gly1guu7jqw8xoj60nk0580u802.jpg" alt="唯一值、值计数、成员资格方法"></p><p>有时，你可能希望得到DataFrame中多个相关列的一张柱状图。例如：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">263</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data = pd.DataFrame(<span class="token punctuation">{</span><span class="token key atrule">'Qu1'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                      <span class="token key atrule">'Qu2'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token key atrule">.....</span><span class="token punctuation">:</span>                      <span class="token key atrule">'Qu3'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">}</span>)In <span class="token punctuation">[</span><span class="token number">264</span><span class="token punctuation">]</span><span class="token punctuation">:</span> dataOut<span class="token punctuation">[</span><span class="token number">264</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    Qu1  Qu2  Qu30    1    2    11    3    3    52    4    1    23    3    2    44    4    3    4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将pandas.value_counts传给该DataFrame的apply函数，就会出现：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">In <span class="token punctuation">[</span><span class="token number">265</span><span class="token punctuation">]</span><span class="token punctuation">:</span> result = data.apply(pd.value_counts).fillna(0)In <span class="token punctuation">[</span><span class="token number">266</span><span class="token punctuation">]</span><span class="token punctuation">:</span> resultOut<span class="token punctuation">[</span><span class="token number">266</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    Qu1  Qu2  Qu31  1.0  1.0  1.02  0.0  2.0  1.03  2.0  2.0  0.04  2.0  0.0  2.05  0.0  0.0  1.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里，结果中的行标签是所有列的唯一值。后面的频率值是每个列中这些值的相应计数。</p>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo博客出现的问题及处理方法</title>
      <link href="/2021/09/19/hexo-bo-ke-chu-xian-de-wen-ti-ji-chu-li-fang-fa/"/>
      <url>/2021/09/19/hexo-bo-ke-chu-xian-de-wen-ti-ji-chu-li-fang-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="添加图片（添加线上图片）"><a href="#添加图片（添加线上图片）" class="headerlink" title="添加图片（添加线上图片）"></a>添加图片（添加线上图片）</h2><p>本地图片仍然无法添加进入图片,目前只能实现添加在线图片的功能。</p><p>首先选择一个图床（我选择的微博图床<em>微博图床</em>），上传图片获得链接，具体方法参考<a href="https://www.bilibili.com/read/cv6075030/">想方便快捷的分享/收藏图片？试试免费好用的微博图床</a>。</p><p>然后就可以通过<code>![图名](图片生成的URL链接)</code>的常见方式直接插入在线图片</p><p>例如我的网站logo图片</p><p><img src="https://tva3.sinaimg.cn/large/007mx13gly1gult8rrmexj608c08cjra02.jpg" alt="图名"></p><p>就可以直接通过如下指令直接插入</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token tag">!</span><span class="token punctuation">[</span>图名<span class="token punctuation">]</span>(https<span class="token punctuation">:</span>//tva3.sinaimg.cn/large/007mx13gly1gult8rrmexj608c08cjra02.jpg)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="如何插入公式"><a href="#如何插入公式" class="headerlink" title="如何插入公式"></a>如何插入公式</h2><p>可参考文章<a href="https://zhuanlan.zhihu.com/p/108766968">结合MathType和MathJax在Hexo博客中插入数学公式 </a></p><p>使用时注意：插入mathtype的复制<code>数学公式</code>时：</p><p>首先对<code>Preferences</code>下的<code>Cut and Copy Preferences</code>进行设置。如下图：</p><p><img src="https://pic3.zhimg.com/80/v2-36c773a2a6453de2cd5e9524f5fb2c06_720w.jpg" alt=""></p><p>然后以如下形式插入数学公式</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">{% raw%} 数学公式 {% endraw %}<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>若想在一句话中<code>嵌入公式</code>，则只需要在<code>LaTex</code>公式两端用一个<code>$</code></p><p>公式单行居中显示的方法为</p><pre class="line-numbers language-none"><code class="language-none">$$ 数学公式 $$<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VSCode加C++环境下编译语言遇到的问题以及解决方法</title>
      <link href="/2021/09/19/vscode-jia-c-huan-jing-xia-bian-yi-yu-yan-yu-dao-de-wen-ti-yi-ji-jie-jue-fang-fa/"/>
      <url>/2021/09/19/vscode-jia-c-huan-jing-xia-bian-yi-yu-yan-yu-dao-de-wen-ti-yi-ji-jie-jue-fang-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="中文乱码问题"><a href="#中文乱码问题" class="headerlink" title="中文乱码问题"></a>中文乱码问题</h2><p>运行测试文件<strong>test.cpp</strong>，存在中文乱码的问题</p><p><strong>test.cpp</strong><br></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"> <span class="token comment">#include&lt;iostream&gt;</span> using namespace std; int main()<span class="token punctuation">{</span>int num;cout&lt;&lt;"请输入一个整型数：";cin<span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span>num;cout&lt;&lt;"八进制数是："&lt;&lt;oct&lt;&lt;num&lt;&lt;endl;cout&lt;&lt;"十进制数是："&lt;&lt;dec&lt;&lt;num&lt;&lt;endl;cout&lt;&lt;"十六进制数是："&lt;&lt;hex&lt;&lt;num&lt;&lt;endl;return 0;<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>解决方法：点击vscode右下角的UTF-8，出现“选择操作”界面，选择“通过编码重新打开”，再输出“gbk”，再进行编译即可。（注意更改后保存）</p>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VSCode配置C++环境</title>
      <link href="/2021/09/18/vscode-pei-zhi-c-huan-jing/"/>
      <url>/2021/09/18/vscode-pei-zhi-c-huan-jing/</url>
      
        <content type="html"><![CDATA[<h2 id="安装VSCode与C"><a href="#安装VSCode与C" class="headerlink" title="安装VSCode与C++"></a>安装VSCode与C++</h2><p>参考<a href="https://blog.csdn.net/Zhouzi_heng/article/details/115014059">【c++】VSCode配置 c++ 环境（小白教程））</a></p><h2 id="VSCode配置c"><a href="#VSCode配置c" class="headerlink" title="VSCode配置c++"></a>VSCode配置c++</h2><p>网上有许多关于vscode下c++配置，一种是配置文件的方法，一种是添加插件直接配置的方法</p><h3 id="配置文件法"><a href="#配置文件法" class="headerlink" title="配置文件法"></a>配置文件法</h3><p><img src="https://tva2.sinaimg.cn/large/007mx13gly1gul7mhhg36j60k8087wfz02.jpg" alt="第一步"><br><img src="https://tva4.sinaimg.cn/large/007mx13gly1gul7mqrtwgj60c8047js602.jpg" alt="第二步"></p><h3 id="配置插件法（两种）"><a href="#配置插件法（两种）" class="headerlink" title="配置插件法（两种）"></a>配置插件法（两种）</h3><p>可选两种：</p><p><em>Code runner</em> （右上角箭头运行）</p><p><em>C/C++ Compile Run</em>（F6运行）</p><p>参考<a href="https://zhuanlan.zhihu.com/p/77645306">windows 10上使用vscode编译运行和调试C/C++</a></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="对应测试文件"><a href="#对应测试文件" class="headerlink" title="对应测试文件"></a>对应测试文件</h3><p><strong>test.cpp</strong></p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"> <span class="token comment">#include&lt;iostream&gt;</span> using namespace std; int main()<span class="token punctuation">{</span>int num;cout&lt;&lt;"请输入一个整型数：";cin<span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span>num;cout&lt;&lt;"八进制数是："&lt;&lt;oct&lt;&lt;num&lt;&lt;endl;cout&lt;&lt;"十进制数是："&lt;&lt;dec&lt;&lt;num&lt;&lt;endl;cout&lt;&lt;"十六进制数是："&lt;&lt;hex&lt;&lt;num&lt;&lt;endl;return 0;<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>插件法可以直接在vscode中查看编译结果</p><p>配置文件的方法需要再下载插件<em>Code Runner</em>运行生成的exe文件，配置成功后的运行文件可在输入数字后反应。（存在中文乱码的问题需要处理）</p>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客主题之hexo-theme-matery的介绍（转载于blinkfox）</title>
      <link href="/2021/09/18/hexo-bo-ke-zhu-ti-zhi-hexo-theme-matery-de-jie-shao/"/>
      <url>/2021/09/18/hexo-bo-ke-zhu-ti-zhi-hexo-theme-matery-de-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="hexo-theme-matery"><a href="#hexo-theme-matery" class="headerlink" title="hexo-theme-matery"></a>hexo-theme-matery</h1><blockquote><p>这是一个采用 <code>Material Design</code> 和响应式设计的 Hexo 博客主题。</p></blockquote><h2 id="转载说明"><a href="#转载说明" class="headerlink" title="转载说明"></a>转载说明</h2><p>本文作者为<a href="https://blinkfox.github.io/about/">blinkfox</a>,转载本文仅为个人学习参考，本文为博客小白，如有做的不对的地方，请大佬指出，必定及时修正。</p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li>简单漂亮，文章内容美观易读</li><li><a href="https://material.io/">Material Design</a> 设计</li><li>响应式设计，博客在桌面端、平板、手机等设备上均能很好的展现</li><li>首页轮播文章及每天动态切换 <code>Banner</code> 图片</li><li>瀑布流式的博客文章列表（文章无特色图片时会有 <code>24</code> 张漂亮的图片代替）</li><li>时间轴式的归档页</li><li><strong>词云</strong>的标签页和<strong>雷达图</strong>的分类页</li><li>丰富的关于我页面（包括关于我、文章统计图、我的项目、我的技能、相册等）</li><li>可自定义的数据的友情链接页面</li><li>支持文章置顶和文章打赏</li><li>支持 <code>MathJax</code></li><li><code>TOC</code> 目录</li><li>可设置复制文章内容时追加版权信息</li><li>可设置阅读文章时做密码验证</li><li><a href="https://gitalk.github.io/">Gitalk</a>、<a href="https://imsun.github.io/gitment/">Gitment</a>、<a href="https://valine.js.org/">Valine</a> 和 <a href="https://disqus.com/">Disqus</a> 评论模块（推荐使用 <code>Gitalk</code>）</li><li>集成了<a href="http://busuanzi.ibruce.info/">不蒜子统计</a>、谷歌分析（<code>Google Analytics</code>）和文章字数统计等功能</li><li>支持在首页的音乐播放和视频播放功能</li><li>支持<code>emoji</code>表情，用<code>markdown emoji</code>语法书写直接生成对应的能<strong>跳跃</strong>的表情。</li><li>支持 <a href="http://www.daovoice.io/">DaoVoice</a>、<a href="https://www.tidio.com/">Tidio</a> 在线聊天功能。</li></ul><h2 id="贡献者"><a href="#贡献者" class="headerlink" title="贡献者"></a>贡献者</h2><p>感谢下面列出的贡献者，没有他们，hexo-theme-matery 不会这么完美。</p><ul><li><a href="https://github.com/HarborZeng">@HarborZeng</a></li><li><a href="https://github.com/shw2018">@shw2018</a></li><li><a href="https://github.com/L1cardo">@L1cardo</a></li><li><a href="https://github.com/Five-great">@Five-great</a></li></ul><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>本主题<strong>推荐你使用 Hexo 5.0.0 及以上的版本</strong>。如果，你已经有一个自己的 <a href="https://hexo.io/zh-cn/">Hexo</a> 博客了，建议你将 Hexo 升级到最新稳定的版本。</p><p>点击 <a href="https://codeload.github.com/blinkfox/hexo-theme-matery/zip/master">这里</a> 下载 <code>master</code> 分支的最新稳定版的代码，解压缩后，将 <code>hexo-theme-matery</code> 的文件夹复制到你 Hexo 的 <code>themes</code> 文件夹中即可。</p><p>当然你也可以在你的 <code>themes</code> 文件夹下使用 <code>git clone</code> 命令来下载:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/blinkfox/hexo-theme-matery.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="切换主题"><a href="#切换主题" class="headerlink" title="切换主题"></a>切换主题</h3><p>修改 Hexo 根目录下的 <code>_config.yml</code> 的  <code>theme</code> 的值：<code>theme: hexo-theme-matery</code></p><h4 id="config-yml-文件的其它修改建议"><a href="#config-yml-文件的其它修改建议" class="headerlink" title="_config.yml 文件的其它修改建议:"></a><code>_config.yml</code> 文件的其它修改建议:</h4><ul><li>请修改 <code>_config.yml</code> 的 <code>url</code> 的值为你的网站主 <code>URL</code>（如：<code>http://xxx.github.io</code>）。</li><li>建议修改两个 <code>per_page</code> 的分页条数值为 <code>6</code> 的倍数，如：<code>12</code>、<code>18</code> 等，这样文章列表在各个屏幕下都能较好的显示。</li><li>如果你是中文用户，则建议修改 <code>language</code> 的值为 <code>zh-CN</code>。</li></ul><h3 id="新建分类-categories-页"><a href="#新建分类-categories-页" class="headerlink" title="新建分类 categories 页"></a>新建分类 categories 页</h3><p><code>categories</code> 页是用来展示所有分类的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>categories/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"categories"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/categories/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> categories<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"categories"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"categories"</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="新建标签-tags-页"><a href="#新建标签-tags-页" class="headerlink" title="新建标签 tags 页"></a>新建标签 tags 页</h3><p><code>tags</code> 页是用来展示所有标签的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>tags/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"tags"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/tags/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> tags<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 18:23:38</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"tags"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"tags"</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="新建关于我-about-页"><a href="#新建关于我-about-页" class="headerlink" title="新建关于我 about 页"></a>新建关于我 about 页</h3><p><code>about</code> 页是用来展示<strong>关于我和我的博客</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>about/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"about"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/about/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> about<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"about"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"about"</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="新建留言板-contact-页（可选的）"><a href="#新建留言板-contact-页（可选的）" class="headerlink" title="新建留言板 contact 页（可选的）"></a>新建留言板 contact 页（可选的）</h3><p><code>contact</code> 页是用来展示<strong>留言板</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>contact/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"contact"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/contact/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> contact<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"contact"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"contact"</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><strong>注</strong>：本留言板功能依赖于第三方评论系统，请<strong>激活</strong>你的评论系统才有效果。并且在主题的 <code>_config.yml</code> 文件中，第 <code>19</code> 至 <code>21</code> 行的“<strong>菜单</strong>”配置，取消关于留言板的注释即可。</p></blockquote><h3 id="新建友情链接-friends-页（可选的）"><a href="#新建友情链接-friends-页（可选的）" class="headerlink" title="新建友情链接 friends 页（可选的）"></a>新建友情链接 friends 页（可选的）</h3><p><code>friends</code> 页是用来展示<strong>友情链接</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>friends/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"friends"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/friends/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> friends<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-12-12 21:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"friends"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"friends"</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同时，在你的博客 <code>source</code> 目录下新建 <code>_data</code> 目录，在 <code>_data</code> 目录中新建 <code>friends.json</code> 文件，文件内容如下所示：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span><span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/1_qq_27922023.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"码酱"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"我不是大佬，只是在追寻大佬的脚步"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"http://luokangyuan.com/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/4027734.jpeg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"闪烁之狐"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://blinkfox.github.io/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/avatar.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"ja_rome"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"平凡的脚步也可以走出伟大的行程"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://me.csdn.net/jlh912008548"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="新建-404-页"><a href="#新建-404-页" class="headerlink" title="新建 404 页"></a>新建 404 页</h3><p>如果在你的博客 <code>source</code> 目录下还没有 <code>404.md</code> 文件，那么你就需要新建一个</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token number">404</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/404/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> <span class="token number">404</span><span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"404"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"404"</span><span class="token key atrule">description</span><span class="token punctuation">:</span> <span class="token string">"Oops～，我崩溃了！找不到你想要的页面 :("</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="菜单导航配置"><a href="#菜单导航配置" class="headerlink" title="菜单导航配置"></a>菜单导航配置</h3><h4 id="配置基本菜单导航的名称、路径url和图标icon"><a href="#配置基本菜单导航的名称、路径url和图标icon" class="headerlink" title="配置基本菜单导航的名称、路径url和图标icon."></a>配置基本菜单导航的名称、路径url和图标icon.</h4><p>1.菜单导航名称可以是中文也可以是英文(如：<code>Index</code>或<code>主页</code>)<br>2.图标icon 可以在<a href="https://fontawesome.com/icons">Font Awesome</a> 中查找   </p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="二级菜单配置方法"><a href="#二级菜单配置方法" class="headerlink" title="二级菜单配置方法"></a>二级菜单配置方法</h4><p>如果你需要二级菜单则可以在原基本菜单导航的基础上如下操作</p><ol><li>在需要添加二级菜单的一级菜单下添加<code>children</code>关键字(如:<code>About</code>菜单下添加<code>children</code>)     </li><li>在<code>children</code>下创建二级菜单的 名称name,路径url和图标icon.      </li><li>注意每个二级菜单模块前要加 <code>-</code>.     </li><li>注意缩进格式  </li></ol><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle<span class="token punctuation">-</span>o  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book  <span class="token key atrule">Medias</span><span class="token punctuation">:</span>    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>list    <span class="token key atrule">children</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Music        <span class="token key atrule">url</span><span class="token punctuation">:</span> /music        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>music      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Movies        <span class="token key atrule">url</span><span class="token punctuation">:</span> /movies        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>film      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Books        <span class="token key atrule">url</span><span class="token punctuation">:</span> /books        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>book      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Galleries        <span class="token key atrule">url</span><span class="token punctuation">:</span> /galleries        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>image<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后就可以在文章中对应位置看到你用<code>emoji</code>语法写的表情了。</p><h3 id="代码高亮"><a href="#代码高亮" class="headerlink" title="代码高亮"></a>代码高亮</h3><p>从 Hexo5.0 版本开始自带了 <code>prismjs</code> 代码语法高亮的支持，本主题对此进行了改造支持。</p><p>如果你的博客中曾经安装过 <code>hexo-prism-plugin</code> 的插件，那么你须要执行 <code>npm uninstall hexo-prism-plugin</code> 来卸载掉它，否则生成的代码中会有 <code>&amp;#123;</code> 和 <code>&amp;#125;</code> 的转义字符。</p><p>然后，修改 Hexo 根目录下 <code>_config.yml</code> 文件中 <code>highlight.enable</code> 的值为 <code>false</code>，并将 <code>prismjs.enable</code> 的值设置为 <code>true</code>，主要配置如下：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">highlight</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">line_number</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">auto_detect</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">tab_replace</span><span class="token punctuation">:</span> <span class="token string">''</span>  <span class="token key atrule">wrap</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">hljs</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">prismjs</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">preprocess</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">line_number</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">tab_replace</span><span class="token punctuation">:</span> <span class="token string">''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主题中默认的 <code>prismjs</code> 主题是 <code>Tomorrow Night</code>，如果你想定制自己的主题，可以前往 <a href="https://prismjs.com/download.html">prismjs 下载页面</a> 定制下载自己喜欢的主题 <code>css</code> 文件，然后将此 css 主题文件取名为 <code>prism.css</code>，替换掉 <code>hexo-theme-matery</code> 主题文件夹中的 <code>source/libs/prism/prism.css</code> 文件即可。</p><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>本主题中还使用到了 <a href="https://github.com/wzpan/hexo-generator-search">hexo-generator-search</a> 的 Hexo 插件来做内容搜索，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-search --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">search</span><span class="token punctuation">:</span>  <span class="token key atrule">path</span><span class="token punctuation">:</span> search.xml  <span class="token key atrule">field</span><span class="token punctuation">:</span> post<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="中文链接转拼音（建议安装）"><a href="#中文链接转拼音（建议安装）" class="headerlink" title="中文链接转拼音（建议安装）"></a>中文链接转拼音（建议安装）</h3><p>如果你的文章名称是中文的，那么 Hexo 默认生成的永久链接也会有中文，这样不利于 <code>SEO</code>，且 <code>gitment</code> 评论对中文链接也不支持。我们可以用 <a href="https://github.com/viko16/hexo-permalink-pinyin">hexo-permalink-pinyin</a> Hexo 插件使在生成文章时生成中文拼音的永久链接。</p><p>安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> i hexo-permalink-pinyin --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">permalink_pinyin</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">separator</span><span class="token punctuation">:</span> <span class="token string">'-'</span> <span class="token comment"># default: '-'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p><strong>注</strong>：除了此插件外，<a href="https://github.com/rozbo/hexo-abbrlink">hexo-abbrlink</a> 插件也可以生成非中文的链接。</p></blockquote><h3 id="文章字数统计插件（建议安装）"><a href="#文章字数统计插件（建议安装）" class="headerlink" title="文章字数统计插件（建议安装）"></a>文章字数统计插件（建议安装）</h3><p>如果你想要在文章中显示文章字数、阅读时长信息，可以安装 <a href="https://github.com/willin/hexo-wordcount">hexo-wordcount</a>插件。</p><p>安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> i --save hexo-wordcount<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后只需在本主题下的 <code>_config.yml</code> 文件中，将各个文章字数相关的配置激活即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">postInfo</span><span class="token punctuation">:</span>  <span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">update</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">wordCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 设置文章字数统计为 true.</span>  <span class="token key atrule">totalCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 设置站点文章总字数统计为 true.</span>  <span class="token key atrule">min2read</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 阅读时长.</span>  <span class="token key atrule">readCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 阅读次数.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="添加emoji表情支持（可选的）"><a href="#添加emoji表情支持（可选的）" class="headerlink" title="添加emoji表情支持（可选的）"></a>添加emoji表情支持（可选的）</h3><p>本主题新增了对<code>emoji</code>表情的支持，使用到了 <a href="https://npm.taobao.org/package/hexo-filter-github-emojis">hexo-filter-github-emojis</a> 的 Hexo 插件来支持 <code>emoji</code>表情的生成，把对应的<code>markdown emoji</code>语法（<code>::</code>,例如：<code>:smile:</code>）转变成会跳跃的<code>emoji</code>表情，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-filter-github-emojis --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">githubEmojis</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">className</span><span class="token punctuation">:</span> github<span class="token punctuation">-</span>emoji  <span class="token key atrule">inject</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">styles</span><span class="token punctuation">:</span>  customEmojis<span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="添加-RSS-订阅支持（可选的）"><a href="#添加-RSS-订阅支持（可选的）" class="headerlink" title="添加 RSS 订阅支持（可选的）"></a>添加 RSS 订阅支持（可选的）</h3><p>本主题中还使用到了 <a href="https://github.com/hexojs/hexo-generator-feed">hexo-generator-feed</a> 的 Hexo 插件来做 <code>RSS</code>，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-feed --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">feed</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> atom  <span class="token key atrule">path</span><span class="token punctuation">:</span> atom.xml  <span class="token key atrule">limit</span><span class="token punctuation">:</span> <span class="token number">20</span>  <span class="token key atrule">hub</span><span class="token punctuation">:</span>  <span class="token key atrule">content</span><span class="token punctuation">:</span>  <span class="token key atrule">content_limit</span><span class="token punctuation">:</span> <span class="token number">140</span>  <span class="token key atrule">content_limit_delim</span><span class="token punctuation">:</span> <span class="token string">' '</span>  <span class="token key atrule">order_by</span><span class="token punctuation">:</span> <span class="token punctuation">-</span>date<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后在 <code>public</code> 文件夹中即可看到 <code>atom.xml</code> 文件，说明你已经安装成功了。</p><h3 id="添加-DaoVoice-在线聊天功能（可选的）"><a href="#添加-DaoVoice-在线聊天功能（可选的）" class="headerlink" title="添加 DaoVoice 在线聊天功能（可选的）"></a>添加 <a href="http://www.daovoice.io/">DaoVoice</a> 在线聊天功能（可选的）</h3><p>前往 <a href="http://www.daovoice.io/">DaoVoice</a> 官网注册并且获取 <code>app_id</code>，并将 <code>app_id</code> 填入主题的 <code>_config.yml</code> 文件中。</p><h3 id="添加-Tidio-在线聊天功能（可选的）"><a href="#添加-Tidio-在线聊天功能（可选的）" class="headerlink" title="添加 Tidio 在线聊天功能（可选的）"></a>添加 <a href="https://www.tidio.com/">Tidio</a> 在线聊天功能（可选的）</h3><p>前往 <a href="https://www.tidio.com/">Tidio</a> 官网注册并且获取 <code>Public Key</code>，并将 <code>Public Key</code> 填入主题的 <code>_config.yml</code> 文件中。</p><h3 id="修改页脚"><a href="#修改页脚" class="headerlink" title="修改页脚"></a>修改页脚</h3><p>页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 <code>/layout/_partial/footer.ejs</code> 文件中，包括站点、使用的主题、访问量等。</p><h3 id="修改社交链接"><a href="#修改社交链接" class="headerlink" title="修改社交链接"></a>修改社交链接</h3><p>在主题的 <code>_config.yml</code> 文件中，默认支持 <code>QQ</code>、<code>GitHub</code> 和邮箱等的配置，你可以在主题文件的 <code>/layout/_partial/social-link.ejs</code> 文件中，新增、修改你需要的社交链接地址，增加链接可参考如下代码：</p><pre class="line-numbers language-html" data-language="html"><code class="language-html">&lt;% if (theme.socialLink.github) { %&gt;    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>&lt;%= theme.socialLink.github %&gt;<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>tooltipped<span class="token punctuation">"</span></span> <span class="token attr-name">target</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>_blank<span class="token punctuation">"</span></span> <span class="token attr-name">data-tooltip</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>访问我的GitHub<span class="token punctuation">"</span></span> <span class="token attr-name">data-position</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>top<span class="token punctuation">"</span></span> <span class="token attr-name">data-delay</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>50<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>i</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fab fa-github<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>i</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span>&lt;% } %&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，社交图标（如：<code>fa-github</code>）你可以在 <a href="https://fontawesome.com/icons">Font Awesome</a> 中搜索找到。以下是常用社交图标的标识，供你参考：</p><ul><li>Facebook: <code>fab fa-facebook</code></li><li>Twitter: <code>fab fa-twitter</code></li><li>Google-plus: <code>fab fa-google-plus</code></li><li>Linkedin: <code>fab fa-linkedin</code></li><li>Tumblr: <code>fab fa-tumblr</code></li><li>Medium: <code>fab fa-medium</code></li><li>Slack: <code>fab fa-slack</code></li><li>Sina Weibo: <code>fab fa-weibo</code></li><li>Wechat: <code>fab fa-weixin</code></li><li>QQ: <code>fab fa-qq</code></li><li>Zhihu: <code>fab fa-zhihu</code></li></ul><blockquote><p><strong>注意</strong>: 本主题中使用的 <code>Font Awesome</code> 版本为 <code>5.11.0</code>。</p></blockquote><h3 id="修改打赏的二维码图片"><a href="#修改打赏的二维码图片" class="headerlink" title="修改打赏的二维码图片"></a>修改打赏的二维码图片</h3><p>在主题文件的 <code>source/medias/reward</code> 文件中，你可以替换成你的的微信和支付宝的打赏二维码图片。</p><h3 id="配置音乐播放器（可选的）"><a href="#配置音乐播放器（可选的）" class="headerlink" title="配置音乐播放器（可选的）"></a>配置音乐播放器（可选的）</h3><p>要支持音乐播放，在主题的 <code>_config.yml</code> 配置文件中激活music配置即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># 是否在首页显示音乐</span><span class="token key atrule">music</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">title</span><span class="token punctuation">:</span>         <span class="token comment"># 非吸底模式有效</span>    <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>    <span class="token key atrule">show</span><span class="token punctuation">:</span> 听听音乐  <span class="token key atrule">server</span><span class="token punctuation">:</span> netease   <span class="token comment"># require music platform: netease, tencent, kugou, xiami, baidu</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> playlist    <span class="token comment"># require song, playlist, album, search, artist</span>  <span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token number">503838841</span>     <span class="token comment"># require song id / playlist id / album id / search keyword</span>  <span class="token key atrule">fixed</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>      <span class="token comment"># 开启吸底模式</span>  <span class="token key atrule">autoplay</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>   <span class="token comment"># 是否自动播放</span>  <span class="token key atrule">theme</span><span class="token punctuation">:</span> <span class="token string">'#42b983'</span>  <span class="token key atrule">loop</span><span class="token punctuation">:</span> <span class="token string">'all'</span>       <span class="token comment"># 音频循环播放, 可选值: 'all', 'one', 'none'</span>  <span class="token key atrule">order</span><span class="token punctuation">:</span> <span class="token string">'random'</span>   <span class="token comment"># 音频循环顺序, 可选值: 'list', 'random'</span>  <span class="token key atrule">preload</span><span class="token punctuation">:</span> <span class="token string">'auto'</span>   <span class="token comment"># 预加载，可选值: 'none', 'metadata', 'auto'</span>  <span class="token key atrule">volume</span><span class="token punctuation">:</span> <span class="token number">0.7</span>       <span class="token comment"># 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</span>  <span class="token key atrule">listFolded</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token comment"># 列表默认折叠</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><code>server</code>可选<code>netease</code>（网易云音乐），<code>tencent</code>（QQ音乐），<code>kugou</code>（酷狗音乐），<code>xiami</code>（虾米音乐），</p><p><code>baidu</code>（百度音乐）。</p><p><code>type</code>可选<code>song</code>（歌曲），<code>playlist</code>（歌单），<code>album</code>（专辑），<code>search</code>（搜索关键字），<code>artist</code>（歌手）</p><p><code>id</code>获取方法示例: 浏览器打开网易云音乐，点击我喜欢的音乐歌单，浏览器地址栏后面会有一串数字，<code>playlist</code>的<code>id</code></p><p>即为这串数字。</p></blockquote><h2 id="文章-Front-matter-介绍"><a href="#文章-Front-matter-介绍" class="headerlink" title="文章 Front-matter 介绍"></a>文章 Front-matter 介绍</h2><h3 id="Front-matter-选项详解"><a href="#Front-matter-选项详解" class="headerlink" title="Front-matter 选项详解"></a>Front-matter 选项详解</h3><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但我仍然建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><div class="table-container"><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>cover</td><td><code>false</code></td><td><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>keywords</td><td>文章标题</td><td>文章关键字，SEO 时需要</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table></div><blockquote><p><strong>注意</strong>:</p><ol><li>如果 <code>img</code> 属性不填写的话，文章特色图会根据文章标题的 <code>hashcode</code> 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章的特色图<strong>各有特色</strong>。</li><li><code>date</code> 的值尽量保证每篇文章是唯一的，因为本主题中 <code>Gitalk</code> 和 <code>Gitment</code> 识别 <code>id</code> 是通过 <code>date</code> 的值来作为唯一标识的。</li><li>如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 <code>_config.yml</code> 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：<a href="http://tool.oschina.net/encrypt?type=2">开源中国在线工具</a>、<a href="http://encode.chahuo.com/">chahuo</a>、<a href="http://tool.chinaz.com/tools/hash.aspx">站长工具</a>。</li><li>您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则</li></ol></blockquote><p>以下为文章的 <code>Front-matter</code> 示例。</p><h3 id="最简示例"><a href="#最简示例" class="headerlink" title="最简示例"></a>最简示例</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="最全示例"><a href="#最全示例" class="headerlink" title="最全示例"></a>最全示例</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token key atrule">author</span><span class="token punctuation">:</span> 赵奇<span class="token key atrule">img</span><span class="token punctuation">:</span> /source/images/xxx.jpg<span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">coverImg</span><span class="token punctuation">:</span> /images/1.jpg<span class="token key atrule">password</span><span class="token punctuation">:</span> 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92<span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">summary</span><span class="token punctuation">:</span> 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要<span class="token key atrule">categories</span><span class="token punctuation">:</span> Markdown<span class="token key atrule">tags</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> Typora  <span class="token punctuation">-</span> Markdown<span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="效果截图"><a href="#效果截图" class="headerlink" title="效果截图"></a>效果截图</h2><p><img src="http://static.blinkfox.com/matery-20181202-1.png" alt="首页"></p><p><img src="http://static.blinkfox.com/matery-20181202-2.png" alt="首页推荐文章"></p><p><img src="http://static.blinkfox.com/matery-20181202-3.png" alt="首页文章列表"></p><p><img src="http://static.blinkfox.com/matery-20181202-7.png" alt="首页文章列表"></p><p><img src="http://static.blinkfox.com/matery-20181202-8.png" alt="首页文章列表"></p><h2 id="自定制修改"><a href="#自定制修改" class="headerlink" title="自定制修改"></a>自定制修改</h2><p>在本主题的 <code>_config.yml</code> 中可以修改部分自定义信息，有以下几个部分：</p><ul><li>菜单</li><li>我的梦想</li><li>首页的音乐播放器和视频播放器配置</li><li>是否显示推荐文章名称和按钮配置</li><li><code>favicon</code> 和 <code>Logo</code></li><li>个人信息</li><li>TOC 目录</li><li>文章打赏信息</li><li>复制文章内容时追加版权信息</li><li>MathJax</li><li>文章字数统计、阅读时长</li><li>点击页面的’爱心’效果</li><li>我的项目</li><li>我的技能</li><li>我的相册</li><li><code>Gitalk</code>、<code>Gitment</code>、<code>Valine</code> 和 <code>disqus</code> 评论配置</li><li><a href="http://busuanzi.ibruce.info/">不蒜子统计</a>和谷歌分析（<code>Google Analytics</code>）</li><li>默认特色图的集合。当文章没有设置特色图时，本主题会根据文章标题的 <code>hashcode</code> 值取余，来选择展示对应的特色图</li></ul><p><strong>我认为个人博客应该都有自己的风格和特色</strong>。如果本主题中的诸多功能和主题色彩你不满意，可以在主题中自定义修改，很多更自由的功能和细节点的修改难以在主题的 <code>_config.yml</code> 中完成，需要修改源代码才来完成。以下列出了可能对你有用的地方：</p><h3 id="修改主题颜色"><a href="#修改主题颜色" class="headerlink" title="修改主题颜色"></a>修改主题颜色</h3><p>在主题文件的 <code>/source/css/matery.css</code> 文件中，搜索 <code>.bg-color</code> 来修改背景颜色：</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token comment">/* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */</span><span class="token selector">.bg-color</span> <span class="token punctuation">{</span>    <span class="token property">background-image</span><span class="token punctuation">:</span> <span class="token function">linear-gradient</span><span class="token punctuation">(</span>to right<span class="token punctuation">,</span> #4cbf30 0%<span class="token punctuation">,</span> #0f9d58 100%<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@-webkit-keyframes</span> rainbow</span> <span class="token punctuation">{</span>   <span class="token comment">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@keyframes</span> rainbow</span> <span class="token punctuation">{</span>    <span class="token comment">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="修改-banner-图和文章特色图"><a href="#修改-banner-图和文章特色图" class="headerlink" title="修改 banner 图和文章特色图"></a>修改 banner 图和文章特色图</h3><p>你可以直接在 <code>/source/medias/banner</code> 文件夹中更换你喜欢的 <code>banner</code> 图片，主题代码中是每天动态切换一张，只需 <code>7</code> 张即可。如果你会 <code>JavaScript</code> 代码，可以修改成你自己喜欢切换逻辑，如：随机切换等，<code>banner</code> 切换的代码位置在 <code>/layout/_partial/bg-cover-content.ejs</code> 文件的 <code>&lt;script&gt;&lt;/script&gt;</code> 代码中：</p><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript"><span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'.bg-cover'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">css</span><span class="token punctuation">(</span><span class="token string">'background-image'</span><span class="token punctuation">,</span> <span class="token string">'url(/medias/banner/'</span> <span class="token operator">+</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getDay</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'.jpg)'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 <code>/source/medias/featureimages</code> 文件夹中默认有 24 张特色图片，你可以再增加或者减少，并需要在 <code>_config.yml</code> 做同步修改。</p><h2 id="版本变更记录"><a href="#版本变更记录" class="headerlink" title="版本变更记录"></a>版本变更记录</h2><p>参见 <a href="https://github.com/blinkfox/hexo-theme-matery/blob/master/README.md">CHANGELOG.md</a></p>]]></content>
      
      
      <categories>
          
          <category> 转载内容 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo+Github+matery的个人博客搭建（补充）</title>
      <link href="/2021/09/18/hexo-github-matery-de-ge-ren-bo-ke-da-jian-bu-chong/"/>
      <url>/2021/09/18/hexo-github-matery-de-ge-ren-bo-ke-da-jian-bu-chong/</url>
      
        <content type="html"><![CDATA[<p>最近想做一下自己的博客内容，记录一下平时的学习。参考了 <a href="https://zhuanlan.zhihu.com/p/111614119">Github + Hexo 搭建个人博客超详细教程</a> 进行博客搭建。但是出现了一些由于版本更新问题所以在这里记录一下，刚开始写博客，解决方法不一定正确。</p><h2 id="博客根目录下配置文件-config-yml的由于版本更新出现的问题"><a href="#博客根目录下配置文件-config-yml的由于版本更新出现的问题" class="headerlink" title="博客根目录下配置文件_config.yml的由于版本更新出现的问题"></a>博客根目录下配置文件_config.yml的由于版本更新出现的问题</h2><h3 id="配置文件-config-yml最后几行的原始内容"><a href="#配置文件-config-yml最后几行的原始内容" class="headerlink" title="配置文件_config.yml最后几行的原始内容"></a>配置文件_config.yml最后几行的原始内容</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># Deployment</span><span class="token comment">## Docs: https://hexo.io/docs/deployment.html</span><span class="token key atrule">deploy</span><span class="token punctuation">:</span>  type<span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Github-Hexo-搭建个人博客超详细教程-中对于配置文件-config-yml最后几行的修改"><a href="#Github-Hexo-搭建个人博客超详细教程-中对于配置文件-config-yml最后几行的修改" class="headerlink" title="Github + Hexo 搭建个人博客超详细教程 中对于配置文件_config.yml最后几行的修改"></a><a href="https://zhuanlan.zhihu.com/p/111614119">Github + Hexo 搭建个人博客超详细教程</a> 中对于配置文件_config.yml最后几行的修改</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># Deployment</span><span class="token comment">## Docs: https://hexo.io/docs/deployment.html</span><span class="token key atrule">deploy</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> git  <span class="token key atrule">repository</span><span class="token punctuation">:</span> git@github.com<span class="token punctuation">:</span>panakot/panakot.github.io.git（你的github.io地址）  <span class="token key atrule">branch</span><span class="token punctuation">:</span> master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="我对配置文件-config-yml最后几行的修改"><a href="#我对配置文件-config-yml最后几行的修改" class="headerlink" title="我对配置文件_config.yml最后几行的修改"></a>我对配置文件_config.yml最后几行的修改</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># Deployment</span><span class="token comment">## Docs: https://hexo.io/docs/one-command-deployment</span><span class="token key atrule">deploy</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> git  <span class="token key atrule">repository</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//github.com<span class="token punctuation">:</span>panakot/panakot.github.io.git（你的github.io地址）  <span class="token key atrule">branch</span><span class="token punctuation">:</span> main<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="博客主题matery的配置"><a href="#博客主题matery的配置" class="headerlink" title="博客主题matery的配置"></a>博客主题matery的配置</h2><p>最好直接参考原主题开发者的在个人博客中的使用说明，matery的作者闪烁之狐的相关说明网址可参考<a href="https://blinkfox.github.io/2018/09/28/qian-duan/hexo-bo-ke-zhu-ti-zhi-hexo-theme-matery-de-jie-shao/">Hexo博客主题之hexo-theme-matery的介绍</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习经验 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
